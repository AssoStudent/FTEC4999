{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization for Statistical Learning Part 2 - Experiment Notebook #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0 Environment Setup ##\n",
    "\n",
    "In this section, libraries, datasets and associative python programme are imported, as well as the setup of the experiment environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 0.1 Packages and Libraries ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Packages Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install jupyter\n",
    "#!pip install numpy\n",
    "#!pip install torch torchvision \n",
    "#!pip install matplotlib\n",
    "#!pip install pandas\n",
    "#!pip install tensorflow\n",
    "#!pip install torch\n",
    "#!pip install torchvision\n",
    "#!pip install torchvision\n",
    "#!pip install torch_xla\n",
    "#!pip install torch-neuron --extra-index-url=https://pip.repos.neuron.amazonaws.com/\n",
    "#!pip install pytorch torchvision cudatoolkit=9.0 -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics\n",
    "import random\n",
    "import string\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "from typing import List, Optional, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import random_split, Dataset, DataLoader, ConcatDataset, Subset\n",
    "from torch.optim.optimizer import (Optimizer, required, _use_grad_for_differentiable, _default_to_fused_or_foreach,\n",
    "                        _differentiable_doc, _foreach_doc, _maximize_doc)\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Python Programme**\n",
    "\n",
    "Here is the section for importing external python files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 0.1 Set up Experiment Environment ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilize GPU**\n",
    "\n",
    "For local environments, please utilize the GPU to speed up the training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader(DataLoader):\n",
    "        def __init__(self, dl, device):\n",
    "            self.dl = dl\n",
    "            self.device = device\n",
    "\n",
    "        def __iter__(self):\n",
    "            for batch in self.dl:\n",
    "                yield to_device(batch, self.device)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.dl)\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utililze TPU**\n",
    "\n",
    "To shorten the training time, we highly recommend that experiments should be done in Google Colab. Enable the following code in the Google Colab platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assume that you are on the Google Colab platform.\n",
    "#!pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl\n",
    "\n",
    "import os\n",
    "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
    "\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "\n",
    "device = xm.xla_device()\n",
    "\n",
    "def to_device(data, device):\n",
    "    data.to(device)\n",
    "\n",
    "class DeviceDataLoader(DataLoader):\n",
    "        def __init__(self, dl, device):\n",
    "            self.dl = dl\n",
    "            self.device = device\n",
    "\n",
    "        def __iter__(self):\n",
    "            for batch in self.dl:\n",
    "                yield to_device(batch, self.device)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 0.2 Datasets ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 0.2.0 Preprocessing Functions ####\n",
    "Here are the functions for preprocessing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global current_dataset_name\n",
    "global current_method_name\n",
    "\n",
    "def normalize_tensor(tensor):\n",
    "    mean = torch.mean(tensor)\n",
    "    std = torch.std(tensor)\n",
    "    normalized_tensor = (tensor - mean) / std\n",
    "    return normalized_tensor\n",
    "\n",
    "##############################\n",
    "# Text Dataset Preprocessing #\n",
    "##############################\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 0.2.1 Importing Datasets from Packages ####\n",
    "This will load the dataset automatically downloaded from the package. Remember the datasets will be stored in the folder \"Datasets\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MINST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Download Dataset\n",
    "MNIST_train_dataset = MNIST(root='./Datasets', train=True, download=True, transform=transforms.ToTensor())\n",
    "MNIST_test_dataset = MNIST(root='./Datasets', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Load Dataset\n",
    "train_dataset = MNIST_train_dataset\n",
    "test_dataset = MNIST_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"MNIST\"\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the raw data from the dataset\n",
    "print(\"=== Raw Data Samples from the MNIST Train Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = MNIST_train_dataset[i]\n",
    "    image = image.squeeze().numpy()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"=== Raw Data Samples from the MNIST Test Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = MNIST_test_dataset[i]\n",
    "    image = image.squeeze().numpy()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIFAR-10 Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# Download Dataset\n",
    "CIFAR10_train_dataset = CIFAR10(root='./Datasets', train=True, download=True, transform=transforms.ToTensor())\n",
    "CIFAR10_test_dataset = CIFAR10(root='./Datasets', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Load Dataset\n",
    "train_dataset = CIFAR10_train_dataset\n",
    "test_dataset = CIFAR10_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"CIFAR10\"\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the raw data from the CIFAR10 train dataset\n",
    "print(\"=== Raw Data Samples from the CIFAR10 Train Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = CIFAR10_train_dataset[i]\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the raw data from the CIFAR10 test dataset\n",
    "print(\"=== Raw Data Samples from the CIFAR10 Test Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = CIFAR10_test_dataset[i]\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 0.2.2 Importing Datasets from Downloaded Files ####\n",
    "This will load the dataset downloaded in the local directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Give Me Some Credit Dataset**\n",
    "\n",
    "The source of this dataset comes from https://www.kaggle.com/c/GiveMeSomeCredit\n",
    "\n",
    "Note: This dataset is borrowed from the datasets used in the competitive task in FTEC2101 Optimization Methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset Structure\n",
    "class Give_Me_Some_Credit_Dataset_Class(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data, self.targets = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        data_frame = pd.read_csv(self.root)\n",
    "        data = []\n",
    "        targets = []\n",
    "\n",
    "        for _, row in data_frame.iterrows():\n",
    "            features = row.iloc[:-1].values.astype(np.float32)\n",
    "            label = row.iloc[-1]\n",
    "            data.append(features)\n",
    "            targets.append(float(int(label)))\n",
    "        \n",
    "        data = torch.tensor(data)\n",
    "        targets = torch.tensor(targets)\n",
    "        return data, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.data[index]\n",
    "        label = self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            features = self.transform(features)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return features, label\n",
    "\n",
    "# Load Dataset\n",
    "Give_Me_Some_Credit_train_dataset = Give_Me_Some_Credit_Dataset_Class(root='./Datasets/Give_Me_Some_Credit/ftec-cs-full-train.csv', train=True, transform=normalize_tensor)\n",
    "Give_Me_Some_Credit_test_dataset = Give_Me_Some_Credit_Dataset_Class(root='./Datasets/Give_Me_Some_Credit/ftec-cs-full-test.csv', train=False, transform=normalize_tensor)\n",
    "\n",
    "train_dataset = Give_Me_Some_Credit_train_dataset\n",
    "test_dataset = Give_Me_Some_Credit_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"Give Me Some Credit Dataset\"\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Epsilon Dataset**\n",
    "\n",
    "Note: This dataset is best suited for binary classification. The training dataset contains 400000 objects. Each object is described by 2001 columns. The first column contains the label value, all other columns contain numerical features. The validation dataset contains 100000 objects. The structure is identical to the training dataset.\n",
    "\n",
    "Warning: The loading time for this dataset is too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset Structure\n",
    "class EpsilonDataset(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data, self.targets = self._load_data()\n",
    "    \n",
    "    def process_line(self, line):\n",
    "        line = line.split(' ')\n",
    "        label, values = int(line[0]), line[1:]\n",
    "        value = torch.zeros(line[1:].size())\n",
    "        for item in values:\n",
    "            idx, val = item.split(':')\n",
    "            value[int(idx) - 1] = float(val)\n",
    "        return label, value\n",
    "\n",
    "    def _load_data(self):\n",
    "        data_frame = pd.read_csv(self.root, nrows=20000)\n",
    "        data = []\n",
    "        targets = []\n",
    "\n",
    "        with open(self.root, 'r') as fp:\n",
    "            for line in fp:\n",
    "                label, value = self.process_line(line.strip(\"\\n\"))\n",
    "                data.append(value)\n",
    "                targets.append(label)\n",
    "\n",
    "        return data, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.data[index]\n",
    "        label = self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            features = self.transform(features)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return features, label\n",
    "\n",
    "# Load Dataset\n",
    "Epsilon_train_dataset = EpsilonDataset(root='./Datasets/epsilon/epsilon_normalized', train=True, transform=None)\n",
    "Epsilon_test_dataset = EpsilonDataset(root='./Datasets/epsilon/epsilon_normalized.t', train=False, transform=None)\n",
    "\n",
    "train_dataset = Epsilon_train_dataset\n",
    "test_dataset = Epsilon_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"Epsilon\"\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Languages Dataset**\n",
    "\n",
    "The dataset is downloaded from here: https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import glob\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "print(findFiles('Datasets/Language_dataset/names/*.txt'))\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "languages_dataset_category_lines = {}\n",
    "languages_dataset_all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('Datasets/Language_dataset/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    languages_dataset_all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    languages_dataset_category_lines[category] = lines\n",
    "\n",
    "n_categories = len(languages_dataset_all_categories)\n",
    "\n",
    "class LanguageDataset(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data, self.targets = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        data_frame = pd.read_csv(self.root, nrows=20000)\n",
    "        data = []\n",
    "        targets = []\n",
    "\n",
    "        with open(self.root, 'r') as fp:\n",
    "            for line in fp:\n",
    "                label, value = self.process_line(line.strip(\"\\n\"))\n",
    "                data.append(value)\n",
    "                targets.append(label)\n",
    "\n",
    "        return data, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.data[index]\n",
    "        label = self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            features = self.transform(features)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return features, label\n",
    "\n",
    "Languages_train_dataset = LanguageDataset(root='./Datasets/epsilon/epsilon_normalized', train=True, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 Classes, Functions and Algorithms ##\n",
    "All common and helping functions for machine learning tasks are defined here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#     Helping Functions    #\n",
    "############################\n",
    "# Random Seed Function\n",
    "# To ensure a same training result under the random process, you might need to set the random seed via this function.\n",
    "def set_random_seed(custom_random_seed):\n",
    "    torch.manual_seed(custom_random_seed)\n",
    "    random.seed(custom_random_seed)\n",
    "    np.random.seed(custom_random_seed)\n",
    "\n",
    "# Convert anything into a list if input is not a list\n",
    "def convert_to_list(input_list):\n",
    "    if not isinstance(input_list, list):\n",
    "        input_list = [input_list]\n",
    "    return input_list\n",
    "\n",
    "# Graph Plotting Functions\n",
    "def plot_cost_history(cost_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Cost\", title_name=\"Culminative Send Cost History\"):\n",
    "    cost_history_list = convert_to_list(cost_history_list)\n",
    "    for i, cost_history in enumerate(cost_history_list):\n",
    "        plt.plot(cost_history, label=f\"Cost History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if len(cost_history_list) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_culminative_send_cost_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_time_history(time_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Culminative Time Used\", title_name=\"Time History\"):\n",
    "    time_history_list = convert_to_list(time_history_list)\n",
    "    for i, time_history in enumerate(time_history_list):\n",
    "        plt.plot(time_history, label=f\"Time History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if len(time_history_list) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_time_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss_history(train_loss_history_list=[], test_loss_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Loss\", title_name=\"Loss History\"):\n",
    "    train_loss_history_list = convert_to_list(train_loss_history_list)\n",
    "    test_loss_history_list = convert_to_list(test_loss_history_list)\n",
    "    for i, train_loss_history in enumerate(train_loss_history_list):\n",
    "        plt.plot(train_loss_history, label=f\"Train Loss History {i+1}\")\n",
    "    for i, test_loss_history in enumerate(test_loss_history_list):\n",
    "        plt.plot(test_loss_history, label=f\"Test Loss History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if (len(train_loss_history_list) + len(test_loss_history_list)) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_loss_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy_history(train_accuracy_history_list=[], test_accuracy_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Accuracy\", title_name=\"Accuracy History\"):\n",
    "    train_accuracy_history_list = convert_to_list(train_accuracy_history_list)\n",
    "    test_accuracy_history_list = convert_to_list(test_accuracy_history_list)\n",
    "    for i, train_accuracy_history in enumerate(train_accuracy_history_list):\n",
    "        plt.plot(train_accuracy_history, label=f\"Train Accuracy History {i+1}\")\n",
    "    for i, test_accuracy_history in enumerate(test_accuracy_history_list):\n",
    "        plt.plot(test_accuracy_history, label=f\"Test Accuracy History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if (len(train_accuracy_history_list) + len(test_accuracy_history_list)) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_accuracy_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_error_history(train_error_history_list=[], test_error_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Error\", title_name=\"Error History\"):\n",
    "    train_error_history_list = convert_to_list(train_error_history_list)\n",
    "    test_error_history_list = convert_to_list(test_error_history_list)\n",
    "    for i, train_error_history in enumerate(train_error_history_list):\n",
    "        plt.plot(train_error_history, label=f\"Train Error History {i+1}\")\n",
    "    for i, test_error_history in enumerate(test_error_history_list):\n",
    "        plt.plot(test_error_history, label=f\"Test Error History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if (len(train_error_history_list) + len(test_error_history_list)) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_error_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "# Accuracy and Error Rate Calculation\n",
    "def get_accuracy(outputs, labels):\n",
    "    with torch.no_grad():\n",
    "        if outputs.dim() > 1:\n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "        else:\n",
    "            predictions = outputs\n",
    "        return torch.tensor(torch.sum(predictions == labels).item() / len(predictions))\n",
    "\n",
    "def get_error(outputs, labels):\n",
    "    with torch.no_grad():\n",
    "        if outputs.dim() > 1:\n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "        else:\n",
    "            predictions = outputs\n",
    "        return torch.tensor(torch.sum(predictions != labels).item() / len(predictions))\n",
    "\n",
    "def relative_rate_to_client_number(num_client, percentage = 1.00):\n",
    "    return round(num_client * percentage)\n",
    "\n",
    "############################\n",
    "#  Custom Loss Functions   #\n",
    "############################\n",
    "\n",
    "\n",
    "\n",
    "############################\n",
    "#     Custom Optimizer     #\n",
    "############################\n",
    "\n",
    "\n",
    "############################\n",
    "#   Neural Network Model   #\n",
    "############################\n",
    "global Linear_Model_in_features\n",
    "global Linear_Model_out_features\n",
    "class Linear_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(in_features=Linear_Model_in_features, out_features=Linear_Model_out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return torch.squeeze(x)\n",
    "\n",
    "class MNIST_CNN_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = torch.nn.Linear(32 * 7 * 7, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        if len(x.size()) == 1:  # Check if output has a single level of brackets\n",
    "            x = x.unsqueeze(0)  # Add a dimension at the beginning\n",
    "        return x\n",
    "\n",
    "class CIFAR10_CNN_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation_stack = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "\n",
    "            torch.nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "\n",
    "            torch.nn.Flatten(), \n",
    "            torch.nn.Linear(256*4*4, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation_stack(x)\n",
    "        return torch.squeeze(x)\n",
    "\n",
    "class RNN_model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation_stack = torch.nn.Sequential(\n",
    "            torch.nn.RNN()\n",
    "        )\n",
    "\n",
    "############################\n",
    "#    Iterate Algorithm     #\n",
    "############################\n",
    "def evaluate_model_simple(model, dataloader, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "    return loss_average, accuracy_average, error_average\n",
    "\n",
    "def iterate_model_simple(model, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True, test_dataloader=None, include_intial_history=False):\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    error_history = []\n",
    "    time_history = []\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    test_loss_history = []\n",
    "    test_accuracy_history = []\n",
    "    test_error_history = []\n",
    "\n",
    "    if include_intial_history is True:\n",
    "        loss, accuracy, error = evaluate_model_simple(model=model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        loss_history.append(loss)\n",
    "        accuracy_history.append(accuracy)\n",
    "        error_history.append(error)\n",
    "        if test_dataloader is not None:\n",
    "            test_loss, test_accuracy, test_error = evaluate_model_simple(model=model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "            test_loss_history.append(test_loss)\n",
    "            test_accuracy_history.append(test_accuracy)\n",
    "            test_error_history.append(test_error)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        errors = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = model(features)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        time_history.append(time_used)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "        loss_history.append(loss_average)\n",
    "        accuracy_history.append(accuracy_average)\n",
    "        error_history.append(error_average)\n",
    "        if test_dataloader is not None:\n",
    "            test_loss, test_accuracy, test_error = evaluate_model_simple(model=model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "            test_loss_history.append(test_loss)\n",
    "            test_accuracy_history.append(test_accuracy)\n",
    "            test_error_history.append(test_error)\n",
    "        if show_history:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {loss_average:.16f}, Average Accuracy: {accuracy_average:.16f}, Average Error: {error_average:.16f}, Culminative Time Used: {time_used}')\n",
    "            if test_dataloader is not None:\n",
    "                print(f'Test Loss: {test_loss:.16f}, Test Accuracy: {test_accuracy:.16f}, Test Error: {test_error:.16f}')\n",
    "    if test_dataloader is not None:\n",
    "        return loss_history, accuracy_history, error_history, time_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "    return loss_history, accuracy_history, error_history, time_history\n",
    "\n",
    "##################################################################\n",
    "#  Dataset Preprocessing Functions Before Splitting For Clients  #\n",
    "##################################################################\n",
    "# Acknowledge from https://github.com/adap/flower/blob/main/baselines/fedprox/fedprox/dataset_preparation.py\n",
    "# Balance: Trims the dataset so each class contains as many elements as the class that contained the least elements.\n",
    "def dataset_balance_classes(trainset, seed=42):\n",
    "    class_counts = np.bincount(trainset.targets)\n",
    "    smallest = np.min(class_counts)\n",
    "    idxs = trainset.targets.argsort()\n",
    "    tmp = [Subset(trainset, idxs[: int(smallest)])]\n",
    "    tmp_targets = [trainset.targets[idxs[: int(smallest)]]]\n",
    "    for count in np.cumsum(class_counts):\n",
    "        tmp.append(Subset(trainset, idxs[int(count) : int(count + smallest)]))\n",
    "        tmp_targets.append(trainset.targets[idxs[int(count) : int(count + smallest)]])\n",
    "    unshuffled = ConcatDataset(tmp)\n",
    "    unshuffled_targets = torch.cat(tmp_targets)\n",
    "    shuffled_idxs = torch.randperm(\n",
    "        len(unshuffled), generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "    shuffled = Subset(unshuffled, shuffled_idxs)\n",
    "    shuffled.targets = unshuffled_targets[shuffled_idxs]\n",
    "    return shuffled\n",
    "\n",
    "def dataset_sort_by_class(trainset: Dataset):\n",
    "    class_counts = np.bincount(trainset.targets)\n",
    "    idxs = trainset.targets.argsort()  # sort targets in ascending order\n",
    "\n",
    "    tmp = []  # create subset of smallest class\n",
    "    tmp_targets = []  # same for targets\n",
    "\n",
    "    start = 0\n",
    "    for count in np.cumsum(class_counts):\n",
    "        tmp.append(\n",
    "            Subset(trainset, idxs[start : int(count + start)])\n",
    "        )  # add rest of classes\n",
    "        tmp_targets.append(trainset.targets[idxs[start : int(count + start)]])\n",
    "        start += count\n",
    "    sorted_dataset = ConcatDataset(tmp)  # concat dataset\n",
    "    sorted_dataset.targets = torch.cat(tmp_targets)  # concat targets\n",
    "    return sorted_dataset\n",
    "\n",
    "# Implemention follow Li et al 2020: https://arxiv.org/abs/1812.06127 with default values set accordingly.\n",
    "global custom_power_law_num_labels_per_partition\n",
    "global custom_power_law_min_data_per_partition\n",
    "global custom_power_law_mean\n",
    "global custom_power_law_sigma\n",
    "custom_power_law_num_labels_per_partition = 2\n",
    "custom_power_law_min_data_per_partition = 10\n",
    "custom_power_law_mean = 0.0\n",
    "custom_power_law_sigma = 2.0\n",
    "def dataset_power_law_split(sorted_trainset, num_partitions):\n",
    "    # Custom Parameters\n",
    "    num_labels_per_partition = custom_power_law_num_labels_per_partition\n",
    "    min_data_per_partition = custom_power_law_min_data_per_partition\n",
    "    mean = custom_power_law_mean\n",
    "    sigma = custom_power_law_sigma\n",
    "\n",
    "    targets = sorted_trainset.targets\n",
    "    full_idx = list(range(len(targets)))\n",
    "\n",
    "    class_counts = np.bincount(sorted_trainset.targets)\n",
    "    labels_cs = np.cumsum(class_counts)\n",
    "    labels_cs = [0] + labels_cs[:-1].tolist()\n",
    "\n",
    "    partitions_idx: List[List[int]] = []\n",
    "    num_classes = len(np.bincount(targets))\n",
    "    hist = np.zeros(num_classes, dtype=np.int32)\n",
    "\n",
    "    # assign min_data_per_partition\n",
    "    min_data_per_class = int(min_data_per_partition / num_labels_per_partition)\n",
    "    for u_id in range(num_partitions):\n",
    "        partitions_idx.append([])\n",
    "        for cls_idx in range(num_labels_per_partition):\n",
    "            # label for the u_id-th client\n",
    "            cls = (u_id + cls_idx) % num_classes\n",
    "            # record minimum data\n",
    "            indices = list(\n",
    "                full_idx[\n",
    "                    labels_cs[cls]\n",
    "                    + hist[cls] : labels_cs[cls]\n",
    "                    + hist[cls]\n",
    "                    + min_data_per_class\n",
    "                ]\n",
    "            )\n",
    "            partitions_idx[-1].extend(indices)\n",
    "            hist[cls] += min_data_per_class\n",
    "\n",
    "    # add remaining images following power-law\n",
    "    probs = np.random.lognormal(\n",
    "        mean,\n",
    "        sigma,\n",
    "        (num_classes, int(num_partitions / num_classes), num_labels_per_partition),\n",
    "    )\n",
    "    remaining_per_class = class_counts - hist\n",
    "    # obtain how many samples each partition should be assigned for each of the\n",
    "    # labels it contains\n",
    "    # pylint: disable=too-many-function-args\n",
    "    probs = (\n",
    "        remaining_per_class.reshape(-1, 1, 1)\n",
    "        * probs\n",
    "        / np.sum(probs, (1, 2), keepdims=True)\n",
    "    )\n",
    "\n",
    "    for u_id in range(num_partitions):\n",
    "        for cls_idx in range(num_labels_per_partition):\n",
    "            cls = (u_id + cls_idx) % num_classes\n",
    "            count = int(probs[cls, u_id // num_classes, cls_idx])\n",
    "\n",
    "            # add count of specific class to partition\n",
    "            indices = full_idx[\n",
    "                labels_cs[cls] + hist[cls] : labels_cs[cls] + hist[cls] + count\n",
    "            ]\n",
    "            partitions_idx[u_id].extend(indices)\n",
    "            hist[cls] += count\n",
    "\n",
    "    # construct subsets\n",
    "    partitions = [Subset(sorted_trainset, p) for p in partitions_idx]\n",
    "    return partitions\n",
    "\n",
    "# Distribute the training datasets to clients, remember it returns an array of datasets\n",
    "def split_datasets_for_clients_random(dataset, num_clients=1):\n",
    "    total_sample_size = len(dataset)\n",
    "    samples_per_clients = total_sample_size // num_clients\n",
    "    client_datasets = random_split(dataset, [min(i + samples_per_clients, total_sample_size) - i for i in range(0, total_sample_size, samples_per_clients)])\n",
    "    return client_datasets\n",
    "\n",
    "global custom_split_dataset_iid\n",
    "global custom_split_dataset_power_law\n",
    "global custom_split_dataset_balance\n",
    "global custom_split_dataset_seed\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "def split_datasets_for_clients_custom(dataset, num_clients=1):\n",
    "    # Custom Parameters\n",
    "    iid=custom_split_dataset_iid\n",
    "    power_law=custom_split_dataset_power_law\n",
    "    balance=custom_split_dataset_balance\n",
    "    seed=custom_split_dataset_seed\n",
    "\n",
    "    trainset = dataset\n",
    "    if balance:\n",
    "        trainset = dataset_balance_classes(trainset, seed)\n",
    "\n",
    "    partition_size = int(len(trainset) / num_clients)\n",
    "    lengths = [partition_size] * num_clients\n",
    "\n",
    "    if iid is True:\n",
    "        client_datasets = random_split(trainset, lengths, torch.Generator().manual_seed(seed))\n",
    "    else:\n",
    "        if power_law is True:\n",
    "            trainset_sorted = dataset_sort_by_class(trainset)\n",
    "            client_datasets = dataset_power_law_split(\n",
    "                trainset_sorted,\n",
    "                num_partitions=num_clients,\n",
    "            )\n",
    "        else:\n",
    "            shard_size = int(partition_size / 2)\n",
    "            idxs = trainset.targets.argsort()\n",
    "            sorted_data = Subset(trainset, idxs)\n",
    "            tmp = []\n",
    "            for idx in range(num_clients * 2):\n",
    "                tmp.append(\n",
    "                    Subset(\n",
    "                        sorted_data, np.arange(shard_size * idx, shard_size * (idx + 1))\n",
    "                    )\n",
    "                )\n",
    "            idxs_list = torch.randperm(\n",
    "                num_clients * 2, generator=torch.Generator().manual_seed(seed)\n",
    "            )\n",
    "            client_datasets = [\n",
    "                ConcatDataset((tmp[idxs_list[2 * i]], tmp[idxs_list[2 * i + 1]]))\n",
    "                for i in range(num_clients)\n",
    "            ]\n",
    "\n",
    "    return client_datasets\n",
    "\n",
    "############################\n",
    "#      Client Devices      #\n",
    "############################\n",
    "# Define a custom class for each client so they can update separately\n",
    "class ClientDevice:\n",
    "    def __init__(self, client_id, model, optimizer, dataset, batch_size, iterate_func, loss_func, accuracy_func=get_accuracy, error_func=get_error, straggler_bool=False):\n",
    "        self.id = client_id\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.dataset = dataset\n",
    "        self.dataloader = DeviceDataLoader(torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True), device)\n",
    "        self.iterate_func = iterate_func\n",
    "        self.loss_func = loss_func\n",
    "        self.accuracy_func = accuracy_func\n",
    "        self.error_func = error_func\n",
    "\n",
    "        # Framework Specificed Variables\n",
    "        self.straggler = straggler_bool\n",
    "        self.client_controls = {}\n",
    "\n",
    "    def load_weights(self, weights):\n",
    "        self.model.load_state_dict(weights)\n",
    "\n",
    "    def get_local_weights(self):\n",
    "        return self.model.state_dict()\n",
    "\n",
    "    def get_client_id(self):\n",
    "        return self.id\n",
    "    \n",
    "    def get_dataset_size(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def save_local_history(self, num_epochs, loss_history, accuracy_history, error_history, time_history, value=train_start_time):\n",
    "        filename = \"{}_client_{}_with_local_epochs_{}_local_loss_accuracy_error_history_{}.npy\".format(current_dataset_name, self.id, num_epochs, value)\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.savez(f, loss_history=loss_history, accuracy_history=accuracy_history, error_history=error_history, time_history=time_history)\n",
    "\n",
    "    def train(self, num_epochs, show_history=False):\n",
    "        if show_history:\n",
    "            print(f\"!-- Client {self.id} start iterations. ---!\")\n",
    "        loss_history, accuracy_history, error_history, time_history = self.iterate_func(self.model, self.dataloader, num_epochs, self.optimizer, self.loss_func, self.accuracy_func, self.error_func)\n",
    "        if show_history:\n",
    "            plot_time_history(time_history)\n",
    "            plot_loss_history(loss_history)\n",
    "            plot_accuracy_history(accuracy_history)\n",
    "            plot_error_history(error_history)\n",
    "            print(f\"!-- Client {self.id} finish iterations. ---!\")\n",
    "        return self.model.state_dict()\n",
    "\n",
    "    # Framework Specificed Functions\n",
    "    def is_straggler(self):\n",
    "        return self.straggler\n",
    "\n",
    "    def get_local_client_controls(self):\n",
    "        return self.client_controls\n",
    "\n",
    "    def train_Scaffold(self, global_weights, server_controls, num_epochs, Scaffold_update_controls_use_gradient):\n",
    "        loss_history, accuracy_history, error_history, time_history, delta_weights, delta_client_controls = iterate_Scaffold_client(self, global_weights, server_controls, self.dataloader, num_epochs, self.optimizer, self.loss_func, self.accuracy_func, self.error_func, Scaffold_update_controls_use_gradient)\n",
    "        return delta_weights, delta_client_controls\n",
    "\n",
    "# Establish client devices\n",
    "def establish_client_devices(num_clients, model_list, optimizer_list, dataset_list, batch_size_list, iterate_func_list, loss_func_list, accuracy_func_list, error_func_list):\n",
    "    client_device = [None] * num_clients\n",
    "    for client_id in range(num_clients):\n",
    "        client_device[client_id] = ClientDevice(client_id, model_list[client_id], optimizer_list[client_id], dataset_list[client_id], batch_size_list[client_id], iterate_func_list[client_id], loss_func_list[client_id], accuracy_func_list[client_id], error_func_list[client_id])\n",
    "    return client_device\n",
    "\n",
    "#########################################\n",
    "#     Federated Learning Algorithms     #\n",
    "#########################################\n",
    "def federated_averaging(client_weights_total):\n",
    "    subset_clients = len(client_weights_total)\n",
    "    aggregate_weights = {}\n",
    "\n",
    "    # Initialize aggregate_weights with the first client's weights\n",
    "    for layer_name, layer_weights in client_weights_total[0].items():\n",
    "        aggregate_weights[layer_name] = layer_weights / subset_clients\n",
    "\n",
    "    # Aggregate weights from the remaining clients\n",
    "    for client_weights in client_weights_total[1:]:\n",
    "        for layer_name, layer_weights in client_weights.items():\n",
    "            aggregate_weights[layer_name] += layer_weights / subset_clients\n",
    "\n",
    "    return aggregate_weights\n",
    "\n",
    "def iterate_federated_learning_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, aggregate_func=federated_averaging, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True):\n",
    "    cost_history = []\n",
    "    time_history = []\n",
    "    start_time = timeit.default_timer()\n",
    "    send_cost = 0.00\n",
    "\n",
    "    train_loss_history = []\n",
    "    train_accuracy_history = []\n",
    "    train_error_history = []\n",
    "    test_loss_history = []\n",
    "    test_accuracy_history = []\n",
    "    test_error_history = []\n",
    "\n",
    "    # Initial Loss, Accuracy, Error\n",
    "    train_loss, train_accuracy, train_error = evaluate_model_simple(model=global_model, dataloader=train_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "    train_error_history.append(train_error)\n",
    "\n",
    "    if test_dataloader is not None:\n",
    "        test_loss, test_accuracy, test_error = evaluate_model_simple(model=global_model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        test_loss_history.append(test_loss)\n",
    "        test_accuracy_history.append(test_accuracy)\n",
    "        test_error_history.append(test_error)\n",
    "\n",
    "    for epoch in range(global_epochs):\n",
    "        global_weights = global_model.state_dict()\n",
    "        client_weights_total = []\n",
    "        random_client_list = random.sample(client_list, random_sample_client_number)\n",
    "        for client in random_client_list:\n",
    "            send_cost += sum(value.numel() for value in global_weights.values())\n",
    "            client.load_weights(global_weights)\n",
    "            if client.straggler is True:\n",
    "                client_weights = client.train(num_epochs=random.randint(1, local_epochs))\n",
    "            else:\n",
    "                client_weights = client.train(num_epochs=local_epochs)\n",
    "            client_weights_total.append(client_weights)\n",
    "            send_cost += sum(value.numel() for value in client_weights.values())\n",
    "        global_weights.update(aggregate_func(client_weights_total))\n",
    "        global_model.load_state_dict(global_weights)\n",
    "\n",
    "        # Record\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        cost_history.append(send_cost)\n",
    "        time_history.append(time_used)\n",
    "\n",
    "        train_loss, train_accuracy, train_error = evaluate_model_simple(model=global_model, dataloader=train_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "        train_error_history.append(train_error)\n",
    "\n",
    "        if test_dataloader is not None:\n",
    "            test_loss, test_accuracy, test_error = evaluate_model_simple(model=global_model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "            test_loss_history.append(test_loss)\n",
    "            test_accuracy_history.append(test_accuracy)\n",
    "            test_error_history.append(test_error)\n",
    "\n",
    "        if show_history:\n",
    "            print(f'Epoch [{epoch+1}/{global_epochs}], Culminative Send Cost: {send_cost}, Culminative Time Used: {time_used}')\n",
    "            print(f'Train Loss: {train_loss:.16f}, Train Accuracy: {train_accuracy:.16f}, Train Error: {train_error:.16f}')\n",
    "            if test_dataloader is not None:\n",
    "                print(f'Test Loss: {test_loss:.16f}, Test Accuracy: {test_accuracy:.16f}, Test Error: {test_error:.16f}')\n",
    "\n",
    "    return cost_history, time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "#################################\n",
    "#  FedProx Framework Algorithm  #\n",
    "#################################\n",
    "def iterate_model_FedProx(model, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True):\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    error_history = []\n",
    "    time_history = []\n",
    "    start_time = timeit.default_timer()\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        errors = []\n",
    "        for features, labels in dataloader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = model(features)\n",
    "            optimizer.zero_grad()\n",
    "            proximal_term = 0.0\n",
    "            for w, w_t in zip(model.parameters(), FedProx_global_model.parameters()):\n",
    "                proximal_term += torch.square((w - w_t).norm(2))\n",
    "            loss = loss_func(outputs, labels) + (FedProx_mu / 2) * proximal_term\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        time_history.append(time_used)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "        loss_history.append(loss_average)\n",
    "        accuracy_history.append(accuracy_average)\n",
    "        error_history.append(error_average)\n",
    "        if show_history:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {loss_average:.16f}, Average Accuracy: {accuracy_average:.16f}, Average Error: {error_average:.16f}, Culminative Time Used: {time_used}')\n",
    "    return loss_history, accuracy_history, error_history, time_history\n",
    "\n",
    "##################################\n",
    "#  SCAFFOLD Framework Algorithm  #\n",
    "##################################\n",
    "# Inspired by https://github.com/ki-ljl/Scaffold-Federated-Learning/blob/main/ScaffoldOptimizer.py\n",
    "# c: server_controls, ci: client_controls\n",
    "class ScaffoldOptimizer(Optimizer):\n",
    "    def __init__(self, params, lr=required, weight_decay=None):\n",
    "        if lr is not required and lr < 0.0:\n",
    "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
    "        if weight_decay is not None and weight_decay < 0.0:\n",
    "            raise ValueError(f\"Invalid weight_decay value: {weight_decay}\")\n",
    "        defaults = dict(lr=lr, weight_decay=weight_decay)\n",
    "        super(ScaffoldOptimizer, self).__init__(params, defaults)\n",
    "                \n",
    "    def step(self, server_controls, client_controls, return_grad=False):\n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group['weight_decay']\n",
    "            lr = group['lr']\n",
    "            for parameters, c, ci in zip(group['params'], server_controls.values(), client_controls.values()):\n",
    "                if parameters.grad is None:\n",
    "                    continue\n",
    "                parameters_derivative = parameters.grad.data - ci.data + c.data\n",
    "                parameters.data = parameters.data - lr * parameters_derivative\n",
    "                if weight_decay is not None:\n",
    "                    parameters.data = weight_decay * parameters.data - lr * parameters_derivative\n",
    "                else:\n",
    "                    parameters.data = parameters.data - lr * parameters_derivative\n",
    "        if return_grad is True:\n",
    "            return parameters.grad.data\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def get_step_size(self):\n",
    "        return self.param_groups[0]['lr']\n",
    "\n",
    "def iterate_Scaffold_client(client, global_model_data, server_controls, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, Scaffold_update_controls_use_gradient=True, show_history=True):\n",
    "    local_model = client.model\n",
    "    client_controls = client.client_controls\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    error_history = []\n",
    "    time_history = []\n",
    "    start_time = timeit.default_timer()\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        errors = []\n",
    "        for features, labels in dataloader:\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            outputs = local_model(features)\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            gradient = optimizer.step(server_controls, client_controls, Scaffold_update_controls_use_gradient)\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        time_history.append(time_used)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "        loss_history.append(loss_average)\n",
    "        accuracy_history.append(accuracy_average)\n",
    "        error_history.append(error_average)\n",
    "        if show_history:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {loss_average:.16f}, Average Accuracy: {accuracy_average:.16f}, Average Error: {error_average:.16f}, Culminative Time Used: {time_used}')\n",
    "    \n",
    "    client_controls_update = {}\n",
    "\n",
    "    # gradient not working yet\n",
    "    if Scaffold_update_controls_use_gradient is True:\n",
    "        client_controls_update = gradient\n",
    "    else:\n",
    "        for k, v in local_model.named_parameters():\n",
    "            client_controls_update[k] = client_controls[k] - server_controls[k] + (global_model_data[k] - v.data) / (num_epochs * optimizer.get_step_size())\n",
    "    \n",
    "    delta_weights = {}\n",
    "    delta_client_controls = {}\n",
    "    for k, v in local_model.named_parameters():\n",
    "        delta_weights = global_model_data[k] - v.data\n",
    "        delta_client_controls = server_controls[k] - client_controls[k]\n",
    "\n",
    "    client.client_controls = client_controls_update\n",
    "\n",
    "    return loss_history, accuracy_history, error_history, time_history, delta_weights, delta_client_controls\n",
    "\n",
    "def iterate_Scaffold_global(train_dataloader, test_dataloader, global_model, client_list, random_sample_client_number, global_epochs, global_step_size, local_epochs, Scaffold_update_controls_use_gradient=False, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True):\n",
    "    cost_history = []\n",
    "    time_history = []\n",
    "    start_time = timeit.default_timer()\n",
    "    send_cost = 0.00\n",
    "\n",
    "    train_loss_history = []\n",
    "    train_accuracy_history = []\n",
    "    train_error_history = []\n",
    "    test_loss_history = []\n",
    "    test_accuracy_history = []\n",
    "    test_error_history = []\n",
    "\n",
    "    # Initial Loss, Accuracy, Error\n",
    "    train_loss, train_accuracy, train_error = evaluate_model_simple(model=global_model, dataloader=train_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "    train_error_history.append(train_error)\n",
    "\n",
    "    if test_dataloader is not None:\n",
    "        test_loss, test_accuracy, test_error = evaluate_model_simple(model=global_model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        test_loss_history.append(test_loss)\n",
    "        test_accuracy_history.append(test_accuracy)\n",
    "        test_error_history.append(test_error)\n",
    "\n",
    "    # Initialize server and client controls\n",
    "    num_clients = len(client_list)\n",
    "    server_controls = {}\n",
    "    for k, v in global_model.named_parameters():\n",
    "        server_controls[k] = torch.zeros_like(v.data)\n",
    "    for client in client_list:\n",
    "        for k, v in client.model.named_parameters():\n",
    "            client.client_controls[k] = torch.zeros_like(v.data)\n",
    "\n",
    "    for epoch in range(global_epochs):\n",
    "        global_weights = global_model.state_dict()\n",
    "        global_model_data = {}\n",
    "        for k, v in global_model.named_parameters():\n",
    "            global_model_data[k] = v.data.clone()\n",
    "        delta_weights_total = []\n",
    "        delta_client_controls_total = []\n",
    "        random_client_list = random.sample(client_list, random_sample_client_number)\n",
    "        for client in random_client_list:\n",
    "            client.load_weights(global_weights)\n",
    "            send_cost += sum(value.numel() for value in global_weights.values())\n",
    "            send_cost += sum(value.numel() for value in server_controls.values())\n",
    "            if client.straggler is True:\n",
    "                delta_weights, delta_client_controls = client.train_Scaffold(global_model_data, server_controls, random.randint(1, local_epochs), Scaffold_update_controls_use_gradient)\n",
    "            else:\n",
    "                delta_weights, delta_client_controls = client.train_Scaffold(global_model_data, server_controls, local_epochs, Scaffold_update_controls_use_gradient)\n",
    "            delta_weights_total.append(delta_weights)\n",
    "            delta_client_controls_total.append(delta_client_controls)\n",
    "            send_cost += delta_weights.numel()\n",
    "            send_cost += delta_client_controls.numel()\n",
    "        \n",
    "        # Aggregation\n",
    "        aggregated_weights = {}\n",
    "        aggregated_client_controls = {}\n",
    "        for k, v in global_model.named_parameters():\n",
    "            aggregated_weights[k] = torch.zeros_like(v.data)\n",
    "            aggregated_client_controls[k] = torch.zeros_like(v.data)\n",
    "\n",
    "        for client in random_client_list:\n",
    "            for delta_weights, delta_client_controls in zip(delta_weights_total, delta_client_controls_total):\n",
    "                for (k, v), delta_weight, delta_client_controls in zip(client.model.named_parameters(), delta_weights, delta_client_controls):\n",
    "                    aggregated_weights[k] += delta_weight / random_sample_client_number\n",
    "                    aggregated_client_controls[k] += delta_client_controls / random_sample_client_number\n",
    "\n",
    "        for k, v in global_model.named_parameters():\n",
    "            v.data += global_step_size * aggregated_weights[k]\n",
    "            server_controls[k] += (random_sample_client_number / num_clients) * aggregated_client_controls[k]\n",
    "\n",
    "        # Record\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        cost_history.append(send_cost)\n",
    "        time_history.append(time_used)\n",
    "\n",
    "        train_loss, train_accuracy, train_error = evaluate_model_simple(model=global_model, dataloader=train_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "        train_error_history.append(train_error)\n",
    "\n",
    "        if test_dataloader is not None:\n",
    "            test_loss, test_accuracy, test_error = evaluate_model_simple(model=global_model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "            test_loss_history.append(test_loss)\n",
    "            test_accuracy_history.append(test_accuracy)\n",
    "            test_error_history.append(test_error)\n",
    "\n",
    "        if show_history:\n",
    "            print(f'Epoch [{epoch+1}/{global_epochs}], Culminative Send Cost: {send_cost}, Culminative Time Used: {time_used}')\n",
    "            print(f'Train Loss: {train_loss:.16f}, Train Accuracy: {train_accuracy:.16f}, Train Error: {train_error:.16f}')\n",
    "            if test_dataloader is not None:\n",
    "                print(f'Test Loss: {test_loss:.16f}, Test Accuracy: {test_accuracy:.16f}, Test Error: {test_error:.16f}')\n",
    "\n",
    "    return cost_history, time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "############################\n",
    "#    Training Algorithm    #\n",
    "############################\n",
    "def train_neural_network_model(model, train_dataloader, test_dataloader, num_epochs, optimizer, learning_rate, batch_size, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True, save_result=True):\n",
    "    if test_dataloader is not None:\n",
    "        train_loss_history, train_accuracy_history, train_error_history, time_history, test_loss_history, test_accuracy_history, test_error_history = iterate_model_simple(model, train_dataloader, num_epochs, optimizer, loss_func, accuracy_func, error_func, show_history, test_dataloader, True)\n",
    "    else:\n",
    "        train_loss_history, train_accuracy_history, train_error_history, time_history = iterate_model_simple(model, train_dataloader, num_epochs, optimizer, loss_func, accuracy_func, error_func, show_history, True)\n",
    "\n",
    "    # Print learned parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f'{name}: {param.data}')\n",
    "    \n",
    "    # Save Results\n",
    "    if save_result:\n",
    "        filename = \"{}_train_NN_with_num_epochs_{}_batch_size_{}_lr_{}_{}_{}.npy\".format(current_dataset_name, num_epochs, batch_size, learning_rate, train_start_time, experiment_id)\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.savez(f, time_history=time_history, train_loss_history=train_loss_history, train_accuracy_history=train_accuracy_history, train_error_history=train_error_history, test_loss_history=test_loss_history, test_accuracy_history=test_accuracy_history, test_error_history=test_error_history)\n",
    "        torch.save(model.state_dict(), filename + \"_model_state_dict.pth\")\n",
    "\n",
    "    # Graph\n",
    "    if show_history:\n",
    "        plot_time_history([time_history])\n",
    "        plot_loss_history([train_loss_history], [test_loss_history])\n",
    "        plot_accuracy_history([train_accuracy_history], [test_accuracy_history])\n",
    "        plot_error_history([train_error_history], [test_error_history])\n",
    "    \n",
    "    return time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "def train_federated_learning_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, batch_size, aggregate_func=federated_averaging, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True, save_result=True):\n",
    "    cost_history, time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = iterate_federated_learning_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, aggregate_func, loss_func, accuracy_func, error_func, show_history)\n",
    "\n",
    "    # Print learned parameters\n",
    "    for name, param in global_model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f'{name}: {param.data}')\n",
    "    \n",
    "    # Save Results\n",
    "    if save_result:\n",
    "        filename = \"{}_{}_with_global_epochs_{}_local_epochs_{}_num_clients_{}_batch_size_{}_{}_{}.npy\".format(current_dataset_name, current_method_name, global_epochs, local_epochs, len(client_list), batch_size, train_start_time, experiment_id)\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.savez(f, cost_history=cost_history, time_history=time_history, train_loss_history=train_loss_history, train_accuracy_history=train_accuracy_history, train_error_history=train_error_history, test_loss_history=test_loss_history, test_accuracy_history=test_accuracy_history, test_error_history=test_error_history)\n",
    "        torch.save(global_model.state_dict(), filename + \"_model_state_dict.pth\")\n",
    "\n",
    "    # Graph\n",
    "    if show_history:\n",
    "        plot_cost_history([cost_history])\n",
    "        plot_time_history([time_history])\n",
    "        plot_loss_history([train_loss_history], [test_loss_history])\n",
    "        plot_accuracy_history([train_accuracy_history], [test_accuracy_history])\n",
    "        plot_error_history([train_error_history], [test_error_history])\n",
    "    \n",
    "    return cost_history, time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "def train_Scaffold_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, batch_size, global_step_size, Scaffold_update_controls_use_gradient, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True, save_result=True):\n",
    "    cost_history, time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = iterate_Scaffold_global(train_dataloader, test_dataloader, global_model, client_list, random_sample_client_number, global_epochs, global_step_size, local_epochs, Scaffold_update_controls_use_gradient, loss_func, accuracy_func, error_func, show_history)\n",
    "\n",
    "    # Print learned parameters\n",
    "    for name, param in global_model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f'{name}: {param.data}')\n",
    "    \n",
    "    # Save Results\n",
    "    if save_result:\n",
    "        filename = \"{}_{}_with_global_epochs_{}_local_epochs_{}_num_clients_{}_batch_size_{}_{}_{}.npy\".format(current_dataset_name, current_method_name, global_epochs, local_epochs, len(client_list), batch_size, train_start_time, experiment_id)\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.savez(f, cost_history=cost_history, time_history=time_history, train_loss_history=train_loss_history, train_accuracy_history=train_accuracy_history, train_error_history=train_error_history, test_loss_history=test_loss_history, test_accuracy_history=test_accuracy_history, test_error_history=test_error_history)\n",
    "        torch.save(global_model.state_dict(), filename + \"_model_state_dict.pth\")\n",
    "\n",
    "    # Graph\n",
    "    if show_history:\n",
    "        plot_cost_history([cost_history])\n",
    "        plot_time_history([time_history])\n",
    "        plot_loss_history([train_loss_history], [test_loss_history])\n",
    "        plot_accuracy_history([train_accuracy_history], [test_accuracy_history])\n",
    "        plot_error_history([train_error_history], [test_error_history])\n",
    "    \n",
    "    return cost_history, time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "############################\n",
    "#   Experiment Functions   #\n",
    "############################\n",
    "def experiment_neural_network_model(train_dataset, test_dataset, modelClass, optimizerClass, train_func, epochs_list, learning_rate_list, batch_size_list, loss_func_list, accuracy_func_list, error_func_list, compare_id = 0, show_history=True, save_result=True):\n",
    "    global experiment_id\n",
    "    experiment_id = 0\n",
    "\n",
    "    epochs_list = convert_to_list(epochs_list)\n",
    "    learning_rate_list = convert_to_list(learning_rate_list)\n",
    "    batch_size_list = convert_to_list(batch_size_list)\n",
    "    loss_func_list = convert_to_list(loss_func_list)\n",
    "    accuracy_func_list = convert_to_list(accuracy_func_list)\n",
    "    error_func_list = convert_to_list(error_func_list)\n",
    "\n",
    "    local_epochs_list_size = len(epochs_list)\n",
    "    learning_rate_list_size = len(learning_rate_list)\n",
    "    batch_size_list_size = len(batch_size_list)\n",
    "    loss_func_list_size = len(loss_func_list)\n",
    "    accuracy_func_list_size = len(accuracy_func_list)\n",
    "    error_func_list_size = len(error_func_list)\n",
    "\n",
    "    time_history_total = []\n",
    "    train_loss_history_total = []\n",
    "    train_accuracy_history_total = []\n",
    "    train_error_history_total = []\n",
    "    test_loss_history_total = []\n",
    "    test_accuracy_history_total = []\n",
    "    test_error_history_total = []\n",
    "\n",
    "    if compare_id == 2:\n",
    "        iteration_list = learning_rate_list\n",
    "    elif compare_id == 3:\n",
    "        iteration_list = batch_size_list\n",
    "    elif compare_id == 4:\n",
    "        iteration_list = loss_func_list\n",
    "    elif compare_id == 5:\n",
    "        iteration_list = accuracy_func_list\n",
    "    elif compare_id == 6:\n",
    "        iteration_list = error_func_list\n",
    "    else:\n",
    "        iteration_list = epochs_list\n",
    "    \n",
    "    for n in range(len(iteration_list)):\n",
    "        experiment_id = experiment_id + 1\n",
    "        if compare_id == 2:\n",
    "            print(f'=== The training for learning_rate_list is {learning_rate_list[n]} ===')\n",
    "            num_epochs = epochs_list[0]\n",
    "            learning_rate = learning_rate_list[n]\n",
    "            batch_size = batch_size_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "        elif compare_id == 3:\n",
    "            print(f'=== The training for batch_size_list is {batch_size_list[n]} ===')\n",
    "            num_epochs = epochs_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[n]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "        elif compare_id == 4:\n",
    "            print(f'=== The training for loss function is {loss_func_list[n].__name__} ===')\n",
    "            num_epochs = epochs_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            loss_func = loss_func_list[n]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "        elif compare_id == 5:\n",
    "            print(f'=== The training for accuracy function is {accuracy_func_list[n].__name__} ===')\n",
    "            num_epochs = epochs_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[n]\n",
    "            error_func = error_func_list[0]\n",
    "        elif compare_id == 6:\n",
    "            print(f'=== The training for error function is {error_func_list[n].__name__} ===')\n",
    "            num_epochs = epochs_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[n]\n",
    "        else:\n",
    "            print(f'=== The training for num_epochs is {epochs_list[n]} ===')\n",
    "            num_epochs = epochs_list[n]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[n]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "        \n",
    "        model = to_device(modelClass(), device)\n",
    "        print(model)\n",
    "        print(model.state_dict())\n",
    "\n",
    "        train_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True), device)\n",
    "        test_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False), device)\n",
    "\n",
    "        optimizer = optimizerClass(model.parameters(), learning_rate)\n",
    "\n",
    "        time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = train_func(model, train_dataloader, test_dataloader, num_epochs, optimizer, learning_rate, batch_size, loss_func, accuracy_func, error_func, show_history, save_result)\n",
    "\n",
    "        time_history_total.append(time_history)\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        train_accuracy_history_total.append(train_accuracy_history)\n",
    "        train_error_history_total.append(train_error_history)\n",
    "        test_loss_history_total.append(test_loss_history)\n",
    "        test_accuracy_history_total.append(test_accuracy_history)\n",
    "        test_error_history_total.append(test_error_history)\n",
    "    \n",
    "    print(f'=== The Experiment Result ===')\n",
    "    print(f'Name of current dataset: {current_dataset_name}')\n",
    "    plot_time_history(time_history_total)\n",
    "    plot_loss_history(train_loss_history_total, test_loss_history_total)\n",
    "    plot_accuracy_history(train_accuracy_history_total, test_accuracy_history_total)\n",
    "    plot_error_history(train_error_history_total, test_error_history_total)\n",
    "\n",
    "def experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelClass, optimizerClass, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, compare_id = 0, show_history=True, save_result=True):\n",
    "    global experiment_id\n",
    "    experiment_id = 0\n",
    "\n",
    "    global_epochs_list = convert_to_list(global_epochs_list)\n",
    "    local_epochs_list = convert_to_list(local_epochs_list)\n",
    "    num_clients_list = convert_to_list(num_clients_list)\n",
    "    random_sample_client_number_list = convert_to_list(random_sample_client_number_list)\n",
    "    learning_rate_list = convert_to_list(learning_rate_list)\n",
    "    batch_size_list = convert_to_list(batch_size_list)\n",
    "    aggregate_func_list = convert_to_list(aggregate_func_list)\n",
    "    loss_func_list = convert_to_list(loss_func_list)\n",
    "    accuracy_func_list = convert_to_list(accuracy_func_list)\n",
    "    error_func_list = convert_to_list(error_func_list)\n",
    "\n",
    "    global_epochs_list_size = len(global_epochs_list)\n",
    "    local_epochs_list_size = len(local_epochs_list)\n",
    "    num_clients_list_size = len(num_clients_list)\n",
    "    random_sample_client_number_list_size = len(random_sample_client_number_list)\n",
    "    learning_rate_list_size = len(learning_rate_list)\n",
    "    batch_size_list_size = len(batch_size_list)\n",
    "    aggregate_func_list_size = len(aggregate_func_list)\n",
    "    loss_func_list_size = len(loss_func_list)\n",
    "    accuracy_func_list_size = len(accuracy_func_list)\n",
    "    error_func_list_size = len(error_func_list)\n",
    "\n",
    "    cost_history_total = []\n",
    "    time_history_total = []\n",
    "    train_loss_history_total = []\n",
    "    train_accuracy_history_total = []\n",
    "    train_error_history_total = []\n",
    "    test_loss_history_total = []\n",
    "    test_accuracy_history_total = []\n",
    "    test_error_history_total = []\n",
    "\n",
    "    if compare_id == 2:\n",
    "        iteration_list = local_epochs_list\n",
    "    elif compare_id == 3:\n",
    "        iteration_list = num_clients_list\n",
    "    elif compare_id == 4:\n",
    "        iteration_list = random_sample_client_number_list\n",
    "    elif compare_id == 5:\n",
    "        iteration_list = learning_rate_list\n",
    "    elif compare_id == 6:\n",
    "        iteration_list = batch_size_list\n",
    "    elif compare_id == 7:\n",
    "        iteration_list = aggregate_func_list\n",
    "    elif compare_id == 8:\n",
    "        iteration_list = loss_func_list\n",
    "    elif compare_id == 9:\n",
    "        iteration_list = accuracy_func_list\n",
    "    elif compare_id == 10:\n",
    "        iteration_list = error_func_list\n",
    "    else:\n",
    "        iteration_list = global_epochs_list\n",
    "    \n",
    "    for n in range(len(iteration_list)):\n",
    "        experiment_id = experiment_id + 1\n",
    "        if compare_id == 2:\n",
    "            print(f'=== The training for local_epochs is {local_epochs_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[n]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "        elif compare_id == 3:\n",
    "            print(f'=== The training for num_clients is {num_clients_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[n]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "        elif compare_id == 4:\n",
    "            print(f'=== The training for random_sample_client_number is {random_sample_client_number_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[n]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "        elif compare_id == 5:\n",
    "            print(f'=== The training for learning_rate_list is {learning_rate_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[n]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "        elif compare_id == 6:\n",
    "            print(f'=== The training for batch_size_list is {batch_size_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[n]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "        elif compare_id == 7:\n",
    "            print(f'=== The training for aggregate function is {aggregate_func_list[n].__name__} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[n]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "        elif compare_id == 8:\n",
    "            print(f'=== The training for loss function is {loss_func_list[n].__name__} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[n]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "        elif compare_id == 9:\n",
    "            print(f'=== The training for accuracy function is {accuracy_func_list[n].__name__} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[n]\n",
    "            error_func = error_func_list[0]\n",
    "        elif compare_id == 10:\n",
    "            print(f'=== The training for error function is {error_func_list[n].__name__} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[n]\n",
    "        else:\n",
    "            print(f'=== The training for global_epochs is {global_epochs_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[n]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "        \n",
    "        global_model = to_device(modelClass(), device)\n",
    "        print(global_model)\n",
    "        print(global_model.state_dict())\n",
    "\n",
    "        train_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True), device)\n",
    "        test_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False), device)\n",
    "\n",
    "        print(\"Establishing client devices...\")\n",
    "\n",
    "        client_model_list = [to_device(modelClass(), device)] * num_clients\n",
    "        client_optimizer_list = [optimizerClass(model.parameters(), learning_rate) for model in client_model_list]\n",
    "        client_dataset_list = dataset_distributing_func(train_dataset, num_clients)\n",
    "        print(f'Training dataset has been distributed into {len(client_dataset_list)} pieces.')\n",
    "        client_batch_size_list = [batch_size] * num_clients\n",
    "        client_itera_func_list = [itera_func] * num_clients\n",
    "        client_loss_func_list = [loss_func] * num_clients\n",
    "        client_accuracy_func_list = [accuracy_func] * num_clients\n",
    "        client_error_func_list = [error_func] * num_clients\n",
    "        client_list = establish_client_devices(num_clients, client_model_list, client_optimizer_list, client_dataset_list, client_batch_size_list, client_itera_func_list, client_loss_func_list, client_accuracy_func_list, client_error_func_list)\n",
    "\n",
    "        # Visualize the client dataset. Please comment these codes to avoid a long code output if necessary.\n",
    "        #for i in range(len(client_list)):\n",
    "        #    print(client_dataset_list[i])\n",
    "\n",
    "        print(f'Established {len(client_list)} client devices.')\n",
    "\n",
    "        cost_history, time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = train_federated_learning_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, batch_size, aggregate_func, loss_func, accuracy_func, error_func, show_history, save_result)\n",
    "\n",
    "        cost_history_total.append(cost_history)\n",
    "        time_history_total.append(time_history)\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        train_accuracy_history_total.append(train_accuracy_history)\n",
    "        train_error_history_total.append(train_error_history)\n",
    "        test_loss_history_total.append(test_loss_history)\n",
    "        test_accuracy_history_total.append(test_accuracy_history)\n",
    "        test_error_history_total.append(test_error_history)\n",
    "    \n",
    "    print(f'=== The Experiment Result ===')\n",
    "    print(f'Name of current dataset: {current_dataset_name}')\n",
    "    plot_cost_history(cost_history_total)\n",
    "    plot_time_history(time_history_total)\n",
    "    plot_loss_history(train_loss_history_total, test_loss_history_total)\n",
    "    plot_accuracy_history(train_accuracy_history_total, test_accuracy_history_total)\n",
    "    plot_error_history(train_error_history_total, test_error_history_total)\n",
    "\n",
    "def experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelClass, optimizerClass, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, compare_id = 0, show_history=True, save_result=True):\n",
    "    global experiment_id\n",
    "    experiment_id = 0\n",
    "\n",
    "    global_epochs_list = convert_to_list(global_epochs_list)\n",
    "    local_epochs_list = convert_to_list(local_epochs_list)\n",
    "    num_clients_list = convert_to_list(num_clients_list)\n",
    "    random_sample_client_number_list = convert_to_list(random_sample_client_number_list)\n",
    "    learning_rate_list = convert_to_list(learning_rate_list)\n",
    "    batch_size_list = convert_to_list(batch_size_list)\n",
    "    aggregate_func_list = convert_to_list(aggregate_func_list)\n",
    "    loss_func_list = convert_to_list(loss_func_list)\n",
    "    accuracy_func_list = convert_to_list(accuracy_func_list)\n",
    "    error_func_list = convert_to_list(error_func_list)\n",
    "    straggler_list = convert_to_list(straggler_list)\n",
    "    mu_list = convert_to_list(mu_list)\n",
    "\n",
    "    global_epochs_list_size = len(global_epochs_list)\n",
    "    local_epochs_list_size = len(local_epochs_list)\n",
    "    num_clients_list_size = len(num_clients_list)\n",
    "    random_sample_client_number_list_size = len(random_sample_client_number_list)\n",
    "    learning_rate_list_size = len(learning_rate_list)\n",
    "    batch_size_list_size = len(batch_size_list)\n",
    "    aggregate_func_list_size = len(aggregate_func_list)\n",
    "    loss_func_list_size = len(loss_func_list)\n",
    "    accuracy_func_list_size = len(accuracy_func_list)\n",
    "    error_func_list_size = len(error_func_list)\n",
    "    straggler_list_size = len(straggler_list)\n",
    "    mu_list_size = len(mu_list)\n",
    "\n",
    "    global FedProx_global_model\n",
    "    global FedProx_mu\n",
    "\n",
    "    cost_history_total = []\n",
    "    time_history_total = []\n",
    "    train_loss_history_total = []\n",
    "    train_accuracy_history_total = []\n",
    "    train_error_history_total = []\n",
    "    test_loss_history_total = []\n",
    "    test_accuracy_history_total = []\n",
    "    test_error_history_total = []\n",
    "\n",
    "    if compare_id == 2:\n",
    "        iteration_list = local_epochs_list\n",
    "    elif compare_id == 3:\n",
    "        iteration_list = num_clients_list\n",
    "    elif compare_id == 4:\n",
    "        iteration_list = random_sample_client_number_list\n",
    "    elif compare_id == 5:\n",
    "        iteration_list = learning_rate_list\n",
    "    elif compare_id == 6:\n",
    "        iteration_list = batch_size_list\n",
    "    elif compare_id == 7:\n",
    "        iteration_list = aggregate_func_list\n",
    "    elif compare_id == 8:\n",
    "        iteration_list = loss_func_list\n",
    "    elif compare_id == 9:\n",
    "        iteration_list = accuracy_func_list\n",
    "    elif compare_id == 10:\n",
    "        iteration_list = error_func_list\n",
    "    elif compare_id == 11:\n",
    "        iteration_list = straggler_list\n",
    "    elif compare_id == 12:\n",
    "        iteration_list = mu_list\n",
    "    else:\n",
    "        iteration_list = global_epochs_list\n",
    "    \n",
    "    for n in range(len(iteration_list)):\n",
    "        experiment_id = experiment_id + 1\n",
    "        if compare_id == 2:\n",
    "            print(f'=== The training for local_epochs is {local_epochs_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[n]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "            FedProx_mu = mu_list[0]\n",
    "        elif compare_id == 3:\n",
    "            print(f'=== The training for num_clients is {num_clients_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[n]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "            FedProx_mu = mu_list[0]\n",
    "        elif compare_id == 4:\n",
    "            print(f'=== The training for random_sample_client_number is {random_sample_client_number_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[n]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "            FedProx_mu = mu_list[0]\n",
    "        elif compare_id == 5:\n",
    "            print(f'=== The training for learning_rate_list is {learning_rate_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[n]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "            FedProx_mu = mu_list[0]\n",
    "        elif compare_id == 6:\n",
    "            print(f'=== The training for batch_size_list is {batch_size_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[n]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "            FedProx_mu = mu_list[0]\n",
    "        elif compare_id == 7:\n",
    "            print(f'=== The training for aggregate function is {aggregate_func_list[n].__name__} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[n]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "            FedProx_mu = mu_list[0]\n",
    "        elif compare_id == 8:\n",
    "            print(f'=== The training for loss function is {loss_func_list[n].__name__} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[n]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "            FedProx_mu = mu_list[0]\n",
    "        elif compare_id == 9:\n",
    "            print(f'=== The training for accuracy function is {accuracy_func_list[n].__name__} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[n]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "            FedProx_mu = mu_list[0]\n",
    "        elif compare_id == 10:\n",
    "            print(f'=== The training for error function is {error_func_list[n].__name__} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[n]\n",
    "            straggler = straggler_list[0]\n",
    "            FedProx_mu = mu_list[0]\n",
    "        elif compare_id == 11:\n",
    "            print(f'=== The training for straggler_list is {straggler_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[n]\n",
    "            FedProx_mu = mu_list[0]\n",
    "        elif compare_id == 12:\n",
    "            print(f'=== The training for mu is {mu_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "            FedProx_mu = mu_list[n]\n",
    "        else:\n",
    "            print(f'=== The training for global_epochs is {global_epochs_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[n]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            aggregate_func = aggregate_func_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "            FedProx_mu = mu_list[0]\n",
    "        \n",
    "        global_model = to_device(modelClass(), device)\n",
    "        print(global_model)\n",
    "        print(global_model.state_dict())\n",
    "        FedProx_global_model = global_model\n",
    "\n",
    "        train_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True), device)\n",
    "        test_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False), device)\n",
    "\n",
    "        print(\"Establishing client devices...\")\n",
    "\n",
    "        client_model_list = [to_device(modelClass(), device)] * num_clients\n",
    "        client_optimizer_list = [optimizerClass(model.parameters(), learning_rate) for model in client_model_list]\n",
    "        client_dataset_list = dataset_distributing_func(train_dataset, num_clients)\n",
    "        print(f'Training dataset has been distributed into {len(client_dataset_list)} pieces.')\n",
    "        client_batch_size_list = [batch_size] * num_clients\n",
    "        client_itera_func_list = [itera_func] * num_clients\n",
    "        client_loss_func_list = [loss_func] * num_clients\n",
    "        client_accuracy_func_list = [accuracy_func] * num_clients\n",
    "        client_error_func_list = [error_func] * num_clients\n",
    "        client_list = establish_client_devices(num_clients, client_model_list, client_optimizer_list, client_dataset_list, client_batch_size_list, client_itera_func_list, client_loss_func_list, client_accuracy_func_list, client_error_func_list)\n",
    "\n",
    "        for i in range(straggler):\n",
    "            client_list[i].straggler = True\n",
    "\n",
    "        # Visualize the client dataset. Please comment these codes to avoid a long code output if necessary.\n",
    "        #for i in range(len(client_list)):\n",
    "        #    print(client_dataset_list[i])\n",
    "\n",
    "        print(f'Established {len(client_list)} client devices.')\n",
    "\n",
    "        cost_history, time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = train_federated_learning_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, batch_size, aggregate_func, loss_func, accuracy_func, error_func, show_history, save_result)\n",
    "\n",
    "        cost_history_total.append(cost_history)\n",
    "        time_history_total.append(time_history)\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        train_accuracy_history_total.append(train_accuracy_history)\n",
    "        train_error_history_total.append(train_error_history)\n",
    "        test_loss_history_total.append(test_loss_history)\n",
    "        test_accuracy_history_total.append(test_accuracy_history)\n",
    "        test_error_history_total.append(test_error_history)\n",
    "    \n",
    "    print(f'=== The Experiment Result ===')\n",
    "    print(f'Name of current dataset: {current_dataset_name}')\n",
    "    plot_cost_history(cost_history_total)\n",
    "    plot_time_history(time_history_total)\n",
    "    plot_loss_history(train_loss_history_total, test_loss_history_total)\n",
    "    plot_accuracy_history(train_accuracy_history_total, test_accuracy_history_total)\n",
    "    plot_error_history(train_error_history_total, test_error_history_total)\n",
    "\n",
    "def experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelClass, optimizerClass, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, Scaffold_update_controls_use_gradient, compare_id = 0, show_history=True, save_result=True):\n",
    "    global experiment_id\n",
    "    experiment_id = 0\n",
    "\n",
    "    global_epochs_list = convert_to_list(global_epochs_list)\n",
    "    local_epochs_list = convert_to_list(local_epochs_list)\n",
    "    num_clients_list = convert_to_list(num_clients_list)\n",
    "    random_sample_client_number_list = convert_to_list(random_sample_client_number_list)\n",
    "    learning_rate_list = convert_to_list(learning_rate_list)\n",
    "    global_step_size_list = convert_to_list(global_step_size_list)\n",
    "    batch_size_list = convert_to_list(batch_size_list)\n",
    "    loss_func_list = convert_to_list(loss_func_list)\n",
    "    accuracy_func_list = convert_to_list(accuracy_func_list)\n",
    "    error_func_list = convert_to_list(error_func_list)\n",
    "    straggler_list = convert_to_list(straggler_list)\n",
    "\n",
    "    global_epochs_list_size = len(global_epochs_list)\n",
    "    local_epochs_list_size = len(local_epochs_list)\n",
    "    num_clients_list_size = len(num_clients_list)\n",
    "    random_sample_client_number_list_size = len(random_sample_client_number_list)\n",
    "    learning_rate_list_size = len(learning_rate_list)\n",
    "    global_step_size_list_size = len(global_step_size_list)\n",
    "    batch_size_list_size = len(batch_size_list)\n",
    "    loss_func_list_size = len(loss_func_list)\n",
    "    accuracy_func_list_size = len(accuracy_func_list)\n",
    "    error_func_list_size = len(error_func_list)\n",
    "    straggler_list_size = len(straggler_list)\n",
    "\n",
    "    cost_history_total = []\n",
    "    time_history_total = []\n",
    "    train_loss_history_total = []\n",
    "    train_accuracy_history_total = []\n",
    "    train_error_history_total = []\n",
    "    test_loss_history_total = []\n",
    "    test_accuracy_history_total = []\n",
    "    test_error_history_total = []\n",
    "\n",
    "    if compare_id == 2:\n",
    "        iteration_list = local_epochs_list\n",
    "    elif compare_id == 3:\n",
    "        iteration_list = num_clients_list\n",
    "    elif compare_id == 4:\n",
    "        iteration_list = random_sample_client_number_list\n",
    "    elif compare_id == 5:\n",
    "        iteration_list = learning_rate_list\n",
    "    elif compare_id == 6:\n",
    "        iteration_list = global_step_size_list\n",
    "    elif compare_id == 7:\n",
    "        iteration_list = batch_size_list\n",
    "    elif compare_id == 8:\n",
    "        iteration_list = loss_func_list\n",
    "    elif compare_id == 9:\n",
    "        iteration_list = accuracy_func_list\n",
    "    elif compare_id == 10:\n",
    "        iteration_list = error_func_list\n",
    "    elif compare_id == 11:\n",
    "        iteration_list = straggler_list\n",
    "    else:\n",
    "        iteration_list = global_epochs_list\n",
    "    \n",
    "    for n in range(len(iteration_list)):\n",
    "        experiment_id = experiment_id + 1\n",
    "        if compare_id == 2:\n",
    "            print(f'=== The training for local_epochs is {local_epochs_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[n]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            global_step_size = global_step_size_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "        elif compare_id == 3:\n",
    "            print(f'=== The training for num_clients is {num_clients_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[n]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            global_step_size = global_step_size_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "        elif compare_id == 4:\n",
    "            print(f'=== The training for random_sample_client_number is {random_sample_client_number_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[n]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            global_step_size = global_step_size_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "        elif compare_id == 5:\n",
    "            print(f'=== The training for learning_rate_list is {learning_rate_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[n]\n",
    "            global_step_size = global_step_size_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "        elif compare_id == 6:\n",
    "            print(f'=== The training for global_step_size_list is {global_step_size_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            global_step_size = global_step_size_list[n]\n",
    "            batch_size = batch_size_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "        elif compare_id == 7:\n",
    "            print(f'=== The training for batch_size_list is {batch_size_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            global_step_size = global_step_size_list[0]\n",
    "            batch_size = batch_size_list[n]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "        elif compare_id == 8:\n",
    "            print(f'=== The training for loss function is {loss_func_list[n].__name__} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            global_step_size = global_step_size_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            loss_func = loss_func_list[n]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "        elif compare_id == 9:\n",
    "            print(f'=== The training for accuracy function is {accuracy_func_list[n].__name__} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            global_step_size = global_step_size_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[n]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "        elif compare_id == 10:\n",
    "            print(f'=== The training for error function is {error_func_list[n].__name__} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            global_step_size = global_step_size_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[n]\n",
    "            straggler = straggler_list[0]\n",
    "        elif compare_id == 11:\n",
    "            print(f'=== The training for straggler_list is {straggler_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            global_step_size = global_step_size_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[n]\n",
    "        else:\n",
    "            print(f'=== The training for global_epochs is {global_epochs_list[n]} ===')\n",
    "            global_epochs = global_epochs_list[0]\n",
    "            local_epochs = local_epochs_list[0]\n",
    "            num_clients = num_clients_list[0]\n",
    "            random_sample_client_number = random_sample_client_number_list[0]\n",
    "            learning_rate = learning_rate_list[0]\n",
    "            global_step_size = global_step_size_list[0]\n",
    "            batch_size = batch_size_list[0]\n",
    "            loss_func = loss_func_list[0]\n",
    "            accuracy_func = accuracy_func_list[0]\n",
    "            error_func = error_func_list[0]\n",
    "            straggler = straggler_list[0]\n",
    "\n",
    "        global_model = to_device(modelClass(), device)\n",
    "        print(global_model)\n",
    "        print(global_model.state_dict())\n",
    "\n",
    "        train_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True), device)\n",
    "        test_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False), device)\n",
    "\n",
    "        print(\"Establishing client devices...\")\n",
    "\n",
    "        client_model_list = [to_device(modelClass(), device)] * num_clients\n",
    "        client_optimizer_list = [optimizerClass(model.parameters(), learning_rate) for model in client_model_list]\n",
    "        client_dataset_list = dataset_distributing_func(train_dataset, num_clients)\n",
    "        print(f'Training dataset has been distributed into {len(client_dataset_list)} pieces.')\n",
    "        client_batch_size_list = [batch_size] * num_clients\n",
    "        client_itera_func_list = [itera_func] * num_clients\n",
    "        client_loss_func_list = [loss_func] * num_clients\n",
    "        client_accuracy_func_list = [accuracy_func] * num_clients\n",
    "        client_error_func_list = [error_func] * num_clients\n",
    "        client_list = establish_client_devices(num_clients, client_model_list, client_optimizer_list, client_dataset_list, client_batch_size_list, client_itera_func_list, client_loss_func_list, client_accuracy_func_list, client_error_func_list)\n",
    "\n",
    "        for i in range(straggler):\n",
    "            client_list[i].straggler = True\n",
    "\n",
    "        # Visualize the client dataset. Please comment these codes to avoid a long code output if necessary.\n",
    "        #for i in range(len(client_list)):\n",
    "        #    print(client_dataset_list[i])\n",
    "\n",
    "        print(f'Established {len(client_list)} client devices.')\n",
    "\n",
    "        cost_history, time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = train_Scaffold_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, batch_size, global_step_size, Scaffold_update_controls_use_gradient, loss_func, accuracy_func, error_func, show_history, save_result)\n",
    "\n",
    "        cost_history_total.append(cost_history)\n",
    "        time_history_total.append(time_history)\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        train_accuracy_history_total.append(train_accuracy_history)\n",
    "        train_error_history_total.append(train_error_history)\n",
    "        test_loss_history_total.append(test_loss_history)\n",
    "        test_accuracy_history_total.append(test_accuracy_history)\n",
    "        test_error_history_total.append(test_error_history)\n",
    "    \n",
    "    print(f'=== The Experiment Result ===')\n",
    "    print(f'Name of current dataset: {current_dataset_name}')\n",
    "    plot_cost_history(cost_history_total)\n",
    "    plot_time_history(time_history_total)\n",
    "    plot_loss_history(train_loss_history_total, test_loss_history_total)\n",
    "    plot_accuracy_history(train_accuracy_history_total, test_accuracy_history_total)\n",
    "    plot_error_history(train_error_history_total, test_error_history_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 Experiment ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.1 Choosing Dataset ###\n",
    "\n",
    "In this section, execute a cell only to choose a dataset you want do experiment with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNIST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train_dataset = MNIST_train_dataset\n",
    "test_dataset = MNIST_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"MNIST\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')\n",
    "\n",
    "# Validation Dataset\n",
    "#split_ratio = 0.01\n",
    "#train_dataset, validation_dataset = random_split(train_dataset, [int(len(train_dataset) * split_ratio), int(len(train_dataset) - int(len(train_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the train dataset after random split: {len(train_dataset)}')\n",
    "#split_ratio = 0.01\n",
    "#test_dataset, _ = random_split(test_dataset, [int(len(test_dataset) * split_ratio), int(len(test_dataset) - int(len(test_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the test dataset after random split: {len(test_dataset)}')\n",
    "\n",
    "# Define variables associate with the dataset\n",
    "learning_rate_preset = 0.5\n",
    "batch_size_preset = 100\n",
    "num_features_preset = 1\n",
    "num_classes_preset = 10\n",
    "input_dim = 784\n",
    "model_type_preset = MNIST_CNN_Model\n",
    "optimizer_type_preset = torch.optim.SGD\n",
    "loss_func_preset = torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIFAR10 Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train_dataset = CIFAR10_train_dataset\n",
    "test_dataset = CIFAR10_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"CIFAR10\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')\n",
    "\n",
    "# Validation Dataset\n",
    "split_ratio = 0.50\n",
    "train_dataset, validation_dataset = random_split(train_dataset, [int(len(train_dataset) * split_ratio), int(len(train_dataset) - int(len(train_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the train dataset after random split: {len(train_dataset)}')\n",
    "split_ratio = 0.007\n",
    "test_dataset, _ = random_split(test_dataset, [int(len(test_dataset) * split_ratio), int(len(test_dataset) - int(len(test_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the test dataset after random split: {len(test_dataset)}')\n",
    "\n",
    "# Define variables associate with the dataset\n",
    "learning_rate_preset = 0.5\n",
    "batch_size_preset = 100\n",
    "num_features_preset = 1\n",
    "num_classes_preset = 10\n",
    "input_dim = 1024\n",
    "model_type_preset = CIFAR10_CNN_Model\n",
    "optimizer_type_preset = torch.optim.SGD\n",
    "loss_func_preset = torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Give Me Some Credit Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train_dataset = Give_Me_Some_Credit_train_dataset\n",
    "test_dataset = Give_Me_Some_Credit_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"Give Me Some Credit Dataset\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')\n",
    "\n",
    "# Validation Dataset\n",
    "#split_ratio = 0.01\n",
    "#train_dataset, validation_dataset = random_split(train_dataset, [int(len(train_dataset) * split_ratio), int(len(train_dataset) - int(len(train_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the train dataset after random split: {len(train_dataset)}')\n",
    "#split_ratio = 0.01\n",
    "#test_dataset, _ = random_split(test_dataset, [int(len(test_dataset) * split_ratio), int(len(test_dataset) - int(len(test_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the test dataset after random split: {len(test_dataset)}')\n",
    "\n",
    "# Define variables associate with the dataset\n",
    "learning_rate_preset = 0.5\n",
    "batch_size_preset = 100\n",
    "num_features_preset = 7\n",
    "num_classes_preset = 2\n",
    "\n",
    "Linear_Model_in_features = 7\n",
    "Linear_Model_out_features = 1\n",
    "model_type_preset = Linear_Model\n",
    "optimizer_type_preset = torch.optim.SGD\n",
    "loss_func_preset = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Epsilon Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train_dataset = Epsilon_train_dataset\n",
    "test_dataset = Epsilon_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"Epsilon\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')\n",
    "\n",
    "# Validation Dataset\n",
    "split_ratio = 0.50\n",
    "train_dataset, validation_dataset = random_split(train_dataset, [int(len(train_dataset) * split_ratio), int(len(train_dataset) - int(len(train_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the train dataset after random split: {len(train_dataset)}')\n",
    "split_ratio = 0.007\n",
    "test_dataset, _ = random_split(test_dataset, [int(len(test_dataset) * split_ratio), int(len(test_dataset) - int(len(test_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the test dataset after random split: {len(test_dataset)}')\n",
    "\n",
    "# Define variables associate with the dataset\n",
    "learning_rate_preset = 0.5\n",
    "batch_size_preset = 100\n",
    "num_features_preset = 7\n",
    "num_classes_preset = 2\n",
    "\n",
    "model_type_preset = Linear_Model\n",
    "optimizer_type_preset = torch.optim.SGD\n",
    "loss_func_preset = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.2 Neural Network Experiments ###\n",
    "\n",
    "Note that, compare_id represents:\n",
    "\n",
    "1: compare number of epochs\n",
    "\n",
    "2: compare learning rate\n",
    "\n",
    "3: compare batch size\n",
    "\n",
    "4: compare loss function\n",
    "\n",
    "5: compare accuracy function\n",
    "\n",
    "6: compare error function\n",
    "\n",
    "Others: compare number of epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Learning Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "train_func = train_neural_network_model\n",
    "\n",
    "#Linear_Model_in_features = 28\n",
    "#Linear_Model_out_features = 10\n",
    "\n",
    "num_epochs_list = 100\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "\n",
    "compare_id = 1\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "experiment_neural_network_model(train_dataset, test_dataset, modelType, optimizerType, train_func, num_epochs_list, learning_rate_list, batch_size_list, loss_func_list, accuracy_func_list, error_func_list, compare_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Batch Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "train_func = train_neural_network_model\n",
    "\n",
    "num_epochs_list = 25\n",
    "learning_rate_list = 0.02\n",
    "batch_size_list = [10, 1000]\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "\n",
    "compare_id = 3\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "experiment_neural_network_model(train_dataset, test_dataset, modelType, optimizerType, train_func, num_epochs_list, learning_rate_list, batch_size_list, loss_func_list, accuracy_func_list, error_func_list, compare_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.3 FedAvg Federated Learning Experiments ###\n",
    "\n",
    "Note that, compare_id represents:\n",
    "\n",
    "1: compare global epochs\n",
    "\n",
    "2: compare local epochs\n",
    "\n",
    "3: compare number of clients\n",
    "\n",
    "4: compare random sample client number\n",
    "\n",
    "5: compare learning rate\n",
    "\n",
    "6: compare batch size\n",
    "\n",
    "7: compare the aggregate weight algorithms\n",
    "\n",
    "8: compare loss function\n",
    "\n",
    "9: compare accuracy function\n",
    "\n",
    "10: compare error function\n",
    "\n",
    "Others: compare global epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Local Update Epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_random\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = [10]\n",
    "num_clients_list = [10]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "\n",
    "compare_id = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, compare_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Number of Clients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_random\n",
    "\n",
    "global_epochs_list = 5\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "\n",
    "compare_id = 3\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, compare_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Random Client Number**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_random\n",
    "\n",
    "global_epochs_list = 5\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "\n",
    "compare_id = 4\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, compare_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Learning Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_random\n",
    "\n",
    "global_epochs_list = 5\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "\n",
    "compare_id = 5\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, compare_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Batch Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = torch.optim.Adam\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 20\n",
    "num_clients_list = [1000]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 10\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "\n",
    "compare_id = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, compare_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.4 FedProx Federated Learning Experiments ###\n",
    "\n",
    "Note that, compare_id represents:\n",
    "\n",
    "1: compare global epochs\n",
    "\n",
    "2: compare local epochs\n",
    "\n",
    "3: compare number of clients\n",
    "\n",
    "4: compare random sample client number\n",
    "\n",
    "5: compare learning rate\n",
    "\n",
    "6: compare batch size\n",
    "\n",
    "7: compare the aggregate weight algorithms\n",
    "\n",
    "8: compare loss function\n",
    "\n",
    "9: compare accuracy function\n",
    "\n",
    "10: compare error function\n",
    "\n",
    "11: compare straggler\n",
    "\n",
    "12: compare mu value\n",
    "\n",
    "Others: compare global epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Local Update Epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 20\n",
    "num_clients_list = [1000]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 10\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0]\n",
    "mu_list = [0.00, 1.00]\n",
    "\n",
    "compare_id = 12\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, compare_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Number of Clients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = torch.optim.Adam\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 20\n",
    "num_clients_list = [1000]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 10\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0]\n",
    "mu_list = [1.00]\n",
    "\n",
    "compare_id = 12\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, compare_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = True\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 50\n",
    "local_epochs_list = 20\n",
    "num_clients_list = [1000]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 10\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0]\n",
    "mu_list = [0.00, 1.00]\n",
    "\n",
    "compare_id = 12\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, compare_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Learning Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 20\n",
    "num_clients_list = [1000]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 10\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [relative_rate_to_client_number(num_clients_list[0], 0.5)]\n",
    "mu_list = [0.00, 1.00]\n",
    "\n",
    "compare_id = 12\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, compare_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Batch Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_random\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 20\n",
    "num_clients_list = [1000]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 10\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0]\n",
    "mu_list = [0.00, 1.00]\n",
    "\n",
    "compare_id = 12\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, compare_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Straggler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 20\n",
    "num_clients_list = [1000]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 10\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0]\n",
    "mu_list = [0.00, 1.00]\n",
    "\n",
    "compare_id = 12\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, compare_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Mu Value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_random\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 20\n",
    "num_clients_list = [1000]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 10\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = []\n",
    "mu_list = [1.00]\n",
    "\n",
    "random_local_epoch = False\n",
    "compare_id = 11\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, learning_rate_list, batch_size_list, straggler_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, mu_list, random_local_epoch, compare_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.5 Scaffold Federated Learning Experiments ###\n",
    "\n",
    "Note that, compare_id represents:\n",
    "\n",
    "1: compare global epochs\n",
    "\n",
    "2: compare local epochs\n",
    "\n",
    "3: compare number of clients\n",
    "\n",
    "4: compare random sample client number\n",
    "\n",
    "5: compare learning rate\n",
    "\n",
    "6: compare batch size\n",
    "\n",
    "7: compare the aggregate weight algorithms\n",
    "\n",
    "8: compare loss function\n",
    "\n",
    "9: compare accuracy function\n",
    "\n",
    "10: compare error function\n",
    "\n",
    "11: compare straggler\n",
    "\n",
    "12: compare mu value\n",
    "\n",
    "Others: compare global epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Local Epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 5\n",
    "local_epochs_list = 1\n",
    "num_clients_list = [2]\n",
    "random_sample_client_number_list = [2]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 0.03\n",
    "batch_size_list = 10\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0]\n",
    "Scaffold_update_controls_use_gradient = False\n",
    "# Scaffold use gradient has bug\n",
    "\n",
    "compare_id = 1\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, Scaffold_update_controls_use_gradient, compare_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 Analysis ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3.0 Loading Data ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clear and Initialize Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cost_history_total = []\n",
    "data_time_history_total = []\n",
    "data_train_loss_history_total = []\n",
    "data_train_accuracy_history_total = []\n",
    "data_train_error_history_total = []\n",
    "data_test_loss_history_total = []\n",
    "data_test_accuracy_history_total = []\n",
    "data_test_error_history_total = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data Manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these variables manually here!!\n",
    "load_dataset_name = \"MNIST\"\n",
    "load_aggreagte_func = \"FedAvg\"\n",
    "load_global_epochs = 100\n",
    "load_local_epochs = 20\n",
    "load_num_clients = 1000\n",
    "load_batch_size = 128\n",
    "load_train_start_time = \"2024-02-04 13.59.58\"\n",
    "load_experiment_id = 0\n",
    "data_append_load = True\n",
    "\n",
    "# Load the file\n",
    "if load_experiment_id == 0:\n",
    "    filename_load = \"{}_{}_with_global_epochs_{}_local_epochs_{}_num_clients_{}_batch_size_{}_{}.npy\".format(load_dataset_name, load_aggreagte_func, load_global_epochs, load_local_epochs, load_num_clients, load_batch_size, load_train_start_time)\n",
    "else:\n",
    "    filename_load = \"{}_{}_with_global_epochs_{}_local_epochs_{}_num_clients_{}_batch_size_{}_{}_{}.npy\".format(load_dataset_name, load_aggreagte_func, load_global_epochs, load_local_epochs, load_num_clients, load_batch_size, load_train_start_time, load_experiment_id)\n",
    "load_result = np.load(filename_load)\n",
    "print('Result has been loaded from the file: ', filename_load)\n",
    "\n",
    "# Load the attributes from the file\n",
    "data_cost_history = load_result['cost_history']\n",
    "data_time_history = load_result['time_history']\n",
    "data_train_loss_history = load_result['train_loss_history']\n",
    "data_train_accuracy_history = load_result['train_accuracy_history']\n",
    "data_train_error_history = load_result['train_error_history']\n",
    "data_test_loss_history = load_result['test_loss_history']\n",
    "data_test_accuracy_history = load_result['test_accuracy_history']\n",
    "data_test_error_history = load_result['test_error_history']\n",
    "\n",
    "print(\"=======Content of the File=======\")\n",
    "print(load_result.files)\n",
    "\n",
    "print(\"=======VISUALIZATION RESULT=======\")\n",
    "plot_cost_history([data_cost_history], save=False)\n",
    "plot_time_history([data_time_history], save=False)\n",
    "plot_loss_history([data_train_loss_history], [data_test_loss_history], save=False)\n",
    "plot_accuracy_history([data_train_accuracy_history], [data_test_accuracy_history], save=False)\n",
    "plot_error_history([data_train_error_history], [data_test_error_history], save=False)\n",
    "\n",
    "print(\"=======STATUS RESULT=======\")\n",
    "print(\"Cost History: \", data_cost_history)\n",
    "print(\"Time History: \", data_time_history)\n",
    "\n",
    "print(\"=======TRAIN RESULT=======\")\n",
    "print(\"Train Loss History: \", data_train_loss_history)\n",
    "print(\"Train Accuracy History: \", data_train_accuracy_history)\n",
    "print(\"Train Error History: \", data_train_error_history)\n",
    "\n",
    "print(\"=======TEST RESULT=======\")\n",
    "print(\"Test Loss History: \", data_test_loss_history)\n",
    "print(\"Test Accuracy History: \", data_test_accuracy_history)\n",
    "print(\"Test Error History: \", data_test_error_history)\n",
    "\n",
    "# Append the data\n",
    "if data_append_load:\n",
    "    data_cost_history_total.append(data_cost_history)\n",
    "    data_time_history_total.append(data_time_history)\n",
    "    data_train_loss_history_total.append(data_train_loss_history)\n",
    "    data_train_accuracy_history_total.append(data_train_accuracy_history)\n",
    "    data_train_error_history_total.append(data_train_error_history)\n",
    "    data_test_loss_history_total.append(data_test_loss_history)\n",
    "    data_test_accuracy_history_total.append(data_test_accuracy_history)\n",
    "    data_test_error_history_total.append(data_test_error_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data Using Specific Path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the filename_load path manually here!!\n",
    "filename_load = \"MNIST_train_NN_with_num_epochs_100_batch_size_128_lr_0.03_2024-02-04 13.59.58_1.npy\"\n",
    "data_append_load = True\n",
    "\n",
    "# Load the file\n",
    "load_result = np.load(filename_load)\n",
    "print('Result has been loaded from the file: ', filename_load)\n",
    "\n",
    "# Load the attributes from the file\n",
    "#data_cost_history = load_result['cost_history']\n",
    "data_time_history = load_result['time_history']\n",
    "data_train_loss_history = load_result['train_loss_history']\n",
    "data_train_accuracy_history = load_result['train_accuracy_history']\n",
    "data_train_error_history = load_result['train_error_history']\n",
    "data_test_loss_history = load_result['test_loss_history']\n",
    "data_test_accuracy_history = load_result['test_accuracy_history']\n",
    "data_test_error_history = load_result['test_error_history']\n",
    "\n",
    "print(\"=======Content of the File=======\")\n",
    "print(load_result.files)\n",
    "\n",
    "print(\"=======VISUALIZATION RESULT=======\")\n",
    "#plot_cost_history([data_cost_history], save=False)\n",
    "plot_time_history([data_time_history], save=False)\n",
    "plot_loss_history([data_train_loss_history], [data_test_loss_history], save=False)\n",
    "plot_accuracy_history([data_train_accuracy_history], [data_test_accuracy_history], save=False)\n",
    "plot_error_history([data_train_error_history], [data_test_error_history], save=False)\n",
    "\n",
    "print(\"=======STATUS RESULT=======\")\n",
    "#print(\"Cost History: \", data_cost_history)\n",
    "print(\"Time History: \", data_time_history)\n",
    "\n",
    "print(\"=======TRAIN RESULT=======\")\n",
    "print(\"Train Loss History: \", data_train_loss_history)\n",
    "print(\"Train Accuracy History: \", data_train_accuracy_history)\n",
    "print(\"Train Error History: \", data_train_error_history)\n",
    "\n",
    "print(\"=======TEST RESULT=======\")\n",
    "print(\"Test Loss History: \", data_test_loss_history)\n",
    "print(\"Test Accuracy History: \", data_test_accuracy_history)\n",
    "print(\"Test Error History: \", data_test_error_history)\n",
    "\n",
    "# Append the data\n",
    "if data_append_load:\n",
    "    #data_cost_history_total.append(data_cost_history)\n",
    "    data_time_history_total.append(data_time_history)\n",
    "    data_train_loss_history_total.append(data_train_loss_history)\n",
    "    data_train_accuracy_history_total.append(data_train_accuracy_history)\n",
    "    data_train_error_history_total.append(data_train_error_history)\n",
    "    data_test_loss_history_total.append(data_test_loss_history)\n",
    "    data_test_accuracy_history_total.append(data_test_accuracy_history)\n",
    "    data_test_error_history_total.append(data_test_error_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data Using Loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change these variables manually here!!\n",
    "# load_loop_max correspond to number of files you want to load\n",
    "load_dataset_name_list = [\"MNIST\"]\n",
    "load_aggreagte_func_list = [\"FedAvg\"]\n",
    "load_global_epochs_list = [2]\n",
    "load_local_epochs_list = [1]\n",
    "load_num_clients_list = [2]\n",
    "load_batch_size_list = [128]\n",
    "load_train_start_time_list = [\"2023-12-04 19.48.18\"]\n",
    "load_loop_max = 1\n",
    "data_append_load = True\n",
    "\n",
    "for n in range(load_loop_max):\n",
    "    # Load the file\n",
    "    filename_load = \"{}_{}_with_global_epochs_{}_local_epochs_{}_num_clients_{}_batch_size_{}_{}.npy\".format(load_dataset_name_list[n], load_aggreagte_func_list[n], load_global_epochs_list[n], load_local_epochs_list[n], load_num_clients_list[n], load_batch_size_list[n], load_train_start_time_list[n])\n",
    "    load_result = np.load(filename_load)\n",
    "    print('Result has been loaded from the file: ', filename_load)\n",
    "\n",
    "    # Load the attributes from the file\n",
    "    data_cost_history = load_result['cost_history']\n",
    "    data_time_history = load_result['time_history']\n",
    "    data_train_loss_history = load_result['train_loss_history']\n",
    "    data_train_accuracy_history = load_result['train_accuracy_history']\n",
    "    data_train_error_history = load_result['train_error_history']\n",
    "    data_test_loss_history = load_result['test_loss_history']\n",
    "    data_test_accuracy_history = load_result['test_accuracy_history']\n",
    "    data_test_error_history = load_result['test_error_history']\n",
    "\n",
    "    # Append the data\n",
    "    if data_append_load:\n",
    "        data_cost_history_total.append(data_cost_history)\n",
    "        data_time_history_total.append(data_time_history)\n",
    "        data_train_loss_history_total.append(data_train_loss_history)\n",
    "        data_train_accuracy_history_total.append(data_train_accuracy_history)\n",
    "        data_train_error_history_total.append(data_train_error_history)\n",
    "        data_test_loss_history_total.append(data_test_loss_history)\n",
    "        data_test_accuracy_history_total.append(data_test_accuracy_history)\n",
    "        data_test_error_history_total.append(data_test_error_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3.1 Data Visualization ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize All Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost_history(data_cost_history_total, save=False)\n",
    "plot_time_history(data_time_history_total, save=False)\n",
    "plot_loss_history(data_train_loss_history_total, data_test_loss_history_total, save=False)\n",
    "plot_accuracy_history(data_train_accuracy_history_total, data_test_accuracy_history_total, save=False)\n",
    "plot_error_history(data_train_error_history_total, data_test_error_history_total, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment in Centralized Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameter_list = [1, 2, 3, 4, 5, 10]\n",
    "\n",
    "plot_different_parameter_train_loss_history = convert_to_list(data_train_loss_history_total)\n",
    "plot_different_parameter_test_loss_history = convert_to_list(data_test_loss_history_total)\n",
    "for i, plot_train_loss_history in enumerate(plot_different_parameter_train_loss_history):\n",
    "    plt.plot(plot_train_loss_history, label=f\"Train Loss History\")\n",
    "for i, plot_test_loss_history in enumerate(plot_different_parameter_test_loss_history):\n",
    "    plt.plot(plot_test_loss_history, label=f\"Test Loss History\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History in Centralized Training\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_train_accuracy_history = convert_to_list(data_train_accuracy_history_total)\n",
    "plot_different_parameter_test_accuracy_history = convert_to_list(data_test_accuracy_history_total)\n",
    "for i, plot_train_accuracy_history in enumerate(plot_different_parameter_train_accuracy_history):\n",
    "    plt.plot(plot_train_accuracy_history, label=f\"Train Accuracy History\")\n",
    "for i, plot_test_accuracy_history in enumerate(plot_different_parameter_test_accuracy_history):\n",
    "    plt.plot(plot_test_accuracy_history, label=f\"Test Accuracy History\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy History in Centralized Training\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_train_error_history = convert_to_list(data_train_error_history_total)\n",
    "plot_different_parameter_test_error_history = convert_to_list(data_test_error_history_total)\n",
    "for i, plot_train_error_history in enumerate(plot_different_parameter_train_error_history):\n",
    "    plt.plot(plot_train_error_history, label=f\"Train Error History\")\n",
    "for i, plot_test_error_history in enumerate(plot_different_parameter_test_error_history):\n",
    "    plt.plot(plot_test_error_history, label=f\"Test Error History\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Error History in Centralized Training\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment between different Local Updates Epochs Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_local_update_epochs_list = [1, 2, 3, 4, 5, 10]\n",
    "\n",
    "plot_different_local_epoch_train_loss_history = convert_to_list(data_train_loss_history_total)\n",
    "plot_different_local_epoch_test_loss_history = convert_to_list(data_test_loss_history_total)\n",
    "for i, plot_train_loss_history in enumerate(plot_different_local_epoch_train_loss_history):\n",
    "    plt.plot(plot_train_loss_history, label=f\"Train Loss History with local epochs = {plot_local_update_epochs_list[i]}\")\n",
    "#for i, plot_test_loss_history in enumerate(plot_different_local_epoch_test_loss_history):\n",
    "#    plt.plot(plot_test_loss_history, label=f\"Test Loss History with local epochs = {plot_local_update_epochs_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History with different local update epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{current_dataset_name}_loss_history_compare_local_update_epochs_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_local_epoch_train_accuracy_history = convert_to_list(data_train_accuracy_history_total)\n",
    "plot_different_local_epoch_test_accuracy_history = convert_to_list(data_test_accuracy_history_total)\n",
    "for i, plot_train_accuracy_history in enumerate(plot_different_local_epoch_train_accuracy_history):\n",
    "    plt.plot(plot_train_accuracy_history, label=f\"Train Accuracy History with local epochs = {plot_local_update_epochs_list[i]}\")\n",
    "#for i, plot_test_accuracy_history in enumerate(plot_different_local_epoch_test_accuracy_history):\n",
    "#    plt.plot(plot_test_accuracy_history, label=f\"Test Accuracy History with local epochs = {plot_local_update_epochs_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy History with different local update epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{current_dataset_name}_accuracy_history_compare_local_update_epochs_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_local_epoch_train_error_history = convert_to_list(data_train_error_history_total)\n",
    "plot_different_local_epoch_test_error_history = convert_to_list(data_test_error_history_total)\n",
    "for i, plot_train_error_history in enumerate(plot_different_local_epoch_train_error_history):\n",
    "    plt.plot(plot_train_error_history, label=f\"Train Error History with local epochs = {plot_local_update_epochs_list[i]}\")\n",
    "#for i, plot_test_error_history in enumerate(plot_different_local_epoch_test_error_history):\n",
    "#    plt.plot(plot_test_error_history, label=f\"Test Accuracy History with local epochs = {plot_local_update_epochs_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Error History with different local update epochs\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{current_dataset_name}_error_history_compare_local_update_epochs_{train_start_time}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment between different Number of Clients Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_num_clients_list = [1, 5, 10, 20]\n",
    "\n",
    "plot_different_local_epoch_train_loss_history = convert_to_list(data_train_loss_history_total)\n",
    "plot_different_local_epoch_test_loss_history = convert_to_list(data_test_loss_history_total)\n",
    "for i, plot_train_loss_history in enumerate(plot_different_local_epoch_train_loss_history):\n",
    "    plt.plot(plot_train_loss_history, label=f\"Train Loss History with number of clients = {plot_num_clients_list[i]}\")\n",
    "for i, plot_test_loss_history in enumerate(plot_different_local_epoch_test_loss_history):\n",
    "    plt.plot(plot_test_loss_history, label=f\"Test Loss History with number of clients = {plot_num_clients_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History with different number of clients\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{current_dataset_name}_loss_history_compare_number_of_clients_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_local_epoch_train_accuracy_history = convert_to_list(data_train_accuracy_history_total)\n",
    "plot_different_local_epoch_test_accuracy_history = convert_to_list(data_test_accuracy_history_total)\n",
    "for i, plot_train_accuracy_history in enumerate(plot_different_local_epoch_train_accuracy_history):\n",
    "    plt.plot(plot_train_accuracy_history, label=f\"Train Accuracy History with number of clients = {plot_num_clients_list[i]}\")\n",
    "for i, plot_test_accuracy_history in enumerate(plot_different_local_epoch_test_accuracy_history):\n",
    "    plt.plot(plot_test_accuracy_history, label=f\"Test Accuracy History with number of clients = {plot_num_clients_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy History with different number of clients\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{current_dataset_name}_accuracy_history_compare_number_of_clients_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_local_epoch_train_error_history = convert_to_list(data_train_error_history_total)\n",
    "plot_different_local_epoch_test_error_history = convert_to_list(data_test_error_history_total)\n",
    "for i, plot_train_error_history in enumerate(plot_different_local_epoch_train_error_history):\n",
    "    plt.plot(plot_train_error_history, label=f\"Train Error History with number of clients = {plot_num_clients_list[i]}\")\n",
    "for i, plot_test_error_history in enumerate(plot_different_local_epoch_test_error_history):\n",
    "    plt.plot(plot_test_error_history, label=f\"Test Accuracy History with number of clients = {plot_num_clients_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Error History with different number of clients\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{current_dataset_name}_error_history_compare_number_of_clients_{train_start_time}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment between different Batch Size Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_batch_size_list = [1, 5, 10, 20]\n",
    "\n",
    "plot_different_time_history = convert_to_list(data_time_history_total)\n",
    "for i, plot_time_history in enumerate(plot_different_time_history):\n",
    "    plt.plot(plot_time_history, label=f\"Time History with batch size = {plot_batch_size_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "plt.ylabel(\"Culminative Time Used\")\n",
    "plt.title(\"Time History\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{current_dataset_name}_time_history_compare_batch_size_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_local_epoch_train_loss_history = convert_to_list(data_train_loss_history_total)\n",
    "plot_different_local_epoch_test_loss_history = convert_to_list(data_test_loss_history_total)\n",
    "for i, plot_train_loss_history in enumerate(plot_different_local_epoch_train_loss_history):\n",
    "    plt.plot(plot_train_loss_history, label=f\"Train Loss History with batch size = {plot_batch_size_list[i]}\")\n",
    "for i, plot_test_loss_history in enumerate(plot_different_local_epoch_test_loss_history):\n",
    "    plt.plot(plot_test_loss_history, label=f\"Test Loss History with batch size = {plot_batch_size_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History with different batch size\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{current_dataset_name}_loss_history_compare_batch_size_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_local_epoch_train_accuracy_history = convert_to_list(data_train_accuracy_history_total)\n",
    "plot_different_local_epoch_test_accuracy_history = convert_to_list(data_test_accuracy_history_total)\n",
    "for i, plot_train_accuracy_history in enumerate(plot_different_local_epoch_train_accuracy_history):\n",
    "    plt.plot(plot_train_accuracy_history, label=f\"Train Accuracy History with batch size = {plot_batch_size_list[i]}\")\n",
    "for i, plot_test_accuracy_history in enumerate(plot_different_local_epoch_test_accuracy_history):\n",
    "    plt.plot(plot_test_accuracy_history, label=f\"Test Accuracy History with batch size = {plot_batch_size_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy History with different batch size\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{current_dataset_name}_accuracy_history_compare_batch_size_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_local_epoch_train_error_history = convert_to_list(data_train_error_history_total)\n",
    "plot_different_local_epoch_test_error_history = convert_to_list(data_test_error_history_total)\n",
    "for i, plot_train_error_history in enumerate(plot_different_local_epoch_train_error_history):\n",
    "    plt.plot(plot_train_error_history, label=f\"Train Error History with batch size = {plot_batch_size_list[i]}\")\n",
    "for i, plot_test_error_history in enumerate(plot_different_local_epoch_test_error_history):\n",
    "    plt.plot(plot_test_error_history, label=f\"Test Accuracy History with batch size = {plot_batch_size_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Error History with different batch size\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{current_dataset_name}_error_history_compare_batch_size_{train_start_time}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment between different Mu Rate Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mu_list = [0.00, 1.00]\n",
    "\n",
    "plot_different_time_history = convert_to_list(data_time_history_total)\n",
    "for i, plot_time_history in enumerate(plot_different_time_history):\n",
    "    plt.plot(plot_time_history, label=f\"Time History with mu = {plot_mu_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "plt.ylabel(\"Culminative Time Used\")\n",
    "plt.title(\"Time History\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{current_dataset_name}_time_history_compare_mu_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_local_epoch_train_loss_history = convert_to_list(data_train_loss_history_total)\n",
    "plot_different_local_epoch_test_loss_history = convert_to_list(data_test_loss_history_total)\n",
    "for i, plot_train_loss_history in enumerate(plot_different_local_epoch_train_loss_history):\n",
    "    plt.plot(plot_train_loss_history, label=f\"Train Loss History with mu = {plot_mu_list[i]}\")\n",
    "#for i, plot_test_loss_history in enumerate(plot_different_local_epoch_test_loss_history):\n",
    "#    plt.plot(plot_test_loss_history, label=f\"Test Loss History with mu = {plot_mu_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History with different mu\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{current_dataset_name}_loss_history_compare_mu_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_local_epoch_train_accuracy_history = convert_to_list(data_train_accuracy_history_total)\n",
    "plot_different_local_epoch_test_accuracy_history = convert_to_list(data_test_accuracy_history_total)\n",
    "for i, plot_train_accuracy_history in enumerate(plot_different_local_epoch_train_accuracy_history):\n",
    "    plt.plot(plot_train_accuracy_history, label=f\"Train Accuracy History with mu = {plot_mu_list[i]}\")\n",
    "#for i, plot_test_accuracy_history in enumerate(plot_different_local_epoch_test_accuracy_history):\n",
    "#    plt.plot(plot_test_accuracy_history, label=f\"Test Accuracy History with mu = {plot_mu_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy History with different mu\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{current_dataset_name}_accuracy_history_compare_mu_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_local_epoch_train_error_history = convert_to_list(data_train_error_history_total)\n",
    "plot_different_local_epoch_test_error_history = convert_to_list(data_test_error_history_total)\n",
    "for i, plot_train_error_history in enumerate(plot_different_local_epoch_train_error_history):\n",
    "    plt.plot(plot_train_error_history, label=f\"Train Error History with mu = {plot_mu_list[i]}\")\n",
    "#for i, plot_test_error_history in enumerate(plot_different_local_epoch_test_error_history):\n",
    "#    plt.plot(plot_test_error_history, label=f\"Test Accuracy History with mu = {plot_mu_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Error History with different mu\")\n",
    "plt.legend()\n",
    "plt.savefig(f'{current_dataset_name}_error_history_compare_mu_{train_start_time}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment between different Federated Learning Framework**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Log Scale Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment Graph Averaging**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3.2 Analysing ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variance Analysis**\n",
    "\n",
    "We analysis the variance of a particular file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_variance = statistics.variance(data_cost_history)\n",
    "time_variance = statistics.variance(data_time_history)\n",
    "train_loss_variance = statistics.variance(data_train_loss_history)\n",
    "train_accuracy_variance = statistics.variance(data_train_accuracy_history)\n",
    "train_error_variance = statistics.variance(data_train_error_history)\n",
    "test_loss_variance = statistics.variance(data_test_loss_history)\n",
    "test_accuracy_variance = statistics.variance(data_test_accuracy_history)\n",
    "test_error_variance = statistics.variance(data_test_error_history)\n",
    "print(\"=======VARIANCE RESULT=======\")\n",
    "print(\"Cost Variance: \", cost_variance)\n",
    "print(\"Time Variance: \", time_variance)\n",
    "print(\"Train Loss Variance: \", train_loss_variance)\n",
    "print(\"Train Accuracy Variance: \", train_accuracy_variance)\n",
    "print(\"Train Error Variance: \", train_error_variance)\n",
    "print(\"Test Loss Variance: \", test_loss_variance)\n",
    "print(\"Test Accuracy Variance: \", test_accuracy_variance)\n",
    "print(\"Test Error Variance: \", test_error_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_variance_subset_min = 0\n",
    "analysis_variance_subset_max = len(data_cost_history) // 2\n",
    "\n",
    "cost_variance_subset = statistics.variance(data_cost_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "time_variance_subset = statistics.variance(data_time_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "train_loss_variance_subset = statistics.variance(data_train_loss_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "train_accuracy_variance_subset = statistics.variance(data_train_accuracy_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "train_error_variance_subset = statistics.variance(data_train_error_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "test_loss_variance_subset = statistics.variance(data_test_loss_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "test_accuracy_variance_subset = statistics.variance(data_test_accuracy_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "test_error_variance_subset = statistics.variance(data_test_error_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "print(f'=======VARIANCE RESULT IN SUBSET BETWEEN {analysis_variance_subset_min} and {analysis_variance_subset_max}=======')\n",
    "print(\"Cost Variance in Subset: \", cost_variance_subset)\n",
    "print(\"Time Variance in Subset: \", time_variance_subset)\n",
    "print(\"Train Loss Variance in Subset: \", train_loss_variance_subset)\n",
    "print(\"Train Accuracy Variance in Subset: \", train_accuracy_variance_subset)\n",
    "print(\"Train Error Variance in Subset: \", train_error_variance_subset)\n",
    "print(\"Test Loss Variance in Subset: \", test_loss_variance_subset)\n",
    "print(\"Test Accuracy Variance in Subset: \", test_accuracy_variance_subset)\n",
    "print(\"Test Error Variance in Subset: \", test_error_variance_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_variance_subset = statistics.variance(data_cost_history[:len(data_cost_history) // 2])\n",
    "time_variance_subset = statistics.variance(data_time_history[:len(data_time_history) // 2])\n",
    "train_loss_variance_subset = statistics.variance(data_train_loss_history[:len(data_train_loss_history) // 2])\n",
    "train_accuracy_variance_subset = statistics.variance(data_train_accuracy_history[:len(data_train_accuracy_history) // 2])\n",
    "train_error_variance_subset = statistics.variance(data_train_error_history[:len(data_train_error_history) // 2])\n",
    "test_loss_variance_subset = statistics.variance(data_test_loss_history[:len(data_test_loss_history) // 2])\n",
    "test_accuracy_variance_subset = statistics.variance(data_test_accuracy_history[:len(data_test_accuracy_history) // 2])\n",
    "test_error_variance_subset = statistics.variance(data_test_error_history[:len(data_test_error_history) // 2])\n",
    "print(\"=======VARIANCE FIRST SUBSET RESULT=======\")\n",
    "print(\"Cost Variance in Subset: \", cost_variance_subset)\n",
    "print(\"Time Variance in Subset: \", time_variance_subset)\n",
    "print(\"Train Loss Variance in Subset: \", train_loss_variance_subset)\n",
    "print(\"Train Accuracy Variance in Subset: \", train_accuracy_variance_subset)\n",
    "print(\"Train Error Variance in Subset: \", train_error_variance_subset)\n",
    "print(\"Test Loss Variance in Subset: \", test_loss_variance_subset)\n",
    "print(\"Test Accuracy Variance in Subset: \", test_accuracy_variance_subset)\n",
    "print(\"Test Error Variance in Subset: \", test_error_variance_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_variance_subset = statistics.variance(data_cost_history[len(data_cost_history) // 2:])\n",
    "time_variance_subset = statistics.variance(data_time_history[len(data_time_history) // 2:])\n",
    "train_loss_variance_subset = statistics.variance(data_train_loss_history[len(data_train_loss_history) // 2:])\n",
    "train_accuracy_variance_subset = statistics.variance(data_train_accuracy_history[len(data_train_accuracy_history) // 2:])\n",
    "train_error_variance_subset = statistics.variance(data_train_error_history[len(data_train_error_history) // 2:])\n",
    "test_loss_variance_subset = statistics.variance(data_test_loss_history[len(data_test_loss_history) // 2:])\n",
    "test_accuracy_variance_subset = statistics.variance(data_test_accuracy_history[len(data_test_accuracy_history) // 2:])\n",
    "test_error_variance_subset = statistics.variance(data_test_error_history[len(data_test_error_history) // 2:])\n",
    "print(\"=======VARIANCE LAST SUBSET RESULT=======\")\n",
    "print(\"Cost Variance in Subset: \", cost_variance_subset)\n",
    "print(\"Time Variance in Subset: \", time_variance_subset)\n",
    "print(\"Train Loss Variance in Subset: \", train_loss_variance_subset)\n",
    "print(\"Train Accuracy Variance in Subset: \", train_accuracy_variance_subset)\n",
    "print(\"Train Error Variance in Subset: \", train_error_variance_subset)\n",
    "print(\"Test Loss Variance in Subset: \", test_loss_variance_subset)\n",
    "print(\"Test Accuracy Variance in Subset: \", test_accuracy_variance_subset)\n",
    "print(\"Test Error Variance in Subset: \", test_error_variance_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
