{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization for Statistical Learning Part 2 - Experiment Notebook #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0 Environment Setup ##\n",
    "\n",
    "In this section, libraries, datasets and associative python programme are imported, as well as the setup of the experiment environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 0.1 Packages and Libraries ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Packages Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jupyter\n",
    "!pip install numpy\n",
    "!pip install torch torchvision \n",
    "!pip install matplotlib\n",
    "!pip install pandas\n",
    "!pip install tensorflow\n",
    "!pip install torch\n",
    "!pip install torchvision\n",
    "!pip install torch_xla\n",
    "!pip install torch-neuron --extra-index-url=https://pip.repos.neuron.amazonaws.com/\n",
    "!pip install pytorch torchvision cudatoolkit=9.0 -c pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import statistics\n",
    "import random\n",
    "import string\n",
    "import timeit\n",
    "from datetime import datetime\n",
    "from typing import List, Optional, Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import os\n",
    "import csv\n",
    "#import cv2\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import torch\n",
    "from torch.utils.data import random_split, Dataset, DataLoader, ConcatDataset, Subset\n",
    "from torch.optim.optimizer import (Optimizer, required, _use_grad_for_differentiable, _default_to_fused_or_foreach,\n",
    "                        _differentiable_doc, _foreach_doc, _maximize_doc)\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importing Python Programme**\n",
    "\n",
    "Here is the section for importing external python files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 0.1 Set up Experiment Environment ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utilize GPU**\n",
    "\n",
    "For local environments, please utilize the GPU to speed up the training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    return torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)\n",
    "\n",
    "class DeviceDataLoader(DataLoader):\n",
    "        def __init__(self, dl, device):\n",
    "            self.dl = dl\n",
    "            self.device = device\n",
    "\n",
    "        def __iter__(self):\n",
    "            for batch in self.dl:\n",
    "                yield to_device(batch, self.device)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.dl)\n",
    "\n",
    "device = get_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utililze TPU**\n",
    "\n",
    "To shorten the training time, we highly recommend that experiments should be done in Google Colab. Enable the following code in the Google Colab platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assume that you are on the Google Colab platform.\n",
    "#!pip install cloud-tpu-client==0.10 torch==2.0.0 torchvision==0.15.1 https://storage.googleapis.com/tpu-pytorch/wheels/colab/torch_xla-2.0-cp310-cp310-linux_x86_64.whl\n",
    "\n",
    "import os\n",
    "assert os.environ['COLAB_TPU_ADDR'], 'Make sure to select TPU from Edit > Notebook settings > Hardware accelerator'\n",
    "\n",
    "import torch_xla\n",
    "import torch_xla.core.xla_model as xm\n",
    "\n",
    "device = xm.xla_device()\n",
    "\n",
    "def to_device(data, device):\n",
    "    data.to(device)\n",
    "\n",
    "class DeviceDataLoader(DataLoader):\n",
    "        def __init__(self, dl, device):\n",
    "            self.dl = dl\n",
    "            self.device = device\n",
    "\n",
    "        def __iter__(self):\n",
    "            for batch in self.dl:\n",
    "                yield to_device(batch, self.device)\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 0.2 Datasets ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 0.2.0 Preprocessing Functions ####\n",
    "Here are the functions for preprocessing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################\n",
    "#       Normalization        #\n",
    "##############################\n",
    "def normalize_tensor(tensor):\n",
    "    mean = torch.mean(tensor)\n",
    "    std = torch.std(tensor)\n",
    "    normalized_tensor = (tensor - mean) / std\n",
    "    return normalized_tensor\n",
    "\n",
    "##############################\n",
    "#    Image Preprocessing     #\n",
    "##############################\n",
    "def load_image(filename):\n",
    "  im_pil = Image.open(filename)\n",
    "  im = np.array(im_pil).astype(np.float32) / 255\n",
    "  return im\n",
    "\n",
    "##############################\n",
    "# Text Dataset Preprocessing #\n",
    "##############################\n",
    "all_letters = string.ascii_letters + \" .,;'\"\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in all_letters\n",
    "    )\n",
    "\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "# Just for demonstration, turn a letter into a <1 x n_letters> Tensor\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "# Turn a line into a <line_length x 1 x n_letters>,\n",
    "# or an array of one-hot letter vectors\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(len(line), 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 0.2.1 Importing Datasets from Packages ####\n",
    "This will load the dataset automatically downloaded from the package. Remember the datasets will be stored in the folder \"Datasets\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MINST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50.2%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./Datasets\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Datasets\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./Datasets\\MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./Datasets\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./Datasets\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./Datasets\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./Datasets\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ./Datasets\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./Datasets\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./Datasets\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./Datasets\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./Datasets\\MNIST\\raw\n",
      "\n",
      "The current dataset is MNIST.\n",
      "Number of samples in the train dataset: 60000\n",
      "Number of samples in the test dataset: 10000\n"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Download Dataset\n",
    "MNIST_train_dataset = MNIST(root='./Datasets', train=True, download=True, transform=transforms.ToTensor())\n",
    "MNIST_test_dataset = MNIST(root='./Datasets', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Load Dataset\n",
    "train_dataset = MNIST_train_dataset\n",
    "test_dataset = MNIST_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"MNIST\"\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the raw data from the dataset\n",
    "print(\"=== Raw Data Samples from the MNIST Train Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = MNIST_train_dataset[i]\n",
    "    image = image.squeeze().numpy()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()\n",
    "\n",
    "print(\"=== Raw Data Samples from the MNIST Test Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = MNIST_test_dataset[i]\n",
    "    image = image.squeeze().numpy()\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIFAR-10 Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# Download Dataset\n",
    "CIFAR10_train_dataset = CIFAR10(root='./Datasets', train=True, download=True, transform=transforms.ToTensor())\n",
    "CIFAR10_test_dataset = CIFAR10(root='./Datasets', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "# Load Dataset\n",
    "train_dataset = CIFAR10_train_dataset\n",
    "test_dataset = CIFAR10_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"CIFAR10\"\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the raw data from the CIFAR10 train dataset\n",
    "print(\"=== Raw Data Samples from the CIFAR10 Train Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = CIFAR10_train_dataset[i]\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the raw data from the CIFAR10 test dataset\n",
    "print(\"=== Raw Data Samples from the CIFAR10 Test Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = CIFAR10_test_dataset[i]\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EMNIST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import EMNIST\n",
    "\n",
    "# Download Dataset\n",
    "EMNIST_train_dataset = EMNIST(root='./Datasets', split='byclass', train=True, download=True, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "EMNIST_test_dataset = EMNIST(root='./Datasets', split='byclass', train=False, download=True, transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.1307,), (0.3081,))]))\n",
    "\n",
    "# Load Dataset\n",
    "train_dataset = EMNIST_train_dataset\n",
    "test_dataset = EMNIST_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"EMNIST\"\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the raw data from the EMNIST train dataset\n",
    "print(\"=== Raw Data Samples from the EMNIST Train Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = EMNIST_train_dataset[i]\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()\n",
    "\n",
    "# Visualize the raw data from the EMNIST test dataset\n",
    "print(\"=== Raw Data Samples from the EMNIST Test Dataset ===\")\n",
    "for i in range(3):\n",
    "    image, label = EMNIST_test_dataset[i]\n",
    "    plt.imshow(image.permute(1, 2, 0))\n",
    "    plt.title(f\"Label: {label}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 0.2.2 Importing Datasets from Downloaded Files ####\n",
    "This will load the dataset downloaded in the local directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Give Me Some Credit Dataset**\n",
    "\n",
    "The source of this dataset comes from https://www.kaggle.com/c/GiveMeSomeCredit\n",
    "\n",
    "Note: This dataset is borrowed from the datasets used in the competitive task in FTEC2101 Optimization Methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset Structure\n",
    "class Give_Me_Some_Credit_Dataset_Class(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data, self.targets = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        data_frame = pd.read_csv(self.root)\n",
    "        data = []\n",
    "        targets = []\n",
    "\n",
    "        for _, row in data_frame.iterrows():\n",
    "            features = row.iloc[:-1].values.astype(np.float32)\n",
    "            label = row.iloc[-1]\n",
    "            data.append(features)\n",
    "            targets.append(float(int(label)))\n",
    "        \n",
    "        data = torch.tensor(data)\n",
    "        targets = torch.tensor(targets)\n",
    "        return data, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.data[index]\n",
    "        label = self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            features = self.transform(features)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return features, label\n",
    "\n",
    "# Load Dataset\n",
    "Give_Me_Some_Credit_train_dataset = Give_Me_Some_Credit_Dataset_Class(root='./Datasets/Give_Me_Some_Credit/ftec-cs-full-train.csv', train=True, transform=normalize_tensor)\n",
    "Give_Me_Some_Credit_test_dataset = Give_Me_Some_Credit_Dataset_Class(root='./Datasets/Give_Me_Some_Credit/ftec-cs-full-test.csv', train=False, transform=normalize_tensor)\n",
    "\n",
    "train_dataset = Give_Me_Some_Credit_train_dataset\n",
    "test_dataset = Give_Me_Some_Credit_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"Give Me Some Credit Dataset\"\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Epsilon Dataset**\n",
    "\n",
    "Note: This dataset is best suited for binary classification. The training dataset contains 400000 objects. Each object is described by 2001 columns. The first column contains the label value, all other columns contain numerical features. The validation dataset contains 100000 objects. The structure is identical to the training dataset.\n",
    "\n",
    "Warning: The loading time for this dataset is too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset Structure\n",
    "class EpsilonDataset(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data, self.targets = self._load_data()\n",
    "    \n",
    "    def process_line(self, line):\n",
    "        line = line.split(' ')\n",
    "        label, values = int(line[0]), line[1:]\n",
    "        value = torch.zeros(line[1:].size())\n",
    "        for item in values:\n",
    "            idx, val = item.split(':')\n",
    "            value[int(idx) - 1] = float(val)\n",
    "        return label, value\n",
    "\n",
    "    def _load_data(self):\n",
    "        data_frame = pd.read_csv(self.root, nrows=20000)\n",
    "        data = []\n",
    "        targets = []\n",
    "\n",
    "        with open(self.root, 'r') as fp:\n",
    "            for line in fp:\n",
    "                label, value = self.process_line(line.strip(\"\\n\"))\n",
    "                data.append(value)\n",
    "                targets.append(label)\n",
    "\n",
    "        return data, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.data[index]\n",
    "        label = self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            features = self.transform(features)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return features, label\n",
    "\n",
    "# Load Dataset\n",
    "Epsilon_train_dataset = EpsilonDataset(root='./Datasets/epsilon/epsilon_normalized', train=True, transform=None)\n",
    "Epsilon_test_dataset = EpsilonDataset(root='./Datasets/epsilon/epsilon_normalized.t', train=False, transform=None)\n",
    "\n",
    "train_dataset = Epsilon_train_dataset\n",
    "test_dataset = Epsilon_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"Epsilon\"\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Languages Dataset**\n",
    "\n",
    "The dataset is downloaded from here: https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import open\n",
    "import glob\n",
    "\n",
    "def findFiles(path): return glob.glob(path)\n",
    "\n",
    "print(findFiles('Datasets/Language_dataset/names/*.txt'))\n",
    "\n",
    "# Build the category_lines dictionary, a list of names per language\n",
    "languages_dataset_category_lines = {}\n",
    "languages_dataset_all_categories = []\n",
    "\n",
    "# Read a file and split into lines\n",
    "def readLines(filename):\n",
    "    lines = open(filename, encoding='utf-8').read().strip().split('\\n')\n",
    "    return [unicodeToAscii(line) for line in lines]\n",
    "\n",
    "for filename in findFiles('Datasets/Language_dataset/names/*.txt'):\n",
    "    category = os.path.splitext(os.path.basename(filename))[0]\n",
    "    languages_dataset_all_categories.append(category)\n",
    "    lines = readLines(filename)\n",
    "    languages_dataset_category_lines[category] = lines\n",
    "\n",
    "n_categories = len(languages_dataset_all_categories)\n",
    "\n",
    "class LanguageDataset(Dataset):\n",
    "    def __init__(self, root, train=True, transform=None, target_transform=None):\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data, self.targets = self._load_data()\n",
    "\n",
    "    def _load_data(self):\n",
    "        data_frame = pd.read_csv(self.root, nrows=20000)\n",
    "        data = []\n",
    "        targets = []\n",
    "\n",
    "        with open(self.root, 'r') as fp:\n",
    "            for line in fp:\n",
    "                label, value = self.process_line(line.strip(\"\\n\"))\n",
    "                data.append(value)\n",
    "                targets.append(label)\n",
    "\n",
    "        return data, targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        features = self.data[index]\n",
    "        label = self.targets[index]\n",
    "\n",
    "        if self.transform is not None:\n",
    "            features = self.transform(features)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            label = self.target_transform(label)\n",
    "\n",
    "        return features, label\n",
    "\n",
    "Languages_train_dataset = LanguageDataset(root='./Datasets/epsilon/epsilon_normalized', train=True, transform=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1 Classes, Functions and Algorithms ##\n",
    "All common and helping functions for machine learning tasks are defined here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################\n",
    "#     Helping Functions    #\n",
    "############################\n",
    "# Random Seed Function\n",
    "# To ensure a same training result under the random process, you might need to set the random seed via this function.\n",
    "def set_random_seed(custom_random_seed):\n",
    "    torch.manual_seed(custom_random_seed)\n",
    "    random.seed(custom_random_seed)\n",
    "    np.random.seed(custom_random_seed)\n",
    "\n",
    "# Convert anything into a list if input is not a list\n",
    "def convert_to_list(input_list):\n",
    "    if not isinstance(input_list, list):\n",
    "        input_list = [input_list]\n",
    "    return input_list\n",
    "\n",
    "# Graph Plotting Functions\n",
    "def plot_cost_history(cost_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Cost\", title_name=\"Culminative Send Cost History\"):\n",
    "    cost_history_list = convert_to_list(cost_history_list)\n",
    "    for i, cost_history in enumerate(cost_history_list):\n",
    "        plt.plot(cost_history, label=f\"Cost History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if len(cost_history_list) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_culminative_send_cost_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_time_history(time_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Culminative Time Used\", title_name=\"Time History\"):\n",
    "    time_history_list = convert_to_list(time_history_list)\n",
    "    for i, time_history in enumerate(time_history_list):\n",
    "        plt.plot(time_history, label=f\"Time History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if len(time_history_list) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_time_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_adversary_history(adversary_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Adversaries\", title_name=\"Number of Adversaries History\"):\n",
    "    adversary_history_list = convert_to_list(adversary_history_list)\n",
    "    for i, adversary_history in enumerate(adversary_history_list):\n",
    "        plt.plot(adversary_history, label=f\"Adversary History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if len(adversary_history_list) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_adversary_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_straggler_history(straggler_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Stragglers\", title_name=\"Number of Stragglers History\"):\n",
    "    straggler_history_list = convert_to_list(straggler_history_list)\n",
    "    for i, straggler_history in enumerate(straggler_history_list):\n",
    "        plt.plot(straggler_history, label=f\"Straggler History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if len(straggler_history) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_straggler_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_loss_history(train_loss_history_list=[], test_loss_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Loss\", title_name=\"Loss History\"):\n",
    "    train_loss_history_list = convert_to_list(train_loss_history_list)\n",
    "    test_loss_history_list = convert_to_list(test_loss_history_list)\n",
    "    for i, train_loss_history in enumerate(train_loss_history_list):\n",
    "        plt.plot(train_loss_history, label=f\"Train Loss History {i+1}\")\n",
    "    for i, test_loss_history in enumerate(test_loss_history_list):\n",
    "        plt.plot(test_loss_history, label=f\"Test Loss History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if (len(train_loss_history_list) + len(test_loss_history_list)) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_loss_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_accuracy_history(train_accuracy_history_list=[], test_accuracy_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Accuracy\", title_name=\"Accuracy History\"):\n",
    "    train_accuracy_history_list = convert_to_list(train_accuracy_history_list)\n",
    "    test_accuracy_history_list = convert_to_list(test_accuracy_history_list)\n",
    "    for i, train_accuracy_history in enumerate(train_accuracy_history_list):\n",
    "        plt.plot(train_accuracy_history, label=f\"Train Accuracy History {i+1}\")\n",
    "    for i, test_accuracy_history in enumerate(test_accuracy_history_list):\n",
    "        plt.plot(test_accuracy_history, label=f\"Test Accuracy History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if (len(train_accuracy_history_list) + len(test_accuracy_history_list)) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_accuracy_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_error_history(train_error_history_list=[], test_error_history_list=[], save=True, x_label_name=\"Epochs\", y_label_name=\"Error\", title_name=\"Error History\"):\n",
    "    train_error_history_list = convert_to_list(train_error_history_list)\n",
    "    test_error_history_list = convert_to_list(test_error_history_list)\n",
    "    for i, train_error_history in enumerate(train_error_history_list):\n",
    "        plt.plot(train_error_history, label=f\"Train Error History {i+1}\")\n",
    "    for i, test_error_history in enumerate(test_error_history_list):\n",
    "        plt.plot(test_error_history, label=f\"Test Error History {i+1}\")\n",
    "    plt.xlabel(x_label_name)\n",
    "    plt.ylabel(y_label_name)\n",
    "    plt.title(title_name)\n",
    "    if (len(train_error_history_list) + len(test_error_history_list)) > 1:\n",
    "        plt.legend()\n",
    "    if save:\n",
    "        plt.savefig(f'{current_dataset_name}_error_history_{train_start_time}.png')\n",
    "    plt.show()\n",
    "\n",
    "# Accuracy and Error Rate Calculation\n",
    "def get_accuracy(outputs, labels):\n",
    "    with torch.no_grad():\n",
    "        if outputs.dim() > 1:\n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "        else:\n",
    "            predictions = outputs\n",
    "        return torch.tensor(torch.sum(predictions == labels).item() / len(predictions))\n",
    "\n",
    "def get_error(outputs, labels):\n",
    "    with torch.no_grad():\n",
    "        if outputs.dim() > 1:\n",
    "            _, predictions = torch.max(outputs, dim=1)\n",
    "        else:\n",
    "            predictions = outputs\n",
    "        return torch.tensor(torch.sum(predictions != labels).item() / len(predictions))\n",
    "\n",
    "def relative_rate_to_client_number(num_client, percentage = 1.00):\n",
    "    return round(num_client * percentage)\n",
    "\n",
    "############################\n",
    "#   Neural Network Model   #\n",
    "############################\n",
    "global Linear_Model_in_features\n",
    "global Linear_Model_out_features\n",
    "class Linear_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(in_features=Linear_Model_in_features, out_features=Linear_Model_out_features)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return torch.squeeze(x)\n",
    "\n",
    "class MNIST_CNN_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.pool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels=16, out_channels=32, kernel_size=5, stride=1, padding=2)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.pool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.fc1 = torch.nn.Linear(32 * 7 * 7, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        if len(x.size()) == 1:  # Check if output has a single level of brackets\n",
    "            x = x.unsqueeze(0)  # Add a dimension at the beginning\n",
    "        return x\n",
    "\n",
    "class CIFAR10_CNN_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation_stack = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2), # output: 64 x 16 x 16\n",
    "            torch.nn.BatchNorm2d(64),\n",
    "\n",
    "            torch.nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2), # output: 128 x 8 x 8\n",
    "            torch.nn.BatchNorm2d(128),\n",
    "\n",
    "            torch.nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(2, 2), # output: 256 x 4 x 4\n",
    "            torch.nn.BatchNorm2d(256),\n",
    "\n",
    "            torch.nn.Flatten(), \n",
    "            torch.nn.Linear(256*4*4, 1024),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, 10)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.activation_stack(x)\n",
    "        if len(x.size()) == 1:  # Check if output has a single level of brackets\n",
    "            x = x.unsqueeze(0)  # Add a dimension at the beginning\n",
    "        return x\n",
    "\n",
    "class EMNIST_CNN_Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = torch.nn.ReLU()\n",
    "        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.fc1 = torch.nn.Linear(7 * 7 * 64, 128)\n",
    "        self.relu3 = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "        self.fc2 = torch.nn.Linear(128, 26)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        if len(x.size()) == 1:  # Check if output has a single level of brackets\n",
    "            x = x.unsqueeze(0)  # Add a dimension at the beginning\n",
    "        return x\n",
    "\n",
    "class RNN_model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.activation_stack = torch.nn.Sequential(\n",
    "            torch.nn.RNN()\n",
    "        )\n",
    "\n",
    "############################\n",
    "#    Iterate Algorithm     #\n",
    "############################\n",
    "def evaluate_model_simple(model, dataloader, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error):\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "    return loss_average, accuracy_average, error_average\n",
    "\n",
    "def iterate_model_simple(model, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True, test_dataloader=None, include_intial_history=False):\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    error_history = []\n",
    "    time_history = [0]\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    test_loss_history = []\n",
    "    test_accuracy_history = []\n",
    "    test_error_history = []\n",
    "\n",
    "    if include_intial_history is True:\n",
    "        loss, accuracy, error = evaluate_model_simple(model=model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        loss_history.append(loss)\n",
    "        accuracy_history.append(accuracy)\n",
    "        error_history.append(error)\n",
    "        if test_dataloader is not None:\n",
    "            test_loss, test_accuracy, test_error = evaluate_model_simple(model=model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "            test_loss_history.append(test_loss)\n",
    "            test_accuracy_history.append(test_accuracy)\n",
    "            test_error_history.append(test_error)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        errors = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss.detach()\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        time_history.append(time_used)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "        loss_history.append(loss_average)\n",
    "        accuracy_history.append(accuracy_average)\n",
    "        error_history.append(error_average)\n",
    "        if test_dataloader is not None:\n",
    "            test_loss, test_accuracy, test_error = evaluate_model_simple(model=model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "            test_loss_history.append(test_loss)\n",
    "            test_accuracy_history.append(test_accuracy)\n",
    "            test_error_history.append(test_error)\n",
    "        if show_history:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {loss_average:.16f}, Train Accuracy: {accuracy_average:.16f}, Train Error: {error_average:.16f}, Culminative Time Used: {time_used}')\n",
    "            if test_dataloader is not None:\n",
    "                print(f'Test Loss: {test_loss:.16f}, Test Accuracy: {test_accuracy:.16f}, Test Error: {test_error:.16f}')\n",
    "    if test_dataloader is not None:\n",
    "        return loss_history, accuracy_history, error_history, time_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "    return loss_history, accuracy_history, error_history, time_history\n",
    "\n",
    "##################################################################\n",
    "#  Dataset Preprocessing Functions Before Splitting For Clients  #\n",
    "##################################################################\n",
    "# Acknowledge from https://github.com/adap/flower/blob/main/baselines/fedprox/fedprox/dataset_preparation.py\n",
    "# Balance: Trims the dataset so each class contains as many elements as the class that contained the least elements.\n",
    "def dataset_balance_classes(trainset, seed=42):\n",
    "    class_counts = np.bincount(trainset.targets)\n",
    "    smallest = np.min(class_counts)\n",
    "    idxs = trainset.targets.argsort()\n",
    "    tmp = [Subset(trainset, idxs[: int(smallest)])]\n",
    "    tmp_targets = [trainset.targets[idxs[: int(smallest)]]]\n",
    "    for count in np.cumsum(class_counts):\n",
    "        tmp.append(Subset(trainset, idxs[int(count) : int(count + smallest)]))\n",
    "        tmp_targets.append(trainset.targets[idxs[int(count) : int(count + smallest)]])\n",
    "    unshuffled = ConcatDataset(tmp)\n",
    "    unshuffled_targets = torch.cat(tmp_targets)\n",
    "    shuffled_idxs = torch.randperm(\n",
    "        len(unshuffled), generator=torch.Generator().manual_seed(seed)\n",
    "    )\n",
    "    shuffled = Subset(unshuffled, shuffled_idxs)\n",
    "    shuffled.targets = unshuffled_targets[shuffled_idxs]\n",
    "    return shuffled\n",
    "\n",
    "def dataset_sort_by_class(trainset: Dataset):\n",
    "    class_counts = np.bincount(trainset.targets)\n",
    "    idxs = trainset.targets.argsort()  # sort targets in ascending order\n",
    "\n",
    "    tmp = []  # create subset of smallest class\n",
    "    tmp_targets = []  # same for targets\n",
    "\n",
    "    start = 0\n",
    "    for count in np.cumsum(class_counts):\n",
    "        tmp.append(\n",
    "            Subset(trainset, idxs[start : int(count + start)])\n",
    "        )  # add rest of classes\n",
    "        tmp_targets.append(trainset.targets[idxs[start : int(count + start)]])\n",
    "        start += count\n",
    "    sorted_dataset = ConcatDataset(tmp)  # concat dataset\n",
    "    sorted_dataset.targets = torch.cat(tmp_targets)  # concat targets\n",
    "    return sorted_dataset\n",
    "\n",
    "# Implemention follow Li et al 2020: https://arxiv.org/abs/1812.06127 with default values set accordingly.\n",
    "global custom_power_law_num_labels_per_partition\n",
    "global custom_power_law_min_data_per_partition\n",
    "global custom_power_law_mean\n",
    "global custom_power_law_sigma\n",
    "custom_power_law_num_labels_per_partition = 2\n",
    "custom_power_law_min_data_per_partition = 10\n",
    "custom_power_law_mean = 0.0\n",
    "custom_power_law_sigma = 2.0\n",
    "def dataset_power_law_split(sorted_trainset, num_partitions):\n",
    "    # Custom Parameters\n",
    "    num_labels_per_partition = custom_power_law_num_labels_per_partition\n",
    "    min_data_per_partition = custom_power_law_min_data_per_partition\n",
    "    mean = custom_power_law_mean\n",
    "    sigma = custom_power_law_sigma\n",
    "\n",
    "    targets = sorted_trainset.targets\n",
    "    full_idx = list(range(len(targets)))\n",
    "\n",
    "    class_counts = np.bincount(sorted_trainset.targets)\n",
    "    labels_cs = np.cumsum(class_counts)\n",
    "    labels_cs = [0] + labels_cs[:-1].tolist()\n",
    "\n",
    "    partitions_idx: List[List[int]] = []\n",
    "    num_classes = len(np.bincount(targets))\n",
    "    hist = np.zeros(num_classes, dtype=np.int32)\n",
    "\n",
    "    # assign min_data_per_partition\n",
    "    min_data_per_class = int(min_data_per_partition / num_labels_per_partition)\n",
    "    for u_id in range(num_partitions):\n",
    "        partitions_idx.append([])\n",
    "        for cls_idx in range(num_labels_per_partition):\n",
    "            # label for the u_id-th client\n",
    "            cls = (u_id + cls_idx) % num_classes\n",
    "            # record minimum data\n",
    "            indices = list(\n",
    "                full_idx[\n",
    "                    labels_cs[cls]\n",
    "                    + hist[cls] : labels_cs[cls]\n",
    "                    + hist[cls]\n",
    "                    + min_data_per_class\n",
    "                ]\n",
    "            )\n",
    "            partitions_idx[-1].extend(indices)\n",
    "            hist[cls] += min_data_per_class\n",
    "\n",
    "    # add remaining images following power-law\n",
    "    probs = np.random.lognormal(\n",
    "        mean,\n",
    "        sigma,\n",
    "        (num_classes, int(num_partitions / num_classes), num_labels_per_partition),\n",
    "    )\n",
    "    remaining_per_class = class_counts - hist\n",
    "    # obtain how many samples each partition should be assigned for each of the\n",
    "    # labels it contains\n",
    "    # pylint: disable=too-many-function-args\n",
    "    probs = (\n",
    "        remaining_per_class.reshape(-1, 1, 1)\n",
    "        * probs\n",
    "        / np.sum(probs, (1, 2), keepdims=True)\n",
    "    )\n",
    "\n",
    "    for u_id in range(num_partitions):\n",
    "        for cls_idx in range(num_labels_per_partition):\n",
    "            cls = (u_id + cls_idx) % num_classes\n",
    "            count = int(probs[cls, u_id // num_classes, cls_idx])\n",
    "\n",
    "            # add count of specific class to partition\n",
    "            indices = full_idx[\n",
    "                labels_cs[cls] + hist[cls] : labels_cs[cls] + hist[cls] + count\n",
    "            ]\n",
    "            partitions_idx[u_id].extend(indices)\n",
    "            hist[cls] += count\n",
    "\n",
    "    # construct subsets\n",
    "    partitions = [Subset(sorted_trainset, p) for p in partitions_idx]\n",
    "    return partitions\n",
    "\n",
    "# Distribute the training datasets to clients, remember it returns an array of datasets\n",
    "def split_datasets_for_clients_random(dataset, num_clients=1):\n",
    "    total_sample_size = len(dataset)\n",
    "    samples_per_clients = total_sample_size // num_clients\n",
    "    client_datasets = random_split(dataset, [min(i + samples_per_clients, total_sample_size) - i for i in range(0, total_sample_size, samples_per_clients)])\n",
    "    return client_datasets\n",
    "\n",
    "global custom_split_dataset_iid\n",
    "global custom_split_dataset_power_law\n",
    "global custom_split_dataset_balance\n",
    "global custom_split_dataset_seed\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "def split_datasets_for_clients_custom(dataset, num_clients=1):\n",
    "    # Custom Parameters\n",
    "    iid=custom_split_dataset_iid\n",
    "    power_law=custom_split_dataset_power_law\n",
    "    balance=custom_split_dataset_balance\n",
    "    seed=custom_split_dataset_seed\n",
    "\n",
    "    trainset = dataset\n",
    "    if balance:\n",
    "        trainset = dataset_balance_classes(trainset, seed)\n",
    "\n",
    "    partition_size = int(len(trainset) / num_clients)\n",
    "    lengths = [partition_size] * num_clients\n",
    "\n",
    "    if iid is True:\n",
    "        client_datasets = random_split(trainset, lengths, torch.Generator().manual_seed(seed))\n",
    "    else:\n",
    "        if power_law is True:\n",
    "            trainset_sorted = dataset_sort_by_class(trainset)\n",
    "            client_datasets = dataset_power_law_split(\n",
    "                trainset_sorted,\n",
    "                num_partitions=num_clients,\n",
    "            )\n",
    "        else:\n",
    "            shard_size = int(partition_size / 2)\n",
    "            idxs = trainset.targets.argsort()\n",
    "            sorted_data = Subset(trainset, idxs)\n",
    "            tmp = []\n",
    "            for idx in range(num_clients * 2):\n",
    "                tmp.append(\n",
    "                    Subset(\n",
    "                        sorted_data, np.arange(shard_size * idx, shard_size * (idx + 1))\n",
    "                    )\n",
    "                )\n",
    "            idxs_list = torch.randperm(\n",
    "                num_clients * 2, generator=torch.Generator().manual_seed(seed)\n",
    "            )\n",
    "            client_datasets = [\n",
    "                ConcatDataset((tmp[idxs_list[2 * i]], tmp[idxs_list[2 * i + 1]]))\n",
    "                for i in range(num_clients)\n",
    "            ]\n",
    "\n",
    "    return client_datasets\n",
    "\n",
    "############################\n",
    "#      Client Devices      #\n",
    "############################\n",
    "# Define a custom class for each client so they can update separately\n",
    "class ClientDevice:\n",
    "    def __init__(self, client_id, model, optimizer, dataset, batch_size, iterate_func, loss_func, accuracy_func=get_accuracy, error_func=get_error):\n",
    "        self.id = client_id\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "        self.dataset = dataset\n",
    "        self.dataloader = DeviceDataLoader(torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True), device)\n",
    "        self.iterate_func = iterate_func\n",
    "        self.loss_func = loss_func\n",
    "        self.accuracy_func = accuracy_func\n",
    "        self.error_func = error_func\n",
    "\n",
    "        # Framework Specificed Variables\n",
    "        self.straggler = False\n",
    "        self.client_controls = {}\n",
    "        self.full_batch_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(dataset, batch_size=len(dataset), shuffle=False), device)\n",
    "\n",
    "        # Custom Variables\n",
    "        self.adversary = False\n",
    "        self.adversary_attack_func = None\n",
    "        self.adversary_attack_value = 0\n",
    "        self.adversary_attack_Scaffold_all = False\n",
    "\n",
    "    def load_weights(self, weights):\n",
    "        self.model.load_state_dict(weights)\n",
    "\n",
    "    def load_global_model(self, global_model):\n",
    "        for parameters, new_parameters in zip(self.model.parameters(), global_model.parameters()):\n",
    "            parameters.data = new_parameters.data.clone()\n",
    "\n",
    "    def copy_local_weights(self):\n",
    "        # This ensures dereferencing\n",
    "        model_weights = {}\n",
    "        for name, parameters in self.model.named_parameters():\n",
    "            model_weights[name] = parameters.data.clone()\n",
    "        return(model_weights)\n",
    "\n",
    "    def copy_local_model(self):\n",
    "        return self.model.state_dict().copy()\n",
    "\n",
    "    def get_client_id(self):\n",
    "        return self.id\n",
    "    \n",
    "    def get_dataset_size(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def save_local_history(self, num_epochs, loss_history, accuracy_history, error_history, time_history, value=train_start_time):\n",
    "        filename = \"{}_client_{}_with_local_epochs_{}_local_loss_accuracy_error_history_{}.npy\".format(current_dataset_name, self.id, num_epochs, value)\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.savez(f, loss_history=loss_history, accuracy_history=accuracy_history, error_history=error_history, time_history=time_history)\n",
    "\n",
    "    def train(self, num_epochs, show_message=True, plot_history=False):\n",
    "        if self.adversary is True:\n",
    "            if show_message:\n",
    "                print(f\"!-- Client {self.id} is a adversary and start iterations. ---!\")\n",
    "            self.adversary_attack_func(self.model, self.adversary_attack_value, self.dataloader, num_epochs, self.optimizer, self.loss_func, self.accuracy_func, self.error_func)\n",
    "        else:\n",
    "            if self.straggler is True:\n",
    "                if show_message:\n",
    "                    print(f\"!-- Client {self.id} is a straggler and start iterations. ---!\")\n",
    "                loss_history, accuracy_history, error_history, time_history = self.iterate_func(self.model, self.dataloader, random.randint(1, num_epochs), self.optimizer, self.loss_func, self.accuracy_func, self.error_func)\n",
    "            else:\n",
    "                if show_message:\n",
    "                    print(f\"!-- Client {self.id} is normal and start iterations. ---!\")\n",
    "                loss_history, accuracy_history, error_history, time_history = self.iterate_func(self.model, self.dataloader, num_epochs, self.optimizer, self.loss_func, self.accuracy_func, self.error_func)\n",
    "        if plot_history:\n",
    "            plot_time_history(time_history)\n",
    "            plot_loss_history(loss_history)\n",
    "            plot_accuracy_history(accuracy_history)\n",
    "            plot_error_history(error_history)\n",
    "        return self.copy_local_weights()\n",
    "\n",
    "    ## == Framework Specificed Functions == ##\n",
    "    def is_straggler(self):\n",
    "        return self.straggler\n",
    "\n",
    "    def get_local_client_controls(self):\n",
    "        return self.client_controls\n",
    "\n",
    "    def train_Scaffold(self, server_controls, num_epochs, Scaffold_update_controls_use_gradient, show_message=True, plot_history=False):\n",
    "        if self.adversary is True:\n",
    "            if show_message:\n",
    "                print(f\"!-- Client {self.id} is a adversary and start iterations. ---!\")\n",
    "            delta_weights, delta_client_controls = self.adversary_attack_func(self, self.adversary_attack_value, server_controls, self.dataloader, num_epochs, self.adversary_attack_Scaffold_all, self.loss_func, self.accuracy_func, self.error_func, Scaffold_update_controls_use_gradient)\n",
    "        else:\n",
    "            if self.straggler is True:\n",
    "                if show_message:\n",
    "                    print(f\"!-- Client {self.id} is a straggler and start iterations. ---!\")\n",
    "                loss_history, accuracy_history, error_history, time_history, delta_weights, delta_client_controls = iterate_Scaffold_client(self, server_controls, self.dataloader, random.randint(1, num_epochs), self.optimizer, self.loss_func, self.accuracy_func, self.error_func, Scaffold_update_controls_use_gradient)\n",
    "            else:\n",
    "                if show_message:\n",
    "                    print(f\"!-- Client {self.id} is normal and start iterations. ---!\")\n",
    "                loss_history, accuracy_history, error_history, time_history, delta_weights, delta_client_controls = iterate_Scaffold_client(self, server_controls, self.dataloader, num_epochs, self.optimizer, self.loss_func, self.accuracy_func, self.error_func, Scaffold_update_controls_use_gradient)\n",
    "        if plot_history:\n",
    "            plot_time_history(time_history)\n",
    "            plot_loss_history(loss_history)\n",
    "            plot_accuracy_history(accuracy_history)\n",
    "            plot_error_history(error_history)\n",
    "        return delta_weights, delta_client_controls\n",
    "\n",
    "# Establish client devices\n",
    "def establish_client_devices(num_clients, model_list, optimizer_list, dataset_list, batch_size_list, iterate_func_list, loss_func_list, accuracy_func_list, error_func_list):\n",
    "    client_device = [None] * num_clients\n",
    "    for client_id in range(num_clients):\n",
    "        client_device[client_id] = ClientDevice(client_id, model_list[client_id], optimizer_list[client_id], dataset_list[client_id], batch_size_list[client_id], iterate_func_list[client_id], loss_func_list[client_id], accuracy_func_list[client_id], error_func_list[client_id])\n",
    "    return client_device\n",
    "\n",
    "############################\n",
    "#    Adversarial Attack    #\n",
    "############################\n",
    "def adversarial_attack_by_value(model, value, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error):\n",
    "    for parameters in model.parameters():\n",
    "        parameters.data.fill_(value)\n",
    "    loss, accuracy, error = evaluate_model_simple(model=model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    print(f'Loss: {loss:.16f}, Accuracy: {accuracy:.16f}, Test Error: {error:.16f}')\n",
    "\n",
    "def adversarial_attack_by_random_range(model, value, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, torch.nn.Conv2d):\n",
    "            m.weight.data.uniform_(-value, value)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.uniform_(-value, value)\n",
    "        elif isinstance(m, torch.nn.Linear):\n",
    "            m.weight.data.uniform_(-value, value)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.uniform_(-value, value)\n",
    "    loss, accuracy, error = evaluate_model_simple(model=model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    print(f'Loss: {loss:.16f}, Accuracy: {accuracy:.16f}, Test Error: {error:.16f}')\n",
    "\n",
    "def adversarial_attack_by_train_scaling(model, scale_value, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error):\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    error_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        errors = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss.detach()\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "        loss_history.append(loss_average)\n",
    "        accuracy_history.append(accuracy_average)\n",
    "        error_history.append(error_average)\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss_average:.16f}, Accuracy: {accuracy_average:.16f}, Error: {error_average:.16f}')\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, torch.nn.Conv2d) or isinstance(m, torch.nn.Linear):\n",
    "            m.weight.data *= scale_value\n",
    "            if m.bias is not None:\n",
    "                m.bias.data *= scale_value\n",
    "    loss, accuracy,error = evaluate_model_simple(model=model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    print(f'After scaling weight with {scale_value}, Loss: {loss:.16f}, Accuracy: {accuracy:.16f}, Test Error: {error:.16f}')\n",
    "\n",
    "def adversarial_attack_by_value_Scaffold(client, value, server_controls, dataloader, num_epochs, all_bool, loss_func, accuracy_func, error_func, Scaffold_update_controls_use_gradient):\n",
    "    local_model = client.model\n",
    "    delta_weights = {}\n",
    "    delta_client_controls = {}\n",
    "    if all_bool is False:\n",
    "        client_controls = client.client_controls\n",
    "        client_controls_update = {}\n",
    "        old_model = copy.deepcopy(local_model)\n",
    "        temp = {}\n",
    "        for name, parameters in local_model.named_parameters():\n",
    "            parameters.data.fill_(value)\n",
    "            temp[name] = parameters.data.clone()\n",
    "        if Scaffold_update_controls_use_gradient is True:\n",
    "            old_model.zero_grad()\n",
    "            old_loss_grad_dict = {}\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                old_loss_grad_dict[name] = []\n",
    "            for batch in dataloader:\n",
    "                features, labels = batch\n",
    "                outputs = old_model(features)\n",
    "                loss = loss_func(outputs, labels)\n",
    "                loss.backward()\n",
    "                loss.detach()\n",
    "                for name, parameters in old_model.named_parameters():\n",
    "                    old_loss_grad_dict[name].append(parameters.grad.clone())\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                client_controls_update[name] = torch.from_numpy(np.mean(old_loss_grad_dict[name], axis=0)) / len(dataloader)\n",
    "                delta_weights[name] = temp[name] - parameters.data\n",
    "                delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "        else:\n",
    "            lr = client.optimizer.get_step_size()\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                client_controls_update[name] = client_controls[name] - server_controls[name] + (parameters.data - temp[name]) / (num_epochs * len(dataloader) * lr)\n",
    "                delta_weights[name] = temp[name] - parameters.data\n",
    "                delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "        client.client_controls = client_controls_update\n",
    "    else:\n",
    "        for name, parameters in local_model.named_parameters():\n",
    "            parameters.data.fill_(value)\n",
    "            delta_weights[name] = parameters.data.clone()\n",
    "            delta_client_controls[name] = parameters.data.clone()\n",
    "    loss, accuracy,error = evaluate_model_simple(model=local_model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    print(f'Loss: {loss:.16f}, Accuracy: {accuracy:.16f}, Test Error: {error:.16f}')\n",
    "    return delta_weights, delta_client_controls\n",
    "\n",
    "def adversarial_attack_by_control_variable_Scaffold(client, value, server_controls, dataloader, num_epochs, all_bool, loss_func, accuracy_func, error_func, Scaffold_update_controls_use_gradient):\n",
    "    local_model = client.model\n",
    "    optimizer = client.optimizer\n",
    "    old_model = copy.deepcopy(local_model)\n",
    "    client_controls = client.client_controls\n",
    "    lr = optimizer.get_step_size()\n",
    "    start_time = timeit.default_timer()\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        errors = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = local_model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step(server_controls, client_controls)\n",
    "            optimizer.zero_grad()\n",
    "            loss.detach()\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {loss_average:.16f}, Average Accuracy: {accuracy_average:.16f}, Average Error: {error_average:.16f}, Culminative Time Used: {time_used}')\n",
    "    \n",
    "    client_controls_update = {}\n",
    "    delta_weights = {}\n",
    "    delta_client_controls = {}\n",
    "    temp = {}\n",
    "    for name, parameters in local_model.named_parameters():\n",
    "        temp[name] = parameters.data.clone()\n",
    "    if Scaffold_update_controls_use_gradient is True:\n",
    "        old_model.zero_grad()\n",
    "        old_loss_grad_dict = {}\n",
    "        for name, parameters in old_model.named_parameters():\n",
    "            old_loss_grad_dict[name] = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = old_model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            loss.detach()\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                old_loss_grad_dict[name].append(parameters.grad.clone())\n",
    "        for name, parameters in old_model.named_parameters():\n",
    "            client_controls_update[name] = torch.from_numpy(np.mean(old_loss_grad_dict[name], axis=0)) / len(dataloader)\n",
    "            delta_weights[name] = temp[name] - parameters.data\n",
    "            delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "    else:\n",
    "        for name, parameters in old_model.named_parameters():\n",
    "            client_controls_update[name] = client_controls[name] - server_controls[name] + (parameters.data - temp[name]) / (num_epochs * len(dataloader) * lr)\n",
    "            delta_weights[name] = temp[name] - parameters.data\n",
    "            delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "\n",
    "    for name in delta_client_controls.keys():\n",
    "        delta_client_controls[name] = torch.full_like(delta_client_controls[name], value)\n",
    "\n",
    "    client.client_controls = client_controls_update\n",
    "\n",
    "    return delta_weights, delta_client_controls\n",
    "\n",
    "def adversarial_attack_by_random_range_Scaffold(client, value, server_controls, dataloader, num_epochs, all_bool, loss_func, accuracy_func, error_func, Scaffold_update_controls_use_gradient):\n",
    "    local_model = client.model\n",
    "    delta_weights = {}\n",
    "    delta_client_controls = {}\n",
    "    for m in local_model.modules():\n",
    "        if isinstance(m, torch.nn.Conv2d):\n",
    "            m.weight.data.uniform_(-value, value)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.uniform_(-value, value)\n",
    "        elif isinstance(m, torch.nn.Linear):\n",
    "            m.weight.data.uniform_(-value, value)\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.uniform_(-value, value)\n",
    "    loss, accuracy,error = evaluate_model_simple(model=local_model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    print(f'Loss: {loss:.16f}, Accuracy: {accuracy:.16f}, Test Error: {error:.16f}')\n",
    "    if all_bool is False:\n",
    "        client_controls = client.client_controls\n",
    "        client_controls_update = {}\n",
    "        old_model = copy.deepcopy(local_model)\n",
    "        temp = {}\n",
    "        for name, parameters in local_model.named_parameters():\n",
    "            temp[name] = parameters.data.clone()\n",
    "        if Scaffold_update_controls_use_gradient is True:\n",
    "            old_model.zero_grad()\n",
    "            old_loss_grad_dict = {}\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                old_loss_grad_dict[name] = []\n",
    "            for batch in dataloader:\n",
    "                features, labels = batch\n",
    "                outputs = old_model(features)\n",
    "                loss = loss_func(outputs, labels)\n",
    "                loss.backward()\n",
    "                loss.detach()\n",
    "                for name, parameters in old_model.named_parameters():\n",
    "                    old_loss_grad_dict[name].append(parameters.grad.clone())\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                client_controls_update[name] = torch.from_numpy(np.mean(old_loss_grad_dict[name], axis=0)) / len(dataloader)\n",
    "                delta_weights[name] = temp[name] - parameters.data\n",
    "                delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "        else:\n",
    "            lr = client.optimizer.get_step_size()\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                client_controls_update[name] = client_controls[name] - server_controls[name] + (parameters.data - temp[name]) / (num_epochs * len(dataloader) * lr)\n",
    "                delta_weights[name] = temp[name] - parameters.data\n",
    "                delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "        client.client_controls = client_controls_update\n",
    "    else:\n",
    "        for name, parameters in local_model.named_parameters():\n",
    "            delta_weights[name] = parameters.data.clone()\n",
    "            delta_client_controls[name] = parameters.data.clone()\n",
    "    loss, accuracy,error = evaluate_model_simple(model=local_model, dataloader=dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    print(f'Loss: {loss:.16f}, Accuracy: {accuracy:.16f}, Test Error: {error:.16f}')\n",
    "    return delta_weights, delta_client_controls\n",
    "\n",
    "#########################################\n",
    "#     Federated Learning Algorithms     #\n",
    "#########################################\n",
    "def federated_averaging(global_model, client_weights_total, num_clients, random_sample_client_number, global_step_size = 1.0):\n",
    "    aggregated_weights = {}\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        aggregated_weights[name] = torch.zeros_like(parameters.data)\n",
    "\n",
    "    for model in client_weights_total:\n",
    "        for name, parameters in global_model.named_parameters():\n",
    "            aggregated_weights[name] += model[name] / random_sample_client_number\n",
    "\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        parameters.data = global_step_size * aggregated_weights[name].data\n",
    "\n",
    "def federated_median(global_model, client_weights_total, num_clients, random_sample_client_number, global_step_size = 1.0):\n",
    "    aggregated_weights = {}\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        aggregated_weights[name] = []\n",
    "\n",
    "    for model in client_weights_total:\n",
    "        for name, parameters in global_model.named_parameters():\n",
    "            aggregated_weights[name].append(model[name])\n",
    "\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        parameters.data = global_step_size * torch.from_numpy(np.median(aggregated_weights[name], axis=0))\n",
    "\n",
    "def iterate_federated_learning_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, aggregate_func=federated_averaging, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True):\n",
    "    cost_history = [0]\n",
    "    time_history = [0]\n",
    "    adversary_history = [0]\n",
    "    straggler_history = [0]\n",
    "    \n",
    "    send_cost = 0.00\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    train_loss_history = []\n",
    "    train_accuracy_history = []\n",
    "    train_error_history = []\n",
    "    test_loss_history = []\n",
    "    test_accuracy_history = []\n",
    "    test_error_history = []\n",
    "\n",
    "    # Initial Loss, Accuracy, Error\n",
    "    train_loss, train_accuracy, train_error = evaluate_model_simple(model=global_model, dataloader=train_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "    train_error_history.append(train_error)\n",
    "\n",
    "    # Initialize server\n",
    "    num_clients = len(client_list)\n",
    "\n",
    "    if test_dataloader is not None:\n",
    "        test_loss, test_accuracy, test_error = evaluate_model_simple(model=global_model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        test_loss_history.append(test_loss)\n",
    "        test_accuracy_history.append(test_accuracy)\n",
    "        test_error_history.append(test_error)\n",
    "\n",
    "    for epoch in range(global_epochs):\n",
    "        global_weights = global_model.state_dict()\n",
    "        client_weights_total = []\n",
    "        random_client_list = random.sample(client_list, random_sample_client_number)\n",
    "        num_adversary_in_round = 0\n",
    "        num_straggler_in_round = 0\n",
    "        for client in random_client_list:\n",
    "            send_cost += sum(value.numel() for value in global_weights.values())\n",
    "            client.load_global_model(global_model)\n",
    "            client_weights = client.train(num_epochs=local_epochs)\n",
    "            client_weights_total.append(client_weights)\n",
    "            send_cost += sum(value.numel() for value in client_weights.values())\n",
    "            if client.adversary is True:\n",
    "               num_adversary_in_round += 1\n",
    "            else:\n",
    "                if client.straggler is True:\n",
    "                   num_straggler_in_round += 1\n",
    "        aggregate_func(global_model, client_weights_total, num_clients, random_sample_client_number)\n",
    "\n",
    "        # Record\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        cost_history.append(send_cost)\n",
    "        time_history.append(time_used)\n",
    "        adversary_history.append(num_adversary_in_round)\n",
    "        straggler_history.append(num_straggler_in_round)\n",
    "\n",
    "        train_loss, train_accuracy, train_error = evaluate_model_simple(model=global_model, dataloader=train_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "        train_error_history.append(train_error)\n",
    "\n",
    "        if test_dataloader is not None:\n",
    "            test_loss, test_accuracy, test_error = evaluate_model_simple(model=global_model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "            test_loss_history.append(test_loss)\n",
    "            test_accuracy_history.append(test_accuracy)\n",
    "            test_error_history.append(test_error)\n",
    "\n",
    "        if show_history:\n",
    "            print(\"!-- Server Model Status --!\")\n",
    "            print(f'Epoch [{epoch+1}/{global_epochs}], Culminative Send Cost: {send_cost}, Culminative Time Used: {time_used}')\n",
    "            print(f'Train Loss: {train_loss:.16f}, Train Accuracy: {train_accuracy:.16f}, Train Error: {train_error:.16f}')\n",
    "            if test_dataloader is not None:\n",
    "                print(f'Test Loss: {test_loss:.16f}, Test Accuracy: {test_accuracy:.16f}, Test Error: {test_error:.16f}')\n",
    "            print(f'Number of adversaries sampled: {num_adversary_in_round}, Number of stragglers sampled: {num_straggler_in_round}')\n",
    "\n",
    "    return cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "#################################\n",
    "#  FedProx Framework Algorithm  #\n",
    "#################################\n",
    "def iterate_model_FedProx(model, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True):\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    error_history = []\n",
    "    time_history = [0]\n",
    "    start_time = timeit.default_timer()\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        errors = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = model(features)\n",
    "            proximal_term = 0.0\n",
    "            for w, w_t in zip(model.parameters(), FedProx_global_model.parameters()):\n",
    "                proximal_term += torch.square((w - w_t).norm(2))\n",
    "            loss = loss_func(outputs, labels) + (FedProx_mu / 2) * proximal_term\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss.detach()\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        time_history.append(time_used)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "        loss_history.append(loss_average)\n",
    "        accuracy_history.append(accuracy_average)\n",
    "        error_history.append(error_average)\n",
    "        if show_history:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {loss_average:.16f}, Average Accuracy: {accuracy_average:.16f}, Average Error: {error_average:.16f}, Culminative Time Used: {time_used}')\n",
    "    return loss_history, accuracy_history, error_history, time_history\n",
    "\n",
    "##################################\n",
    "#  SCAFFOLD Framework Algorithm  #\n",
    "##################################\n",
    "# Inspired by https://github.com/ki-ljl/Scaffold-Federated-Learning/blob/main/ScaffoldOptimizer.py\n",
    "# c: server_controls, ci: client_controls\n",
    "class ScaffoldOptimizer(Optimizer):\n",
    "    def __init__(self, params, lr=required, weight_decay=None):\n",
    "        if lr is not required and lr < 0.0:\n",
    "            raise ValueError(f\"Invalid learning rate: {lr}\")\n",
    "        if weight_decay is not None and weight_decay < 0.0:\n",
    "            raise ValueError(f\"Invalid weight_decay value: {weight_decay}\")\n",
    "        defaults = dict(lr=lr, weight_decay=weight_decay)\n",
    "        super(ScaffoldOptimizer, self).__init__(params, defaults)\n",
    "                \n",
    "    def step(self, server_controls, client_controls):\n",
    "        for group in self.param_groups:\n",
    "            weight_decay = group['weight_decay']\n",
    "            lr = group['lr']\n",
    "            for parameters, c, ci in zip(group['params'], server_controls.values(), client_controls.values()):\n",
    "                if parameters.grad is None:\n",
    "                    continue\n",
    "                parameters_derivative = parameters.grad.data - ci.data + c.data\n",
    "                if weight_decay is not None:\n",
    "                    parameters.data = weight_decay * parameters.data - lr * parameters_derivative.data\n",
    "                else:\n",
    "                    parameters.data = parameters.data - lr * parameters_derivative.data\n",
    "\n",
    "    def get_step_size(self):\n",
    "        return self.param_groups[0]['lr']\n",
    "\n",
    "def iterate_Scaffold_client(client, server_controls, dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, Scaffold_update_controls_use_gradient=True, show_history=True):\n",
    "    local_model = client.model\n",
    "    old_model = copy.deepcopy(local_model)\n",
    "    client_controls = client.client_controls\n",
    "    lr = optimizer.get_step_size()\n",
    "    loss_history = []\n",
    "    accuracy_history = []\n",
    "    error_history = []\n",
    "    time_history = [0]\n",
    "    start_time = timeit.default_timer()\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "        accuracies = []\n",
    "        errors = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = local_model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = accuracy_func(outputs, labels)\n",
    "            error = error_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step(server_controls, client_controls)\n",
    "            optimizer.zero_grad()\n",
    "            loss.detach()\n",
    "            losses.append(loss)\n",
    "            accuracies.append(accuracy)\n",
    "            errors.append(error)\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        time_history.append(time_used)\n",
    "        loss_average = torch.stack(losses).mean().item()\n",
    "        accuracy_average = torch.stack(accuracies).mean().item()\n",
    "        error_average = torch.stack(errors).mean().item()\n",
    "        loss_history.append(loss_average)\n",
    "        accuracy_history.append(accuracy_average)\n",
    "        error_history.append(error_average)\n",
    "        if show_history:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Average Loss: {loss_average:.16f}, Average Accuracy: {accuracy_average:.16f}, Average Error: {error_average:.16f}, Culminative Time Used: {time_used}')\n",
    "    \n",
    "    client_controls_update = {}\n",
    "    delta_weights = {}\n",
    "    delta_client_controls = {}\n",
    "    temp = {}\n",
    "    for name, parameters in local_model.named_parameters():\n",
    "        temp[name] = parameters.data.clone()\n",
    "    if Scaffold_update_controls_use_gradient is True:\n",
    "        old_model.zero_grad()\n",
    "        old_loss_grad_dict = {}\n",
    "        for name, parameters in old_model.named_parameters():\n",
    "            old_loss_grad_dict[name] = []\n",
    "        for batch in dataloader:\n",
    "            features, labels = batch\n",
    "            outputs = old_model(features)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward()\n",
    "            loss.detach()\n",
    "            for name, parameters in old_model.named_parameters():\n",
    "                old_loss_grad_dict[name].append(parameters.grad.clone())\n",
    "        for name, parameters in old_model.named_parameters():\n",
    "            client_controls_update[name] = torch.from_numpy(np.mean(old_loss_grad_dict[name], axis=0)) / len(dataloader)\n",
    "            delta_weights[name] = temp[name] - parameters.data\n",
    "            delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "    else:\n",
    "        for name, parameters in old_model.named_parameters():\n",
    "            client_controls_update[name] = client_controls[name] - server_controls[name] + (parameters.data - temp[name]) / (num_epochs * len(dataloader) * lr)\n",
    "            delta_weights[name] = temp[name] - parameters.data\n",
    "            delta_client_controls[name] = client_controls_update[name] - client_controls[name]\n",
    "    print(client_controls_update)\n",
    "\n",
    "    client.client_controls = client_controls_update\n",
    "\n",
    "    return loss_history, accuracy_history, error_history, time_history, delta_weights, delta_client_controls\n",
    "\n",
    "def federated_averaging_Scaffold(global_model, server_controls, delta_weights_total, delta_client_controls_total, num_clients, random_sample_client_number, global_step_size = 1.0):\n",
    "    aggregated_weights = {}\n",
    "    aggregated_client_controls = {}\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        aggregated_weights[name] = torch.zeros_like(parameters.data)\n",
    "        aggregated_client_controls[name] = torch.zeros_like(parameters.data)\n",
    "\n",
    "    for delta_weights, delta_client_controls in zip(delta_weights_total, delta_client_controls_total):\n",
    "        for name, parameters in global_model.named_parameters():\n",
    "            aggregated_weights[name] += delta_weights[name] / random_sample_client_number\n",
    "            aggregated_client_controls[name] += delta_client_controls[name] / random_sample_client_number\n",
    "\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        parameters.data += global_step_size * aggregated_weights[name].data\n",
    "        server_controls[name].data += (random_sample_client_number / num_clients) * aggregated_client_controls[name].data\n",
    "\n",
    "def federated_median_Scaffold(global_model, server_controls, delta_weights_total, delta_client_controls_total, num_clients, random_sample_client_number, global_step_size = 1.0):\n",
    "    aggregated_weights = {}\n",
    "    aggregated_client_controls = {}\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        aggregated_weights[name] = []\n",
    "        aggregated_client_controls[name] = []\n",
    "\n",
    "    for delta_weights, delta_client_controls in zip(delta_weights_total, delta_client_controls_total):\n",
    "        for name, parameters in global_model.named_parameters():\n",
    "            aggregated_weights[name].append(delta_weights[name])\n",
    "            aggregated_client_controls[name].append(delta_client_controls[name])\n",
    "\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        parameters.data += global_step_size * torch.from_numpy(np.median(aggregated_weights[name], axis=0))\n",
    "        server_controls[name].data += (random_sample_client_number / num_clients) * torch.from_numpy(np.median(aggregated_client_controls[name], axis=0))\n",
    "\n",
    "def iterate_Scaffold_global(train_dataloader, test_dataloader, global_model, client_list, random_sample_client_number, global_epochs, global_step_size, local_epochs, Scaffold_update_controls_use_gradient=False, aggregate_func=federated_averaging_Scaffold, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True):\n",
    "    cost_history = [0]\n",
    "    time_history = [0]\n",
    "    adversary_history = [0]\n",
    "    straggler_history = [0]\n",
    "    \n",
    "    send_cost = 0.00\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    train_loss_history = []\n",
    "    train_accuracy_history = []\n",
    "    train_error_history = []\n",
    "    test_loss_history = []\n",
    "    test_accuracy_history = []\n",
    "    test_error_history = []\n",
    "\n",
    "    # Initial Loss, Accuracy, Error\n",
    "    train_loss, train_accuracy, train_error = evaluate_model_simple(model=global_model, dataloader=train_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "    train_loss_history.append(train_loss)\n",
    "    train_accuracy_history.append(train_accuracy)\n",
    "    train_error_history.append(train_error)\n",
    "\n",
    "    if test_dataloader is not None:\n",
    "        test_loss, test_accuracy, test_error = evaluate_model_simple(model=global_model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        test_loss_history.append(test_loss)\n",
    "        test_accuracy_history.append(test_accuracy)\n",
    "        test_error_history.append(test_error)\n",
    "\n",
    "    # Initialize server and client controls\n",
    "    num_clients = len(client_list)\n",
    "    server_controls = {}\n",
    "    for name, parameters in global_model.named_parameters():\n",
    "        server_controls[name] = torch.zeros_like(parameters.data)\n",
    "    for client in client_list:\n",
    "        for name, parameters in client.model.named_parameters():\n",
    "            client.client_controls[name] = torch.zeros_like(parameters.data)\n",
    "\n",
    "    for epoch in range(global_epochs):\n",
    "        global_weights = global_model.state_dict()\n",
    "        delta_weights_total = []\n",
    "        delta_client_controls_total = []\n",
    "        random_client_list = random.sample(client_list, random_sample_client_number)\n",
    "        num_adversary_in_round = 0\n",
    "        num_straggler_in_round = 0\n",
    "        for client in random_client_list:\n",
    "            send_cost += sum(value.numel() for value in global_weights.values())\n",
    "            send_cost += sum(value.numel() for value in server_controls.values())\n",
    "            client.load_global_model(global_model)\n",
    "            delta_weights, delta_client_controls = client.train_Scaffold(server_controls, local_epochs, Scaffold_update_controls_use_gradient)\n",
    "            delta_weights_total.append(delta_weights)\n",
    "            delta_client_controls_total.append(delta_client_controls)\n",
    "            send_cost += sum(value.numel() for value in delta_weights.values())\n",
    "            send_cost += sum(value.numel() for value in delta_client_controls.values())\n",
    "            if client.adversary is True:\n",
    "               num_adversary_in_round += 1\n",
    "            else:\n",
    "                if client.straggler is True:\n",
    "                   num_straggler_in_round += 1\n",
    "        aggregate_func(global_model, server_controls, delta_weights_total, delta_client_controls_total, num_clients, random_sample_client_number, global_step_size)\n",
    "\n",
    "        # Record\n",
    "        time_used = timeit.default_timer() - start_time\n",
    "        cost_history.append(send_cost)\n",
    "        time_history.append(time_used)\n",
    "        adversary_history.append(num_adversary_in_round)\n",
    "        straggler_history.append(num_straggler_in_round)\n",
    "\n",
    "        train_loss, train_accuracy, train_error = evaluate_model_simple(model=global_model, dataloader=train_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "        train_loss_history.append(train_loss)\n",
    "        train_accuracy_history.append(train_accuracy)\n",
    "        train_error_history.append(train_error)\n",
    "\n",
    "        if test_dataloader is not None:\n",
    "            test_loss, test_accuracy, test_error = evaluate_model_simple(model=global_model, dataloader=test_dataloader, loss_func=loss_func, accuracy_func=accuracy_func, error_func=error_func)\n",
    "            test_loss_history.append(test_loss)\n",
    "            test_accuracy_history.append(test_accuracy)\n",
    "            test_error_history.append(test_error)\n",
    "\n",
    "        if show_history:\n",
    "            print(\"!-- Server Model Status --!\")\n",
    "            print(f'Epoch [{epoch+1}/{global_epochs}], Culminative Send Cost: {send_cost}, Culminative Time Used: {time_used}')\n",
    "            print(f'Train Loss: {train_loss:.16f}, Train Accuracy: {train_accuracy:.16f}, Train Error: {train_error:.16f}')\n",
    "            if test_dataloader is not None:\n",
    "                print(f'Test Loss: {test_loss:.16f}, Test Accuracy: {test_accuracy:.16f}, Test Error: {test_error:.16f}')\n",
    "            print(f'Number of adversaries sampled: {num_adversary_in_round}, Number of stragglers sampled: {num_straggler_in_round}')\n",
    "\n",
    "    return cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "############################\n",
    "#    Training Algorithm    #\n",
    "############################\n",
    "global save_file_extra_information\n",
    "save_file_extra_information = \"None.\"\n",
    "def train_neural_network_model(model, train_dataloader, test_dataloader, num_epochs, optimizer, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True, save_result=True, save_path_str=\"Centralized\"):\n",
    "    if test_dataloader is not None:\n",
    "        train_loss_history, train_accuracy_history, train_error_history, time_history, test_loss_history, test_accuracy_history, test_error_history = iterate_model_simple(model, train_dataloader, num_epochs, optimizer, loss_func, accuracy_func, error_func, show_history, test_dataloader, True)\n",
    "    else:\n",
    "        train_loss_history, train_accuracy_history, train_error_history, time_history = iterate_model_simple(model, train_dataloader, num_epochs, optimizer, loss_func, accuracy_func, error_func, show_history, True)\n",
    "\n",
    "    # Print learned parameters\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f'{name}: {param.data}')\n",
    "    \n",
    "    # Save Results\n",
    "    if save_result:\n",
    "        filename = \"{}_{}_{}.npy\".format(save_path_str, train_start_time, experiment_id)\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.savez(f, time_history=time_history, train_loss_history=train_loss_history, train_accuracy_history=train_accuracy_history, train_error_history=train_error_history, test_loss_history=test_loss_history, test_accuracy_history=test_accuracy_history, test_error_history=test_error_history, extra_information=save_file_extra_information)\n",
    "        torch.save(model.state_dict(), filename + \"_model_state_dict.pth\")\n",
    "        logname = \"{}_{}_{}.txt\".format(save_path_str, train_start_time, experiment_id)\n",
    "        with open(logname, 'wb') as f:\n",
    "            f.write(save_file_extra_information.encode('utf-8'))\n",
    "\n",
    "    # Graph\n",
    "    if show_history:\n",
    "        plot_time_history([time_history])\n",
    "        plot_loss_history([train_loss_history], [test_loss_history])\n",
    "        plot_accuracy_history([train_accuracy_history], [test_accuracy_history])\n",
    "        plot_error_history([train_error_history], [test_error_history])\n",
    "    \n",
    "    return time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "def train_federated_learning_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, aggregate_func=federated_averaging, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True, save_result=True, save_path_str=\"FederatedLearning\"):\n",
    "    cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = iterate_federated_learning_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, aggregate_func, loss_func, accuracy_func, error_func, show_history)\n",
    "\n",
    "    # Print learned parameters\n",
    "    for name, param in global_model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f'{name}: {param.data}')\n",
    "    \n",
    "    # Save Results\n",
    "    if save_result:\n",
    "        filename = \"{}_{}_{}.npy\".format(save_path_str, train_start_time, experiment_id)\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.savez(f, cost_history=cost_history, time_history=time_history, adversary_history=adversary_history, straggler_history=straggler_history, train_loss_history=train_loss_history, train_accuracy_history=train_accuracy_history, train_error_history=train_error_history, test_loss_history=test_loss_history, test_accuracy_history=test_accuracy_history, test_error_history=test_error_history, extra_information=save_file_extra_information)\n",
    "        torch.save(global_model.state_dict(), filename + \"_model_state_dict.pth\")\n",
    "        logname = \"{}_{}_{}.txt\".format(save_path_str, train_start_time, experiment_id)\n",
    "        with open(logname, 'wb') as f:\n",
    "            f.write(save_file_extra_information.encode('utf-8'))\n",
    "\n",
    "    # Graph\n",
    "    if show_history:\n",
    "        plot_cost_history([cost_history])\n",
    "        plot_time_history([time_history])\n",
    "        plot_loss_history([train_loss_history], [test_loss_history])\n",
    "        plot_accuracy_history([train_accuracy_history], [test_accuracy_history])\n",
    "        plot_error_history([train_error_history], [test_error_history])\n",
    "        plot_adversary_history([adversary_history])\n",
    "        plot_straggler_history([straggler_history])\n",
    "    \n",
    "    return cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "def train_Scaffold_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, global_step_size, Scaffold_update_controls_use_gradient, aggregate_func=federated_averaging_Scaffold, loss_func=torch.nn.functional.cross_entropy, accuracy_func=get_accuracy, error_func=get_error, show_history=True, save_result=True, save_path_str=\"Scaffold\"):\n",
    "    cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = iterate_Scaffold_global(train_dataloader, test_dataloader, global_model, client_list, random_sample_client_number, global_epochs, global_step_size, local_epochs, Scaffold_update_controls_use_gradient, aggregate_func, loss_func, accuracy_func, error_func, show_history)\n",
    "\n",
    "    # Print learned parameters\n",
    "    for name, param in global_model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            print(f'{name}: {param.data}')\n",
    "    \n",
    "    # Save Results\n",
    "    if save_result:\n",
    "        filename = \"{}_{}_{}.npy\".format(save_path_str, train_start_time, experiment_id)\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.savez(f, cost_history=cost_history, time_history=time_history, adversary_history=adversary_history, straggler_history=straggler_history, train_loss_history=train_loss_history, train_accuracy_history=train_accuracy_history, train_error_history=train_error_history, test_loss_history=test_loss_history, test_accuracy_history=test_accuracy_history, test_error_history=test_error_history, extra_information=save_file_extra_information)\n",
    "        torch.save(global_model.state_dict(), filename + \"_model_state_dict.pth\")\n",
    "        logname = \"{}_{}_{}.txt\".format(save_path_str, train_start_time, experiment_id)\n",
    "        with open(logname, 'wb') as f:\n",
    "            f.write(save_file_extra_information.encode('utf-8'))\n",
    "\n",
    "    # Graph\n",
    "    if show_history:\n",
    "        plot_cost_history([cost_history])\n",
    "        plot_time_history([time_history])\n",
    "        plot_loss_history([train_loss_history], [test_loss_history])\n",
    "        plot_accuracy_history([train_accuracy_history], [test_accuracy_history])\n",
    "        plot_error_history([train_error_history], [test_error_history])\n",
    "        plot_adversary_history([adversary_history])\n",
    "        plot_straggler_history([straggler_history])\n",
    "    \n",
    "    return cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history\n",
    "\n",
    "############################\n",
    "#   Experiment Functions   #\n",
    "############################\n",
    "def experiment_neural_network_model(train_dataset, test_dataset, modelClass, optimizerClass, train_func, epochs_list, learning_rate_list, batch_size_list, loss_func_list, accuracy_func_list, error_func_list, experiment_rounds = 1, show_history=True, save_result=True):\n",
    "    global experiment_id\n",
    "    experiment_id = 0\n",
    "\n",
    "    epochs_list = convert_to_list(epochs_list)\n",
    "    learning_rate_list = convert_to_list(learning_rate_list)\n",
    "    batch_size_list = convert_to_list(batch_size_list)\n",
    "    loss_func_list = convert_to_list(loss_func_list)\n",
    "    accuracy_func_list = convert_to_list(accuracy_func_list)\n",
    "    error_func_list = convert_to_list(error_func_list)\n",
    "\n",
    "    time_history_total = []\n",
    "    train_loss_history_total = []\n",
    "    train_accuracy_history_total = []\n",
    "    train_error_history_total = []\n",
    "    test_loss_history_total = []\n",
    "    test_accuracy_history_total = []\n",
    "    test_error_history_total = []\n",
    "    \n",
    "    for n in range(experiment_rounds):\n",
    "        experiment_id = experiment_id + 1\n",
    "        print(f'=== Training Experiment {experiment_id} ===')\n",
    "        print(f'number of epochs is {epochs_list[min(n, len(epochs_list) - 1)]}')\n",
    "        num_epochs = epochs_list[min(n, len(epochs_list) - 1)]\n",
    "        print(f'learning rate is {learning_rate_list[min(n, len(learning_rate_list) - 1)]}')\n",
    "        learning_rate = learning_rate_list[min(n, len(learning_rate_list) - 1)]\n",
    "        print(f'batch size is {batch_size_list[min(n, len(batch_size_list) - 1)]}')\n",
    "        batch_size = batch_size_list[min(n, len(batch_size_list) - 1)]\n",
    "        print(f'loss function is {loss_func_list[min(n, len(loss_func_list) - 1)].__name__}')\n",
    "        loss_func = loss_func_list[min(n, len(loss_func_list) - 1)]\n",
    "        print(f'accuracy function is {accuracy_func_list[min(n, len(accuracy_func_list) - 1)].__name__}')\n",
    "        accuracy_func = accuracy_func_list[min(n, len(accuracy_func_list) - 1)]\n",
    "        print(f'error function is {error_func_list[min(n, len(error_func_list) - 1)].__name__}')\n",
    "        error_func = error_func_list[min(n, len(error_func_list) - 1)]\n",
    "        \n",
    "        global_model = to_device(modelClass(), device)\n",
    "        print(global_model)\n",
    "        print(global_model.state_dict())\n",
    "\n",
    "        train_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True), device)\n",
    "        test_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False), device)\n",
    "\n",
    "        optimizer = optimizerClass(global_model.parameters(), learning_rate)\n",
    "\n",
    "        save_path_str = f\"{current_dataset_name}_Centralized_E_{num_epochs}_lr_{learning_rate}_B_{batch_size}\"\n",
    "\n",
    "        global save_file_extra_information\n",
    "        save_file_extra_information = f\"\"\"\n",
    "        === {save_path_str} ===\n",
    "        The experiment ID is: {experiment_id}\n",
    "        The train start time is: {train_start_time}\n",
    "        The dataset is: {current_dataset_name}\n",
    "        [should be Centralized Training]\n",
    "\n",
    "        experiment_rounds = {experiment_rounds}\n",
    "\n",
    "        modelType = {modelClass.__name__}\n",
    "        optimizerType = {optimizerClass.__name__}\n",
    "\n",
    "        num_epochs_list = {epochs_list}\n",
    "        learning_rate_list = {learning_rate_list}\n",
    "        batch_size_list = {batch_size_list}\n",
    "        loss_func_list = {loss_func_list}\n",
    "        accuracy_func_list = {accuracy_func_list}\n",
    "        error_func_list = {error_func_list}\n",
    "\n",
    "        !-- Current Status --!\n",
    "        num_epochs = {num_epochs}\n",
    "        learning_rate = {learning_rate}\n",
    "        batch_size = {batch_size}\n",
    "        loss_func = {loss_func.__name__}\n",
    "        accuracy_func = {accuracy_func.__name__}\n",
    "        error_func = {error_func.__name__}\n",
    "        \"\"\"\n",
    "\n",
    "        time_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = train_func(global_model, train_dataloader, test_dataloader, num_epochs, optimizer, loss_func, accuracy_func, error_func, show_history, save_result, save_path_str)\n",
    "\n",
    "        time_history_total.append(time_history)\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        train_accuracy_history_total.append(train_accuracy_history)\n",
    "        train_error_history_total.append(train_error_history)\n",
    "        test_loss_history_total.append(test_loss_history)\n",
    "        test_accuracy_history_total.append(test_accuracy_history)\n",
    "        test_error_history_total.append(test_error_history)\n",
    "    \n",
    "    print(f'=== The Experiment Result ===')\n",
    "    print(f'Name of current dataset: {current_dataset_name}')\n",
    "    plot_time_history(time_history_total)\n",
    "    plot_loss_history(train_loss_history_total, test_loss_history_total)\n",
    "    plot_accuracy_history(train_accuracy_history_total, test_accuracy_history_total)\n",
    "    plot_error_history(train_error_history_total, test_error_history_total)\n",
    "\n",
    "def experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelClass, optimizerClass, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list = [0], adversary_attack_func_list = None, adversary_attack_value_list = 0, experiment_rounds = 1, show_history=True, save_result=True):\n",
    "    global experiment_id\n",
    "    experiment_id = 0\n",
    "\n",
    "    global_epochs_list = convert_to_list(global_epochs_list)\n",
    "    local_epochs_list = convert_to_list(local_epochs_list)\n",
    "    num_clients_list = convert_to_list(num_clients_list)\n",
    "    random_sample_client_number_list = convert_to_list(random_sample_client_number_list)\n",
    "    learning_rate_list = convert_to_list(learning_rate_list)\n",
    "    batch_size_list = convert_to_list(batch_size_list)\n",
    "    aggregate_func_list = convert_to_list(aggregate_func_list)\n",
    "    loss_func_list = convert_to_list(loss_func_list)\n",
    "    accuracy_func_list = convert_to_list(accuracy_func_list)\n",
    "    error_func_list = convert_to_list(error_func_list)\n",
    "    adversary_list = convert_to_list(adversary_list)\n",
    "    adversary_attack_func_list = convert_to_list(adversary_attack_func_list)\n",
    "    adversary_attack_value_list = convert_to_list(adversary_attack_value_list)\n",
    "\n",
    "    cost_history_total = []\n",
    "    time_history_total = []\n",
    "    adversary_history_total = []\n",
    "    straggler_history_total = []\n",
    "    train_loss_history_total = []\n",
    "    train_accuracy_history_total = []\n",
    "    train_error_history_total = []\n",
    "    test_loss_history_total = []\n",
    "    test_accuracy_history_total = []\n",
    "    test_error_history_total = []\n",
    "\n",
    "    for n in range(experiment_rounds):\n",
    "        experiment_id = experiment_id + 1\n",
    "        print(f'=== Training Experiment {experiment_id} ===')\n",
    "        print(f'global epochs is {global_epochs_list[min(n, len(global_epochs_list) - 1)]}')\n",
    "        global_epochs = global_epochs_list[min(n, len(global_epochs_list) - 1)]\n",
    "        print(f'local epochs is {local_epochs_list[min(n, len(local_epochs_list) - 1)]}')\n",
    "        local_epochs = local_epochs_list[min(n, len(local_epochs_list) - 1)]\n",
    "        print(f'num clients is {num_clients_list[min(n, len(num_clients_list) - 1)]}')\n",
    "        num_clients = num_clients_list[min(n, len(num_clients_list) - 1)]\n",
    "        print(f'random sample client number is {random_sample_client_number_list[min(n, len(random_sample_client_number_list) - 1)]}')\n",
    "        random_sample_client_number = random_sample_client_number_list[min(n, len(random_sample_client_number_list) - 1)]\n",
    "        print(f'learning rate is {learning_rate_list[min(n, len(learning_rate_list) - 1)]}')\n",
    "        learning_rate = learning_rate_list[min(n, len(learning_rate_list) - 1)]\n",
    "        print(f'batch size is {batch_size_list[min(n, len(batch_size_list) - 1)]}')\n",
    "        batch_size = batch_size_list[min(n, len(batch_size_list) - 1)]\n",
    "        print(f'aggregate function is {aggregate_func_list[min(n, len(aggregate_func_list) - 1)].__name__}')\n",
    "        aggregate_func = aggregate_func_list[min(n, len(aggregate_func_list) - 1)]\n",
    "        print(f'loss function is {loss_func_list[min(n, len(loss_func_list) - 1)].__name__}')\n",
    "        loss_func = loss_func_list[min(n, len(loss_func_list) - 1)]\n",
    "        print(f'accuracy function is {accuracy_func_list[min(n, len(accuracy_func_list) - 1)].__name__}')\n",
    "        accuracy_func = accuracy_func_list[min(n, len(accuracy_func_list) - 1)]\n",
    "        print(f'error function is {error_func_list[min(n, len(error_func_list) - 1)].__name__}')\n",
    "        error_func = error_func_list[min(n, len(error_func_list) - 1)]\n",
    "        print(f'adversary is {adversary_list[min(n, len(adversary_list) - 1)]}')\n",
    "        adversary = adversary_list[min(n, len(adversary_list) - 1)]\n",
    "        print(f'adversary attack function is {adversary_attack_func_list[min(n, len(adversary_attack_func_list) - 1)]}')\n",
    "        adversary_attack_func = adversary_attack_func_list[min(n, len(adversary_attack_func_list) - 1)]\n",
    "        print(f'adversary attack value is {adversary_attack_value_list[min(n, len(adversary_attack_value_list) - 1)]}')\n",
    "        adversary_attack_value = adversary_attack_value_list[min(n, len(adversary_attack_value_list) - 1)]\n",
    "        \n",
    "        global_model = to_device(modelClass(), device)\n",
    "        print(global_model)\n",
    "        print(global_model.state_dict())\n",
    "\n",
    "        train_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True), device)\n",
    "        test_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False), device)\n",
    "\n",
    "        print(\"Establishing client devices...\")\n",
    "\n",
    "        client_model_list = [to_device(modelClass(), device)] * num_clients\n",
    "        client_optimizer_list = [optimizerClass(model.parameters(), learning_rate) for model in client_model_list]\n",
    "        client_dataset_list = dataset_distributing_func(train_dataset, num_clients)\n",
    "        print(f'Training dataset has been distributed into {len(client_dataset_list)} pieces.')\n",
    "        client_batch_size_list = [batch_size] * num_clients\n",
    "        client_itera_func_list = [itera_func] * num_clients\n",
    "        client_loss_func_list = [loss_func] * num_clients\n",
    "        client_accuracy_func_list = [accuracy_func] * num_clients\n",
    "        client_error_func_list = [error_func] * num_clients\n",
    "        client_list = establish_client_devices(num_clients, client_model_list, client_optimizer_list, client_dataset_list, client_batch_size_list, client_itera_func_list, client_loss_func_list, client_accuracy_func_list, client_error_func_list)\n",
    "\n",
    "        for i in range(adversary):\n",
    "            client_list[i].adversary = True\n",
    "            client_list[i].adversary_attack_func = adversary_attack_func\n",
    "            client_list[i].adversary_attack_value = adversary_attack_value\n",
    "\n",
    "        # Visualize the client dataset. Please comment these codes to avoid a long code output if necessary.\n",
    "        #for i in range(len(client_list)):\n",
    "        #    print(client_dataset_list[i])\n",
    "\n",
    "        print(f'Established {len(client_list)} client devices.')\n",
    "\n",
    "        save_path_str = f\"{current_dataset_name}_{current_method_name}_GE_{global_epochs}_LE_{local_epochs}_C_{num_clients}_RC_{random_sample_client_number}_lr_{learning_rate}_B_{batch_size}\"\n",
    "\n",
    "        global save_file_extra_information\n",
    "        save_file_extra_information = f\"\"\"\n",
    "        === {save_path_str} ===\n",
    "        The experiment ID is: {experiment_id}\n",
    "        The train start time is: {train_start_time}\n",
    "        The dataset is: {current_dataset_name}\n",
    "        current_method_name = {current_method_name}\n",
    "        [should be FedAvg]\n",
    "\n",
    "        experiment_rounds = {experiment_rounds}\n",
    "\n",
    "        modelType = {modelClass.__name__}\n",
    "        itera_func = {itera_func.__name__}\n",
    "        optimizerType = {optimizerClass.__name__}\n",
    "        dataset_distributing_func = {dataset_distributing_func.__name__}\n",
    "\n",
    "        custom_split_dataset_iid = {custom_split_dataset_iid}\n",
    "        custom_split_dataset_power_law = {custom_split_dataset_power_law}\n",
    "        custom_split_dataset_balance = {custom_split_dataset_balance}\n",
    "        custom_split_dataset_seed = {custom_split_dataset_seed}\n",
    "\n",
    "        global_epochs_list = {global_epochs_list}\n",
    "        local_epochs_list = {local_epochs_list}\n",
    "        num_clients_list = {num_clients_list}\n",
    "        random_sample_client_number_list = {random_sample_client_number_list}\n",
    "        learning_rate_list = {learning_rate_list}\n",
    "        batch_size_list = {batch_size_list}\n",
    "        aggregate_func_list = {aggregate_func_list}\n",
    "        loss_func_list = {loss_func_list}\n",
    "        accuracy_func_list = {accuracy_func_list}\n",
    "        error_func_list = {error_func_list}\n",
    "        adversary_list = {adversary_list}\n",
    "        adversary_attack_func_list = {adversary_attack_func_list}\n",
    "        adversary_attack_value_list = {adversary_attack_value_list}\n",
    "\n",
    "        !-- Current Status --!\n",
    "        global_epochs = {global_epochs}\n",
    "        local_epochs = {local_epochs}\n",
    "        num_clients = {num_clients}\n",
    "        random_sample_client_number = {random_sample_client_number}\n",
    "        learning_rate = {learning_rate}\n",
    "        batch_size = {batch_size}\n",
    "        aggregate_func = {aggregate_func.__name__}\n",
    "        loss_func = {loss_func.__name__}\n",
    "        accuracy_func = {accuracy_func.__name__}\n",
    "        error_func = {error_func.__name__}\n",
    "        adversary = {adversary}\n",
    "        adversary_attack_func = {adversary_attack_func}\n",
    "        adversary_attack_value = {adversary_attack_value}\n",
    "        \"\"\"\n",
    "\n",
    "        cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = train_federated_learning_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, aggregate_func, loss_func, accuracy_func, error_func, show_history, save_result, save_path_str)\n",
    "\n",
    "        cost_history_total.append(cost_history)\n",
    "        time_history_total.append(time_history)\n",
    "        adversary_history_total.append(adversary_history)\n",
    "        straggler_history_total.append(straggler_history)\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        train_accuracy_history_total.append(train_accuracy_history)\n",
    "        train_error_history_total.append(train_error_history)\n",
    "        test_loss_history_total.append(test_loss_history)\n",
    "        test_accuracy_history_total.append(test_accuracy_history)\n",
    "        test_error_history_total.append(test_error_history)\n",
    "    \n",
    "    print(f'=== The Experiment Result ===')\n",
    "    print(f'Name of current dataset: {current_dataset_name}')\n",
    "    plot_cost_history(cost_history_total)\n",
    "    plot_time_history(time_history_total)\n",
    "    plot_loss_history(train_loss_history_total, test_loss_history_total)\n",
    "    plot_accuracy_history(train_accuracy_history_total, test_accuracy_history_total)\n",
    "    plot_error_history(train_error_history_total, test_error_history_total)\n",
    "    plot_adversary_history(adversary_history_total)\n",
    "    plot_straggler_history(straggler_history_total)\n",
    "\n",
    "def experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelClass, optimizerClass, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list = [0], adversary_attack_func_list = None, adversary_attack_value_list = 0, experiment_rounds = 1, show_history=True, save_result=True):\n",
    "    global experiment_id\n",
    "    experiment_id = 0\n",
    "\n",
    "    global_epochs_list = convert_to_list(global_epochs_list)\n",
    "    local_epochs_list = convert_to_list(local_epochs_list)\n",
    "    num_clients_list = convert_to_list(num_clients_list)\n",
    "    random_sample_client_number_list = convert_to_list(random_sample_client_number_list)\n",
    "    learning_rate_list = convert_to_list(learning_rate_list)\n",
    "    batch_size_list = convert_to_list(batch_size_list)\n",
    "    aggregate_func_list = convert_to_list(aggregate_func_list)\n",
    "    loss_func_list = convert_to_list(loss_func_list)\n",
    "    accuracy_func_list = convert_to_list(accuracy_func_list)\n",
    "    error_func_list = convert_to_list(error_func_list)\n",
    "    straggler_list = convert_to_list(straggler_list)\n",
    "    mu_list = convert_to_list(mu_list)\n",
    "    adversary_list = convert_to_list(adversary_list)\n",
    "    adversary_attack_func_list = convert_to_list(adversary_attack_func_list)\n",
    "    adversary_attack_value_list = convert_to_list(adversary_attack_value_list)\n",
    "\n",
    "    global FedProx_global_model\n",
    "    global FedProx_mu\n",
    "\n",
    "    cost_history_total = []\n",
    "    time_history_total = []\n",
    "    adversary_history_total = []\n",
    "    straggler_history_total = []\n",
    "    train_loss_history_total = []\n",
    "    train_accuracy_history_total = []\n",
    "    train_error_history_total = []\n",
    "    test_loss_history_total = []\n",
    "    test_accuracy_history_total = []\n",
    "    test_error_history_total = []\n",
    "    \n",
    "    for n in range(experiment_rounds):\n",
    "        experiment_id = experiment_id + 1\n",
    "        print(f'=== Training Experiment {experiment_id} ===')\n",
    "        print(f'global epochs is {global_epochs_list[min(n, len(global_epochs_list) - 1)]}')\n",
    "        global_epochs = global_epochs_list[min(n, len(global_epochs_list) - 1)]\n",
    "        print(f'local epochs is {local_epochs_list[min(n, len(local_epochs_list) - 1)]}')\n",
    "        local_epochs = local_epochs_list[min(n, len(local_epochs_list) - 1)]\n",
    "        print(f'num clients is {num_clients_list[min(n, len(num_clients_list) - 1)]}')\n",
    "        num_clients = num_clients_list[min(n, len(num_clients_list) - 1)]\n",
    "        print(f'random sample client number is {random_sample_client_number_list[min(n, len(random_sample_client_number_list) - 1)]}')\n",
    "        random_sample_client_number = random_sample_client_number_list[min(n, len(random_sample_client_number_list) - 1)]\n",
    "        print(f'learning rate list is {learning_rate_list[min(n, len(learning_rate_list) - 1)]}')\n",
    "        learning_rate = learning_rate_list[min(n, len(learning_rate_list) - 1)]\n",
    "        print(f'batch size list is {batch_size_list[min(n, len(batch_size_list) - 1)]}')\n",
    "        batch_size = batch_size_list[min(n, len(batch_size_list) - 1)]\n",
    "        print(f'aggregate function is {aggregate_func_list[min(n, len(aggregate_func_list) - 1)].__name__}')\n",
    "        aggregate_func = aggregate_func_list[min(n, len(aggregate_func_list) - 1)]\n",
    "        print(f'loss function is {loss_func_list[min(n, len(loss_func_list) - 1)].__name__}')\n",
    "        loss_func = loss_func_list[min(n, len(loss_func_list) - 1)]\n",
    "        print(f'accuracy function is {accuracy_func_list[min(n, len(accuracy_func_list) - 1)].__name__}')\n",
    "        accuracy_func = accuracy_func_list[min(n, len(accuracy_func_list) - 1)]\n",
    "        print(f'error function is {error_func_list[min(n, len(error_func_list) - 1)].__name__}')\n",
    "        error_func = error_func_list[min(n, len(error_func_list) - 1)]\n",
    "        print(f'straggler is {straggler_list[min(n, len(straggler_list) - 1)]}')\n",
    "        straggler = straggler_list[min(n, len(straggler_list) - 1)]\n",
    "        print(f'mu is {mu_list[min(n, len(mu_list) - 1)]}')\n",
    "        FedProx_mu = mu_list[min(n, len(mu_list) - 1)]\n",
    "        print(f'adversary is {adversary_list[min(n, len(adversary_list) - 1)]}')\n",
    "        adversary = adversary_list[min(n, len(adversary_list) - 1)]\n",
    "        print(f'adversary attack function is {adversary_attack_func_list[min(n, len(adversary_attack_func_list) - 1)]}')\n",
    "        adversary_attack_func = adversary_attack_func_list[min(n, len(adversary_attack_func_list) - 1)]\n",
    "        print(f'adversary attack value is {adversary_attack_value_list[min(n, len(adversary_attack_value_list) - 1)]}')\n",
    "        adversary_attack_value = adversary_attack_value_list[min(n, len(adversary_attack_value_list) - 1)]\n",
    "        \n",
    "        global_model = to_device(modelClass(), device)\n",
    "        print(global_model)\n",
    "        print(global_model.state_dict())\n",
    "        FedProx_global_model = global_model\n",
    "\n",
    "        train_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True), device)\n",
    "        test_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False), device)\n",
    "\n",
    "        print(\"Establishing client devices...\")\n",
    "\n",
    "        client_model_list = [to_device(modelClass(), device)] * num_clients\n",
    "        client_optimizer_list = [optimizerClass(model.parameters(), learning_rate) for model in client_model_list]\n",
    "        client_dataset_list = dataset_distributing_func(train_dataset, num_clients)\n",
    "        print(f'Training dataset has been distributed into {len(client_dataset_list)} pieces.')\n",
    "        client_batch_size_list = [batch_size] * num_clients\n",
    "        client_itera_func_list = [itera_func] * num_clients\n",
    "        client_loss_func_list = [loss_func] * num_clients\n",
    "        client_accuracy_func_list = [accuracy_func] * num_clients\n",
    "        client_error_func_list = [error_func] * num_clients\n",
    "        client_list = establish_client_devices(num_clients, client_model_list, client_optimizer_list, client_dataset_list, client_batch_size_list, client_itera_func_list, client_loss_func_list, client_accuracy_func_list, client_error_func_list)\n",
    "\n",
    "        for i in range(straggler):\n",
    "            client_list[i].straggler = True\n",
    "\n",
    "        for i in range(adversary):\n",
    "            if client_list[i].straggler is True:\n",
    "                client_list[i+straggler].adversary = True\n",
    "                client_list[i+straggler].adversary_attack_func = adversary_attack_func\n",
    "                client_list[i+straggler].adversary_attack_value = adversary_attack_value\n",
    "            else:\n",
    "                client_list[i].adversary = True\n",
    "                client_list[i].adversary_attack_func = adversary_attack_func\n",
    "                client_list[i].adversary_attack_value = adversary_attack_value\n",
    "\n",
    "        # Visualize the client dataset. Please comment these codes to avoid a long code output if necessary.\n",
    "        #for i in range(len(client_list)):\n",
    "        #    print(client_dataset_list[i])\n",
    "\n",
    "        print(f'Established {len(client_list)} client devices.')\n",
    "\n",
    "        save_path_str = f\"{current_dataset_name}_{current_method_name}_GE_{global_epochs}_LE_{local_epochs}_C_{num_clients}_RC_{random_sample_client_number}_lr_{learning_rate}_B_{batch_size}\"\n",
    "\n",
    "        global save_file_extra_information\n",
    "        save_file_extra_information = f\"\"\"\n",
    "        === {save_path_str} ===\n",
    "        The experiment ID is: {experiment_id}\n",
    "        The train start time is: {train_start_time}\n",
    "        The dataset is: {current_dataset_name}\n",
    "        current_method_name = {current_method_name}\n",
    "        [should be FedProx]\n",
    "\n",
    "        experiment_rounds = {experiment_rounds}\n",
    "\n",
    "        modelType = {modelClass.__name__}\n",
    "        itera_func = {itera_func.__name__}\n",
    "        optimizerType = {optimizerClass.__name__}\n",
    "        dataset_distributing_func = {dataset_distributing_func.__name__}\n",
    "\n",
    "        custom_split_dataset_iid = {custom_split_dataset_iid}\n",
    "        custom_split_dataset_power_law = {custom_split_dataset_power_law}\n",
    "        custom_split_dataset_balance = {custom_split_dataset_balance}\n",
    "        custom_split_dataset_seed = {custom_split_dataset_seed}\n",
    "\n",
    "        global_epochs_list = {global_epochs_list}\n",
    "        local_epochs_list = {local_epochs_list}\n",
    "        num_clients_list = {num_clients_list}\n",
    "        random_sample_client_number_list = {random_sample_client_number_list}\n",
    "        learning_rate_list = {learning_rate_list}\n",
    "        batch_size_list = {batch_size_list}\n",
    "        aggregate_func_list = {aggregate_func_list}\n",
    "        loss_func_list = {loss_func_list}\n",
    "        accuracy_func_list = {accuracy_func_list}\n",
    "        error_func_list = {error_func_list}\n",
    "        straggler_list = {straggler_list}\n",
    "        mu_list = {mu_list}\n",
    "        adversary_list = {adversary_list}\n",
    "        adversary_attack_func_list = {adversary_attack_func_list}\n",
    "        adversary_attack_value_list = {adversary_attack_value_list}\n",
    "\n",
    "        !-- Current Status --!\n",
    "        global_epochs = {global_epochs}\n",
    "        local_epochs = {local_epochs}\n",
    "        num_clients = {num_clients}\n",
    "        random_sample_client_number = {random_sample_client_number}\n",
    "        learning_rate = {learning_rate}\n",
    "        batch_size = {batch_size}\n",
    "        aggregate_func = {aggregate_func.__name__}\n",
    "        loss_func = {loss_func.__name__}\n",
    "        accuracy_func = {accuracy_func.__name__}\n",
    "        error_func = {error_func.__name__}\n",
    "        straggler = {straggler}\n",
    "        mu = {FedProx_mu}\n",
    "        adversary = {adversary}\n",
    "        adversary_attack_func = {adversary_attack_func}\n",
    "        adversary_attack_value = {adversary_attack_value}\n",
    "        \"\"\"\n",
    "\n",
    "        cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = train_federated_learning_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, aggregate_func, loss_func, accuracy_func, error_func, show_history, save_result, save_path_str)\n",
    "\n",
    "        cost_history_total.append(cost_history)\n",
    "        time_history_total.append(time_history)\n",
    "        adversary_history_total.append(adversary_history)\n",
    "        straggler_history_total.append(straggler_history)\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        train_accuracy_history_total.append(train_accuracy_history)\n",
    "        train_error_history_total.append(train_error_history)\n",
    "        test_loss_history_total.append(test_loss_history)\n",
    "        test_accuracy_history_total.append(test_accuracy_history)\n",
    "        test_error_history_total.append(test_error_history)\n",
    "    \n",
    "    print(f'=== The Experiment Result ===')\n",
    "    print(f'Name of current dataset: {current_dataset_name}')\n",
    "    plot_cost_history(cost_history_total)\n",
    "    plot_time_history(time_history_total)\n",
    "    plot_loss_history(train_loss_history_total, test_loss_history_total)\n",
    "    plot_accuracy_history(train_accuracy_history_total, test_accuracy_history_total)\n",
    "    plot_error_history(train_error_history_total, test_error_history_total)\n",
    "    plot_adversary_history(adversary_history_total)\n",
    "    plot_straggler_history(straggler_history_total)\n",
    "\n",
    "def experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelClass, optimizerClass, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list = False, straggler_list = [0], adversary_list = [0], adversary_attack_func_list = None, adversary_attack_value_list = 0, adversary_attack_Scaffold_all_list = False, experiment_rounds = 1, show_history=True, save_result=True):\n",
    "    global experiment_id\n",
    "    experiment_id = 0\n",
    "\n",
    "    global_epochs_list = convert_to_list(global_epochs_list)\n",
    "    local_epochs_list = convert_to_list(local_epochs_list)\n",
    "    num_clients_list = convert_to_list(num_clients_list)\n",
    "    random_sample_client_number_list = convert_to_list(random_sample_client_number_list)\n",
    "    learning_rate_list = convert_to_list(learning_rate_list)\n",
    "    global_step_size_list = convert_to_list(global_step_size_list)\n",
    "    batch_size_list = convert_to_list(batch_size_list)\n",
    "    aggregate_func_list = convert_to_list(aggregate_func_list)\n",
    "    loss_func_list = convert_to_list(loss_func_list)\n",
    "    accuracy_func_list = convert_to_list(accuracy_func_list)\n",
    "    error_func_list = convert_to_list(error_func_list)\n",
    "    Scaffold_update_controls_use_gradient_list = convert_to_list(Scaffold_update_controls_use_gradient_list)\n",
    "    straggler_list = convert_to_list(straggler_list)\n",
    "    adversary_list = convert_to_list(adversary_list)\n",
    "    adversary_attack_func_list = convert_to_list(adversary_attack_func_list)\n",
    "    adversary_attack_value_list = convert_to_list(adversary_attack_value_list)\n",
    "    adversary_attack_Scaffold_all_list = convert_to_list(adversary_attack_Scaffold_all_list)\n",
    "\n",
    "    cost_history_total = []\n",
    "    time_history_total = []\n",
    "    adversary_history_total = []\n",
    "    straggler_history_total = []\n",
    "    train_loss_history_total = []\n",
    "    train_accuracy_history_total = []\n",
    "    train_error_history_total = []\n",
    "    test_loss_history_total = []\n",
    "    test_accuracy_history_total = []\n",
    "    test_error_history_total = []\n",
    "    \n",
    "    for n in range(experiment_rounds):\n",
    "        experiment_id = experiment_id + 1\n",
    "        print(f'=== Training Experiment {experiment_id} ===')\n",
    "        print(f'global epochs is {global_epochs_list[min(n, len(global_epochs_list) - 1)]}')\n",
    "        global_epochs = global_epochs_list[min(n, len(global_epochs_list) - 1)]\n",
    "        print(f'local epochs is {local_epochs_list[min(n, len(local_epochs_list) - 1)]}')\n",
    "        local_epochs = local_epochs_list[min(n, len(local_epochs_list) - 1)]\n",
    "        print(f'num clients is {num_clients_list[min(n, len(num_clients_list) - 1)]}')\n",
    "        num_clients = num_clients_list[min(n, len(num_clients_list) - 1)]\n",
    "        print(f'random sample client number is {random_sample_client_number_list[min(n, len(random_sample_client_number_list) - 1)]}')\n",
    "        random_sample_client_number = random_sample_client_number_list[min(n, len(random_sample_client_number_list) - 1)]\n",
    "        print(f'learning rate list is {learning_rate_list[min(n, len(learning_rate_list) - 1)]}')\n",
    "        learning_rate = learning_rate_list[min(n, len(learning_rate_list) - 1)]\n",
    "        print(f'global step size is {global_step_size_list[min(n, len(global_step_size_list) - 1)]}')\n",
    "        global_step_size = global_step_size_list[min(n, len(global_step_size_list) - 1)]\n",
    "        print(f'batch size list is {batch_size_list[min(n, len(batch_size_list) - 1)]}')\n",
    "        batch_size = batch_size_list[min(n, len(batch_size_list) - 1)]\n",
    "        print(f'aggregate function is {aggregate_func_list[min(n, len(aggregate_func_list) - 1)].__name__}')\n",
    "        aggregate_func = aggregate_func_list[min(n, len(aggregate_func_list) - 1)]\n",
    "        print(f'loss function is {loss_func_list[min(n, len(loss_func_list) - 1)].__name__}')\n",
    "        loss_func = loss_func_list[min(n, len(loss_func_list) - 1)]\n",
    "        print(f'accuracy function is {accuracy_func_list[min(n, len(accuracy_func_list) - 1)].__name__}')\n",
    "        accuracy_func = accuracy_func_list[min(n, len(accuracy_func_list) - 1)]\n",
    "        print(f'error function is {error_func_list[min(n, len(error_func_list) - 1)].__name__}')\n",
    "        error_func = error_func_list[min(n, len(error_func_list) - 1)]\n",
    "        print(f'use gradient to update control variable is {Scaffold_update_controls_use_gradient_list[min(n, len(Scaffold_update_controls_use_gradient_list) - 1)]}')\n",
    "        Scaffold_update_controls_use_gradient = Scaffold_update_controls_use_gradient_list[min(n, len(Scaffold_update_controls_use_gradient_list) - 1)]\n",
    "        print(f'straggler is {straggler_list[min(n, len(straggler_list) - 1)]}')\n",
    "        straggler = straggler_list[min(n, len(straggler_list) - 1)]\n",
    "        print(f'adversary is {adversary_list[min(n, len(adversary_list) - 1)]}')\n",
    "        adversary = adversary_list[min(n, len(adversary_list) - 1)]\n",
    "        print(f'adversary attack function is {adversary_attack_func_list[min(n, len(adversary_attack_func_list) - 1)]}')\n",
    "        adversary_attack_func = adversary_attack_func_list[min(n, len(adversary_attack_func_list) - 1)]\n",
    "        print(f'adversary attack value is {adversary_attack_value_list[min(n, len(adversary_attack_value_list) - 1)]}')\n",
    "        adversary_attack_value = adversary_attack_value_list[min(n, len(adversary_attack_value_list) - 1)]\n",
    "        print(f'adversary attack include control variables is {adversary_attack_Scaffold_all_list[min(n, len(adversary_attack_Scaffold_all_list) - 1)]}')\n",
    "        adversary_attack_Scaffold_all = adversary_attack_Scaffold_all_list[min(n, len(adversary_attack_Scaffold_all_list) - 1)]\n",
    "\n",
    "        global_model = to_device(modelClass(), device)\n",
    "        print(global_model)\n",
    "        print(global_model.state_dict())\n",
    "\n",
    "        train_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True), device)\n",
    "        test_dataloader = DeviceDataLoader(torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False), device)\n",
    "\n",
    "        print(\"Establishing client devices...\")\n",
    "\n",
    "        client_model_list = [to_device(modelClass(), device)] * num_clients\n",
    "        client_optimizer_list = [optimizerClass(model.parameters(), learning_rate) for model in client_model_list]\n",
    "        client_dataset_list = dataset_distributing_func(train_dataset, num_clients)\n",
    "        print(f'Training dataset has been distributed into {len(client_dataset_list)} pieces.')\n",
    "        client_batch_size_list = [batch_size] * num_clients\n",
    "        client_itera_func_list = [itera_func] * num_clients\n",
    "        client_loss_func_list = [loss_func] * num_clients\n",
    "        client_accuracy_func_list = [accuracy_func] * num_clients\n",
    "        client_error_func_list = [error_func] * num_clients\n",
    "        client_list = establish_client_devices(num_clients, client_model_list, client_optimizer_list, client_dataset_list, client_batch_size_list, client_itera_func_list, client_loss_func_list, client_accuracy_func_list, client_error_func_list)\n",
    "\n",
    "        for i in range(straggler):\n",
    "            client_list[i].straggler = True\n",
    "\n",
    "        for i in range(adversary):\n",
    "            if client_list[i].straggler is True:\n",
    "                client_list[i+straggler].adversary = True\n",
    "                client_list[i+straggler].adversary_attack_func = adversary_attack_func\n",
    "                client_list[i+straggler].adversary_attack_value = adversary_attack_value\n",
    "                client_list[i+straggler].adversary_attack_Scaffold_all = adversary_attack_Scaffold_all\n",
    "            else:\n",
    "                client_list[i].adversary = True\n",
    "                client_list[i].adversary_attack_func = adversary_attack_func\n",
    "                client_list[i].adversary_attack_value = adversary_attack_value\n",
    "                client_list[i].adversary_attack_Scaffold_all = adversary_attack_Scaffold_all\n",
    "\n",
    "        # Visualize the client dataset. Please comment these codes to avoid a long code output if necessary.\n",
    "        #for i in range(len(client_list)):\n",
    "        #    print(client_dataset_list[i])\n",
    "\n",
    "        print(f'Established {len(client_list)} client devices.')\n",
    "\n",
    "        save_path_str = f\"{current_dataset_name}_{current_method_name}_GE_{global_epochs}_LE_{local_epochs}_C_{num_clients}_RC_{random_sample_client_number}_lr_{learning_rate}_B_{batch_size}\"\n",
    "\n",
    "        global save_file_extra_information\n",
    "        save_file_extra_information = f\"\"\"\n",
    "        === {save_path_str} ===\n",
    "        The experiment ID is: {experiment_id}\n",
    "        The train start time is: {train_start_time}\n",
    "        The dataset is: {current_dataset_name}\n",
    "        current_method_name = {current_method_name}\n",
    "        [should be Scaffold]\n",
    "\n",
    "        experiment_rounds = {experiment_rounds}\n",
    "\n",
    "        modelType = {modelClass.__name__}\n",
    "        itera_func = {itera_func.__name__}\n",
    "        optimizerType = {optimizerClass.__name__}\n",
    "        dataset_distributing_func = {dataset_distributing_func.__name__}\n",
    "\n",
    "        custom_split_dataset_iid = {custom_split_dataset_iid}\n",
    "        custom_split_dataset_power_law = {custom_split_dataset_power_law}\n",
    "        custom_split_dataset_balance = {custom_split_dataset_balance}\n",
    "        custom_split_dataset_seed = {custom_split_dataset_seed}\n",
    "\n",
    "        global_epochs_list = {global_epochs_list}\n",
    "        local_epochs_list = {local_epochs_list}\n",
    "        num_clients_list = {num_clients_list}\n",
    "        random_sample_client_number_list = {random_sample_client_number_list}\n",
    "        learning_rate_list = {learning_rate_list}\n",
    "        global_step_size_list = {global_step_size_list}\n",
    "        batch_size_list = {batch_size_list}\n",
    "        aggregate_func_list = {aggregate_func_list}\n",
    "        loss_func_list = {loss_func_list}\n",
    "        accuracy_func_list = {accuracy_func_list}\n",
    "        error_func_list = {error_func_list}\n",
    "        Scaffold_update_controls_use_gradient_list = {Scaffold_update_controls_use_gradient_list}\n",
    "        straggler_list = {straggler_list}\n",
    "        adversary_list = {adversary_list}\n",
    "        adversary_attack_func_list = {adversary_attack_func_list}\n",
    "        adversary_attack_value_list = {adversary_attack_value_list}\n",
    "        adversary_attack_Scaffold_all_list = {adversary_attack_Scaffold_all_list}\n",
    "\n",
    "        !-- Current Status --!\n",
    "        global_epochs = {global_epochs}\n",
    "        local_epochs = {local_epochs}\n",
    "        num_clients = {num_clients}\n",
    "        random_sample_client_number = {random_sample_client_number}\n",
    "        learning_rate = {learning_rate}\n",
    "        global_step_size = {global_step_size}\n",
    "        batch_size = {batch_size}\n",
    "        aggregate_func = {aggregate_func.__name__}\n",
    "        loss_func = {loss_func.__name__}\n",
    "        accuracy_func = {accuracy_func.__name__}\n",
    "        error_func = {error_func.__name__}\n",
    "        Scaffold_update_controls_use_gradient = {Scaffold_update_controls_use_gradient}\n",
    "        straggler = {straggler}\n",
    "        adversary = {adversary}\n",
    "        adversary_attack_func = {adversary_attack_func}\n",
    "        adversary_attack_value = {adversary_attack_value}\n",
    "        adversary_attack_Scaffold_all = {adversary_attack_Scaffold_all}\n",
    "        \"\"\"\n",
    "\n",
    "        cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history = train_Scaffold_model(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, global_step_size, Scaffold_update_controls_use_gradient, aggregate_func, loss_func, accuracy_func, error_func, show_history, save_result, save_path_str)\n",
    "\n",
    "        cost_history_total.append(cost_history)\n",
    "        time_history_total.append(time_history)\n",
    "        adversary_history_total.append(adversary_history)\n",
    "        straggler_history_total.append(straggler_history)\n",
    "        train_loss_history_total.append(train_loss_history)\n",
    "        train_accuracy_history_total.append(train_accuracy_history)\n",
    "        train_error_history_total.append(train_error_history)\n",
    "        test_loss_history_total.append(test_loss_history)\n",
    "        test_accuracy_history_total.append(test_accuracy_history)\n",
    "        test_error_history_total.append(test_error_history)\n",
    "    \n",
    "    print(f'=== The Experiment Result ===')\n",
    "    print(f'Name of current dataset: {current_dataset_name}')\n",
    "    plot_cost_history(cost_history_total)\n",
    "    plot_time_history(time_history_total)\n",
    "    plot_loss_history(train_loss_history_total, test_loss_history_total)\n",
    "    plot_accuracy_history(train_accuracy_history_total, test_accuracy_history_total)\n",
    "    plot_error_history(train_error_history_total, test_error_history_total)\n",
    "    plot_adversary_history(adversary_history_total)\n",
    "    plot_straggler_history(straggler_history_total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 Experiment ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.1 Choosing Dataset ###\n",
    "\n",
    "In this section, execute a cell only to choose a dataset you want do experiment with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MNIST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current dataset is MNIST.\n",
      "Number of samples in the train dataset: 60000\n",
      "Number of samples in the test dataset: 10000\n",
      "Number of samples in the train dataset after random split: 60000\n",
      "Number of samples in the test dataset after random split: 10000\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "train_dataset = MNIST_train_dataset\n",
    "test_dataset = MNIST_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"MNIST\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')\n",
    "\n",
    "# Validation Dataset\n",
    "#split_ratio = 0.01\n",
    "#train_dataset, validation_dataset = random_split(train_dataset, [int(len(train_dataset) * split_ratio), int(len(train_dataset) - int(len(train_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the train dataset after random split: {len(train_dataset)}')\n",
    "#split_ratio = 0.01\n",
    "#test_dataset, _ = random_split(test_dataset, [int(len(test_dataset) * split_ratio), int(len(test_dataset) - int(len(test_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the test dataset after random split: {len(test_dataset)}')\n",
    "\n",
    "# Define variables associate with the dataset\n",
    "learning_rate_preset = 0.5\n",
    "batch_size_preset = 100\n",
    "num_features_preset = 1\n",
    "num_classes_preset = 10\n",
    "input_dim = 784\n",
    "model_type_preset = MNIST_CNN_Model\n",
    "optimizer_type_preset = torch.optim.SGD\n",
    "loss_func_preset = torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CIFAR10 Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train_dataset = CIFAR10_train_dataset\n",
    "test_dataset = CIFAR10_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"CIFAR10\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')\n",
    "\n",
    "# Validation Dataset\n",
    "#split_ratio = 0.50\n",
    "#train_dataset, validation_dataset = random_split(train_dataset, [int(len(train_dataset) * split_ratio), int(len(train_dataset) - int(len(train_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the train dataset after random split: {len(train_dataset)}')\n",
    "#split_ratio = 0.007\n",
    "#test_dataset, _ = random_split(test_dataset, [int(len(test_dataset) * split_ratio), int(len(test_dataset) - int(len(test_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the test dataset after random split: {len(test_dataset)}')\n",
    "\n",
    "# Define variables associate with the dataset\n",
    "learning_rate_preset = 0.5\n",
    "batch_size_preset = 100\n",
    "num_features_preset = 1\n",
    "num_classes_preset = 10\n",
    "input_dim = 1024\n",
    "model_type_preset = CIFAR10_CNN_Model\n",
    "optimizer_type_preset = torch.optim.SGD\n",
    "loss_func_preset = torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EMNIST Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train_dataset = EMNIST_train_dataset\n",
    "test_dataset = EMNIST_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"EMNIST\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')\n",
    "\n",
    "# Validation Dataset\n",
    "#split_ratio = 0.50\n",
    "#train_dataset, validation_dataset = random_split(train_dataset, [int(len(train_dataset) * split_ratio), int(len(train_dataset) - int(len(train_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the train dataset after random split: {len(train_dataset)}')\n",
    "#split_ratio = 0.007\n",
    "#test_dataset, _ = random_split(test_dataset, [int(len(test_dataset) * split_ratio), int(len(test_dataset) - int(len(test_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the test dataset after random split: {len(test_dataset)}')\n",
    "\n",
    "# Define variables associate with the dataset\n",
    "learning_rate_preset = 0.5\n",
    "batch_size_preset = 100\n",
    "num_features_preset = 1\n",
    "num_classes_preset = 26\n",
    "input_dim = 784\n",
    "model_type_preset = EMNIST_CNN_Model\n",
    "optimizer_type_preset = torch.optim.SGD\n",
    "loss_func_preset = torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Give Me Some Credit Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train_dataset = Give_Me_Some_Credit_train_dataset\n",
    "test_dataset = Give_Me_Some_Credit_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"Give Me Some Credit Dataset\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')\n",
    "\n",
    "# Validation Dataset\n",
    "#split_ratio = 0.01\n",
    "#train_dataset, validation_dataset = random_split(train_dataset, [int(len(train_dataset) * split_ratio), int(len(train_dataset) - int(len(train_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the train dataset after random split: {len(train_dataset)}')\n",
    "#split_ratio = 0.01\n",
    "#test_dataset, _ = random_split(test_dataset, [int(len(test_dataset) * split_ratio), int(len(test_dataset) - int(len(test_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the test dataset after random split: {len(test_dataset)}')\n",
    "\n",
    "# Define variables associate with the dataset\n",
    "learning_rate_preset = 0.5\n",
    "batch_size_preset = 100\n",
    "num_features_preset = 7\n",
    "num_classes_preset = 2\n",
    "\n",
    "Linear_Model_in_features = 7\n",
    "Linear_Model_out_features = 1\n",
    "model_type_preset = Linear_Model\n",
    "optimizer_type_preset = torch.optim.SGD\n",
    "loss_func_preset = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Epsilon Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "train_dataset = Epsilon_train_dataset\n",
    "test_dataset = Epsilon_test_dataset\n",
    "\n",
    "# Show Dataset Status\n",
    "current_dataset_name = \"Epsilon\"\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "print(f'Number of samples in the train dataset: {len(train_dataset)}')\n",
    "print(f'Number of samples in the test dataset: {len(test_dataset)}')\n",
    "\n",
    "# Validation Dataset\n",
    "#split_ratio = 0.50\n",
    "#train_dataset, validation_dataset = random_split(train_dataset, [int(len(train_dataset) * split_ratio), int(len(train_dataset) - int(len(train_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the train dataset after random split: {len(train_dataset)}')\n",
    "#split_ratio = 0.007\n",
    "#test_dataset, _ = random_split(test_dataset, [int(len(test_dataset) * split_ratio), int(len(test_dataset) - int(len(test_dataset) * split_ratio))])\n",
    "print(f'Number of samples in the test dataset after random split: {len(test_dataset)}')\n",
    "\n",
    "# Define variables associate with the dataset\n",
    "learning_rate_preset = 0.5\n",
    "batch_size_preset = 100\n",
    "num_features_preset = 7\n",
    "num_classes_preset = 2\n",
    "\n",
    "model_type_preset = Linear_Model\n",
    "optimizer_type_preset = torch.optim.SGD\n",
    "loss_func_preset = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.2 Neural Network Experiments ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Learning Rate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "train_func = train_neural_network_model\n",
    "\n",
    "num_epochs_list = 100\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "\n",
    "experiment_rounds = 1\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "experiment_neural_network_model(train_dataset, test_dataset, modelType, optimizerType, train_func, num_epochs_list, learning_rate_list, batch_size_list, loss_func_list, accuracy_func_list, error_func_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment: Compare Batch Size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "train_func = train_neural_network_model\n",
    "\n",
    "num_epochs_list = 100\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "\n",
    "experiment_rounds = 1\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "experiment_neural_network_model(train_dataset, test_dataset, modelType, optimizerType, train_func, num_epochs_list, learning_rate_list, batch_size_list, loss_func_list, accuracy_func_list, error_func_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.3 FedAvg Federated Learning Experiments ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_median\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_median\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If have time, to in the 2nd day**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = [1, 2, 3, 4, 5, 10]\n",
    "num_clients_list = [10]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 6\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = [1, 2, 3, 4, 5, 10]\n",
    "num_clients_list = [10]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 6\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = [3]\n",
    "num_clients_list = [1, 5, 20, 50, 100]\n",
    "random_sample_client_number_list = [1, 5, 20, 50, 100]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 5\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = [3]\n",
    "num_clients_list = [100]\n",
    "random_sample_client_number_list = [1, 10, 50, 100]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 4\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = [3]\n",
    "num_clients_list = [100]\n",
    "random_sample_client_number_list = [1, 10, 50, 100]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 4\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = [3]\n",
    "num_clients_list = [10]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = [0.001, 0.03, 0.1, 1.0, 2.0]\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 5\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = [3]\n",
    "num_clients_list = [10]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = [10, 128, 1000]\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 3\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.4 FedProx Federated Learning Experiments ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Straggler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [100]\n",
    "random_sample_client_number_list = [20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0, 50, 90, 0, 50, 90]\n",
    "mu_list = [0, 0, 0, 1.0, 1.0, 1.0]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 6\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [100]\n",
    "random_sample_client_number_list = [20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0, 50, 90, 0, 50, 90]\n",
    "mu_list = [0, 0, 0, 1.0, 1.0, 1.0]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 6\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Adversary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0]\n",
    "mu_list = [1.0]\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0]\n",
    "mu_list = [1.0]\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FedProx Median**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100, 10, 100]\n",
    "random_sample_client_number_list = [10, 20, 10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_median\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [1, 20, 1, 20]\n",
    "mu_list = [0.0, 0.0, 1.0, 1.0]\n",
    "adversary_list = [1, 20, 1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 4\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100, 10, 100]\n",
    "random_sample_client_number_list = [10, 20, 10, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_median\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [1, 20, 1, 20]\n",
    "mu_list = [0.0, 0.0, 1.0, 1.0]\n",
    "adversary_list = [1, 20, 1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 4\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.5 Scaffold Federated Learning Experiments ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [100]\n",
    "random_sample_client_number_list = [20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = False\n",
    "straggler_list = [0, 50, 90]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 3\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [100]\n",
    "random_sample_client_number_list = [20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = False\n",
    "straggler_list = [0, 50, 90]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 3\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = False\n",
    "straggler_list = [0]\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = False\n",
    "straggler_list = [0]\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Original**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 10, 100, 100]\n",
    "random_sample_client_number_list = [10, 10, 20, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = [True, True, False, False]\n",
    "straggler_list = [0]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 4\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 10, 100, 100]\n",
    "random_sample_client_number_list = [10, 10, 20, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = [True, True, False, False]\n",
    "straggler_list = [0]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 4\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.6 Federated Median Learning Experiments ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scaffold Median**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_median_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = False\n",
    "straggler_list = [1, 20]\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_median_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = False\n",
    "straggler_list = [1, 20]\n",
    "adversary_list = [1, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.7 Last Experiments ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SCAFFOLD Original**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 10, 100, 100]\n",
    "random_sample_client_number_list = [10, 10, 20, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = [True, False, True, False]\n",
    "straggler_list = [0]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 4\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 10, 100, 100]\n",
    "random_sample_client_number_list = [10, 10, 20, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = [True, False, True, False]\n",
    "straggler_list = [0]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 4\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current dataset is MNIST.\n",
      "The current train start time is 2024-04-10 11.18.24.\n",
      "=== Training Experiment 1 ===\n",
      "global epochs is 100\n",
      "local epochs is 3\n",
      "num clients is 10\n",
      "random sample client number is 10\n",
      "learning rate list is 0.03\n",
      "global step size is 1.0\n",
      "batch size list is 128\n",
      "aggregate function is federated_averaging_Scaffold\n",
      "loss function is cross_entropy\n",
      "accuracy function is get_accuracy\n",
      "error function is get_error\n",
      "use gradient to update control variable is True\n",
      "straggler is 0\n",
      "adversary is 0\n",
      "adversary attack function is <function adversarial_attack_by_value_Scaffold at 0x00000158D3C2BD90>\n",
      "adversary attack value is 10000\n",
      "adversary attack include control variables is False\n",
      "MNIST_CNN_Model(\n",
      "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n",
      "OrderedDict([('conv1.weight', tensor([[[[-0.1294, -0.1985,  0.0570, -0.1344, -0.0403],\n",
      "          [-0.1335, -0.0854,  0.1939,  0.1788,  0.1365],\n",
      "          [ 0.0348, -0.0907,  0.0302,  0.0786, -0.0271],\n",
      "          [-0.0818,  0.1852,  0.1607, -0.1386,  0.1278],\n",
      "          [ 0.0329,  0.1489,  0.1364, -0.1991,  0.1953]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0624, -0.1386,  0.0871,  0.1549, -0.0586],\n",
      "          [-0.1409,  0.0131, -0.0323, -0.1490,  0.0136],\n",
      "          [-0.1988,  0.0080,  0.1746,  0.1183, -0.1304],\n",
      "          [-0.0406, -0.1220, -0.1837,  0.0896,  0.0945],\n",
      "          [ 0.1070, -0.1884,  0.0111, -0.0391,  0.0441]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1288, -0.0577, -0.1731,  0.0915,  0.1007],\n",
      "          [ 0.1074,  0.1559,  0.0244,  0.1066,  0.0473],\n",
      "          [-0.1819,  0.1956,  0.1659, -0.0508, -0.1557],\n",
      "          [ 0.0957,  0.1660, -0.1587,  0.1669, -0.0919],\n",
      "          [-0.1544, -0.0835,  0.1636,  0.1113, -0.0926]]],\n",
      "\n",
      "\n",
      "        [[[-0.0462, -0.0104, -0.1771, -0.1403,  0.1002],\n",
      "          [ 0.1731, -0.1663,  0.1773,  0.1361, -0.0538],\n",
      "          [ 0.1815, -0.1233,  0.1672,  0.0799, -0.0042],\n",
      "          [ 0.0032,  0.0886,  0.0188, -0.0226, -0.0847],\n",
      "          [ 0.1376,  0.0410, -0.0841, -0.0056, -0.0124]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0702, -0.0408,  0.1104, -0.0675, -0.1319],\n",
      "          [-0.0106, -0.1957, -0.0692,  0.1765,  0.0374],\n",
      "          [-0.0736,  0.1702,  0.0588, -0.0666,  0.1879],\n",
      "          [ 0.1944, -0.1557, -0.0762, -0.0602,  0.1885],\n",
      "          [ 0.1024,  0.0904, -0.1269,  0.0409,  0.0362]]],\n",
      "\n",
      "\n",
      "        [[[-0.0413,  0.1086, -0.1402,  0.0744, -0.0600],\n",
      "          [ 0.0655,  0.0351,  0.0578,  0.1110,  0.1607],\n",
      "          [-0.0159,  0.0674,  0.0811, -0.1918, -0.0455],\n",
      "          [-0.1267, -0.0181,  0.1835, -0.0798,  0.0580],\n",
      "          [-0.1623,  0.0763,  0.1505,  0.0173,  0.0286]]],\n",
      "\n",
      "\n",
      "        [[[-0.0031, -0.1241, -0.0918,  0.1087, -0.0080],\n",
      "          [-0.1167, -0.0666,  0.1857, -0.0341, -0.1387],\n",
      "          [ 0.0584,  0.0385,  0.1849,  0.0043,  0.1643],\n",
      "          [-0.1337, -0.0602, -0.1013,  0.1982,  0.1665],\n",
      "          [-0.1409,  0.1826, -0.0059,  0.0948,  0.0457]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0091, -0.1186,  0.0177,  0.1131,  0.0721],\n",
      "          [ 0.1234,  0.0208, -0.0831, -0.1579, -0.1238],\n",
      "          [ 0.1017, -0.1548, -0.0140, -0.1118,  0.1780],\n",
      "          [-0.0179,  0.1432, -0.1286, -0.0096,  0.0186],\n",
      "          [ 0.1334,  0.1836,  0.0903,  0.0035,  0.1973]]],\n",
      "\n",
      "\n",
      "        [[[-0.1706, -0.1056,  0.0288,  0.0906,  0.1827],\n",
      "          [ 0.0552,  0.0478,  0.0924, -0.0270,  0.1046],\n",
      "          [ 0.0349,  0.0970, -0.1941, -0.1557,  0.0656],\n",
      "          [ 0.0803,  0.1187, -0.0290,  0.0142, -0.0563],\n",
      "          [-0.1191,  0.0188, -0.0464, -0.0559,  0.0753]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1828,  0.1319, -0.1948, -0.1545,  0.1974],\n",
      "          [-0.1849, -0.0405,  0.0605,  0.1436, -0.1721],\n",
      "          [-0.1736, -0.1447,  0.1178, -0.1527,  0.0369],\n",
      "          [-0.1325,  0.1122, -0.0940, -0.1625,  0.1262],\n",
      "          [ 0.0342, -0.0040, -0.0370, -0.0356, -0.0327]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0587, -0.0783, -0.0430, -0.0962, -0.0230],\n",
      "          [ 0.1022,  0.1706,  0.0850, -0.1205, -0.0338],\n",
      "          [ 0.1187,  0.1310, -0.1699, -0.1532, -0.1901],\n",
      "          [ 0.0363,  0.0301, -0.1867,  0.1919, -0.0356],\n",
      "          [-0.0828, -0.0927, -0.0408, -0.1626,  0.1286]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1769,  0.0992,  0.0215,  0.1161, -0.0818],\n",
      "          [-0.1650,  0.0102,  0.1474,  0.1054,  0.1643],\n",
      "          [ 0.0527, -0.1992, -0.1467,  0.0023, -0.0022],\n",
      "          [-0.1585, -0.1549, -0.0130, -0.1513, -0.0695],\n",
      "          [ 0.1471, -0.1005,  0.1264, -0.0443,  0.1035]]],\n",
      "\n",
      "\n",
      "        [[[-0.1049,  0.0886,  0.1096,  0.1731, -0.1878],\n",
      "          [-0.1990, -0.0696, -0.0558, -0.1184,  0.0505],\n",
      "          [ 0.1549, -0.1664, -0.0548,  0.1322,  0.0814],\n",
      "          [ 0.0262,  0.1932, -0.0042, -0.1852, -0.0060],\n",
      "          [-0.0500, -0.1055,  0.0879,  0.0749, -0.0276]]],\n",
      "\n",
      "\n",
      "        [[[-0.1206,  0.1606, -0.0300, -0.1016, -0.0955],\n",
      "          [-0.0165, -0.1457, -0.1434,  0.0671, -0.0304],\n",
      "          [ 0.0308,  0.0351,  0.1755, -0.0699, -0.1943],\n",
      "          [ 0.0848, -0.1362,  0.1263,  0.1713, -0.0913],\n",
      "          [-0.1951, -0.1777,  0.0127,  0.1240,  0.1282]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1089,  0.0523, -0.1300,  0.0519,  0.0242],\n",
      "          [-0.1246, -0.1709, -0.1322,  0.1300,  0.1218],\n",
      "          [ 0.1990,  0.1995, -0.1475,  0.1537, -0.0422],\n",
      "          [ 0.0450, -0.0146,  0.1453,  0.0844, -0.0684],\n",
      "          [-0.1510,  0.1589,  0.0253,  0.0016, -0.1779]]],\n",
      "\n",
      "\n",
      "        [[[-0.0209,  0.0542,  0.1737, -0.1382, -0.1948],\n",
      "          [ 0.1232,  0.1324,  0.0730, -0.1823,  0.1622],\n",
      "          [ 0.1089, -0.1491,  0.1571, -0.1838, -0.0317],\n",
      "          [-0.0278,  0.0233, -0.1941, -0.0088, -0.1314],\n",
      "          [ 0.1007,  0.1499, -0.1741,  0.1489,  0.1213]]]])), ('conv1.bias', tensor([-0.1550, -0.0995,  0.0791,  0.1134, -0.1122, -0.1784, -0.1545,  0.0888,\n",
      "        -0.1170, -0.0037,  0.1734, -0.1832,  0.1805, -0.1148,  0.1075, -0.1782])), ('conv2.weight', tensor([[[[-4.3080e-02,  3.6868e-02,  2.5102e-02, -2.2366e-02, -2.6309e-02],\n",
      "          [-4.9222e-02, -4.2573e-02, -3.3446e-02,  2.6153e-02,  1.1731e-04],\n",
      "          [-3.6488e-02, -4.2362e-02, -1.8743e-02, -4.4361e-03,  3.5678e-02],\n",
      "          [ 4.9783e-02,  3.7786e-02, -4.0259e-02,  3.5249e-02, -4.6303e-02],\n",
      "          [-4.7008e-03,  1.7166e-02,  1.6956e-02, -5.0505e-04, -3.0181e-02]],\n",
      "\n",
      "         [[ 2.4506e-03,  1.6421e-02, -4.0819e-02, -3.8107e-02,  1.0362e-02],\n",
      "          [ 1.8283e-03,  4.0205e-03,  6.2027e-03, -3.4308e-02, -3.5787e-02],\n",
      "          [ 3.1664e-02, -4.6843e-02, -2.6622e-02,  7.0493e-03,  4.0867e-02],\n",
      "          [-3.1211e-02, -4.1514e-02,  1.0859e-03, -1.7385e-02,  3.9180e-02],\n",
      "          [-1.7147e-02, -5.8172e-03,  1.5128e-02,  2.4064e-02, -2.0901e-02]],\n",
      "\n",
      "         [[-4.5804e-02, -2.3758e-03, -1.1991e-02, -2.8994e-02,  1.8598e-02],\n",
      "          [ 4.6134e-02, -3.0606e-02,  3.8782e-02,  3.7536e-02, -2.0004e-02],\n",
      "          [ 3.8883e-02, -5.6720e-03, -4.0403e-02,  1.2776e-02,  4.2412e-02],\n",
      "          [ 4.7799e-02, -3.5732e-02,  3.9755e-02,  1.9199e-02, -3.8763e-02],\n",
      "          [ 8.5781e-03,  3.6611e-02,  2.5038e-02,  4.6637e-02, -3.7730e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9438e-02,  4.4503e-02,  9.0861e-03,  3.9918e-02,  3.1258e-02],\n",
      "          [-1.3058e-02, -2.4996e-02, -1.5948e-02, -1.6005e-02,  2.5254e-02],\n",
      "          [-4.1953e-02,  7.3980e-03, -4.4505e-02, -1.6898e-02,  4.6641e-02],\n",
      "          [-4.4354e-02,  1.9692e-02,  2.0768e-02,  3.9405e-02, -2.5525e-02],\n",
      "          [-2.7851e-02,  1.9562e-02, -3.9509e-02, -4.8745e-02,  2.4362e-02]],\n",
      "\n",
      "         [[ 1.3384e-03,  4.2383e-02, -2.8590e-02, -1.5649e-02, -4.7466e-02],\n",
      "          [-3.9094e-03, -3.7401e-02,  3.2985e-02, -2.4380e-02, -2.4067e-02],\n",
      "          [ 4.6999e-02,  4.0300e-02,  3.7356e-02, -4.5684e-02, -5.2538e-03],\n",
      "          [-2.2483e-02,  3.9673e-02,  1.5847e-02, -4.7602e-02, -3.8215e-02],\n",
      "          [-3.2260e-02,  3.9144e-02,  1.7103e-02,  2.2269e-02,  1.9426e-02]],\n",
      "\n",
      "         [[ 1.8903e-02, -7.1288e-03,  3.8105e-02, -1.2695e-02,  4.1379e-02],\n",
      "          [-2.0235e-02, -1.0474e-02, -3.2786e-02,  2.6122e-02,  1.3723e-02],\n",
      "          [ 1.9276e-02,  3.2197e-02, -1.1854e-02, -9.1272e-03,  4.3297e-02],\n",
      "          [ 2.9041e-02, -1.3643e-02, -4.4035e-02,  2.4142e-02,  2.5146e-02],\n",
      "          [-1.2090e-02,  4.2399e-02,  2.9527e-02,  2.7798e-02, -1.5221e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.2465e-02,  3.5631e-02,  2.3139e-02, -3.0278e-02,  4.3929e-02],\n",
      "          [ 8.6490e-03, -3.7827e-02, -3.9289e-02,  3.0021e-03,  4.4505e-02],\n",
      "          [ 2.6405e-02,  8.5091e-03,  9.4156e-03, -2.4170e-02, -3.8576e-02],\n",
      "          [-4.0563e-02,  2.7414e-02,  1.8540e-02, -2.0433e-02, -8.8777e-03],\n",
      "          [-1.2710e-02,  1.2525e-02, -1.6557e-02,  3.6763e-02,  4.7052e-02]],\n",
      "\n",
      "         [[-1.8184e-02,  8.6566e-03,  3.1771e-02, -4.0078e-02, -3.2655e-02],\n",
      "          [ 4.3022e-02,  2.1382e-02, -4.1062e-02, -3.6896e-02,  3.6579e-03],\n",
      "          [-2.3181e-02,  1.2431e-02,  1.0956e-02,  3.5426e-03, -3.5196e-02],\n",
      "          [-1.9922e-02, -7.8091e-03, -3.9496e-02,  4.0253e-04,  2.0989e-02],\n",
      "          [ 1.7003e-02, -4.7758e-02, -3.1795e-02, -1.1726e-02, -1.1312e-02]],\n",
      "\n",
      "         [[-3.8841e-02,  2.5805e-02,  4.4463e-02, -2.9846e-02, -2.3694e-02],\n",
      "          [ 2.2047e-02, -2.6085e-02, -3.5265e-02,  1.5720e-02,  3.3137e-02],\n",
      "          [-1.6500e-02,  2.1096e-02, -4.7358e-02, -9.2839e-03, -4.5977e-02],\n",
      "          [-4.8016e-02, -1.6508e-02, -4.5768e-02,  4.2859e-02,  2.6255e-02],\n",
      "          [ 2.7685e-02, -4.5028e-02, -2.6019e-02,  2.9594e-03,  9.9766e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1844e-02, -4.3526e-02, -3.1481e-02, -9.3452e-03,  2.6208e-02],\n",
      "          [ 2.4258e-02,  2.6448e-03,  4.6957e-02,  2.0268e-02,  9.3758e-03],\n",
      "          [-1.9297e-02, -3.5280e-02, -1.1074e-02,  1.0359e-02, -1.7677e-02],\n",
      "          [ 7.0234e-03,  6.2455e-04, -3.7911e-02, -2.8260e-03,  2.7694e-02],\n",
      "          [-5.7039e-03, -4.2297e-02,  1.6254e-02, -2.4354e-02, -2.9620e-02]],\n",
      "\n",
      "         [[ 3.3516e-03,  3.6187e-02, -2.4950e-02, -1.3163e-02, -4.2877e-02],\n",
      "          [-3.3937e-02, -2.8422e-03, -4.4293e-02,  3.4150e-02,  3.3992e-02],\n",
      "          [-7.3033e-03,  6.1439e-04,  3.2045e-02, -4.6810e-03,  3.7697e-02],\n",
      "          [-7.0674e-03, -1.2601e-02, -2.7451e-02, -1.1526e-02, -1.7130e-02],\n",
      "          [ 3.1601e-02, -3.1627e-02,  4.6575e-02, -2.2976e-02,  3.8632e-02]],\n",
      "\n",
      "         [[-2.7995e-02,  4.3044e-02,  3.6704e-02, -4.1747e-02,  2.5582e-02],\n",
      "          [-4.2595e-05, -2.3721e-02,  1.7825e-02,  8.6615e-03,  3.2323e-02],\n",
      "          [-2.1384e-02,  2.7381e-02,  8.2363e-03, -4.8215e-02, -1.6863e-02],\n",
      "          [-4.4189e-02, -4.4053e-02,  1.6362e-02, -3.1420e-02, -2.7758e-02],\n",
      "          [ 4.2242e-02, -3.1776e-02,  3.3629e-02,  8.8969e-03,  1.6420e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5513e-02,  4.7466e-02,  1.0781e-02,  1.1109e-02,  2.1389e-03],\n",
      "          [-6.4621e-03,  4.2999e-02, -1.4351e-02, -4.7238e-02, -2.3735e-02],\n",
      "          [-4.8196e-02, -2.2445e-02, -4.9546e-02,  1.0867e-02,  3.5546e-02],\n",
      "          [ 3.7089e-03,  2.1462e-02, -1.8950e-02,  4.7596e-02, -1.8472e-02],\n",
      "          [-2.2302e-02,  4.1032e-02, -3.8537e-02,  3.7152e-02, -5.8451e-03]],\n",
      "\n",
      "         [[ 2.4816e-02,  1.2286e-02, -4.0701e-02, -1.3303e-02, -1.4398e-02],\n",
      "          [-4.4682e-02, -3.0515e-02, -2.8000e-02,  4.4445e-02,  1.2037e-02],\n",
      "          [ 3.9516e-02, -9.4350e-03, -4.4678e-02,  3.3962e-02,  1.0510e-03],\n",
      "          [-3.9428e-03, -3.0985e-02,  2.8346e-02, -3.0982e-02,  2.1296e-02],\n",
      "          [-4.7470e-02,  1.3536e-02,  3.8502e-02, -1.6278e-02,  1.0042e-02]],\n",
      "\n",
      "         [[-3.6229e-02,  2.7725e-02, -4.1670e-02,  4.4122e-02,  3.2104e-02],\n",
      "          [-1.4849e-02,  1.9786e-02, -2.0598e-02, -3.3274e-02, -1.7116e-02],\n",
      "          [ 4.8659e-02,  3.7599e-02,  3.7638e-02,  4.6037e-02, -1.9583e-02],\n",
      "          [ 2.8340e-02,  1.0368e-02,  1.9314e-02,  1.6171e-02, -4.2898e-02],\n",
      "          [ 3.1297e-02,  3.1822e-02, -2.4431e-02,  6.6811e-04,  4.6955e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5935e-03,  1.5716e-02, -1.9182e-02,  1.8330e-02,  1.5307e-02],\n",
      "          [ 2.5258e-02, -3.3664e-02,  1.0623e-03,  1.5130e-02, -1.2650e-02],\n",
      "          [ 8.0630e-03, -2.8713e-02, -1.9665e-03, -1.3049e-02, -3.3140e-02],\n",
      "          [-1.8372e-04, -3.1237e-02,  2.1577e-02,  1.8003e-02, -5.7499e-03],\n",
      "          [ 4.2054e-02,  4.9470e-02, -4.6961e-02,  4.1144e-02,  2.1995e-02]],\n",
      "\n",
      "         [[ 9.5978e-03,  2.8844e-02, -4.5763e-02, -2.2198e-02,  2.0655e-02],\n",
      "          [-2.5234e-02, -3.5403e-02,  7.9330e-03, -1.5367e-04, -3.3082e-02],\n",
      "          [-4.7200e-02,  3.0242e-02, -7.3248e-03,  3.1323e-02,  1.3935e-02],\n",
      "          [ 3.1911e-02,  2.0902e-02, -4.9931e-02, -4.5956e-02,  9.0156e-03],\n",
      "          [-2.7776e-02,  2.4375e-02,  4.0499e-02,  1.4720e-03,  1.3959e-02]],\n",
      "\n",
      "         [[ 4.4342e-03,  3.8767e-02, -3.7137e-02, -3.6288e-02, -1.4063e-02],\n",
      "          [ 1.3551e-02, -4.3020e-02,  1.4314e-02, -2.1717e-02, -2.6078e-02],\n",
      "          [ 2.5562e-02,  2.6883e-02,  3.6466e-03,  6.6520e-03, -2.4216e-02],\n",
      "          [ 1.2144e-02, -3.3416e-02, -1.5437e-02, -3.8156e-02, -4.3284e-02],\n",
      "          [ 1.5730e-02, -3.8450e-02,  2.8014e-02, -1.2851e-02,  2.8447e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-4.1441e-02,  2.3511e-02, -4.1447e-02,  2.3389e-02, -2.4065e-03],\n",
      "          [-3.0698e-02, -4.8701e-02, -3.8716e-02, -4.8162e-02,  7.4120e-03],\n",
      "          [ 3.4525e-02, -1.0956e-02,  4.9234e-02, -4.5656e-02, -2.5188e-02],\n",
      "          [ 2.1617e-02, -4.6071e-02,  3.2187e-02, -4.5330e-02, -6.8979e-03],\n",
      "          [ 1.1324e-02, -4.6052e-02, -3.2515e-02, -3.4972e-02, -2.6949e-02]],\n",
      "\n",
      "         [[ 2.1965e-02,  2.8947e-02, -2.2839e-02,  2.9403e-02, -1.0626e-03],\n",
      "          [-2.8017e-02,  2.2584e-02,  3.5314e-02,  1.0198e-02,  4.1084e-02],\n",
      "          [ 2.0610e-02,  6.8582e-04, -1.8068e-03,  4.3100e-02, -2.6660e-02],\n",
      "          [ 3.1956e-02, -4.9078e-02, -8.2401e-03, -3.4234e-02, -2.9075e-02],\n",
      "          [ 2.7170e-02,  4.5344e-03, -2.9758e-02,  2.4606e-04,  4.9171e-02]],\n",
      "\n",
      "         [[ 1.8133e-02,  1.9479e-02, -2.3498e-02, -2.9264e-02,  3.2535e-02],\n",
      "          [ 3.4698e-03,  2.3500e-02, -4.0526e-02, -4.0461e-02, -4.1198e-02],\n",
      "          [ 2.7898e-02, -2.0969e-02,  1.2138e-02,  2.4405e-03,  1.6368e-02],\n",
      "          [-4.7458e-03,  3.1564e-02, -6.3417e-03, -2.5290e-02, -4.5826e-02],\n",
      "          [-1.5376e-02, -4.2699e-02,  7.6883e-03,  1.1115e-03, -3.7133e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8519e-02,  4.8886e-03, -3.2783e-02,  1.3817e-02,  2.6318e-02],\n",
      "          [ 4.9482e-02,  1.1176e-02, -2.1567e-02,  1.9227e-04,  2.4803e-02],\n",
      "          [-1.3480e-02,  3.0931e-02,  2.6084e-02, -2.4360e-02,  4.9163e-04],\n",
      "          [-4.2852e-02, -4.9259e-03, -4.5007e-02,  4.5926e-03, -2.6710e-03],\n",
      "          [-3.6367e-03, -4.7776e-02, -1.4819e-03,  4.5417e-02,  2.4156e-03]],\n",
      "\n",
      "         [[ 1.3252e-02,  3.1805e-02, -1.0862e-02,  3.7584e-02, -2.9935e-02],\n",
      "          [-9.4833e-03, -4.3161e-02,  1.7176e-02,  1.7909e-02, -1.6185e-02],\n",
      "          [ 1.4598e-03,  3.6261e-02,  4.8279e-02,  4.5895e-02,  4.6895e-03],\n",
      "          [ 4.8186e-02,  2.0053e-02, -3.0248e-02, -6.9150e-03, -9.3597e-03],\n",
      "          [-2.5719e-02,  2.4336e-02, -2.3966e-02,  8.8921e-04,  8.9835e-03]],\n",
      "\n",
      "         [[-2.4539e-02, -1.3784e-02,  8.9235e-04,  4.2254e-03,  1.3510e-02],\n",
      "          [-1.1446e-02, -4.3699e-02, -2.0208e-02, -3.3007e-02, -1.3087e-02],\n",
      "          [-3.9183e-02, -4.2400e-02, -1.0001e-02,  1.0516e-02, -3.5693e-02],\n",
      "          [ 3.0111e-02, -3.3620e-02, -5.3718e-04, -2.0882e-02, -3.9534e-02],\n",
      "          [ 3.9183e-02, -2.7827e-02,  3.9046e-02,  1.5356e-02,  2.3237e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0901e-02, -3.7215e-02,  1.5009e-03, -1.5646e-02, -2.2410e-03],\n",
      "          [ 4.4325e-02,  2.3960e-02,  3.3010e-02,  3.6682e-02,  4.4870e-02],\n",
      "          [-2.6959e-02,  1.7129e-02,  2.9207e-02,  4.6358e-02,  6.5704e-03],\n",
      "          [-1.3433e-02, -2.2759e-02, -4.1797e-02, -1.9204e-02,  4.4391e-02],\n",
      "          [-4.3911e-02,  4.5316e-02, -8.7827e-03, -2.2720e-02, -2.7987e-03]],\n",
      "\n",
      "         [[-1.2772e-02,  5.0545e-03,  4.3150e-02, -2.7273e-02,  2.7659e-03],\n",
      "          [ 3.2359e-02,  4.5526e-02, -5.0275e-03,  7.6363e-03, -6.7967e-03],\n",
      "          [-3.0703e-02,  4.1816e-02, -3.0315e-02, -2.6874e-02,  2.6556e-03],\n",
      "          [ 4.2503e-03,  2.2715e-02,  2.2789e-02,  2.3023e-02,  3.4953e-02],\n",
      "          [-2.7137e-02,  1.5405e-03,  4.9561e-02,  4.9956e-02, -3.9576e-02]],\n",
      "\n",
      "         [[-4.4913e-02, -4.1783e-02, -1.5239e-03,  1.2073e-02,  2.9562e-02],\n",
      "          [-1.8163e-03,  1.3213e-02,  1.0910e-02,  3.4409e-02,  4.4966e-02],\n",
      "          [ 1.1703e-02,  2.7750e-02,  3.9704e-03, -2.6866e-02,  1.6502e-02],\n",
      "          [ 2.6260e-02, -4.1213e-02, -5.0015e-03,  1.5439e-02,  1.1127e-02],\n",
      "          [ 5.7688e-03, -4.1741e-02, -4.4802e-02,  5.3991e-03,  2.6506e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.7887e-02, -9.6812e-03, -2.0312e-02,  2.0441e-02,  3.3638e-02],\n",
      "          [-2.4404e-02, -4.2219e-02, -4.3331e-02, -1.2864e-02,  2.9964e-02],\n",
      "          [-9.0611e-03,  3.6544e-02, -4.0378e-03,  7.6886e-03,  1.8833e-02],\n",
      "          [ 4.2214e-02,  2.9172e-02,  1.6163e-02, -3.6869e-02, -2.3306e-02],\n",
      "          [-2.7872e-02,  4.4245e-02, -2.7353e-02, -3.4530e-02, -3.6912e-02]],\n",
      "\n",
      "         [[ 4.9879e-02, -2.6426e-02,  2.7808e-02,  1.8534e-02, -4.0655e-02],\n",
      "          [ 2.7208e-02,  1.0277e-02,  8.3403e-03,  4.8067e-02,  4.1279e-02],\n",
      "          [ 3.1046e-03, -3.0290e-02,  5.5165e-03,  4.0449e-02,  3.4791e-02],\n",
      "          [ 4.3206e-02,  4.8408e-02, -2.6102e-02,  3.8206e-02, -2.9460e-02],\n",
      "          [ 4.1100e-02,  4.6111e-02,  1.7662e-02, -1.1699e-02,  4.3491e-02]],\n",
      "\n",
      "         [[-3.8958e-02,  2.6744e-02, -2.6578e-02,  4.2537e-04, -1.8314e-02],\n",
      "          [ 4.5359e-02,  1.1530e-02, -3.8170e-02, -9.2798e-03, -3.0799e-02],\n",
      "          [-9.3767e-03, -3.2946e-02,  3.3813e-02,  4.2781e-02, -4.2018e-02],\n",
      "          [ 1.7995e-02,  3.4634e-02, -4.4284e-02,  8.5376e-03,  6.9294e-03],\n",
      "          [-3.6935e-02,  4.1670e-02, -3.3108e-02,  1.0610e-02, -2.8234e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.4584e-02,  2.1758e-02, -4.1614e-02, -4.6226e-02, -1.5639e-02],\n",
      "          [-1.1380e-02, -2.0114e-02, -4.6460e-02, -1.7424e-02,  1.3116e-02],\n",
      "          [ 2.7974e-02, -7.6642e-03,  4.0853e-02,  4.5925e-02,  2.2380e-02],\n",
      "          [-4.8997e-02,  1.8816e-02, -3.6872e-04,  4.4464e-02, -2.7568e-02],\n",
      "          [-3.1506e-02,  4.0736e-02, -8.5194e-03,  1.1427e-02,  2.2123e-02]],\n",
      "\n",
      "         [[ 2.2499e-02, -3.5732e-02, -2.3463e-02, -3.0570e-02, -2.7756e-02],\n",
      "          [-1.1138e-02,  4.2194e-02,  9.5191e-03, -4.2127e-02, -5.5363e-03],\n",
      "          [ 3.7417e-02,  3.4531e-02, -1.4925e-02, -3.7022e-02,  2.8681e-02],\n",
      "          [ 2.2964e-02,  3.7823e-02,  4.4418e-02,  8.5717e-04, -4.8606e-02],\n",
      "          [ 4.9624e-02,  1.4200e-02,  2.7221e-02, -4.9606e-02, -4.5967e-02]],\n",
      "\n",
      "         [[-2.2022e-02, -3.4813e-03, -2.2727e-02,  3.6955e-02, -4.1527e-02],\n",
      "          [-4.6749e-02, -2.2016e-02,  1.7413e-02, -1.9347e-02, -1.8940e-02],\n",
      "          [ 2.0040e-02, -1.0816e-02, -2.0960e-02, -1.9294e-02,  2.5853e-02],\n",
      "          [-1.4420e-03,  2.9770e-02, -4.5376e-02, -1.7837e-02, -1.2246e-02],\n",
      "          [ 4.1742e-02, -2.3806e-02,  1.1664e-02, -2.6456e-02, -1.3357e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8067e-02,  3.7453e-02, -2.7483e-02,  2.6573e-02, -4.1418e-02],\n",
      "          [-2.5639e-02,  3.5324e-02,  6.5747e-03, -3.6826e-02, -1.8069e-03],\n",
      "          [ 1.9156e-02,  9.7029e-03, -4.8729e-02,  4.3671e-03, -3.2737e-02],\n",
      "          [ 4.2988e-02,  4.6772e-02,  4.5952e-02, -1.3590e-02,  1.8515e-03],\n",
      "          [-3.5190e-02,  5.5471e-03,  7.9030e-04, -2.0300e-02, -1.6595e-03]],\n",
      "\n",
      "         [[-3.5799e-03, -5.3345e-03,  1.2368e-02, -3.8481e-02,  3.9203e-02],\n",
      "          [ 4.9547e-04, -3.6066e-02, -1.6456e-02, -2.0573e-03,  2.6024e-02],\n",
      "          [-2.9941e-02, -1.3378e-03,  2.3757e-02, -3.1908e-02,  4.9314e-02],\n",
      "          [ 1.9372e-02, -4.2930e-02,  1.5355e-02, -4.9569e-02, -5.0050e-03],\n",
      "          [ 3.0619e-02, -4.2728e-02,  3.3265e-02,  2.4829e-02,  1.8242e-02]],\n",
      "\n",
      "         [[ 4.4416e-02,  4.0941e-02, -1.3085e-02,  2.3707e-02, -3.3179e-02],\n",
      "          [-1.7666e-03,  1.3590e-02,  2.8045e-02,  2.6638e-02, -2.3280e-02],\n",
      "          [-1.7166e-02,  3.4726e-02, -4.8874e-02, -2.8940e-02, -4.3063e-02],\n",
      "          [ 1.1741e-02, -4.8991e-02,  5.2011e-04, -3.5029e-02,  3.7789e-02],\n",
      "          [-2.0542e-02, -2.7593e-02,  2.1243e-02, -2.4919e-02,  3.0930e-02]]]])), ('conv2.bias', tensor([-0.0389,  0.0009, -0.0100,  0.0390, -0.0224,  0.0104,  0.0372,  0.0334,\n",
      "         0.0426,  0.0466, -0.0370,  0.0240, -0.0395,  0.0368,  0.0246,  0.0263,\n",
      "         0.0258,  0.0324, -0.0056, -0.0380,  0.0408,  0.0292,  0.0442, -0.0437,\n",
      "        -0.0134,  0.0036,  0.0472, -0.0116, -0.0298, -0.0213,  0.0268, -0.0011])), ('fc1.weight', tensor([[ 0.0196, -0.0097,  0.0176,  ...,  0.0202, -0.0197,  0.0015],\n",
      "        [-0.0073,  0.0051,  0.0009,  ...,  0.0112, -0.0137,  0.0058],\n",
      "        [-0.0181, -0.0126,  0.0111,  ...,  0.0107, -0.0226,  0.0252],\n",
      "        ...,\n",
      "        [-0.0151,  0.0157,  0.0227,  ..., -0.0133,  0.0083,  0.0007],\n",
      "        [ 0.0249,  0.0069,  0.0154,  ...,  0.0229, -0.0033,  0.0006],\n",
      "        [ 0.0110,  0.0033, -0.0048,  ..., -0.0003,  0.0230, -0.0144]])), ('fc1.bias', tensor([-0.0213,  0.0142, -0.0008,  0.0126,  0.0119,  0.0237, -0.0147,  0.0237,\n",
      "        -0.0067,  0.0239]))])\n",
      "Establishing client devices...\n",
      "Training dataset has been distributed into 10 pieces.\n",
      "Established 10 client devices.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!-- Client 5 is normal and start iterations. ---!\n",
      "Epoch [1/3], Average Loss: 0.5515913963317871, Average Accuracy: 0.8846982717514038, Average Error: 0.1153017207980156, Culminative Time Used: 0.5769011005759239\n",
      "Epoch [2/3], Average Loss: 0.2350761443376541, Average Accuracy: 0.9286949634552002, Average Error: 0.0713050141930580, Culminative Time Used: 1.1653838008642197\n",
      "Epoch [3/3], Average Loss: 0.1949082911014557, Average Accuracy: 0.9300987124443054, Average Error: 0.0699013173580170, Culminative Time Used: 1.731893703341484\n",
      "{'conv1.weight': tensor([[[[-6.9374e-04,  8.3529e-04,  2.9958e-03,  2.8115e-03,  1.1966e-03],\n",
      "          [-8.8750e-04,  3.3700e-04,  2.5415e-03,  3.5860e-03,  2.4506e-03],\n",
      "          [ 4.4281e-04,  8.9091e-04,  2.1033e-03,  2.9683e-03,  2.3359e-03],\n",
      "          [ 1.9384e-03,  1.7607e-03,  1.5522e-03,  1.8374e-03,  5.0955e-04],\n",
      "          [ 2.6158e-03,  1.6145e-03,  4.6646e-04,  4.8574e-04, -9.3064e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.6414e-05, -1.1965e-04,  1.0855e-05,  4.7412e-04,  5.9338e-04],\n",
      "          [ 2.0639e-04,  4.9400e-04,  9.4308e-04,  1.3040e-03,  1.4237e-03],\n",
      "          [ 7.5704e-05,  3.4399e-04,  3.7743e-04,  1.9214e-04,  6.2500e-04],\n",
      "          [ 5.1800e-05,  1.6001e-04,  3.1819e-04,  1.7797e-04,  4.8905e-04],\n",
      "          [ 9.2467e-05,  1.3325e-04,  1.0741e-03,  1.6539e-03,  1.2181e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.6215e-03,  2.5129e-04,  2.9488e-03,  5.6656e-03,  6.9580e-03],\n",
      "          [ 2.7524e-03,  5.1390e-03,  7.0802e-03,  7.5519e-03,  7.0794e-03],\n",
      "          [ 5.6328e-03,  8.5024e-03,  9.0587e-03,  6.9077e-03,  4.1473e-03],\n",
      "          [ 6.4432e-03,  9.0403e-03,  9.3305e-03,  8.7434e-03,  5.8726e-03],\n",
      "          [ 4.6168e-03,  7.9593e-03,  1.1362e-02,  1.1014e-02,  8.3249e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.7992e-03, -2.9543e-03, -3.0067e-03, -3.1171e-03, -3.7751e-03],\n",
      "          [-5.2509e-03, -3.6708e-03, -3.0887e-03, -3.0915e-03, -2.6452e-03],\n",
      "          [-4.8617e-03, -2.3285e-03, -1.6067e-03, -1.8626e-03, -1.4081e-03],\n",
      "          [-3.5743e-03, -1.7777e-03, -1.3542e-03, -2.2280e-03, -1.6205e-03],\n",
      "          [-3.6648e-03, -2.8218e-03, -2.4616e-03, -2.9682e-03, -2.1432e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8636e-03,  1.7177e-03,  2.3509e-04, -3.9899e-05,  4.5925e-04],\n",
      "          [ 3.6746e-03,  2.5562e-03,  2.7361e-03,  4.4754e-03,  5.8713e-03],\n",
      "          [ 3.7830e-03,  4.8975e-03,  6.3704e-03,  8.2383e-03,  9.9225e-03],\n",
      "          [ 3.3793e-03,  4.6556e-03,  6.1064e-03,  8.0876e-03,  8.5563e-03],\n",
      "          [ 2.1608e-03,  2.8647e-03,  3.8771e-03,  4.9331e-03,  3.8700e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8010e-03,  3.1496e-03,  4.1988e-03,  5.2779e-03,  5.5060e-03],\n",
      "          [ 3.8154e-03,  5.1433e-03,  6.0930e-03,  5.9350e-03,  4.5594e-03],\n",
      "          [ 3.7368e-03,  5.3947e-03,  5.8680e-03,  3.8887e-03,  1.5636e-03],\n",
      "          [ 2.4111e-03,  4.0947e-03,  3.8003e-03,  1.4571e-03, -4.6509e-04],\n",
      "          [ 3.6266e-04,  1.3048e-03,  1.7124e-03,  6.8868e-04, -3.7154e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3817e-04,  7.0667e-04,  9.1880e-04,  1.1989e-03,  9.8654e-04],\n",
      "          [-7.8946e-04, -6.8649e-04,  3.1076e-04,  1.0264e-03,  5.1544e-04],\n",
      "          [-8.4345e-04, -7.5180e-04,  5.6692e-04,  1.7529e-03,  1.4874e-03],\n",
      "          [ 4.4823e-04,  1.2696e-03,  2.9470e-03,  4.6551e-03,  3.6616e-03],\n",
      "          [ 2.5395e-03,  4.0553e-03,  5.0294e-03,  5.1707e-03,  3.8251e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.8564e-03, -2.9541e-03, -2.2069e-03, -1.8448e-03, -1.9637e-03],\n",
      "          [-2.7877e-03, -2.0153e-03, -1.1552e-03, -1.0078e-03, -1.8559e-03],\n",
      "          [-2.6978e-03, -1.3986e-03, -5.7653e-04, -6.9627e-04, -1.8152e-03],\n",
      "          [-3.3844e-03, -2.0337e-03, -9.8427e-04, -1.4199e-03, -1.8497e-03],\n",
      "          [-2.6166e-03, -2.3023e-03, -3.0585e-03, -3.5065e-03, -3.5110e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.4808e-04, -1.7082e-03, -1.4607e-03, -3.9799e-04, -6.2837e-04],\n",
      "          [-2.6276e-03, -3.2066e-03, -3.4689e-03, -2.5016e-03, -2.3601e-03],\n",
      "          [-2.0936e-03, -2.5443e-03, -3.2025e-03, -2.9404e-03, -2.3375e-03],\n",
      "          [-5.1125e-04, -2.5105e-04, -8.8591e-04, -9.7079e-04, -3.0993e-04],\n",
      "          [ 1.7070e-04,  1.0019e-03,  8.2855e-04,  7.8632e-04,  1.1198e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7530e-03,  1.2903e-03,  7.0717e-04,  1.2697e-03,  3.0889e-03],\n",
      "          [ 5.4798e-04,  1.6230e-04,  2.5575e-04,  6.5847e-04,  1.5962e-03],\n",
      "          [ 2.5645e-05,  8.9763e-05,  1.5469e-04,  3.2949e-04,  1.2421e-03],\n",
      "          [ 9.9840e-05,  1.2024e-04,  1.6236e-04,  1.7675e-04,  9.1759e-04],\n",
      "          [-3.7091e-04,  2.7764e-05,  2.8089e-04,  3.2510e-04,  5.8140e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.4860e-03, -2.7339e-03, -3.4564e-03, -3.1245e-03, -2.3478e-03],\n",
      "          [-1.9342e-03, -3.3447e-03, -3.3114e-03, -2.1160e-03, -1.7974e-03],\n",
      "          [-2.8169e-03, -3.4314e-03, -3.3966e-03, -2.8287e-03, -2.8261e-03],\n",
      "          [-2.5860e-03, -2.5889e-03, -3.2316e-03, -4.3423e-03, -5.2338e-03],\n",
      "          [-2.4779e-03, -2.2179e-03, -3.4282e-03, -5.4393e-03, -7.8678e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8365e-03,  4.8086e-03,  5.3972e-03,  5.2743e-03,  4.7969e-03],\n",
      "          [ 2.9456e-03,  3.7108e-03,  5.0181e-03,  6.1770e-03,  6.9228e-03],\n",
      "          [ 1.0482e-03,  9.9583e-04,  1.2122e-03,  2.1195e-03,  3.6914e-03],\n",
      "          [ 1.4974e-04, -4.9995e-05, -2.9250e-05,  1.5119e-05,  1.0827e-03],\n",
      "          [-5.3326e-04, -8.1936e-04, -8.2554e-04, -5.5727e-04,  5.7216e-04]]],\n",
      "\n",
      "\n",
      "        [[[-6.2642e-03, -6.1143e-03, -5.0835e-03, -3.8072e-03, -2.0880e-03],\n",
      "          [-6.0506e-03, -7.0018e-03, -6.5250e-03, -5.4290e-03, -5.5835e-03],\n",
      "          [-9.4568e-03, -8.8205e-03, -9.2330e-03, -9.0658e-03, -8.3209e-03],\n",
      "          [-1.2135e-02, -1.1688e-02, -1.0431e-02, -8.9813e-03, -7.5139e-03],\n",
      "          [-1.0029e-02, -9.3884e-03, -9.3110e-03, -8.9726e-03, -7.2618e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.5438e-04, -1.1112e-03, -1.3884e-03, -1.1412e-03, -9.4043e-04],\n",
      "          [ 6.3690e-04, -5.2354e-04, -1.6812e-03, -1.7827e-03, -1.0964e-03],\n",
      "          [ 2.4300e-03,  1.5145e-03, -5.4050e-04, -1.4080e-03, -8.1406e-04],\n",
      "          [ 2.3053e-03,  1.9222e-03,  8.4840e-05, -4.6698e-04, -1.0642e-04],\n",
      "          [ 5.4895e-04,  2.7280e-04, -8.9991e-04, -7.5254e-04,  2.7543e-04]]],\n",
      "\n",
      "\n",
      "        [[[-7.2030e-03, -7.9142e-03, -7.5672e-03, -7.4881e-03, -7.9595e-03],\n",
      "          [-8.4338e-03, -9.2487e-03, -1.0637e-02, -9.9273e-03, -8.3984e-03],\n",
      "          [-1.4542e-02, -1.4603e-02, -1.4156e-02, -1.2071e-02, -8.2529e-03],\n",
      "          [-1.5808e-02, -1.3706e-02, -1.2822e-02, -1.0919e-02, -6.6437e-03],\n",
      "          [-9.8985e-03, -8.0082e-03, -7.7761e-03, -7.2952e-03, -4.6742e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4913e-03,  1.8613e-03,  2.1774e-03,  1.9262e-03,  2.0306e-03],\n",
      "          [ 2.6646e-03,  2.2744e-03,  2.3106e-03,  2.1322e-03,  2.2080e-03],\n",
      "          [ 1.6076e-03,  1.4137e-03,  1.7580e-03,  1.4029e-03,  1.0524e-03],\n",
      "          [ 3.5297e-05,  5.4937e-04,  1.5447e-03,  1.3306e-03,  3.1046e-05],\n",
      "          [-2.0598e-03, -8.7046e-04, -1.4132e-05, -5.6423e-04, -1.4814e-03]]]]), 'conv1.bias': tensor([ 0.0006, -0.0012,  0.0043, -0.0197,  0.0068,  0.0044,  0.0030,  0.0062,\n",
      "        -0.0010,  0.0049,  0.0091,  0.0058, -0.0377, -0.0006, -0.0385, -0.0004]), 'conv2.weight': tensor([[[[-5.3899e-03, -3.5720e-03, -2.6347e-03, -8.1053e-04, -6.3871e-04],\n",
      "          [-4.1113e-03, -3.3966e-03, -1.7319e-03, -1.3938e-03, -2.6118e-03],\n",
      "          [-3.6437e-03, -4.3564e-03, -3.2234e-03, -3.3241e-03, -4.5569e-03],\n",
      "          [-3.2692e-03, -4.1489e-03, -3.3893e-03, -5.1270e-03, -3.4010e-03],\n",
      "          [-7.5471e-04, -1.4739e-03, -2.2898e-03, -2.4565e-03,  5.5902e-04]],\n",
      "\n",
      "         [[-4.3381e-04, -3.6814e-04, -1.1057e-04, -1.5742e-05, -3.7085e-05],\n",
      "          [-2.7333e-04, -5.2704e-04, -1.0565e-04,  4.3872e-05,  1.2348e-04],\n",
      "          [-1.7695e-04, -3.1802e-04, -1.4200e-04,  6.9986e-06,  2.9306e-04],\n",
      "          [-7.3754e-05, -1.1581e-04, -1.7949e-04, -8.3473e-05, -7.0960e-05],\n",
      "          [-3.4563e-05,  8.4637e-05, -9.2945e-05, -3.2112e-04, -1.0128e-04]],\n",
      "\n",
      "         [[-8.5498e-03, -1.0358e-02, -8.4660e-03, -5.4775e-03, -3.7257e-03],\n",
      "          [-7.9751e-03, -9.0912e-03, -9.0471e-03, -5.0150e-03, -3.7355e-03],\n",
      "          [-6.8869e-03, -7.1765e-03, -7.2586e-03, -6.3378e-03, -5.6128e-03],\n",
      "          [-8.3339e-03, -7.5831e-03, -9.1527e-03, -9.7816e-03, -6.5059e-03],\n",
      "          [-8.6704e-03, -7.7822e-03, -9.2251e-03, -1.0778e-02, -5.7345e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2332e-03, -2.5305e-03, -9.3634e-04, -2.2708e-04,  5.2056e-05],\n",
      "          [-6.3086e-04, -1.6134e-03, -1.5406e-03, -4.0835e-04,  5.7575e-04],\n",
      "          [-6.8852e-04, -1.6409e-03, -1.3893e-03, -3.4314e-04,  5.8010e-04],\n",
      "          [-3.2367e-04, -7.1633e-04, -1.8892e-03, -1.0016e-03, -1.8637e-04],\n",
      "          [ 3.1235e-04,  2.0114e-04, -6.4105e-04, -6.2738e-04, -8.9119e-05]],\n",
      "\n",
      "         [[-7.4403e-03, -8.0339e-03, -7.6829e-03, -4.4359e-03, -2.5517e-03],\n",
      "          [-6.3940e-03, -5.6271e-03, -5.5211e-03, -4.5470e-03, -5.0428e-03],\n",
      "          [-6.6594e-03, -6.1328e-03, -5.6547e-03, -6.0533e-03, -5.8293e-03],\n",
      "          [-7.5072e-03, -6.9412e-03, -7.7828e-03, -9.1565e-03, -5.6639e-03],\n",
      "          [-7.2388e-03, -6.4173e-03, -7.5565e-03, -7.2287e-03, -4.8047e-03]],\n",
      "\n",
      "         [[-3.4861e-04, -4.8767e-04, -2.8427e-04, -1.6802e-05, -6.2493e-04],\n",
      "          [-8.7728e-04, -9.0283e-04, -8.2248e-04, -3.7471e-04, -3.8712e-04],\n",
      "          [-1.0923e-03, -1.4553e-03, -1.2233e-03, -7.3740e-04, -5.2490e-04],\n",
      "          [-7.0232e-04, -1.0006e-03, -1.1909e-03, -9.3919e-04, -9.9872e-04],\n",
      "          [ 2.5017e-04,  1.4946e-04, -8.6402e-04, -1.8495e-03, -1.5375e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8628e-03,  5.3568e-03,  4.9849e-03,  3.9223e-03,  3.1834e-03],\n",
      "          [ 1.5427e-03,  1.0544e-03,  1.4356e-03,  1.7360e-03,  1.9492e-03],\n",
      "          [-2.4914e-03, -3.4243e-03, -1.6355e-03, -2.3302e-03, -3.3303e-03],\n",
      "          [-4.5510e-03, -6.9515e-03, -7.7733e-03, -1.1109e-02, -9.6279e-03],\n",
      "          [-6.4238e-03, -9.9146e-03, -1.4220e-02, -1.6207e-02, -1.0723e-02]],\n",
      "\n",
      "         [[ 2.6708e-04,  5.0482e-04,  1.9672e-04,  4.0090e-05,  9.1169e-05],\n",
      "          [-1.3430e-04,  4.6834e-04,  6.4379e-04,  1.7623e-04,  3.6445e-04],\n",
      "          [-1.6927e-04,  1.0433e-04,  2.6557e-04,  4.0578e-04,  3.5295e-04],\n",
      "          [-2.2798e-04, -1.6378e-04, -6.1804e-05,  1.3974e-04,  1.8125e-04],\n",
      "          [-3.0532e-04, -2.5725e-04, -2.1710e-04,  2.3370e-05,  3.1259e-04]],\n",
      "\n",
      "         [[ 7.9234e-03,  1.0087e-02,  1.2785e-02,  1.1401e-02,  8.4665e-03],\n",
      "          [ 6.3098e-03,  5.6682e-03,  7.1686e-03,  7.1616e-03,  5.9332e-03],\n",
      "          [ 6.9318e-04, -3.7675e-04,  8.7033e-04,  2.6104e-03,  2.3589e-03],\n",
      "          [-3.4119e-03, -4.7227e-03, -4.6645e-03, -6.1669e-03, -4.6434e-03],\n",
      "          [-4.4431e-03, -7.5712e-03, -1.2091e-02, -1.5723e-02, -1.4605e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2110e-04,  7.3449e-04,  1.0723e-03, -1.1477e-04, -8.4163e-04],\n",
      "          [-3.1844e-04, -1.8131e-04,  6.7120e-04,  8.1962e-04,  6.6979e-04],\n",
      "          [-4.0137e-04, -5.7527e-04, -2.8536e-04,  7.6116e-05,  9.0749e-04],\n",
      "          [-5.9126e-04, -1.0128e-03, -1.2599e-03, -5.9678e-04,  3.5156e-04],\n",
      "          [-1.2002e-04, -7.4226e-04, -1.1865e-03, -6.3599e-04,  1.2920e-04]],\n",
      "\n",
      "         [[ 9.0921e-03,  1.0206e-02,  1.0997e-02,  9.6005e-03,  8.1376e-03],\n",
      "          [ 4.6827e-03,  3.6493e-03,  3.8569e-03,  5.8179e-03,  5.0509e-03],\n",
      "          [ 8.0104e-05,  5.6773e-04,  2.2139e-03,  1.4799e-03,  1.6816e-04],\n",
      "          [-2.8634e-03, -2.8140e-03, -3.6283e-03, -6.7296e-03, -6.1072e-03],\n",
      "          [-4.4489e-03, -6.2677e-03, -1.2863e-02, -1.4581e-02, -1.4308e-02]],\n",
      "\n",
      "         [[ 8.9629e-04,  7.6287e-04,  9.2282e-04,  1.8930e-03,  2.0372e-03],\n",
      "          [ 5.4849e-04,  7.0896e-04,  4.8746e-04,  1.2587e-03,  6.2568e-04],\n",
      "          [ 6.0564e-04, -8.7792e-04, -2.0727e-03, -8.7709e-04, -8.6121e-04],\n",
      "          [ 3.5037e-04, -2.1798e-03, -2.8202e-03, -2.0469e-03, -3.0430e-03],\n",
      "          [ 4.2563e-04, -1.6371e-03, -1.8263e-03, -2.5341e-03, -3.5509e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9159e-04,  9.0919e-04,  7.3787e-04, -1.3296e-03, -3.5061e-03],\n",
      "          [-1.2255e-04,  1.1027e-05, -3.5545e-04, -3.7563e-03, -5.1587e-03],\n",
      "          [ 3.5018e-03,  2.9187e-03,  1.9504e-03, -2.7116e-03, -4.1364e-03],\n",
      "          [ 7.2074e-03,  6.0534e-03,  3.1381e-03,  1.2691e-03, -3.3969e-05],\n",
      "          [ 4.9822e-03,  4.8678e-03,  1.4999e-03,  4.2148e-05,  4.2085e-04]],\n",
      "\n",
      "         [[-4.4327e-05,  7.2272e-05,  1.3377e-04, -4.5331e-04, -3.1117e-04],\n",
      "          [-4.7921e-05, -1.0290e-04,  9.4880e-06, -8.3973e-04, -9.4529e-04],\n",
      "          [-4.2863e-05, -3.4464e-04, -1.2734e-04, -3.0953e-04, -1.0023e-03],\n",
      "          [ 1.4339e-04,  2.5892e-04, -2.5618e-04, -1.7234e-04, -5.0449e-04],\n",
      "          [ 8.6101e-05,  2.1362e-04,  3.3807e-05, -2.5813e-04, -2.7656e-04]],\n",
      "\n",
      "         [[-1.4333e-03, -7.7710e-04,  1.6175e-04, -1.8242e-03, -6.5032e-03],\n",
      "          [ 2.3444e-03,  2.2235e-03,  3.3304e-03,  9.5723e-04, -4.1862e-03],\n",
      "          [ 4.0460e-03,  3.9038e-03,  2.1937e-03, -2.1314e-03, -5.2703e-03],\n",
      "          [ 7.9340e-03,  5.9625e-03,  4.0524e-03, -1.4573e-03, -4.0515e-03],\n",
      "          [ 1.3641e-02,  9.4778e-03,  5.4370e-03,  2.9436e-03, -1.9055e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.2414e-05,  2.6162e-04,  4.6826e-04, -5.5668e-04, -3.8259e-04],\n",
      "          [-1.3454e-04, -1.8797e-04,  1.4893e-06, -6.6320e-04, -1.9771e-03],\n",
      "          [ 3.2200e-04,  2.8558e-04, -5.6993e-04, -6.3165e-04, -1.6974e-03],\n",
      "          [ 7.1257e-04,  1.0166e-03,  4.7526e-04, -9.5548e-04, -8.0230e-04],\n",
      "          [ 1.1202e-03,  4.9318e-04, -2.2614e-04, -5.4484e-04, -2.1774e-04]],\n",
      "\n",
      "         [[ 9.9127e-04,  6.1640e-04,  1.3325e-03, -4.2112e-04, -3.4483e-03],\n",
      "          [ 3.2694e-03,  2.6303e-03,  3.1343e-03, -3.6388e-04, -2.2338e-03],\n",
      "          [ 4.3321e-03,  3.9588e-03,  3.0275e-03, -1.7560e-03, -2.6961e-03],\n",
      "          [ 9.3369e-03,  5.8092e-03,  3.5241e-03,  3.9420e-04, -2.6045e-03],\n",
      "          [ 9.4121e-03,  6.8643e-03,  3.7276e-03,  2.9560e-03, -1.0943e-04]],\n",
      "\n",
      "         [[-7.6242e-04, -9.9341e-04, -1.1111e-03, -8.1780e-04, -1.3035e-03],\n",
      "          [-6.0878e-04, -5.2108e-04, -8.0139e-04, -6.8535e-04, -1.2764e-03],\n",
      "          [ 7.2045e-06,  5.5776e-04,  1.1602e-03,  7.6057e-04, -4.8359e-04],\n",
      "          [ 1.2568e-03,  1.2751e-03,  2.2227e-03,  1.2073e-03, -6.0589e-05],\n",
      "          [ 2.3183e-03,  2.1720e-03,  1.8447e-03,  4.7641e-04,  3.4197e-05]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 6.4296e-04, -6.6155e-05,  3.5380e-05,  3.0089e-05,  1.2836e-05],\n",
      "          [ 7.6868e-04,  3.8940e-04,  2.9945e-04,  7.7162e-05, -1.7641e-07],\n",
      "          [-3.1431e-05,  4.8038e-04,  1.1919e-04, -1.1115e-05, -1.9465e-05],\n",
      "          [ 4.6938e-05,  6.4284e-06, -2.3924e-05, -2.1923e-05, -6.3275e-06],\n",
      "          [-1.7393e-04, -7.3529e-05, -9.7376e-05,  2.7264e-06,  1.3173e-06]],\n",
      "\n",
      "         [[-1.5846e-04, -7.2479e-06, -1.5254e-06, -1.8544e-06, -4.8199e-06],\n",
      "          [-3.3631e-05, -2.5869e-06,  3.0673e-07, -7.7583e-08,  1.8460e-06],\n",
      "          [-8.1380e-06, -5.5178e-06,  1.4133e-07,  3.3376e-08,  1.1427e-07],\n",
      "          [ 1.1262e-05, -1.6488e-05, -7.3031e-06,  2.9543e-08,  4.7214e-07],\n",
      "          [ 4.4439e-06, -1.1931e-05, -1.5845e-05, -5.1600e-07, -2.8906e-07]],\n",
      "\n",
      "         [[-3.1921e-04, -1.0152e-03,  4.6145e-06, -1.9529e-05, -3.9084e-04],\n",
      "          [ 1.9811e-03,  9.0802e-04,  3.9393e-04,  1.3734e-04, -3.8635e-04],\n",
      "          [ 2.5694e-03,  2.1651e-03,  9.2432e-04,  2.5655e-04, -4.0253e-04],\n",
      "          [ 1.4739e-03,  1.6548e-03,  7.6311e-04,  1.2463e-04, -4.2698e-04],\n",
      "          [ 2.5883e-04,  3.6058e-04,  3.6686e-04, -7.3124e-05, -4.1738e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5446e-04, -9.8337e-06,  2.2236e-06,  1.1738e-06, -1.2764e-06],\n",
      "          [ 9.4827e-05,  4.8049e-05,  1.9026e-05,  7.5372e-06,  7.7872e-06],\n",
      "          [ 1.1669e-04,  2.5590e-06,  1.3976e-05, -1.1468e-06,  2.2573e-06],\n",
      "          [-2.0270e-05, -2.9371e-05, -5.2766e-05, -8.0936e-07, -1.1180e-06],\n",
      "          [ 1.2959e-05, -1.9996e-06, -5.0300e-05, -1.7193e-06,  1.1210e-06]],\n",
      "\n",
      "         [[ 8.6200e-04,  2.5005e-04,  3.0192e-04,  3.0509e-05, -5.2139e-04],\n",
      "          [ 1.6815e-03,  1.7880e-03,  8.6903e-04,  1.9779e-04, -5.3581e-04],\n",
      "          [ 1.5487e-03,  2.2237e-03,  1.1807e-03,  2.3031e-04, -5.6550e-04],\n",
      "          [ 1.0037e-03,  9.9463e-04,  7.3659e-04,  5.9235e-05, -5.6460e-04],\n",
      "          [ 5.4952e-04,  5.0914e-04,  6.3086e-04, -8.4279e-06, -5.7674e-04]],\n",
      "\n",
      "         [[ 3.7999e-05, -4.2320e-04, -2.8247e-04,  2.7308e-05,  1.7564e-06],\n",
      "          [ 6.5017e-04, -1.6097e-04, -1.5887e-04,  1.3923e-05,  4.3263e-06],\n",
      "          [ 6.1002e-04,  1.3272e-04,  1.5434e-04,  5.4796e-05,  6.7359e-06],\n",
      "          [ 1.1425e-04,  1.1839e-04,  2.4482e-04, -1.2957e-05,  2.1942e-07],\n",
      "          [-4.4588e-04, -2.7343e-05, -7.1654e-06, -6.9190e-05, -7.3678e-06]]],\n",
      "\n",
      "\n",
      "        [[[-3.4643e-05, -2.1178e-04, -8.9514e-04,  1.4127e-03,  5.0133e-03],\n",
      "          [-4.0236e-03, -3.6998e-03, -3.1483e-03, -6.7583e-04,  3.6170e-03],\n",
      "          [-4.6371e-03, -3.4287e-03, -1.9320e-03,  2.3637e-03,  6.3321e-03],\n",
      "          [-2.2482e-03, -6.3776e-04,  1.5791e-03,  6.5572e-03,  9.7055e-03],\n",
      "          [ 8.9633e-04,  1.2359e-03,  5.1732e-03,  8.6238e-03,  6.4392e-03]],\n",
      "\n",
      "         [[ 1.3476e-04,  2.2052e-04, -7.7823e-05,  2.4000e-04,  5.9224e-04],\n",
      "          [-1.3542e-04,  1.3724e-05,  1.3458e-05,  5.5214e-04,  6.6970e-04],\n",
      "          [-2.3202e-04, -2.5763e-04,  6.7241e-05,  4.4854e-04,  6.9499e-04],\n",
      "          [-1.1146e-04, -1.3924e-04,  4.3090e-04,  5.0674e-04,  4.9532e-04],\n",
      "          [-1.3648e-05, -4.5485e-05,  4.9358e-04,  1.0285e-03,  6.4237e-04]],\n",
      "\n",
      "         [[-1.0722e-03,  2.3107e-03,  3.1243e-03,  4.8712e-03,  1.0967e-02],\n",
      "          [-6.0588e-03, -2.1813e-03,  1.8454e-04,  3.7084e-03,  9.0893e-03],\n",
      "          [-8.4829e-03, -5.7992e-03, -2.4439e-03,  1.3062e-03,  7.4764e-03],\n",
      "          [-6.2559e-03, -5.0272e-03, -2.1859e-03,  5.4257e-03,  1.0032e-02],\n",
      "          [-2.5311e-03, -7.4505e-04,  7.5098e-04,  8.5800e-03,  1.1890e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.3832e-04,  1.7960e-04,  3.1524e-04,  7.4507e-04,  1.1454e-03],\n",
      "          [-1.1647e-03, -3.3648e-04,  2.8013e-04,  1.8196e-03,  2.6654e-03],\n",
      "          [-1.9469e-04,  3.2681e-04,  1.7458e-03,  1.6804e-03,  1.9178e-03],\n",
      "          [ 3.0817e-04,  1.2285e-05,  1.8807e-03,  2.3288e-03,  1.1755e-03],\n",
      "          [ 3.4981e-04, -2.5384e-04,  3.5462e-04,  1.1681e-03,  1.1037e-03]],\n",
      "\n",
      "         [[-2.1506e-03,  1.5379e-04,  1.2973e-03,  4.9033e-03,  9.6345e-03],\n",
      "          [-6.2387e-03, -3.3221e-03, -1.3396e-03,  1.4473e-03,  6.5100e-03],\n",
      "          [-6.8309e-03, -4.2032e-03, -2.6844e-03,  1.9535e-03,  7.5672e-03],\n",
      "          [-5.3059e-03, -2.8405e-03, -1.9450e-03,  5.1124e-03,  9.3604e-03],\n",
      "          [-1.7660e-03,  5.4269e-04,  2.7059e-03,  6.2519e-03,  7.9211e-03]],\n",
      "\n",
      "         [[-8.8165e-04, -4.6733e-04, -1.3358e-04, -6.6389e-04, -3.8033e-04],\n",
      "          [-1.3851e-03, -8.6639e-04, -7.1599e-04, -1.0932e-03, -2.7625e-04],\n",
      "          [-2.2128e-03, -1.7217e-03, -1.4415e-03, -9.4858e-04, -3.5545e-04],\n",
      "          [-2.5715e-03, -1.5331e-03, -8.6061e-04, -2.1849e-04,  8.5703e-04],\n",
      "          [-1.2114e-03,  2.0360e-04,  1.6832e-04,  1.0983e-03,  2.5765e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9435e-03,  3.3234e-03,  2.8195e-03,  1.2799e-03,  1.1190e-03],\n",
      "          [ 2.5784e-03,  1.7410e-03,  1.5609e-03,  1.8168e-03, -4.3030e-04],\n",
      "          [ 3.7540e-03,  5.5401e-03,  6.6233e-03,  4.3122e-03,  1.1163e-04],\n",
      "          [ 8.0656e-03,  1.1793e-02,  1.3654e-02,  7.2529e-03,  1.2173e-03],\n",
      "          [ 1.0658e-02,  1.4438e-02,  1.0804e-02,  2.9518e-03, -1.4363e-03]],\n",
      "\n",
      "         [[ 2.4251e-04,  1.1633e-04,  6.5959e-05,  1.2220e-04,  7.1690e-05],\n",
      "          [ 1.1141e-04,  3.6194e-04,  1.6106e-04,  1.4432e-04, -5.5290e-05],\n",
      "          [ 1.4927e-04,  4.8304e-04,  2.4750e-04,  1.3985e-06, -1.9505e-04],\n",
      "          [ 1.4584e-04,  3.9030e-04,  2.1745e-04, -1.2157e-04, -3.2115e-04],\n",
      "          [ 1.5372e-04,  1.2322e-04,  3.4261e-05, -2.3184e-04, -5.2414e-04]],\n",
      "\n",
      "         [[ 1.4677e-02,  1.4325e-02,  1.1403e-02,  8.4706e-03,  6.5720e-03],\n",
      "          [ 1.2692e-02,  1.2494e-02,  1.2787e-02,  8.1879e-03,  5.7153e-03],\n",
      "          [ 1.1277e-02,  1.0310e-02,  1.2595e-02,  1.0126e-02,  4.6152e-03],\n",
      "          [ 1.1213e-02,  1.3505e-02,  1.5408e-02,  1.2751e-02,  5.9108e-03],\n",
      "          [ 1.6545e-02,  1.9466e-02,  2.0246e-02,  1.4575e-02,  6.4896e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.3111e-04,  2.0111e-03,  9.8649e-04,  7.6790e-04, -8.8167e-05],\n",
      "          [ 3.2868e-04,  1.5489e-03,  1.6443e-03,  1.9400e-04, -6.1822e-04],\n",
      "          [ 1.4288e-03,  1.8802e-03,  1.4447e-03,  1.5661e-04, -2.5879e-04],\n",
      "          [ 1.8086e-03,  2.1794e-03,  1.6002e-03,  4.0503e-04, -2.7013e-04],\n",
      "          [ 1.1189e-03,  3.7791e-04,  1.5085e-04, -3.5054e-05, -3.5061e-04]],\n",
      "\n",
      "         [[ 1.1823e-02,  1.2064e-02,  1.0786e-02,  7.0474e-03,  6.3260e-03],\n",
      "          [ 1.2077e-02,  9.6201e-03,  1.0265e-02,  9.0323e-03,  6.4477e-03],\n",
      "          [ 1.0316e-02,  1.0370e-02,  1.1237e-02,  1.0010e-02,  5.4160e-03],\n",
      "          [ 1.2068e-02,  1.4980e-02,  1.6944e-02,  1.3394e-02,  7.6805e-03],\n",
      "          [ 1.6099e-02,  1.9102e-02,  1.4797e-02,  1.0100e-02,  4.4909e-03]],\n",
      "\n",
      "         [[ 2.9888e-03,  1.9551e-03,  9.5840e-04,  1.3639e-03,  8.6956e-04],\n",
      "          [ 1.7206e-03,  1.2574e-03,  1.1520e-03,  1.6132e-03,  4.5423e-04],\n",
      "          [ 1.5386e-03,  1.2044e-03,  1.3099e-03,  2.1065e-03,  1.3419e-03],\n",
      "          [ 1.0653e-03,  6.6353e-04,  1.6370e-03,  2.8702e-03,  1.8004e-03],\n",
      "          [ 8.5204e-04,  1.1757e-03,  3.6255e-03,  4.0120e-03,  2.0822e-03]]]]), 'conv2.bias': tensor([-0.0132,  0.0131,  0.0192,  0.0481,  0.0354, -0.0292, -0.0088,  0.0527,\n",
      "        -0.0047, -0.0276,  0.0219,  0.0375,  0.0213,  0.0072, -0.0205, -0.0084,\n",
      "        -0.0116, -0.0152, -0.0018,  0.0075,  0.0502,  0.0006, -0.0329,  0.0111,\n",
      "         0.0007, -0.0158,  0.0899,  0.0417,  0.0083,  0.0052,  0.0009,  0.0544]), 'fc1.weight': tensor([[2.7584e-05, 1.9380e-03, 4.6545e-03,  ..., 8.9756e-04, 1.0352e-03,\n",
      "         3.8411e-04],\n",
      "        [2.7811e-05, 1.9893e-03, 4.7974e-03,  ..., 9.3436e-04, 1.0692e-03,\n",
      "         3.9556e-04],\n",
      "        [3.0548e-05, 2.1600e-03, 5.1755e-03,  ..., 1.0016e-03, 1.1539e-03,\n",
      "         4.2783e-04],\n",
      "        ...,\n",
      "        [2.7158e-05, 1.9701e-03, 4.7531e-03,  ..., 9.2842e-04, 1.0624e-03,\n",
      "         3.9258e-04],\n",
      "        [2.7689e-05, 1.9870e-03, 4.7824e-03,  ..., 9.3519e-04, 1.0685e-03,\n",
      "         3.9572e-04],\n",
      "        [2.7923e-05, 2.0241e-03, 4.8779e-03,  ..., 9.5930e-04, 1.0948e-03,\n",
      "         4.0423e-04]]), 'fc1.bias': tensor([ 0.0483,  0.0500,  0.0538,  0.0515,  0.0594, -0.4338,  0.0200,  0.0497,\n",
      "         0.0500,  0.0511])}\n",
      "!-- Client 9 is normal and start iterations. ---!\n",
      "Epoch [1/3], Average Loss: 0.5456385016441345, Average Accuracy: 0.8205819129943848, Average Error: 0.1794181019067764, Culminative Time Used: 1.0570670999586582\n",
      "Epoch [2/3], Average Loss: 0.1044868230819702, Average Accuracy: 0.9697563052177429, Average Error: 0.0302437264472246, Culminative Time Used: 2.101190097630024\n",
      "Epoch [3/3], Average Loss: 0.0613637864589691, Average Accuracy: 0.9823069572448730, Average Error: 0.0176930148154497, Culminative Time Used: 3.270489901304245\n",
      "{'conv1.weight': tensor([[[[-9.2644e-04, -2.2199e-03, -3.7918e-03, -2.3812e-03,  6.9292e-04],\n",
      "          [ 7.4935e-04, -6.6176e-04, -1.7608e-03, -8.5835e-04,  1.0386e-03],\n",
      "          [ 3.0207e-03,  2.4892e-03,  1.3172e-03,  7.3585e-04,  4.0788e-04],\n",
      "          [ 4.6373e-03,  4.8645e-03,  4.1013e-03,  1.9206e-03, -9.2882e-05],\n",
      "          [ 3.5076e-03,  4.6024e-03,  4.2655e-03,  2.3390e-03, -4.2943e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7819e-04,  2.1258e-03,  4.1154e-03,  4.6588e-03,  3.3837e-03],\n",
      "          [ 2.0972e-04,  1.2411e-03,  3.1797e-03,  4.1821e-03,  3.5852e-03],\n",
      "          [ 1.5898e-05,  4.1423e-04,  2.4383e-03,  4.3812e-03,  4.1393e-03],\n",
      "          [ 5.7142e-06,  3.9296e-05,  8.1308e-04,  3.4687e-03,  3.9745e-03],\n",
      "          [-4.0183e-05, -2.4002e-05,  3.6378e-05,  1.3326e-03,  2.7461e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1228e-03,  1.3564e-03,  1.0511e-03,  2.9458e-03,  4.9075e-03],\n",
      "          [ 1.0010e-03,  7.1290e-05,  1.4574e-03,  2.8397e-03,  3.3966e-03],\n",
      "          [-4.5797e-04, -8.9314e-04,  3.1841e-04,  8.2526e-04,  9.0205e-04],\n",
      "          [-1.7948e-03, -2.3637e-03, -2.2146e-03, -2.4348e-03, -2.8129e-03],\n",
      "          [-3.9992e-03, -3.8108e-03, -4.0338e-03, -5.0431e-03, -5.4471e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8946e-03,  8.5672e-05,  2.7004e-04,  2.4225e-03,  4.1816e-03],\n",
      "          [ 2.5819e-03,  6.2643e-04,  1.5553e-03,  2.8133e-03,  2.9909e-03],\n",
      "          [ 2.8078e-03,  1.7281e-03,  2.8384e-03,  3.6849e-03,  2.5208e-03],\n",
      "          [ 2.6589e-03,  3.4000e-03,  4.2497e-03,  5.1993e-03,  2.9936e-03],\n",
      "          [ 2.1099e-03,  4.0726e-03,  5.8663e-03,  5.3061e-03,  1.8192e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6153e-03,  4.4186e-03,  3.8480e-03,  2.0803e-03, -5.4151e-04],\n",
      "          [ 4.1687e-03,  2.4785e-03,  1.7791e-03,  1.0557e-03, -5.6320e-04],\n",
      "          [ 2.8192e-03,  1.0793e-03, -1.6177e-04,  4.6007e-04,  1.7073e-04],\n",
      "          [ 2.4952e-03,  2.4945e-04, -1.0581e-03,  1.0671e-03,  2.7678e-03],\n",
      "          [ 3.1801e-03,  1.0780e-03, -7.6341e-04,  2.0807e-03,  4.2041e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.2625e-03, -1.8348e-03, -1.2240e-03, -4.1700e-03, -7.4557e-03],\n",
      "          [-4.7763e-03, -3.4004e-03, -3.9232e-03, -7.0170e-03, -9.7923e-03],\n",
      "          [-5.1910e-03, -4.8021e-03, -6.0086e-03, -7.5179e-03, -9.9231e-03],\n",
      "          [-4.1351e-03, -4.5156e-03, -7.4088e-03, -9.3689e-03, -1.0726e-02],\n",
      "          [-3.8617e-03, -5.0400e-03, -7.4226e-03, -9.4558e-03, -9.9454e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.6849e-04,  7.1586e-04, -2.1077e-03, -5.1123e-03, -4.9198e-03],\n",
      "          [-1.3141e-03, -1.7509e-03, -4.5052e-03, -5.9886e-03, -4.2668e-03],\n",
      "          [-3.2234e-03, -4.4667e-03, -6.2130e-03, -5.2432e-03, -1.0547e-03],\n",
      "          [-3.3880e-03, -4.8394e-03, -4.4604e-03, -1.6771e-03,  2.0034e-03],\n",
      "          [-1.7004e-03, -2.0664e-03, -7.2381e-04,  1.0820e-03,  2.7608e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5342e-05, -4.1771e-04, -8.8830e-05,  8.3272e-04,  1.7361e-03],\n",
      "          [ 3.0487e-04,  1.1010e-03,  3.6565e-03,  4.9667e-03,  3.4648e-03],\n",
      "          [ 3.5036e-03,  4.9013e-03,  6.5583e-03,  7.0922e-03,  4.8295e-03],\n",
      "          [ 6.1352e-03,  6.9106e-03,  6.8439e-03,  6.8521e-03,  5.1000e-03],\n",
      "          [ 6.4142e-03,  6.2121e-03,  5.7898e-03,  6.0211e-03,  4.5406e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5943e-03,  9.6159e-04,  9.6640e-04,  3.7411e-05,  3.5687e-04],\n",
      "          [ 2.3386e-03,  9.5545e-04,  4.0916e-04, -6.9697e-04, -1.3495e-03],\n",
      "          [ 1.8850e-03,  9.3342e-04, -3.7932e-04, -2.1364e-03, -3.5876e-03],\n",
      "          [ 1.2975e-03,  6.1309e-04, -2.1837e-04, -2.4000e-03, -3.8278e-03],\n",
      "          [ 1.6915e-04,  2.2463e-04,  2.6704e-05, -1.8487e-03, -3.2374e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.1848e-03, -1.9856e-03, -7.5862e-04, -1.4681e-03, -4.4150e-03],\n",
      "          [-1.0389e-03, -8.0191e-04, -8.6872e-04, -1.5991e-03, -3.0714e-03],\n",
      "          [-3.2422e-05, -7.1227e-05, -4.4872e-04, -9.9453e-04, -2.3223e-03],\n",
      "          [ 2.8431e-06, -2.5504e-06, -1.4020e-04, -2.6218e-04, -1.3901e-03],\n",
      "          [-1.0989e-04, -2.1978e-04, -3.1096e-04, -1.7382e-04, -7.0729e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.6855e-03, -2.0668e-03, -5.7351e-04, -3.2765e-04, -1.2416e-03],\n",
      "          [-5.8533e-03, -5.4249e-03, -3.1300e-03, -1.5729e-03, -1.6747e-03],\n",
      "          [-8.6773e-03, -7.9949e-03, -4.7802e-03, -2.7238e-03, -1.5663e-03],\n",
      "          [-7.5629e-03, -7.3198e-03, -5.4859e-03, -4.5599e-03, -2.4896e-03],\n",
      "          [-5.4189e-03, -5.8799e-03, -5.3961e-03, -4.1120e-03, -1.9583e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.0216e-04,  1.3479e-03,  2.4698e-03,  3.4036e-03,  3.3290e-03],\n",
      "          [ 1.1192e-03,  2.0885e-03,  3.3217e-03,  4.0208e-03,  3.8780e-03],\n",
      "          [ 1.1003e-03,  1.4156e-03,  2.0939e-03,  2.9238e-03,  3.2351e-03],\n",
      "          [-2.7541e-04, -5.9082e-05,  2.1407e-04,  1.0019e-03,  2.0027e-03],\n",
      "          [-7.0718e-04, -4.8745e-04, -5.2544e-04, -1.4937e-04,  9.2053e-04]]],\n",
      "\n",
      "\n",
      "        [[[-2.6780e-03, -4.5851e-03, -4.4982e-03, -7.8501e-04,  4.3785e-03],\n",
      "          [-2.6143e-04, -2.4388e-03, -2.0292e-03,  8.8554e-04,  5.2697e-03],\n",
      "          [ 5.9251e-04,  4.6609e-05,  7.7858e-04,  3.6087e-03,  6.5108e-03],\n",
      "          [ 1.6474e-03,  1.3528e-03,  1.1354e-03,  1.7625e-03,  4.7251e-03],\n",
      "          [ 1.0082e-03,  4.1843e-04,  4.8118e-04,  1.8961e-03,  3.5329e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.2907e-03, -1.0510e-03, -3.3798e-04,  1.2832e-04, -2.3754e-04],\n",
      "          [-1.7591e-03, -1.4237e-03, -6.9781e-04, -4.9296e-04, -6.4053e-04],\n",
      "          [-1.2929e-03, -1.3378e-03, -1.1187e-03, -9.8001e-04, -7.4773e-04],\n",
      "          [-4.7610e-04, -9.3407e-04, -1.4560e-03, -1.4328e-03, -4.4919e-04],\n",
      "          [ 2.9503e-04,  1.3065e-05, -8.8662e-04, -1.2385e-03, -5.8807e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 8.5039e-03,  5.5771e-03,  5.4976e-03,  7.8624e-03,  1.2623e-02],\n",
      "          [ 6.6090e-03,  3.8622e-03,  5.3950e-03,  8.3061e-03,  1.2340e-02],\n",
      "          [ 9.5577e-03,  8.9722e-03,  8.5203e-03,  8.9576e-03,  1.0292e-02],\n",
      "          [ 1.0828e-02,  1.2139e-02,  1.1779e-02,  1.0380e-02,  9.4619e-03],\n",
      "          [ 9.5748e-03,  1.1714e-02,  1.1801e-02,  1.0260e-02,  9.6553e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8916e-03,  1.0191e-03, -9.1492e-04, -2.2379e-03, -1.6321e-03],\n",
      "          [ 4.8742e-03,  1.0999e-03, -8.3189e-04, -6.5095e-04, -2.8068e-04],\n",
      "          [ 5.6901e-03,  1.6513e-03,  6.4459e-05,  3.2339e-04,  3.8169e-04],\n",
      "          [ 6.6918e-03,  3.9136e-03,  3.1897e-04,  4.7441e-04,  5.3336e-04],\n",
      "          [ 7.1368e-03,  5.8650e-03,  1.9605e-03,  1.7221e-03,  1.8049e-03]]]]), 'conv1.bias': tensor([ 0.0039,  0.0049, -0.0112, -0.0016,  0.0065, -0.0123, -0.0021, -0.0098,\n",
      "         0.0012, -0.0080,  0.0064,  0.0013,  0.0063, -0.0013,  0.0341,  0.0085]), 'conv2.weight': tensor([[[[ 4.5555e-03, -1.1622e-03, -3.3275e-03, -4.9206e-03, -7.6859e-03],\n",
      "          [ 3.1104e-03, -1.5847e-03, -4.7834e-03, -6.7361e-03, -6.1168e-03],\n",
      "          [ 9.3471e-04, -1.7731e-03, -4.7035e-03, -3.7377e-03, -5.6678e-04],\n",
      "          [-5.0173e-04, -1.0589e-03,  6.2533e-04,  1.7272e-03,  9.4654e-04],\n",
      "          [ 1.2917e-04,  1.3194e-03,  4.6452e-03,  1.6328e-03, -2.7677e-03]],\n",
      "\n",
      "         [[ 1.9831e-04,  2.0267e-04, -1.6465e-05,  4.4408e-04,  3.4436e-04],\n",
      "          [ 2.8835e-04,  5.7145e-04,  2.1044e-04,  2.9850e-04,  2.5389e-04],\n",
      "          [ 1.2491e-04,  6.9975e-04,  5.2671e-04,  1.7827e-04,  1.0118e-04],\n",
      "          [ 3.3005e-05,  4.5673e-04,  4.5943e-04,  9.7247e-05, -7.7574e-06],\n",
      "          [ 5.4570e-05,  1.1338e-04,  2.7917e-04,  6.2510e-05, -1.3111e-04]],\n",
      "\n",
      "         [[ 6.2918e-03,  5.5670e-03,  1.6369e-03, -3.6582e-03, -3.7450e-03],\n",
      "          [ 5.6882e-03,  4.7244e-03,  5.0548e-03, -1.1426e-03, -5.3892e-03],\n",
      "          [ 7.4801e-03,  3.2782e-03,  4.4548e-03,  9.0765e-04, -3.9772e-03],\n",
      "          [ 6.6818e-03,  2.4673e-03,  3.2020e-03,  4.1386e-03,  8.4162e-04],\n",
      "          [ 3.2589e-03,  4.0535e-03,  6.4049e-03,  6.5179e-03,  1.7648e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0680e-03,  1.9722e-03,  3.5889e-04, -6.2247e-04, -2.2732e-04],\n",
      "          [ 2.7757e-04,  1.0745e-03,  1.0811e-03,  3.6559e-04,  4.7543e-04],\n",
      "          [ 2.1185e-04,  8.5659e-04,  1.7341e-03,  3.9630e-04, -3.3937e-04],\n",
      "          [ 4.6202e-04,  3.6935e-04,  8.3494e-04,  5.7114e-05, -1.8112e-04],\n",
      "          [ 1.5913e-04,  2.7279e-05,  2.9352e-04,  1.0972e-06, -8.9774e-04]],\n",
      "\n",
      "         [[ 4.1223e-03,  2.0039e-03,  2.4714e-03, -1.0649e-03, -4.1445e-03],\n",
      "          [ 4.0786e-03,  1.1540e-03,  1.5194e-03, -1.4519e-03, -4.9903e-03],\n",
      "          [ 5.0832e-03,  1.3695e-03, -8.1101e-04,  6.8659e-04, -8.0562e-04],\n",
      "          [ 2.3384e-03,  1.2639e-03,  2.3505e-03,  4.8694e-03,  2.8768e-03],\n",
      "          [ 1.8546e-03,  4.3920e-03,  6.8056e-03,  4.5051e-03,  1.5312e-03]],\n",
      "\n",
      "         [[ 1.1558e-04,  9.5104e-04,  1.8291e-05, -5.1255e-04, -5.5635e-04],\n",
      "          [ 9.6254e-04,  3.7037e-04, -1.3615e-04,  1.8125e-04,  5.6124e-05],\n",
      "          [ 1.6461e-03, -4.5411e-05,  4.4990e-04,  1.0322e-03,  1.0164e-04],\n",
      "          [ 2.2027e-03,  5.3688e-04,  4.8691e-04,  9.9973e-04,  1.3497e-04],\n",
      "          [ 1.9232e-03,  1.2385e-04, -2.6516e-05,  2.6611e-03,  1.6626e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.6209e-03, -1.1956e-02, -1.0025e-02, -5.1886e-03,  9.4398e-04],\n",
      "          [-1.0559e-02, -1.3553e-02, -7.5341e-03, -3.5165e-03, -4.2554e-04],\n",
      "          [-8.6012e-03, -7.8859e-03, -4.8544e-03, -1.1311e-04,  2.8497e-03],\n",
      "          [-2.0276e-03, -3.4989e-04,  2.9156e-03,  6.7282e-03,  5.0202e-03],\n",
      "          [ 3.6906e-03,  7.1918e-03,  8.6615e-03,  5.5637e-03,  9.3212e-04]],\n",
      "\n",
      "         [[-7.9227e-04, -1.2077e-03, -2.2352e-04,  2.6008e-04,  1.2214e-03],\n",
      "          [-7.8667e-04, -1.5159e-03, -7.5316e-04,  1.4580e-05,  3.9259e-04],\n",
      "          [-7.2477e-04, -1.1037e-03, -9.8139e-04, -2.7409e-04,  7.6667e-06],\n",
      "          [-1.2907e-04, -5.2686e-04, -8.0787e-04, -4.3971e-04, -9.8748e-05],\n",
      "          [ 1.4107e-04, -1.4048e-04, -5.4184e-04, -1.0630e-03, -1.8653e-04]],\n",
      "\n",
      "         [[ 1.7390e-03, -9.3823e-03, -1.3822e-02, -7.4589e-03, -6.1169e-04],\n",
      "          [-4.8537e-03, -1.2128e-02, -1.6685e-02, -1.2611e-02, -4.2423e-03],\n",
      "          [-7.9179e-03, -1.2635e-02, -1.5213e-02, -1.3878e-02, -6.5140e-03],\n",
      "          [-5.8157e-03, -7.9780e-03, -8.5422e-03, -9.3941e-03, -5.9526e-03],\n",
      "          [ 2.9218e-03,  3.4075e-04,  2.3216e-03, -2.8455e-04, -3.5543e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1331e-03, -2.0579e-03, -1.8932e-03, -3.9284e-04,  9.3069e-05],\n",
      "          [-9.7745e-04, -1.4425e-03, -1.8346e-03, -7.3146e-04, -1.9226e-04],\n",
      "          [-2.0931e-04, -8.2736e-04, -1.6142e-03, -7.1531e-04, -7.5225e-05],\n",
      "          [ 4.9662e-04,  5.1855e-04,  1.2628e-04, -9.1785e-04, -2.6538e-04],\n",
      "          [ 1.2249e-03,  6.4385e-04,  3.6915e-04, -5.7020e-04,  7.5936e-05]],\n",
      "\n",
      "         [[-1.0790e-03, -5.7640e-03, -8.8770e-03, -5.7273e-03, -1.3337e-03],\n",
      "          [-6.0733e-03, -8.3793e-03, -7.9933e-03, -7.2470e-03, -3.5769e-03],\n",
      "          [-6.2085e-03, -7.0206e-03, -6.9530e-03, -6.1940e-03, -3.3467e-03],\n",
      "          [-3.2875e-03, -4.0137e-03, -1.4892e-03, -3.3047e-04, -1.5839e-03],\n",
      "          [ 3.1429e-03,  3.4304e-03,  5.5795e-03,  3.5482e-03, -2.0767e-03]],\n",
      "\n",
      "         [[ 3.6099e-03, -2.1312e-04, -3.1544e-03, -3.5560e-03, -1.5454e-03],\n",
      "          [ 1.6264e-03, -6.8167e-04, -3.8284e-03, -3.6448e-03, -1.7245e-03],\n",
      "          [ 8.7272e-04, -1.1329e-03, -2.9222e-03, -2.5326e-03, -1.9925e-03],\n",
      "          [ 5.6681e-04, -3.9245e-04, -1.4136e-03, -2.1131e-03, -2.3598e-03],\n",
      "          [-7.7526e-05, -1.8898e-06, -5.7077e-04, -9.8905e-04, -1.2153e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.0660e-03, -4.8516e-03, -8.5236e-03, -8.0105e-03, -5.5715e-03],\n",
      "          [-5.0074e-03, -9.3621e-03, -9.7162e-03, -2.1876e-03,  7.6730e-04],\n",
      "          [-1.1068e-02, -1.3831e-02, -7.2570e-03,  1.1971e-03,  2.8805e-03],\n",
      "          [-1.4773e-02, -1.3670e-02, -3.0793e-03,  5.5185e-04, -3.8231e-04],\n",
      "          [-1.1831e-02, -9.3602e-03, -3.1184e-03, -2.0958e-03, -3.1589e-03]],\n",
      "\n",
      "         [[-8.9523e-04, -3.3386e-04,  2.2625e-04,  7.8816e-04,  9.1785e-05],\n",
      "          [-7.8467e-04, -3.3380e-04,  7.9431e-05,  1.0342e-03,  5.7301e-04],\n",
      "          [-5.8011e-04, -3.8009e-04, -3.2881e-05,  5.3011e-04,  7.7378e-04],\n",
      "          [-2.2025e-04, -4.0141e-04, -1.2608e-04,  2.1338e-04,  5.9000e-04],\n",
      "          [-5.4652e-04, -5.0306e-04, -1.2264e-04,  2.4172e-04,  3.4673e-04]],\n",
      "\n",
      "         [[-1.6602e-02, -1.5069e-02, -1.2637e-02, -7.6618e-03, -4.6857e-03],\n",
      "          [-1.3241e-02, -1.9408e-02, -1.8016e-02, -1.1742e-02, -2.7415e-03],\n",
      "          [-1.4545e-02, -2.2219e-02, -1.9314e-02, -8.7914e-03,  1.6478e-04],\n",
      "          [-2.1381e-02, -2.2193e-02, -1.7999e-02, -7.1391e-03, -3.3690e-04],\n",
      "          [-2.5823e-02, -2.1557e-02, -1.3461e-02, -7.8325e-03, -4.2028e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6450e-03, -1.3512e-03, -1.3361e-04,  1.1248e-03,  4.7742e-04],\n",
      "          [-1.1184e-03, -1.1351e-03,  1.3711e-04,  7.7738e-04,  1.7581e-03],\n",
      "          [-7.2604e-04, -1.4790e-03, -6.7698e-04,  9.7825e-06,  6.6948e-04],\n",
      "          [-4.5548e-04, -8.5896e-04, -1.4997e-03, -4.2713e-04,  4.7930e-04],\n",
      "          [-1.2387e-03, -8.3434e-04, -3.5163e-04, -3.6866e-04, -4.0335e-04]],\n",
      "\n",
      "         [[-9.4866e-03, -1.1472e-02, -1.3888e-02, -1.1917e-02, -6.5086e-03],\n",
      "          [-9.1434e-03, -1.6085e-02, -1.6137e-02, -9.4930e-03, -2.7343e-03],\n",
      "          [-1.4400e-02, -1.8102e-02, -1.4697e-02, -6.9781e-03, -2.6835e-03],\n",
      "          [-2.0738e-02, -1.7520e-02, -1.1341e-02, -6.7007e-03, -4.3463e-03],\n",
      "          [-1.8145e-02, -1.4613e-02, -9.4979e-03, -6.6903e-03, -5.0593e-03]],\n",
      "\n",
      "         [[-3.9367e-03, -2.7428e-03, -1.4187e-03, -6.9723e-04,  4.6225e-04],\n",
      "          [-3.0335e-03, -1.4981e-03, -3.4870e-03, -3.1539e-03, -1.4601e-03],\n",
      "          [-1.9122e-03, -1.8924e-03, -6.7722e-03, -4.2364e-03, -6.1554e-04],\n",
      "          [-2.1728e-03, -5.1347e-03, -8.5743e-03, -3.6961e-03,  2.0350e-04],\n",
      "          [-4.1942e-03, -7.8794e-03, -7.5121e-03, -2.2760e-03,  1.4670e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-6.7013e-04, -8.4450e-04, -3.7981e-05, -3.5665e-05, -5.5573e-05],\n",
      "          [ 8.4257e-05, -2.3532e-04, -6.3283e-05, -2.0801e-05, -4.7138e-05],\n",
      "          [ 4.9064e-04, -2.6755e-04, -1.4413e-04, -1.4791e-05, -2.0842e-05],\n",
      "          [ 3.8282e-04, -2.6496e-04, -7.9860e-05, -8.1616e-06,  1.1704e-07],\n",
      "          [-1.2789e-03, -3.9936e-04, -1.3261e-04, -1.2719e-05,  2.3358e-07]],\n",
      "\n",
      "         [[ 8.1401e-05, -1.4248e-06, -3.6889e-07, -7.8370e-06, -3.2850e-05],\n",
      "          [-2.2986e-05, -3.7496e-05, -9.9669e-07, -1.9866e-06, -3.1260e-05],\n",
      "          [-2.2298e-04, -4.6530e-05, -3.8523e-07, -1.4216e-07, -1.2892e-05],\n",
      "          [-9.8415e-05, -3.6488e-05, -3.8096e-06, -1.1137e-08, -4.9469e-07],\n",
      "          [-1.3594e-04, -3.9940e-05, -1.3936e-05,  8.0300e-08, -2.8856e-07]],\n",
      "\n",
      "         [[ 5.3698e-04, -3.5155e-04, -1.2122e-03, -6.5029e-04, -4.2730e-04],\n",
      "          [-6.1095e-04, -5.4298e-04, -8.4913e-04, -4.1379e-04, -2.5486e-04],\n",
      "          [-2.7343e-03, -9.4219e-04, -9.2410e-04, -3.4864e-04, -2.3245e-04],\n",
      "          [-3.3964e-03, -1.4352e-03, -6.6787e-04, -1.7883e-04,  9.5268e-06],\n",
      "          [-3.3711e-03, -2.2229e-03, -7.5829e-04, -1.5702e-04,  8.4129e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4565e-04, -2.3975e-06,  5.1418e-07,  9.1413e-07, -3.2360e-05],\n",
      "          [ 6.1466e-06, -5.2770e-05, -5.3512e-07,  4.1300e-07, -1.0431e-05],\n",
      "          [-2.3538e-04, -1.9187e-04, -4.1470e-05, -2.2061e-06, -1.2455e-07],\n",
      "          [-3.3990e-04, -9.6456e-05, -3.0164e-05, -2.1948e-06, -2.0502e-06],\n",
      "          [-4.8951e-04, -5.4540e-05, -4.3277e-05, -4.3963e-06, -5.9812e-08]],\n",
      "\n",
      "         [[-1.1015e-03, -7.9529e-04, -9.4342e-04, -5.9001e-04, -3.4996e-04],\n",
      "          [-1.6087e-03, -8.1061e-04, -1.0052e-03, -5.2581e-04, -3.0832e-04],\n",
      "          [-2.3732e-03, -1.6932e-03, -1.2028e-03, -4.9227e-04, -2.9905e-04],\n",
      "          [-1.9297e-03, -1.4299e-03, -7.1039e-04, -2.2660e-04,  8.5364e-06],\n",
      "          [-1.9369e-03, -1.9118e-03, -7.2715e-04, -1.5007e-04,  1.0683e-04]],\n",
      "\n",
      "         [[ 3.5031e-04,  4.9959e-04, -4.4719e-04, -1.4932e-04, -2.4109e-05],\n",
      "          [ 7.3896e-05,  4.8233e-04, -2.1963e-04, -3.3236e-06, -6.4863e-06],\n",
      "          [ 2.1781e-04,  5.0115e-04, -1.4788e-04, -1.6468e-05, -1.7197e-06],\n",
      "          [ 5.2613e-04, -2.9947e-04, -3.0549e-04, -5.4104e-05, -2.2922e-06],\n",
      "          [ 1.3264e-04, -1.1617e-03, -4.4887e-04, -7.3226e-05, -9.3808e-06]]],\n",
      "\n",
      "\n",
      "        [[[-1.1631e-03, -4.9894e-03, -8.2849e-03, -9.6560e-03, -3.6556e-03],\n",
      "          [-5.5997e-03, -6.5560e-03, -6.9739e-03, -4.4552e-03,  4.3351e-04],\n",
      "          [-7.6214e-03, -6.4650e-03, -4.5644e-03, -3.7213e-04,  2.7958e-03],\n",
      "          [-9.4633e-03, -7.8186e-03, -6.4609e-03, -6.8480e-04,  3.9447e-03],\n",
      "          [-1.0126e-02, -1.0051e-02, -5.1224e-03,  1.9661e-03,  4.6535e-03]],\n",
      "\n",
      "         [[ 2.9564e-04,  2.2107e-05, -3.3787e-04, -8.0290e-04, -9.7336e-04],\n",
      "          [ 5.2478e-04,  2.1005e-05, -1.3613e-04, -6.1349e-04, -7.0815e-04],\n",
      "          [ 3.1558e-04,  5.3280e-05, -1.7577e-04, -8.6738e-05, -3.5177e-04],\n",
      "          [ 4.7201e-05,  3.7243e-05,  1.0356e-04,  4.9222e-04,  3.1415e-04],\n",
      "          [-1.1334e-04,  1.4032e-04,  5.7992e-04,  1.1238e-03,  6.8427e-04]],\n",
      "\n",
      "         [[-8.8174e-04, -2.5586e-03, -7.1568e-03, -1.1142e-02, -8.7545e-03],\n",
      "          [-2.6636e-03, -3.1309e-03, -7.6743e-03, -8.5860e-03, -4.8827e-03],\n",
      "          [-6.2558e-03, -4.8297e-03, -4.4495e-03, -2.1620e-03, -1.0689e-04],\n",
      "          [-1.0592e-02, -7.7171e-03, -3.5858e-03,  1.6964e-03,  4.9119e-03],\n",
      "          [-1.5025e-02, -1.0514e-02, -5.7718e-03,  2.1346e-03,  6.4673e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.9093e-04, -2.4814e-04, -4.0630e-04, -6.2702e-04, -1.1133e-03],\n",
      "          [ 7.7611e-04,  7.7241e-04, -8.4658e-05, -3.7355e-04, -4.1201e-04],\n",
      "          [ 9.0755e-05,  9.0611e-04,  9.6559e-04,  4.7119e-04,  5.9169e-04],\n",
      "          [-6.6575e-04, -6.5120e-04,  2.3367e-04,  6.3488e-04,  7.8465e-04],\n",
      "          [-1.3480e-03, -5.5982e-04, -3.5727e-04, -2.2220e-05,  3.7279e-04]],\n",
      "\n",
      "         [[-2.3655e-03, -2.7662e-03, -7.3185e-03, -8.0176e-03, -3.1301e-03],\n",
      "          [-5.9144e-03, -5.1675e-03, -7.5236e-03, -5.2794e-03, -1.4234e-03],\n",
      "          [-7.1933e-03, -6.0347e-03, -3.8253e-03, -2.6179e-04,  1.1416e-03],\n",
      "          [-9.8013e-03, -7.7290e-03, -5.7403e-03, -4.9603e-04,  2.7033e-03],\n",
      "          [-1.2531e-02, -1.0023e-02, -5.2107e-03,  7.8804e-04,  3.4603e-03]],\n",
      "\n",
      "         [[ 1.2714e-03, -2.9600e-05, -7.4333e-04, -2.5892e-03, -4.8452e-03],\n",
      "          [ 2.2047e-06, -1.7982e-03, -1.4753e-03, -3.9584e-03, -3.4608e-03],\n",
      "          [-2.5026e-03, -3.7248e-03, -3.0421e-03, -3.8250e-03, -8.6917e-04],\n",
      "          [-4.1729e-03, -4.5962e-03, -2.7407e-03, -1.7616e-03,  1.3588e-03],\n",
      "          [-3.7405e-03, -3.8559e-03, -2.1620e-03, -8.4472e-04,  1.9409e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.7115e-03, -5.4138e-03, -2.1692e-03, -5.7997e-04, -3.9670e-03],\n",
      "          [-4.8036e-03, -2.0825e-03, -6.4831e-04, -2.6383e-03, -6.7953e-03],\n",
      "          [-3.1576e-03, -3.0656e-03, -3.9726e-03, -5.5572e-03, -7.6899e-03],\n",
      "          [-4.4987e-03, -7.6237e-03, -9.3058e-03, -7.3200e-03, -5.5253e-03],\n",
      "          [-5.9739e-03, -1.0105e-02, -7.4729e-03, -2.6869e-03, -6.8239e-04]],\n",
      "\n",
      "         [[-1.8092e-04, -6.4843e-05, -1.0782e-04, -2.4688e-04, -4.3146e-04],\n",
      "          [-3.1432e-04, -3.5315e-04, -1.2293e-04, -1.2087e-04, -1.2079e-04],\n",
      "          [-4.1406e-04, -4.5397e-04, -1.0075e-04,  2.3124e-05, -1.6036e-04],\n",
      "          [-3.6992e-04, -4.4033e-04,  3.1539e-05,  6.5835e-05, -2.7483e-04],\n",
      "          [-1.9440e-04, -2.0985e-04,  1.7984e-04,  1.2344e-04, -1.0450e-04]],\n",
      "\n",
      "         [[-1.2671e-02, -1.3041e-02, -1.1178e-02, -7.9339e-03, -8.2914e-03],\n",
      "          [-1.2120e-02, -1.1097e-02, -8.9559e-03, -5.5300e-03, -8.6826e-03],\n",
      "          [-1.0857e-02, -7.6351e-03, -7.9298e-03, -7.3353e-03, -9.5748e-03],\n",
      "          [-1.0421e-02, -9.8168e-03, -1.1321e-02, -1.0582e-02, -1.0524e-02],\n",
      "          [-1.2243e-02, -1.3728e-02, -1.5151e-02, -1.1919e-02, -7.8087e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4400e-04, -5.7121e-04, -7.5738e-05,  8.4395e-06, -1.7088e-04],\n",
      "          [-1.9043e-04, -5.4908e-04, -4.3848e-04,  5.6940e-05,  3.8200e-04],\n",
      "          [-5.1997e-04, -8.0983e-04, -3.7600e-04,  2.9163e-04,  2.4673e-04],\n",
      "          [-1.1418e-03, -1.2794e-03, -4.5949e-04,  8.8823e-05,  2.4627e-04],\n",
      "          [-6.2445e-04, -3.2633e-04, -3.5504e-04,  2.2485e-05, -8.0438e-05]],\n",
      "\n",
      "         [[-1.0457e-02, -1.0059e-02, -8.8759e-03, -5.9129e-03, -8.1560e-03],\n",
      "          [-9.9513e-03, -6.5020e-03, -6.5560e-03, -7.0020e-03, -1.0150e-02],\n",
      "          [-7.6898e-03, -5.9353e-03, -7.6795e-03, -9.5194e-03, -1.1576e-02],\n",
      "          [-8.6185e-03, -9.0385e-03, -1.2379e-02, -1.2391e-02, -1.0407e-02],\n",
      "          [-1.0332e-02, -1.3525e-02, -1.2639e-02, -9.8800e-03, -5.4167e-03]],\n",
      "\n",
      "         [[-2.8557e-03, -2.4894e-03, -2.9997e-03, -2.3813e-03, -1.0530e-03],\n",
      "          [-3.1201e-03, -2.7567e-03, -2.9483e-03, -1.6079e-03, -1.0043e-04],\n",
      "          [-3.6291e-03, -2.6803e-03, -1.9245e-03, -1.2430e-03, -4.0798e-04],\n",
      "          [-2.5732e-03, -1.2550e-03, -1.5048e-03, -1.6723e-03, -1.6855e-03],\n",
      "          [-1.1678e-03, -6.1747e-04, -1.8433e-03, -2.7412e-03, -2.3425e-03]]]]), 'conv2.bias': tensor([ 0.0011,  0.0188, -0.0389, -0.0423, -0.0132, -0.0213,  0.0371,  0.0311,\n",
      "         0.0284,  0.0349,  0.0175, -0.0157, -0.0137, -0.0071,  0.0349,  0.0280,\n",
      "         0.0503,  0.0447, -0.0116, -0.0225,  0.0174,  0.0245,  0.0361, -0.0242,\n",
      "        -0.0113,  0.0278, -0.0595,  0.0144,  0.0013, -0.0083, -0.0085, -0.0364]), 'fc1.weight': tensor([[-1.5855e-04, -1.2347e-02, -3.1256e-02,  ..., -3.1750e-03,\n",
      "         -5.8960e-03, -2.7543e-03],\n",
      "        [ 1.8753e-05,  1.9307e-03,  5.0126e-03,  ...,  7.3374e-04,\n",
      "          9.8824e-04,  4.3892e-04],\n",
      "        [ 2.1058e-05,  2.1296e-03,  5.5074e-03,  ...,  8.0111e-04,\n",
      "          1.0864e-03,  4.8345e-04],\n",
      "        ...,\n",
      "        [ 1.8064e-05,  1.8901e-03,  4.9060e-03,  ...,  7.2740e-04,\n",
      "          9.7792e-04,  4.3107e-04],\n",
      "        [ 1.8524e-05,  1.9141e-03,  4.9668e-03,  ...,  7.3254e-04,\n",
      "          9.8598e-04,  4.3573e-04],\n",
      "        [-2.4814e-06, -4.2144e-03, -1.1673e-02,  ..., -3.1116e-03,\n",
      "         -2.5999e-03, -1.0112e-03]]), 'fc1.bias': tensor([-0.3013,  0.0486,  0.0534,  0.0510,  0.0588,  0.0519,  0.0575,  0.0480,\n",
      "         0.0484, -0.1165])}\n",
      "!-- Client 4 is normal and start iterations. ---!\n",
      "Epoch [1/3], Average Loss: 0.4920528233051300, Average Accuracy: 0.7865204215049744, Average Error: 0.2134795486927032, Culminative Time Used: 1.8823643997311592\n",
      "Epoch [2/3], Average Loss: 0.0805255994200706, Average Accuracy: 0.9766246080398560, Average Error: 0.0233753826469183, Culminative Time Used: 3.9297777004539967\n",
      "Epoch [3/3], Average Loss: 0.0501557476818562, Average Accuracy: 0.9859148263931274, Average Error: 0.0140851978212595, Culminative Time Used: 5.809206701815128\n",
      "{'conv1.weight': tensor([[[[ 4.2576e-04,  1.0981e-03,  2.2660e-03,  3.2956e-03,  4.2327e-03],\n",
      "          [ 8.8591e-05,  7.7751e-04,  2.4015e-03,  4.2843e-03,  5.3413e-03],\n",
      "          [ 2.2514e-04,  5.7800e-04,  1.8234e-03,  3.7110e-03,  4.9103e-03],\n",
      "          [ 9.3635e-04,  4.9351e-04,  1.0208e-03,  2.7383e-03,  3.8533e-03],\n",
      "          [ 2.0990e-03,  1.1405e-03,  1.1560e-03,  2.7068e-03,  3.9108e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7092e-04,  2.5977e-04, -1.4316e-05,  1.1886e-04,  2.3582e-04],\n",
      "          [ 1.4472e-04,  2.7948e-04,  2.0125e-04,  4.3844e-04,  6.3523e-04],\n",
      "          [ 3.3339e-05,  1.2868e-04, -4.7239e-05, -9.5656e-06,  3.2503e-04],\n",
      "          [ 1.1638e-05,  5.6012e-06, -1.8992e-04, -1.7335e-04,  1.5389e-04],\n",
      "          [-3.8187e-07,  5.9170e-06,  3.0991e-04,  4.7297e-04,  3.7480e-04]]],\n",
      "\n",
      "\n",
      "        [[[-9.3831e-03, -9.2637e-03, -9.2240e-03, -1.1075e-02, -9.3792e-03],\n",
      "          [-8.2180e-03, -9.7507e-03, -1.0627e-02, -1.1204e-02, -8.0232e-03],\n",
      "          [-6.0114e-03, -9.8353e-03, -1.0993e-02, -9.7260e-03, -5.9667e-03],\n",
      "          [-5.5125e-03, -8.5924e-03, -9.2856e-03, -8.2811e-03, -4.0302e-03],\n",
      "          [-4.2903e-03, -6.5574e-03, -7.6848e-03, -5.7497e-03, -1.9866e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.1788e-03, -4.7102e-03, -4.5154e-03, -6.9470e-03, -9.7575e-03],\n",
      "          [-9.1602e-03, -5.5929e-03, -6.7399e-03, -8.2358e-03, -7.5101e-03],\n",
      "          [-1.0002e-02, -6.5759e-03, -7.6312e-03, -7.6330e-03, -5.7477e-03],\n",
      "          [-9.1378e-03, -7.3204e-03, -6.4915e-03, -5.8628e-03, -4.0092e-03],\n",
      "          [-9.2290e-03, -6.3906e-03, -4.7846e-03, -4.5997e-03, -3.6206e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4959e-04,  1.3397e-03,  1.5645e-03,  1.6255e-03,  1.6545e-03],\n",
      "          [ 3.3041e-04,  1.5057e-03,  2.1891e-03,  2.8335e-03,  3.2677e-03],\n",
      "          [ 1.1167e-06,  1.7952e-03,  2.7878e-03,  3.7441e-03,  4.6349e-03],\n",
      "          [ 7.7357e-04,  2.0076e-03,  2.6320e-03,  3.5802e-03,  4.9373e-03],\n",
      "          [ 1.3578e-03,  1.7662e-03,  1.9839e-03,  3.2287e-03,  4.2432e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7862e-03,  5.0680e-03,  6.8891e-03,  9.6654e-03,  1.0129e-02],\n",
      "          [ 4.6488e-03,  6.2371e-03,  8.7661e-03,  1.0386e-02,  9.5395e-03],\n",
      "          [ 3.9674e-03,  6.3619e-03,  9.0463e-03,  8.3405e-03,  6.6416e-03],\n",
      "          [ 3.0474e-03,  6.4033e-03,  8.9110e-03,  7.3119e-03,  5.4300e-03],\n",
      "          [ 2.4590e-03,  5.9930e-03,  7.9446e-03,  6.5729e-03,  5.0311e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.3120e-04, -2.2537e-04, -5.8940e-04, -5.8873e-04, -2.1095e-04],\n",
      "          [-1.1779e-03, -8.4975e-04, -1.2774e-04,  4.4879e-04,  8.4951e-04],\n",
      "          [-1.6884e-03, -1.1915e-03,  1.6889e-04,  1.6656e-03,  2.7027e-03],\n",
      "          [-9.2100e-04, -1.4681e-04,  1.2425e-03,  3.3746e-03,  3.6315e-03],\n",
      "          [ 2.5803e-04,  1.6614e-03,  3.3328e-03,  4.4773e-03,  3.5604e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.0651e-03, -1.9287e-03, -3.3930e-04,  1.2555e-03,  1.7540e-03],\n",
      "          [-2.2384e-03, -1.6877e-03,  7.1405e-04,  2.5151e-03,  2.1792e-03],\n",
      "          [-2.1526e-03, -4.5178e-04,  1.9722e-03,  2.7025e-03,  1.8661e-03],\n",
      "          [-2.1828e-03, -2.1404e-04,  1.8580e-03,  1.4452e-03,  5.8851e-04],\n",
      "          [-2.4914e-03, -8.1128e-04, -7.6753e-05, -9.8968e-04, -1.5569e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1438e-04,  7.3835e-04,  1.1893e-03,  1.1466e-03, -3.3205e-04],\n",
      "          [-1.3127e-03, -8.1915e-04, -4.0229e-04, -5.2764e-04, -1.7655e-03],\n",
      "          [-1.6922e-03, -1.5356e-03, -1.1929e-03, -1.6800e-03, -2.3771e-03],\n",
      "          [-1.0181e-03, -7.3481e-04, -6.0015e-04, -1.4575e-03, -1.5615e-03],\n",
      "          [-5.2960e-04, -9.2491e-05,  2.6168e-05, -7.6875e-04, -6.3414e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7051e-03,  9.8997e-04,  7.8635e-04,  1.2299e-03,  2.3146e-03],\n",
      "          [ 8.3624e-04,  3.3267e-04,  5.1237e-04,  6.7964e-04,  9.8122e-04],\n",
      "          [ 1.4898e-04,  9.6252e-05,  2.8664e-04,  3.6127e-04,  1.7991e-03],\n",
      "          [ 1.2713e-04, -2.9302e-05,  3.3544e-05,  2.9369e-04,  3.0939e-03],\n",
      "          [ 3.6122e-04,  1.5913e-04,  2.8982e-04,  1.2365e-03,  3.1359e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.1296e-03, -5.1385e-03, -5.2439e-03, -4.2372e-03, -3.4500e-03],\n",
      "          [-4.9584e-03, -5.5790e-03, -4.8058e-03, -3.1738e-03, -2.4170e-03],\n",
      "          [-3.4022e-03, -3.5783e-03, -3.2001e-03, -2.3320e-03, -1.7828e-03],\n",
      "          [-8.0485e-04, -1.5714e-03, -2.7270e-03, -3.0647e-03, -2.8590e-03],\n",
      "          [ 2.6898e-04, -9.8956e-04, -2.3691e-03, -3.3524e-03, -3.6833e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.8515e-03, -4.2621e-03, -3.8088e-03, -3.8743e-03, -4.0730e-03],\n",
      "          [-2.9956e-03, -2.5698e-03, -2.4447e-03, -2.6857e-03, -2.8404e-03],\n",
      "          [-1.1291e-03, -7.3243e-04, -1.4738e-03, -2.2205e-03, -2.3114e-03],\n",
      "          [-3.7120e-04, -3.5997e-04, -1.4453e-03, -2.3372e-03, -2.6877e-03],\n",
      "          [-9.6260e-04, -1.1759e-03, -2.1895e-03, -2.6950e-03, -2.9918e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.7578e-04, -5.6665e-04,  8.1862e-04,  7.9884e-04, -1.3032e-03],\n",
      "          [ 6.3967e-04,  1.3464e-03,  1.7540e-03,  4.1669e-04, -2.3381e-03],\n",
      "          [ 1.3740e-03,  1.9968e-03,  1.8256e-03, -3.2833e-04, -2.3957e-03],\n",
      "          [ 1.3538e-03,  1.3786e-03,  1.7319e-03,  9.6064e-04, -2.7748e-05],\n",
      "          [ 1.6648e-03,  1.3464e-03,  1.1078e-03,  5.0915e-04,  8.7672e-04]]],\n",
      "\n",
      "\n",
      "        [[[-6.3574e-05, -4.5031e-04, -9.3637e-04, -1.2123e-03, -9.3119e-04],\n",
      "          [ 3.3026e-04, -3.0330e-04, -1.4304e-03, -2.0487e-03, -1.1361e-03],\n",
      "          [ 1.0194e-03,  4.3421e-04, -1.5077e-03, -2.3224e-03, -9.6538e-04],\n",
      "          [ 9.8585e-04,  6.0818e-04, -1.6800e-03, -2.1959e-03, -5.7719e-04],\n",
      "          [ 2.1364e-04, -3.2410e-04, -2.3200e-03, -2.2999e-03, -6.0280e-04]]],\n",
      "\n",
      "\n",
      "        [[[-2.1204e-03, -4.8630e-03, -7.7305e-03, -1.2513e-02, -1.5305e-02],\n",
      "          [-2.8162e-03, -6.1471e-03, -1.0255e-02, -1.4719e-02, -1.4992e-02],\n",
      "          [-6.3909e-03, -9.9519e-03, -1.3717e-02, -1.5057e-02, -1.2434e-02],\n",
      "          [-7.5115e-03, -1.0056e-02, -1.3171e-02, -1.3066e-02, -9.4921e-03],\n",
      "          [-4.2142e-03, -6.3930e-03, -8.9188e-03, -8.7315e-03, -6.1669e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9780e-03,  5.9722e-03,  5.4352e-03,  3.1180e-03,  1.9705e-03],\n",
      "          [ 7.4407e-03,  7.3171e-03,  5.4184e-03,  2.9040e-03,  2.2921e-03],\n",
      "          [ 7.2953e-03,  5.9534e-03,  3.7699e-03,  1.6129e-03,  1.1657e-03],\n",
      "          [ 6.1674e-03,  4.6305e-03,  1.8676e-03,  7.8164e-04,  1.1123e-04],\n",
      "          [ 4.6207e-03,  2.5928e-03, -3.1875e-04, -7.4701e-04, -1.1209e-03]]]]), 'conv1.bias': tensor([ 0.0042, -0.0007, -0.0412, -0.0369,  0.0048,  0.0121,  0.0062,  0.0053,\n",
      "        -0.0019,  0.0085,  0.0111, -0.0046,  0.0061, -0.0026, -0.0313,  0.0094]), 'conv2.weight': tensor([[[[ 2.3682e-03,  1.7766e-03, -2.7356e-04,  7.4425e-04,  5.5352e-04],\n",
      "          [ 2.2841e-03,  1.2473e-03,  3.8468e-04,  2.6899e-04, -6.4764e-04],\n",
      "          [ 2.8944e-03,  7.7636e-04, -5.7147e-04, -1.0047e-03, -1.9614e-03],\n",
      "          [ 2.0878e-03,  7.7566e-04, -4.6019e-05, -7.3759e-04, -9.4659e-04],\n",
      "          [ 1.9114e-03,  1.6978e-03,  2.4317e-03,  1.3918e-03,  3.9005e-04]],\n",
      "\n",
      "         [[-2.4860e-04, -1.1198e-04,  2.5815e-05,  5.9800e-05, -9.4682e-06],\n",
      "          [-1.1746e-04, -2.9875e-04, -1.0024e-04,  1.5409e-05,  5.4710e-06],\n",
      "          [-5.6415e-05, -2.3108e-05, -4.7774e-05,  3.0080e-05,  2.4398e-04],\n",
      "          [ 1.1397e-04,  1.8147e-04,  5.9100e-05, -3.1581e-06,  1.0312e-04],\n",
      "          [ 2.6176e-04,  1.5780e-04,  4.5148e-07, -1.2062e-04, -4.9792e-05]],\n",
      "\n",
      "         [[ 6.2680e-03,  3.6215e-03,  1.7914e-03,  1.4785e-03,  1.4436e-03],\n",
      "          [ 7.7688e-03,  4.1330e-03,  1.7531e-03,  1.4760e-03,  1.3240e-03],\n",
      "          [ 8.0664e-03,  4.3582e-03,  2.5748e-03,  9.2275e-04,  1.2720e-04],\n",
      "          [ 7.8735e-03,  4.1400e-03,  2.6211e-03,  8.1901e-04, -1.5259e-04],\n",
      "          [ 6.3693e-03,  4.6158e-03,  3.2821e-03,  1.6522e-03,  1.4446e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.1410e-04, -1.0681e-03, -2.3487e-04,  2.2238e-04,  1.3076e-04],\n",
      "          [-2.6352e-04, -8.1854e-04, -1.0109e-03, -5.0066e-04,  3.0217e-04],\n",
      "          [-3.0987e-04, -6.9649e-04, -6.9247e-04, -2.7314e-04,  4.5342e-04],\n",
      "          [ 2.3328e-04, -1.1791e-05,  1.4154e-04, -2.1648e-06,  2.2979e-06],\n",
      "          [ 5.2207e-04,  5.7992e-04,  6.1280e-04, -4.2102e-06, -7.9606e-06]],\n",
      "\n",
      "         [[ 5.2145e-03,  3.3454e-03,  1.5886e-03,  2.0776e-03,  2.1472e-03],\n",
      "          [ 6.6430e-03,  4.1599e-03,  3.0092e-03,  2.3974e-03,  1.6839e-03],\n",
      "          [ 6.8380e-03,  3.7799e-03,  3.1983e-03,  1.9026e-03,  7.0795e-04],\n",
      "          [ 5.9158e-03,  3.8695e-03,  2.6161e-03,  1.6747e-03,  1.7207e-03],\n",
      "          [ 4.5590e-03,  4.1682e-03,  3.8734e-03,  3.0955e-03,  2.8198e-03]],\n",
      "\n",
      "         [[ 3.3660e-03,  2.2694e-03,  2.6484e-03,  8.6961e-04,  2.0897e-04],\n",
      "          [ 2.9232e-03,  2.9909e-03,  2.0640e-03,  9.4399e-04,  7.3865e-04],\n",
      "          [ 2.8023e-03,  2.5424e-03,  1.1268e-03,  7.7345e-04,  7.6188e-04],\n",
      "          [ 2.7314e-03,  1.7025e-03,  4.4451e-04,  4.9154e-04,  1.1924e-04],\n",
      "          [ 2.2700e-03,  1.6249e-03,  4.4111e-04,  1.7288e-04, -5.8411e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 4.9243e-03,  9.5076e-03,  9.5504e-03,  3.9618e-03,  4.9362e-03],\n",
      "          [ 3.9197e-03,  7.1505e-03,  4.6168e-03,  3.5790e-03,  5.5654e-03],\n",
      "          [ 1.0419e-03,  2.5948e-03,  1.2587e-03,  1.5559e-03,  4.1320e-04],\n",
      "          [-6.5136e-04, -1.0318e-03, -1.9676e-03, -4.2808e-03, -3.0277e-03],\n",
      "          [-1.8369e-03, -2.7119e-03, -5.3257e-03, -7.4835e-03, -9.8145e-04]],\n",
      "\n",
      "         [[ 1.5013e-04,  5.8990e-04,  2.2829e-04,  6.6814e-05,  1.0567e-04],\n",
      "          [-7.4510e-05,  7.0521e-04,  5.4363e-04,  6.5435e-05,  2.6369e-04],\n",
      "          [ 1.0195e-04,  5.6249e-04,  2.9272e-04,  1.2594e-04,  2.3968e-04],\n",
      "          [ 1.4478e-04,  3.0956e-04,  1.2305e-04,  4.2853e-05,  2.3775e-04],\n",
      "          [ 1.2367e-04,  1.5019e-04,  1.7362e-05, -5.8481e-05,  3.5604e-04]],\n",
      "\n",
      "         [[ 4.1196e-03,  1.1434e-02,  1.5785e-02,  1.2161e-02,  9.2479e-03],\n",
      "          [ 5.2308e-03,  1.0070e-02,  1.1816e-02,  1.0127e-02,  8.7013e-03],\n",
      "          [ 4.0309e-03,  6.0402e-03,  7.9772e-03,  8.2870e-03,  7.7078e-03],\n",
      "          [ 1.8899e-03,  2.8852e-03,  4.5846e-03,  2.2972e-03,  3.5220e-03],\n",
      "          [-7.7497e-05,  2.3432e-04, -7.6764e-04, -4.0312e-03, -1.2949e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.8819e-05,  1.0428e-03,  9.4681e-04,  1.3001e-04, -4.4987e-04],\n",
      "          [-3.6709e-04,  3.3109e-04,  8.0628e-04,  4.2905e-04,  4.2660e-05],\n",
      "          [-4.4230e-04, -9.7270e-05,  8.7351e-05, -2.0372e-04,  2.8420e-04],\n",
      "          [-2.4610e-04, -2.5433e-04, -5.6700e-04, -4.1784e-04,  4.2392e-04],\n",
      "          [ 1.0398e-04, -1.7343e-04, -6.4967e-04, -2.6309e-04,  4.7579e-04]],\n",
      "\n",
      "         [[ 5.6176e-03,  1.0698e-02,  1.1391e-02,  8.6144e-03,  8.3182e-03],\n",
      "          [ 5.5922e-03,  7.3846e-03,  6.5089e-03,  8.7045e-03,  8.7070e-03],\n",
      "          [ 3.9431e-03,  4.3255e-03,  5.8494e-03,  6.0999e-03,  5.4095e-03],\n",
      "          [ 1.8484e-03,  2.0774e-03,  3.3361e-03,  2.6276e-04,  2.0260e-03],\n",
      "          [ 1.3241e-04,  5.5869e-04, -2.5319e-03, -3.7869e-03, -4.8137e-04]],\n",
      "\n",
      "         [[-2.5020e-04, -1.6529e-04,  3.4744e-03,  4.8918e-03,  2.3253e-03],\n",
      "          [-2.2574e-04,  7.2344e-05,  4.0116e-03,  3.4108e-03,  9.5044e-04],\n",
      "          [ 3.5773e-04,  1.1833e-04,  1.4605e-03,  8.4471e-04,  3.2146e-04],\n",
      "          [ 4.0302e-04, -5.4122e-04, -1.4006e-04,  3.4442e-04, -1.0109e-03],\n",
      "          [ 1.9232e-04, -9.7393e-04, -4.9248e-04, -1.6892e-05, -1.5683e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.0427e-03, -4.7566e-03, -3.6098e-03, -3.4402e-03, -3.6461e-03],\n",
      "          [-4.9466e-03, -3.7702e-03, -2.7656e-03, -3.1710e-03, -3.3346e-03],\n",
      "          [-7.7880e-04, -1.2585e-03, -1.5203e-04, -1.3219e-03, -2.3931e-03],\n",
      "          [-2.0600e-03, -1.5878e-03,  2.4636e-04, -7.0977e-04, -1.5766e-03],\n",
      "          [-5.0098e-03, -2.5000e-03, -1.5676e-03, -4.1437e-03, -2.0536e-03]],\n",
      "\n",
      "         [[-4.7501e-04, -1.1143e-04, -2.4509e-05, -2.7107e-04, -1.2581e-04],\n",
      "          [-3.0602e-04, -1.3028e-04, -3.0456e-05, -3.2700e-04, -3.8437e-04],\n",
      "          [-1.8740e-04, -4.2231e-05, -5.2718e-05, -9.8046e-05, -4.3847e-04],\n",
      "          [ 6.5270e-05,  5.1730e-04, -3.6601e-05, -1.5046e-04, -3.8884e-04],\n",
      "          [-1.3224e-04,  3.8211e-05, -2.7626e-05, -2.4301e-04, -4.0059e-04]],\n",
      "\n",
      "         [[-5.5594e-03, -7.2192e-03, -4.9927e-03, -5.2911e-03, -7.9053e-03],\n",
      "          [-6.4413e-03, -8.8605e-03, -6.1291e-03, -5.0745e-03, -7.6630e-03],\n",
      "          [-5.9981e-03, -6.7501e-03, -5.1206e-03, -6.0255e-03, -7.2156e-03],\n",
      "          [-2.7966e-03, -4.1320e-03, -1.9143e-03, -3.7983e-03, -5.0624e-03],\n",
      "          [-2.6427e-03, -3.2101e-03, -1.6353e-03, -2.2534e-03, -3.0239e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.1554e-04, -4.9099e-04,  9.9576e-05, -4.0777e-04, -5.1291e-04],\n",
      "          [-4.1015e-04, -5.4810e-04, -1.0932e-04, -3.3424e-04, -8.8684e-04],\n",
      "          [-1.0972e-04,  1.6775e-04, -1.3671e-04, -3.6228e-04, -7.6443e-04],\n",
      "          [-1.5794e-04,  3.2793e-04,  8.0786e-05, -6.9571e-04, -4.5112e-04],\n",
      "          [-4.8687e-04, -1.2397e-04, -4.5722e-04, -5.6221e-04, -2.4281e-04]],\n",
      "\n",
      "         [[-4.1105e-03, -6.1244e-03, -4.4474e-03, -4.1836e-03, -5.8652e-03],\n",
      "          [-5.0546e-03, -6.5335e-03, -4.8517e-03, -4.9676e-03, -5.5583e-03],\n",
      "          [-3.7206e-03, -5.3763e-03, -3.1348e-03, -4.7384e-03, -5.2538e-03],\n",
      "          [-2.1439e-03, -3.3733e-03, -1.4717e-03, -3.2293e-03, -4.4943e-03],\n",
      "          [-3.1888e-03, -2.7936e-03, -2.9097e-03, -3.5209e-03, -3.4805e-03]],\n",
      "\n",
      "         [[-8.8442e-04, -2.3361e-03, -2.0697e-03, -9.2424e-04, -1.1069e-03],\n",
      "          [-1.5940e-05, -1.3011e-03, -1.8512e-03, -7.0284e-04, -1.1737e-03],\n",
      "          [ 6.3645e-04, -1.1103e-03, -1.3416e-03, -1.2767e-04, -8.7883e-04],\n",
      "          [ 5.2128e-04, -1.5634e-03, -1.8180e-03, -4.9574e-04, -1.3423e-03],\n",
      "          [-4.0928e-04, -2.6917e-03, -1.9965e-03, -7.5159e-04, -1.9069e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.1645e-04, -3.7226e-04,  2.4997e-05, -3.9663e-05, -9.0259e-05],\n",
      "          [ 3.1128e-04,  3.0892e-05,  1.7884e-04,  4.1601e-05, -5.0490e-05],\n",
      "          [-1.6602e-04,  1.9971e-04,  1.3477e-04,  1.3765e-05, -1.1944e-05],\n",
      "          [-3.6481e-04,  4.2995e-05,  6.3395e-05, -1.1730e-05, -7.5661e-06],\n",
      "          [-2.3692e-04,  1.6820e-05,  1.1926e-05, -9.6422e-06, -5.8943e-06]],\n",
      "\n",
      "         [[-4.5600e-05, -1.4313e-05, -1.7164e-06, -8.6381e-06, -4.0041e-05],\n",
      "          [-4.6589e-05, -3.7923e-05,  6.3554e-07, -7.9778e-07, -2.6648e-05],\n",
      "          [-4.1652e-05, -3.9005e-06,  1.5192e-06, -2.3166e-08, -1.2383e-05],\n",
      "          [ 1.2650e-05,  3.7685e-07,  1.7663e-06,  5.1781e-08, -6.5882e-10],\n",
      "          [ 2.1377e-06,  4.1470e-06,  1.8909e-06, -3.0991e-07, -2.2133e-07]],\n",
      "\n",
      "         [[-6.2633e-04, -7.6431e-04, -1.0711e-04, -2.8197e-04, -4.1061e-04],\n",
      "          [ 1.7582e-04,  1.2738e-04,  2.0651e-04, -1.7201e-04, -3.1538e-04],\n",
      "          [ 3.4570e-04,  7.2931e-04,  4.8919e-04, -3.1373e-05, -2.8461e-04],\n",
      "          [-1.1138e-04,  3.6895e-04,  2.2731e-04, -9.2620e-06, -2.1821e-04],\n",
      "          [-3.7574e-04, -9.1404e-05,  5.0836e-05, -9.1688e-05, -2.1519e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6652e-05, -1.5188e-05,  2.6663e-06,  4.3630e-07, -2.9416e-05],\n",
      "          [-5.9658e-05,  3.5099e-05,  3.6103e-05,  2.1443e-06,  8.8620e-07],\n",
      "          [ 2.0037e-05,  3.1675e-05,  4.3244e-05,  6.5741e-07,  7.1885e-07],\n",
      "          [-1.1970e-05, -1.2573e-06,  1.0375e-06, -1.9533e-06, -7.4600e-07],\n",
      "          [-1.5218e-07,  4.9340e-06, -4.7039e-07,  8.0218e-09, -6.3660e-08]],\n",
      "\n",
      "         [[-1.3091e-04, -2.1398e-04,  1.1773e-04, -3.4373e-04, -4.0219e-04],\n",
      "          [ 1.9498e-04,  6.7518e-04,  4.4281e-04, -1.7880e-04, -3.8307e-04],\n",
      "          [ 1.1598e-04,  7.7921e-04,  5.7639e-04, -8.6990e-05, -3.6965e-04],\n",
      "          [-1.5625e-04,  1.7363e-04,  1.3024e-04, -9.0825e-05, -2.9430e-04],\n",
      "          [-8.7827e-05, -6.9488e-05,  3.5628e-05, -1.2448e-04, -2.9284e-04]],\n",
      "\n",
      "         [[-2.2503e-04, -3.4958e-04, -3.2254e-04,  9.4911e-06,  4.6355e-06],\n",
      "          [ 1.9441e-04, -1.9288e-04, -1.7530e-04,  1.2632e-05, -3.8292e-06],\n",
      "          [ 2.3319e-04, -8.9864e-05,  7.7022e-05,  4.6682e-05,  2.0983e-06],\n",
      "          [-2.0883e-04, -1.9592e-04,  1.1393e-04,  4.6245e-05, -1.0743e-06],\n",
      "          [-4.0912e-04, -1.6228e-04,  3.3863e-05,  2.0537e-05, -3.0311e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0101e-04,  1.7856e-03,  7.2448e-04, -1.9823e-03, -5.0869e-03],\n",
      "          [-1.1229e-03,  1.5752e-04, -1.2091e-03, -4.4312e-03, -5.8573e-03],\n",
      "          [-2.2820e-03, -1.6057e-03, -2.0806e-03, -3.9527e-03, -2.3809e-03],\n",
      "          [-3.2005e-04, -1.6708e-04, -1.4544e-03, -2.1331e-03,  7.9387e-04],\n",
      "          [ 2.7217e-03,  1.5456e-03, -3.0823e-04, -1.3014e-04,  2.3857e-03]],\n",
      "\n",
      "         [[ 1.1514e-04,  7.3267e-05, -2.2636e-04, -1.7663e-04,  4.5230e-05],\n",
      "          [ 6.3549e-05,  4.6710e-05, -7.5810e-05, -2.6453e-04, -9.1336e-05],\n",
      "          [ 6.0292e-05,  8.9942e-05,  6.8072e-05, -1.5880e-04, -1.9835e-04],\n",
      "          [ 1.7775e-04,  2.8436e-04,  2.1542e-04,  4.7360e-05, -6.2495e-05],\n",
      "          [ 1.0844e-04,  8.0222e-05,  1.6932e-04,  1.6546e-04,  1.0236e-04]],\n",
      "\n",
      "         [[-1.4500e-03,  1.0207e-03,  1.2577e-03, -1.4378e-03, -3.6914e-03],\n",
      "          [-2.4997e-03,  9.7745e-04,  1.5972e-03, -2.3115e-03, -4.9707e-03],\n",
      "          [-4.2674e-03, -1.1167e-03, -1.0631e-03, -3.8564e-03, -5.2117e-03],\n",
      "          [-4.9967e-03, -2.9801e-03, -2.8760e-03, -3.3330e-03, -1.9115e-03],\n",
      "          [-1.9172e-03, -1.1486e-03, -3.2788e-03, -1.4931e-03,  1.1033e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.5225e-05,  2.2371e-04,  1.3102e-04, -2.2382e-04, -2.1580e-04],\n",
      "          [-4.3257e-04, -2.8842e-05,  5.7220e-05,  1.2892e-04,  3.9432e-04],\n",
      "          [-5.9062e-06,  1.6839e-04,  4.5911e-04,  5.2048e-04,  5.6956e-04],\n",
      "          [ 6.5085e-04,  1.1874e-04,  5.5875e-04,  8.4713e-04,  6.4120e-04],\n",
      "          [ 7.6069e-04, -5.5074e-05, -3.4856e-05,  4.2614e-04,  6.3899e-04]],\n",
      "\n",
      "         [[-2.5310e-03, -1.1772e-03, -7.2546e-04, -2.3826e-03, -3.4473e-03],\n",
      "          [-3.1336e-03, -7.0513e-04, -6.9047e-04, -3.5800e-03, -4.3719e-03],\n",
      "          [-4.5182e-03, -2.6173e-03, -3.2612e-03, -4.7584e-03, -3.0625e-03],\n",
      "          [-3.9370e-03, -2.0514e-03, -3.4182e-03, -3.5204e-03, -1.7257e-04],\n",
      "          [-5.5890e-04, -5.1236e-04, -3.3149e-03, -1.5043e-03,  4.1771e-04]],\n",
      "\n",
      "         [[-1.1431e-03, -2.4804e-04,  6.6284e-04,  5.7374e-04, -6.5417e-04],\n",
      "          [-1.9199e-03, -3.9085e-04,  8.0599e-04,  9.2733e-04, -1.0733e-03],\n",
      "          [-2.4187e-03, -7.0812e-04,  4.2945e-04,  4.5573e-04, -1.5125e-03],\n",
      "          [-1.8172e-03, -1.0787e-03, -2.6440e-04, -5.1640e-04, -2.0654e-03],\n",
      "          [-5.7096e-04,  2.5262e-04, -4.1815e-05, -7.2426e-04, -7.8165e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 7.9518e-03,  7.4559e-03,  3.6759e-03,  2.2634e-03,  3.3757e-03],\n",
      "          [ 6.9702e-03,  4.2150e-03,  2.7041e-03,  3.8720e-03,  4.3933e-03],\n",
      "          [ 5.0144e-03,  5.3909e-03,  7.2305e-03,  7.3678e-03,  6.3288e-03],\n",
      "          [ 5.8953e-03,  1.0465e-02,  1.3089e-02,  1.0472e-02,  6.7641e-03],\n",
      "          [ 7.7571e-03,  1.3056e-02,  1.1758e-02,  7.4095e-03,  4.6069e-03]],\n",
      "\n",
      "         [[ 5.8259e-04,  4.5646e-04,  1.4932e-04,  1.1882e-04,  1.2803e-04],\n",
      "          [ 4.5235e-04,  7.4082e-04,  2.6641e-04,  1.6249e-04,  1.1977e-04],\n",
      "          [ 4.9769e-04,  7.2345e-04,  3.3023e-04,  1.1269e-04, -1.3779e-05],\n",
      "          [ 3.4655e-04,  6.2558e-04,  3.0064e-04,  2.7925e-06, -5.9754e-05],\n",
      "          [ 1.8213e-04,  2.9186e-04,  2.5390e-04, -4.9787e-05, -5.7952e-05]],\n",
      "\n",
      "         [[ 1.4276e-02,  1.6072e-02,  1.5390e-02,  1.1702e-02,  1.0869e-02],\n",
      "          [ 1.3739e-02,  1.4363e-02,  1.6592e-02,  1.2491e-02,  1.2268e-02],\n",
      "          [ 1.2148e-02,  1.1527e-02,  1.5524e-02,  1.4646e-02,  1.3312e-02],\n",
      "          [ 1.0677e-02,  1.3555e-02,  1.8257e-02,  1.7691e-02,  1.5235e-02],\n",
      "          [ 1.3848e-02,  1.7325e-02,  2.2194e-02,  2.0143e-02,  1.4995e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 8.3032e-04,  1.5491e-03,  8.4961e-04,  8.5116e-04,  5.8046e-04],\n",
      "          [ 2.7408e-04,  1.2697e-03,  1.2848e-03,  5.0329e-04,  4.0494e-04],\n",
      "          [ 9.4850e-04,  1.5200e-03,  1.1492e-03,  5.5976e-04,  4.5977e-04],\n",
      "          [ 1.2791e-03,  1.9365e-03,  1.4958e-03,  4.4634e-04,  3.8514e-04],\n",
      "          [ 7.4177e-04,  4.9454e-04,  5.2617e-04,  1.5627e-04,  2.0767e-04]],\n",
      "\n",
      "         [[ 1.3159e-02,  1.2634e-02,  1.4173e-02,  1.1275e-02,  1.2050e-02],\n",
      "          [ 1.3134e-02,  1.0189e-02,  1.4020e-02,  1.3625e-02,  1.3447e-02],\n",
      "          [ 9.7325e-03,  1.0262e-02,  1.4742e-02,  1.5634e-02,  1.4812e-02],\n",
      "          [ 1.0545e-02,  1.3733e-02,  1.9868e-02,  1.8808e-02,  1.5871e-02],\n",
      "          [ 1.3367e-02,  1.6770e-02,  1.8177e-02,  1.6762e-02,  1.3305e-02]],\n",
      "\n",
      "         [[ 1.8081e-03,  3.4707e-03,  3.2486e-03,  2.2728e-03,  9.5986e-04],\n",
      "          [ 2.0888e-03,  3.5492e-03,  2.8573e-03,  2.5093e-03,  1.0958e-03],\n",
      "          [ 3.2166e-03,  2.9912e-03,  2.2479e-03,  2.6302e-03,  2.1980e-03],\n",
      "          [ 2.3464e-03,  1.1021e-03,  2.1278e-03,  3.2190e-03,  3.4090e-03],\n",
      "          [ 9.7696e-04,  1.0481e-03,  3.5713e-03,  4.4702e-03,  4.2489e-03]]]]), 'conv2.bias': tensor([ 0.0259,  0.0138, -0.0068,  0.0191,  0.0070, -0.0547, -0.0285,  0.0611,\n",
      "        -0.0678, -0.0073,  0.0215,  0.0098,  0.0168,  0.0036, -0.0202, -0.0377,\n",
      "        -0.0162, -0.0088, -0.0058, -0.0038,  0.0390, -0.0147, -0.0331,  0.0163,\n",
      "         0.0061, -0.0334,  0.0061,  0.0063, -0.0018,  0.0034, -0.0093,  0.0756]), 'fc1.weight': tensor([[4.4561e-05, 2.0264e-03, 4.4076e-03,  ..., 1.1952e-03, 1.0845e-03,\n",
      "         4.0168e-04],\n",
      "        [4.4534e-05, 2.0764e-03, 4.5443e-03,  ..., 1.2361e-03, 1.1164e-03,\n",
      "         4.1261e-04],\n",
      "        [5.0432e-05, 2.2817e-03, 4.9368e-03,  ..., 1.3432e-03, 1.2198e-03,\n",
      "         4.5152e-04],\n",
      "        ...,\n",
      "        [4.4471e-05, 2.0567e-03, 4.4940e-03,  ..., 1.2266e-03, 1.1078e-03,\n",
      "         4.0949e-04],\n",
      "        [4.5792e-05, 2.1107e-03, 4.6008e-03,  ..., 1.2590e-03, 1.1349e-03,\n",
      "         4.1965e-04],\n",
      "        [4.6720e-05, 2.1427e-03, 4.6626e-03,  ..., 1.2804e-03, 1.1551e-03,\n",
      "         4.2689e-04]]), 'fc1.bias': tensor([ 0.0466,  0.0481,  0.0523,  0.0493, -0.2338, -0.1660,  0.0575,  0.0477,\n",
      "         0.0488,  0.0496])}\n",
      "!-- Client 8 is normal and start iterations. ---!\n",
      "Epoch [1/3], Average Loss: 0.5929226875305176, Average Accuracy: 0.7491165399551392, Average Error: 0.2508834302425385, Culminative Time Used: 1.982020303606987\n",
      "Epoch [2/3], Average Loss: 0.1543527245521545, Average Accuracy: 0.9490627050399780, Average Error: 0.0509372986853123, Culminative Time Used: 4.0958767011761665\n",
      "Epoch [3/3], Average Loss: 0.0873726382851601, Average Accuracy: 0.9736768603324890, Average Error: 0.0263231415301561, Culminative Time Used: 6.086607303470373\n",
      "{'conv1.weight': tensor([[[[-1.9895e-03, -2.3439e-03, -1.0420e-03,  1.2081e-03,  2.4109e-03],\n",
      "          [-2.0656e-03, -2.4580e-03, -1.2929e-03,  7.7320e-04,  1.7694e-03],\n",
      "          [-6.9380e-04, -8.1473e-04, -3.2779e-04,  3.5928e-04, -2.8805e-05],\n",
      "          [ 2.9199e-03,  2.8714e-03,  1.9281e-03,  6.3341e-04, -1.4733e-03],\n",
      "          [ 5.2282e-03,  4.7434e-03,  3.1929e-03,  1.1903e-03, -1.2397e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.6183e-04, -5.9533e-04, -8.9637e-04, -9.2217e-04, -5.8691e-04],\n",
      "          [-1.3366e-04, -6.1251e-04, -1.0404e-03, -1.2136e-03, -1.1004e-03],\n",
      "          [ 4.2495e-05, -1.5727e-04, -7.3423e-04, -1.0986e-03, -1.1062e-03],\n",
      "          [ 1.0320e-04,  1.0183e-04,  1.4888e-05, -2.9597e-04, -4.9187e-04],\n",
      "          [ 7.4850e-05,  1.9952e-05,  2.6555e-04,  4.2738e-04,  3.5544e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.9148e-03, -2.4204e-03, -1.9762e-03,  5.5424e-04,  2.2639e-03],\n",
      "          [-9.5821e-04, -6.2656e-04,  1.3227e-04,  2.1395e-03,  2.8986e-03],\n",
      "          [-7.7404e-04, -9.5355e-04,  6.1550e-04,  2.1850e-03,  2.1052e-03],\n",
      "          [-2.7293e-03, -2.4810e-03, -4.7242e-04,  3.6983e-04, -3.2355e-04],\n",
      "          [-5.2190e-03, -5.2857e-03, -4.4280e-03, -3.3770e-03, -2.6528e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.4435e-03, -1.5533e-03,  4.6304e-04,  4.1502e-03,  7.6198e-03],\n",
      "          [-1.4289e-03,  2.3736e-04,  3.2158e-03,  5.8366e-03,  5.9621e-03],\n",
      "          [-1.4048e-04,  1.0853e-03,  3.7503e-03,  5.3735e-03,  3.8574e-03],\n",
      "          [ 3.1488e-05,  6.6645e-04,  2.9186e-03,  3.8388e-03,  2.5727e-03],\n",
      "          [ 7.2140e-04,  6.0393e-04,  1.8209e-03,  2.8559e-03,  2.7378e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2585e-03,  9.6048e-04,  2.0795e-04, -1.0100e-03, -1.9987e-03],\n",
      "          [ 4.1366e-04,  4.5935e-04, -2.0824e-04, -2.1842e-03, -2.7229e-03],\n",
      "          [ 2.1682e-04,  1.9825e-04, -3.6577e-04, -1.9846e-03, -1.4296e-03],\n",
      "          [ 7.7991e-04,  7.2940e-04,  3.5670e-04,  6.9276e-04,  1.2991e-03],\n",
      "          [ 1.6067e-03,  1.4006e-03,  1.1893e-03,  2.2984e-03,  1.6849e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6858e-03,  1.8098e-03,  7.1426e-04, -1.4376e-03, -2.3291e-03],\n",
      "          [ 2.7399e-03,  2.4575e-03,  1.1780e-03, -1.1427e-04, -2.2599e-04],\n",
      "          [ 2.5272e-03,  2.4853e-03,  2.2467e-03,  1.6900e-03,  1.2898e-03],\n",
      "          [ 2.5858e-03,  3.4747e-03,  3.6355e-03,  2.5906e-03,  2.1299e-03],\n",
      "          [ 3.1482e-03,  5.5698e-03,  5.0734e-03,  2.8355e-03,  1.7249e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1003e-03,  2.9213e-03,  3.1816e-03,  3.5153e-03,  3.5588e-03],\n",
      "          [ 1.1623e-03,  1.4577e-03,  2.5870e-03,  3.2000e-03,  3.8543e-03],\n",
      "          [-6.0079e-04, -2.3204e-04,  1.1479e-03,  3.2024e-03,  6.4441e-03],\n",
      "          [-1.1318e-03, -5.1325e-04,  1.1879e-03,  4.1247e-03,  7.4973e-03],\n",
      "          [-1.8690e-04,  8.2544e-04,  2.0173e-03,  3.8319e-03,  5.2571e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.3568e-03, -1.7854e-03, -1.8070e-03, -3.0079e-03, -4.6679e-03],\n",
      "          [-3.6215e-03, -2.0404e-03, -1.1165e-03, -1.8441e-03, -4.2183e-03],\n",
      "          [-2.9787e-03, -1.4074e-03, -1.4777e-04, -1.9202e-04, -2.8209e-03],\n",
      "          [-2.5358e-03, -9.3993e-04,  9.1858e-04,  1.1434e-03, -4.2977e-04],\n",
      "          [-1.3567e-03, -3.0794e-04,  1.0753e-03,  1.7304e-03,  4.7844e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.6439e-04, -6.2687e-04, -3.8718e-04,  2.4122e-04,  1.1799e-03],\n",
      "          [-8.7302e-04, -1.3257e-03, -1.4429e-03, -1.8738e-04,  6.7744e-04],\n",
      "          [-2.5357e-03, -2.9827e-03, -2.5162e-03, -1.9601e-03, -9.1966e-04],\n",
      "          [-2.9410e-03, -3.2946e-03, -2.7950e-03, -2.3534e-03, -1.4438e-03],\n",
      "          [-1.4917e-03, -2.2184e-03, -2.3643e-03, -2.0121e-03, -1.4104e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.0490e-03, -1.9534e-03, -1.0587e-03, -1.3848e-03, -3.2446e-03],\n",
      "          [-9.9845e-04, -1.0267e-03, -9.6966e-04, -1.2048e-03, -1.9891e-03],\n",
      "          [-7.6846e-05, -2.4535e-04, -5.2231e-04, -7.7429e-04, -1.8772e-03],\n",
      "          [-1.9033e-05, -8.1652e-06, -1.1859e-04, -3.2902e-04, -1.6735e-03],\n",
      "          [-2.0345e-03, -1.0608e-03, -3.4341e-04, -2.5834e-04, -1.3739e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.7318e-03,  7.8451e-03,  5.6402e-03,  2.5760e-03,  1.8625e-03],\n",
      "          [ 8.6546e-03,  7.4152e-03,  3.5904e-03,  9.7029e-04,  1.0816e-03],\n",
      "          [ 8.1262e-03,  6.7850e-03,  2.7551e-03,  1.2248e-03,  2.3022e-03],\n",
      "          [ 5.9534e-03,  5.3692e-03,  3.8057e-03,  3.4195e-03,  4.1817e-03],\n",
      "          [ 3.4136e-03,  3.9695e-03,  4.3601e-03,  5.0790e-03,  6.4466e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.4013e-03, -2.7446e-03, -2.1769e-03, -1.7902e-03, -2.0782e-03],\n",
      "          [-1.0992e-03, -1.6393e-03, -1.7840e-03, -1.7701e-03, -2.2433e-03],\n",
      "          [-7.8302e-06, -2.9755e-04, -6.3136e-04, -8.9246e-04, -1.3191e-03],\n",
      "          [ 1.5131e-04, -7.9613e-05, -3.9278e-04, -3.0734e-04, -4.1044e-04],\n",
      "          [-5.1818e-05, -3.9664e-04, -7.9861e-04, -9.4770e-04, -1.1680e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.4881e-04, -7.8929e-04, -1.3513e-03, -1.3156e-03, -1.0782e-03],\n",
      "          [-1.3117e-04, -1.5937e-04, -2.5020e-04, -2.4537e-05,  1.1124e-04],\n",
      "          [ 7.0902e-04,  1.1270e-03,  1.7355e-03,  2.4019e-03,  2.7035e-03],\n",
      "          [ 1.4153e-03,  2.7548e-03,  3.5021e-03,  3.3736e-03,  3.8888e-03],\n",
      "          [ 2.8866e-03,  4.3331e-03,  5.8577e-03,  6.0868e-03,  4.6561e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4933e-04,  1.4805e-04, -1.1602e-04, -4.6830e-04, -7.3575e-04],\n",
      "          [-2.3953e-04, -1.3105e-04, -4.1653e-04, -8.5805e-04, -8.4711e-04],\n",
      "          [ 6.3074e-04,  8.2314e-04,  3.2157e-04, -2.5667e-04, -1.9096e-05],\n",
      "          [ 1.0129e-03,  9.9678e-04,  7.8070e-04,  1.6027e-03,  2.6100e-03],\n",
      "          [ 8.0891e-04,  9.9169e-04,  1.5556e-03,  2.1966e-03,  2.6570e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4197e-02,  1.2911e-02,  1.1201e-02,  1.4555e-02,  1.6295e-02],\n",
      "          [ 1.0990e-02,  9.7727e-03,  1.0654e-02,  1.5450e-02,  1.6756e-02],\n",
      "          [ 9.5695e-03,  1.0333e-02,  1.2091e-02,  1.4940e-02,  1.4118e-02],\n",
      "          [ 9.0937e-03,  1.1138e-02,  1.3320e-02,  1.2408e-02,  9.3950e-03],\n",
      "          [ 9.6080e-03,  1.2299e-02,  1.1521e-02,  7.4027e-03,  4.6083e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.0150e-03, -4.7444e-03, -4.3650e-03, -2.9105e-03, -1.8007e-03],\n",
      "          [-5.4243e-03, -4.9851e-03, -3.1547e-03, -1.5601e-03, -1.1858e-03],\n",
      "          [-4.9595e-03, -4.1316e-03, -2.0009e-03, -7.9677e-04, -8.9685e-04],\n",
      "          [-4.6777e-03, -3.8629e-03, -1.7372e-03, -1.1121e-03, -1.4039e-03],\n",
      "          [-4.0774e-03, -3.1953e-03, -1.3135e-03, -1.1821e-03, -1.5109e-03]]]]), 'conv1.bias': tensor([ 0.0018, -0.0008,  0.0200, -0.0122,  0.0044,  0.0028,  0.0059, -0.0259,\n",
      "        -0.0014, -0.0112, -0.0052, -0.0034,  0.0059,  0.0025,  0.0581, -0.0049]), 'conv2.weight': tensor([[[[-1.7441e-03, -1.5263e-03, -2.6744e-03, -4.4429e-03, -4.6276e-03],\n",
      "          [-2.9018e-03, -3.6135e-03, -3.8156e-03, -3.3554e-03, -2.8987e-03],\n",
      "          [-4.9973e-03, -6.1928e-03, -5.2420e-03, -2.7832e-03, -7.5005e-04],\n",
      "          [-6.6726e-03, -7.3220e-03, -4.3701e-03, -2.7435e-03, -2.4875e-03],\n",
      "          [-4.8782e-03, -4.7857e-03, -5.5878e-03, -5.5518e-03, -5.4061e-03]],\n",
      "\n",
      "         [[ 1.2449e-04, -4.1149e-05, -1.5587e-04, -4.9488e-04, -8.0426e-04],\n",
      "          [ 3.2748e-05, -1.5931e-04, -2.2912e-04, -2.3169e-04, -2.3194e-04],\n",
      "          [-1.2150e-04, -2.3119e-04, -1.2521e-04, -1.6647e-04, -1.9087e-04],\n",
      "          [-9.6874e-05, -8.7860e-05, -3.4688e-04, -1.9698e-05,  1.1386e-05],\n",
      "          [-7.3689e-06,  1.0078e-05, -8.2398e-05,  1.7965e-04,  1.1528e-04]],\n",
      "\n",
      "         [[ 7.1387e-04, -9.4339e-05, -2.5474e-03, -3.9554e-03, -6.4488e-03],\n",
      "          [-4.3588e-04, -2.2524e-03, -4.8450e-03, -5.9245e-03, -7.2495e-03],\n",
      "          [-3.3371e-03, -5.1108e-03, -6.9350e-03, -6.2517e-03, -7.0091e-03],\n",
      "          [-7.6274e-03, -7.7183e-03, -9.3820e-03, -8.4483e-03, -5.7487e-03],\n",
      "          [-8.1919e-03, -7.8224e-03, -8.5636e-03, -1.1000e-02, -9.6405e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7807e-06, -4.5056e-04, -7.7480e-04, -8.7803e-04, -6.9765e-04],\n",
      "          [-3.2452e-04, -3.4918e-04, -2.8379e-04, -5.2982e-05,  1.3168e-04],\n",
      "          [-6.7759e-04, -9.0921e-04, -7.2761e-04, -2.7959e-04, -6.1166e-04],\n",
      "          [-7.7607e-04, -7.6340e-04, -2.1554e-03, -1.0049e-03, -9.2095e-05],\n",
      "          [-3.2675e-04, -6.9302e-04, -1.1281e-03, -1.1274e-03, -4.8425e-04]],\n",
      "\n",
      "         [[ 3.8228e-04, -1.5897e-04, -3.0919e-03, -4.5308e-03, -5.1481e-03],\n",
      "          [-1.7606e-03, -2.8045e-03, -4.1671e-03, -4.9647e-03, -6.3565e-03],\n",
      "          [-4.3543e-03, -5.1816e-03, -6.5520e-03, -5.2334e-03, -5.1925e-03],\n",
      "          [-7.5817e-03, -6.9273e-03, -5.7897e-03, -6.5682e-03, -6.7982e-03],\n",
      "          [-5.0595e-03, -5.2949e-03, -6.0836e-03, -8.9734e-03, -1.0307e-02]],\n",
      "\n",
      "         [[-1.7652e-04, -1.2420e-04,  8.0909e-04,  1.0380e-04,  9.9497e-05],\n",
      "          [-7.9513e-04, -4.0827e-04, -2.4919e-04, -1.0937e-03, -1.8959e-04],\n",
      "          [-1.3974e-03, -9.2100e-04, -5.8566e-04, -9.7044e-04, -4.8179e-04],\n",
      "          [-9.4220e-04, -8.8564e-04, -8.8956e-04, -1.6585e-03, -1.0541e-03],\n",
      "          [-8.5897e-04, -9.1616e-04, -1.0366e-03, -1.2120e-03, -1.5636e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.3200e-03, -2.5145e-03,  4.6880e-04, -6.2850e-04, -4.8397e-03],\n",
      "          [-2.1943e-03, -7.6611e-04,  1.2360e-05, -2.4175e-03, -7.5203e-03],\n",
      "          [ 2.9392e-04,  7.2170e-04, -1.1301e-03, -2.6948e-03, -7.0994e-03],\n",
      "          [ 2.3730e-03,  2.6587e-03,  1.5255e-03, -2.1822e-03, -4.2917e-03],\n",
      "          [ 2.6024e-03,  3.7359e-03,  6.2873e-04, -3.7396e-03,  4.7526e-04]],\n",
      "\n",
      "         [[-4.6192e-04, -7.2076e-04, -1.5804e-04, -1.4794e-04, -6.2577e-04],\n",
      "          [-5.9445e-04, -7.4823e-04, -2.2435e-04, -5.2004e-05, -5.3331e-04],\n",
      "          [-6.2480e-04, -3.5486e-04,  3.2268e-05,  5.1067e-05, -3.6076e-04],\n",
      "          [ 1.5468e-04,  1.4739e-04,  1.1389e-04,  5.6957e-05, -1.9141e-04],\n",
      "          [ 4.4791e-04,  2.3580e-04,  1.8607e-04, -2.9244e-04, -1.7856e-06]],\n",
      "\n",
      "         [[-2.9333e-03, -4.9988e-03, -6.0999e-03, -4.4090e-03, -7.7855e-03],\n",
      "          [-2.5831e-03, -2.6843e-03, -3.1220e-03, -3.8322e-03, -8.6018e-03],\n",
      "          [-1.6703e-03, -1.7391e-03, -3.9670e-03, -7.6172e-03, -9.9388e-03],\n",
      "          [ 1.7024e-04, -2.3833e-04, -1.7663e-03, -7.8130e-03, -8.2254e-03],\n",
      "          [ 2.0917e-03,  3.4339e-03,  4.2238e-04, -5.8837e-03, -4.4101e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.9970e-04, -1.1534e-04,  1.9943e-06,  3.0529e-04, -3.9879e-04],\n",
      "          [-4.3036e-04, -4.9428e-04, -8.2720e-05,  1.3349e-04, -1.3791e-04],\n",
      "          [-1.6250e-04, -3.0470e-04, -7.2648e-04, -7.2486e-04,  2.2519e-05],\n",
      "          [ 3.2031e-04,  4.0455e-04,  1.0903e-05, -3.8833e-04,  3.2796e-04],\n",
      "          [ 2.4565e-04,  4.2232e-04,  1.4811e-04, -2.7261e-05,  7.8489e-04]],\n",
      "\n",
      "         [[-3.4354e-03, -2.3548e-03, -2.2734e-03, -3.0134e-03, -6.5308e-03],\n",
      "          [-2.6763e-03, -9.9939e-04, -2.3972e-03, -4.4622e-03, -8.9952e-03],\n",
      "          [-2.4426e-03, -2.8252e-03, -4.0163e-03, -7.6683e-03, -1.0080e-02],\n",
      "          [-1.6455e-04, -3.2421e-04, -3.2279e-04, -6.5831e-03, -6.5226e-03],\n",
      "          [ 4.1727e-04,  2.0674e-03, -1.4467e-03, -5.5045e-03, -2.0053e-03]],\n",
      "\n",
      "         [[ 5.6356e-04, -1.3496e-03, -1.6017e-03, -8.9772e-04, -5.1185e-04],\n",
      "          [-8.7631e-04, -1.6692e-03, -3.5379e-04,  3.8859e-04, -2.5383e-04],\n",
      "          [-7.7649e-04,  1.1990e-03,  2.0358e-03,  5.0303e-04, -7.5006e-04],\n",
      "          [ 7.3635e-04,  2.5577e-03,  1.4674e-03,  6.9714e-04, -2.0651e-03],\n",
      "          [ 1.1842e-03,  2.6462e-03,  1.8290e-03,  1.8537e-04, -3.4681e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.3372e-04,  2.1348e-04, -8.6480e-04, -2.2498e-03, -3.9385e-03],\n",
      "          [-6.1341e-04, -2.5608e-03, -4.1972e-03, -3.8410e-03, -2.7040e-03],\n",
      "          [-4.3302e-03, -6.5871e-03, -4.5558e-03, -2.1910e-03, -2.2696e-03],\n",
      "          [-5.3339e-03, -5.0427e-03, -1.5752e-03, -9.2457e-04, -4.2209e-03],\n",
      "          [-2.1309e-03, -1.6098e-03, -8.9906e-04, -2.5951e-03, -3.4992e-03]],\n",
      "\n",
      "         [[-1.6643e-04, -1.1607e-04,  1.0527e-05,  3.7698e-05, -2.3985e-05],\n",
      "          [-1.9031e-04, -1.5135e-04,  1.6520e-05, -2.7991e-04, -5.3587e-04],\n",
      "          [-9.0714e-05, -1.4706e-04, -4.0104e-05, -1.6888e-04, -5.7961e-04],\n",
      "          [-4.7246e-05, -4.5734e-04, -1.2372e-04, -1.1293e-05, -4.6400e-05],\n",
      "          [-2.2299e-04, -5.2974e-04, -7.9073e-05,  1.1084e-04,  2.5254e-04]],\n",
      "\n",
      "         [[-2.5584e-03, -2.6310e-03, -2.4170e-03, -1.4429e-03, -3.4762e-03],\n",
      "          [ 2.9659e-04, -1.4734e-03, -3.2700e-03, -3.1308e-03, -4.2035e-03],\n",
      "          [ 1.1291e-04, -4.1398e-03, -6.1318e-03, -4.4715e-03, -3.9214e-03],\n",
      "          [-4.6958e-03, -7.4314e-03, -7.1196e-03, -5.5970e-03, -4.0750e-03],\n",
      "          [-5.1085e-03, -5.2163e-03, -5.2972e-03, -6.3466e-03, -6.5884e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1413e-05, -3.9665e-04, -1.2985e-04,  3.4056e-04,  7.7832e-05],\n",
      "          [-1.5241e-04, -3.9417e-04, -1.0454e-04, -8.5705e-05, -6.1154e-04],\n",
      "          [-2.1274e-04, -4.4797e-04, -7.8031e-04, -7.9932e-04, -1.5355e-03],\n",
      "          [ 1.4938e-04, -4.0094e-04, -6.7040e-04, -2.2359e-04, -3.1766e-05],\n",
      "          [ 1.2155e-04, -1.4984e-04,  9.3845e-05,  3.5184e-04,  4.1938e-04]],\n",
      "\n",
      "         [[-8.7443e-04, -5.9164e-04, -2.5777e-03, -2.9672e-03, -4.1573e-03],\n",
      "          [ 1.4911e-03, -9.2182e-04, -3.7446e-03, -3.1927e-03, -2.6233e-03],\n",
      "          [-1.6157e-03, -4.5224e-03, -5.0791e-03, -3.9846e-03, -2.4955e-03],\n",
      "          [-4.6329e-03, -4.5574e-03, -2.8288e-03, -4.5174e-03, -5.5096e-03],\n",
      "          [-3.4077e-03, -2.9407e-03, -4.0774e-03, -5.2683e-03, -4.4251e-03]],\n",
      "\n",
      "         [[-3.6179e-04, -3.8753e-04, -2.1744e-04, -4.4165e-04, -3.1424e-07],\n",
      "          [-7.7743e-04, -5.8184e-04, -9.1769e-04, -1.1828e-03, -6.1146e-04],\n",
      "          [-1.6655e-05, -6.2589e-05, -1.7167e-03, -2.0250e-03, -2.3395e-04],\n",
      "          [-1.6234e-04, -9.5855e-04, -2.2741e-03, -1.4530e-03,  2.7122e-04],\n",
      "          [-1.3185e-03, -1.7552e-03, -1.5047e-03, -8.0165e-04, -5.6739e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.1695e-03, -1.6157e-03, -6.6783e-05, -2.6074e-04, -4.2624e-04],\n",
      "          [-7.2329e-04, -5.9176e-04, -3.2489e-05, -4.8556e-05, -2.8145e-04],\n",
      "          [ 3.0976e-04, -7.7136e-05, -7.3184e-05, -1.2729e-05, -4.7305e-05],\n",
      "          [ 5.2383e-04, -3.0397e-05, -4.2662e-05, -5.6770e-06, -4.8329e-07],\n",
      "          [ 7.9437e-05, -1.0022e-04, -9.9502e-05, -8.0331e-06,  5.0214e-06]],\n",
      "\n",
      "         [[-1.7096e-05, -3.0400e-06, -4.0716e-07, -5.1037e-05, -2.1265e-04],\n",
      "          [-1.5473e-04, -5.4210e-05,  3.5831e-08, -2.6410e-06, -1.0877e-04],\n",
      "          [-3.1128e-04, -4.6861e-05, -5.1285e-08, -2.4374e-07, -3.9469e-05],\n",
      "          [-7.8933e-05, -1.2839e-05, -3.4728e-06,  3.1088e-08,  2.2027e-07],\n",
      "          [ 2.0873e-05, -1.7944e-05, -1.0594e-05, -1.2589e-07, -3.3596e-08]],\n",
      "\n",
      "         [[-1.2766e-03, -1.9305e-03, -1.3465e-03, -7.1029e-04, -9.7928e-04],\n",
      "          [-1.3941e-03, -1.4444e-03, -1.0518e-03, -5.7036e-04, -5.9486e-04],\n",
      "          [-4.5783e-04, -9.8982e-04, -9.2575e-04, -3.7893e-04, -5.3357e-04],\n",
      "          [ 1.0843e-03,  2.3671e-05, -1.2113e-04, -7.4953e-06, -2.9828e-05],\n",
      "          [ 1.2686e-03,  5.0220e-04,  9.6877e-05,  1.3006e-04,  1.3573e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.2498e-04,  6.3169e-06,  8.1063e-08,  3.6762e-07, -1.7598e-04],\n",
      "          [ 4.5783e-05, -2.1885e-05, -3.2607e-07,  6.2773e-08, -2.1063e-05],\n",
      "          [-4.2762e-05, -1.1128e-04, -5.0044e-05,  3.6982e-07, -2.0459e-07],\n",
      "          [ 4.1100e-06, -2.3103e-05, -2.5250e-05,  1.7690e-07,  3.3074e-07],\n",
      "          [ 2.4147e-05, -7.7047e-06, -3.1689e-05,  1.8987e-07,  2.7258e-07]],\n",
      "\n",
      "         [[-1.5838e-03, -1.4814e-03, -9.5072e-04, -7.6313e-04, -6.1305e-04],\n",
      "          [-1.2793e-03, -7.2954e-04, -9.6647e-04, -6.6483e-04, -6.7978e-04],\n",
      "          [-2.7550e-04, -8.4178e-04, -9.2842e-04, -4.5060e-04, -5.8659e-04],\n",
      "          [ 7.9436e-04,  1.4924e-04,  1.1729e-05,  2.2533e-05, -3.5102e-05],\n",
      "          [ 8.4619e-04,  5.2781e-04,  2.7510e-04,  2.3462e-04,  1.7666e-04]],\n",
      "\n",
      "         [[ 1.1235e-04, -8.2854e-04, -1.0733e-03, -1.2935e-04, -2.7729e-05],\n",
      "          [ 1.4203e-04, -7.4213e-04, -5.5047e-04, -3.8318e-06, -1.1711e-05],\n",
      "          [ 2.6083e-04, -1.5028e-04, -4.5272e-05, -1.7610e-05, -3.9562e-06],\n",
      "          [ 7.0875e-04,  2.6853e-04, -3.8308e-05, -4.5125e-05,  4.2081e-09],\n",
      "          [ 8.4915e-04,  1.4105e-04, -5.4033e-05, -5.6552e-05, -4.4596e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5003e-03,  2.7293e-03,  1.8719e-04, -2.6225e-03, -3.4199e-03],\n",
      "          [ 4.5784e-03,  6.3584e-04, -1.5095e-03, -2.0270e-03, -1.9777e-03],\n",
      "          [ 2.6651e-03,  5.8349e-04,  6.1040e-04,  9.3549e-04, -9.1951e-04],\n",
      "          [ 7.7786e-04, -4.5696e-04, -3.4811e-04,  8.4050e-05, -2.4696e-04],\n",
      "          [-2.5267e-03, -2.9675e-03, -2.3797e-04,  3.1697e-05, -5.5980e-04]],\n",
      "\n",
      "         [[-1.4475e-04, -9.0381e-05,  3.1345e-04,  3.1914e-04,  3.7856e-04],\n",
      "          [-2.1644e-04, -9.1704e-05,  1.3301e-04,  1.4190e-04,  1.0323e-04],\n",
      "          [ 8.3307e-08, -1.6030e-04, -2.0844e-04, -5.3798e-04, -6.7262e-04],\n",
      "          [-1.4121e-04, -2.8243e-04, -1.2350e-04, -1.9898e-04, -2.9459e-04],\n",
      "          [-1.9233e-04, -5.8311e-05,  1.8367e-04,  3.2729e-04,  1.4897e-04]],\n",
      "\n",
      "         [[ 8.9207e-03,  8.4673e-03,  6.1745e-03,  4.5453e-03,  3.7250e-03],\n",
      "          [ 8.7607e-03,  6.0554e-03,  2.5083e-03,  1.0972e-03,  7.9077e-04],\n",
      "          [ 6.9154e-03,  4.1709e-03,  3.2218e-03,  3.1143e-03,  1.4162e-03],\n",
      "          [ 7.3406e-03,  3.8059e-03,  4.2263e-03,  4.6337e-03,  2.4885e-03],\n",
      "          [ 4.9102e-03,  3.1491e-03,  3.0963e-03,  4.4818e-03,  3.3078e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6367e-04, -3.3179e-04,  7.0517e-06,  4.4712e-04,  1.5525e-04],\n",
      "          [ 1.5276e-05, -1.1080e-04, -1.2414e-05, -4.9057e-05, -1.3769e-04],\n",
      "          [ 5.9780e-05,  6.5255e-04,  1.1761e-03,  3.6003e-04, -2.4206e-04],\n",
      "          [-1.1873e-04, -6.6640e-04, -2.4865e-05,  2.6731e-04,  1.0254e-04],\n",
      "          [-8.7566e-04, -7.0035e-04, -8.2486e-04, -3.4719e-04, -2.0931e-05]],\n",
      "\n",
      "         [[ 8.0794e-03,  7.1907e-03,  4.4430e-03,  2.2792e-03,  2.7060e-03],\n",
      "          [ 5.2057e-03,  3.9915e-03,  1.9431e-03,  1.8612e-03,  2.9728e-03],\n",
      "          [ 4.8441e-03,  4.3334e-03,  4.4956e-03,  4.3726e-03,  3.1172e-03],\n",
      "          [ 5.3554e-03,  4.1106e-03,  3.2162e-03,  3.6980e-03,  3.7248e-03],\n",
      "          [ 1.4951e-03,  2.5909e-03,  3.8813e-03,  3.0237e-03,  2.0245e-03]],\n",
      "\n",
      "         [[ 2.9547e-03,  2.2627e-03,  9.9768e-04,  6.5614e-04,  3.2590e-05],\n",
      "          [ 4.1589e-03,  2.9427e-03,  9.8223e-04, -7.0058e-04, -1.0447e-03],\n",
      "          [ 3.7879e-03,  1.1348e-03,  1.0653e-04, -9.4107e-04,  1.5144e-04],\n",
      "          [ 2.7446e-03,  4.6410e-04,  7.0011e-05,  4.4458e-04,  1.2464e-03],\n",
      "          [ 2.7155e-03,  4.2792e-04,  3.9286e-04,  1.6721e-03,  1.7259e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.0533e-03, -1.6440e-03, -1.5118e-03, -5.3592e-04, -9.7113e-04],\n",
      "          [ 5.2497e-04, -7.2007e-04, -7.0142e-05,  3.5565e-04, -8.5824e-04],\n",
      "          [ 9.6226e-04, -4.1868e-04,  1.2204e-04,  7.4874e-04, -1.3082e-03],\n",
      "          [ 1.6535e-04,  2.1620e-05,  8.7172e-04,  5.9196e-04, -1.8186e-03],\n",
      "          [ 9.5954e-05,  3.9383e-04,  3.4749e-04, -9.4933e-04, -2.7823e-03]],\n",
      "\n",
      "         [[-4.3043e-04, -2.2088e-04, -1.3672e-04, -1.8081e-04, -2.2827e-04],\n",
      "          [-1.9414e-04, -3.5053e-04, -1.5128e-04, -9.1883e-05, -2.4122e-04],\n",
      "          [-1.8565e-04, -3.5343e-04, -1.6425e-04, -5.3698e-06, -1.1611e-04],\n",
      "          [-9.8263e-06, -1.2034e-04, -3.9641e-05,  3.0850e-05, -2.1300e-04],\n",
      "          [ 3.5641e-05, -3.9049e-05, -5.4851e-05, -3.6603e-05, -2.7142e-04]],\n",
      "\n",
      "         [[-2.0600e-03, -4.0928e-03, -6.3150e-03, -5.7278e-03, -5.4573e-03],\n",
      "          [-2.8909e-03, -4.2020e-03, -7.2270e-03, -5.1815e-03, -4.4712e-03],\n",
      "          [-1.0028e-03, -1.8377e-03, -4.6072e-03, -4.1541e-03, -5.0085e-03],\n",
      "          [ 5.5912e-04, -9.6034e-04, -3.7043e-03, -3.1390e-03, -4.6902e-03],\n",
      "          [ 2.0568e-03,  1.1615e-03, -1.0547e-03, -9.7734e-04, -2.0940e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.6857e-04, -6.6959e-04, -2.0919e-04,  1.2326e-04,  1.6893e-04],\n",
      "          [-8.4522e-06, -3.5914e-04, -4.6111e-04, -7.7021e-05, -1.0941e-04],\n",
      "          [ 5.0571e-05, -1.1056e-04,  2.6418e-06, -8.1301e-05, -2.8659e-04],\n",
      "          [ 1.1856e-04,  1.8216e-04,  1.7674e-06, -3.9354e-05,  1.7232e-04],\n",
      "          [ 1.4839e-04, -2.5719e-04, -8.3467e-04, -1.3620e-06,  6.0975e-06]],\n",
      "\n",
      "         [[-2.3351e-03, -3.4526e-03, -6.9538e-03, -6.0679e-03, -6.0505e-03],\n",
      "          [-2.4396e-03, -2.5925e-03, -5.9031e-03, -5.8680e-03, -5.9324e-03],\n",
      "          [-1.2313e-03, -2.1188e-03, -5.2698e-03, -5.8601e-03, -7.2430e-03],\n",
      "          [-6.4920e-04, -1.2200e-03, -3.7231e-03, -3.6379e-03, -5.3046e-03],\n",
      "          [ 1.6985e-03,  1.9308e-03, -1.4982e-03, -3.0122e-03, -4.4128e-03]],\n",
      "\n",
      "         [[-5.9882e-04, -3.3158e-04, -6.8471e-04, -1.1033e-03, -4.8064e-04],\n",
      "          [ 7.9549e-05, -4.8155e-05, -9.9999e-04, -1.0894e-03, -9.1610e-05],\n",
      "          [ 1.0179e-03,  4.3947e-04, -3.7722e-04, -1.0213e-04,  5.7588e-04],\n",
      "          [ 1.1892e-03,  2.0985e-04, -3.3419e-04, -3.2592e-04,  7.0314e-04],\n",
      "          [ 3.1661e-04,  2.2536e-05, -4.4843e-04, -1.2579e-04,  1.0961e-03]]]]), 'conv2.bias': tensor([-0.0132, -0.0192, -0.0074, -0.0705, -0.0073,  0.0125, -0.0142, -0.0504,\n",
      "         0.0188, -0.0003,  0.0087,  0.0022,  0.0229,  0.0167,  0.0594, -0.0207,\n",
      "         0.0253,  0.0526, -0.0218, -0.0088,  0.0215,  0.0390,  0.0455, -0.0205,\n",
      "         0.0010,  0.0122, -0.0314,  0.0137, -0.0055, -0.0051,  0.0243, -0.0414]), 'fc1.weight': tensor([[ 2.4838e-05,  1.8987e-03,  4.8228e-03,  ...,  1.0369e-03,\n",
      "          9.6723e-04,  3.7982e-04],\n",
      "        [ 2.5480e-05,  1.9995e-03,  5.0992e-03,  ...,  1.0976e-03,\n",
      "          1.0218e-03,  3.9958e-04],\n",
      "        [ 2.8634e-05,  2.1675e-03,  5.4916e-03,  ...,  1.1758e-03,\n",
      "          1.1028e-03,  4.3224e-04],\n",
      "        ...,\n",
      "        [ 2.5470e-05,  1.9791e-03,  5.0409e-03,  ...,  1.0876e-03,\n",
      "          1.0126e-03,  3.9564e-04],\n",
      "        [-1.7356e-04, -8.0289e-03, -1.9225e-02,  ..., -3.9180e-03,\n",
      "         -3.3753e-03, -1.2997e-03],\n",
      "        [-4.6358e-05, -8.9424e-03, -2.3906e-02,  ..., -5.3488e-03,\n",
      "         -5.2784e-03, -2.0877e-03]]), 'fc1.bias': tensor([ 0.0459,  0.0485,  0.0522,  0.0494,  0.0569,  0.0514,  0.0578,  0.0480,\n",
      "        -0.1732, -0.2370])}\n",
      "!-- Client 2 is normal and start iterations. ---!\n",
      "Epoch [1/3], Average Loss: 1.6702827215194702, Average Accuracy: 0.4913602769374847, Average Error: 0.5086396932601929, Culminative Time Used: 0.1550939977169037\n",
      "Epoch [2/3], Average Loss: 0.6986128091812134, Average Accuracy: 0.7882221937179565, Average Error: 0.2117778360843658, Culminative Time Used: 0.31098470091819763\n",
      "Epoch [3/3], Average Loss: 0.8331285715103149, Average Accuracy: 0.5823661088943481, Average Error: 0.4176339209079742, Culminative Time Used: 0.46340319886803627\n",
      "{'conv1.weight': tensor([[[[ 3.4822e-03,  4.6240e-03,  6.8102e-03,  7.3927e-03,  6.8177e-03],\n",
      "          [ 3.4763e-03,  5.9876e-03,  1.0298e-02,  1.2112e-02,  1.0861e-02],\n",
      "          [ 3.7380e-03,  6.9924e-03,  1.0957e-02,  1.2038e-02,  1.0516e-02],\n",
      "          [ 3.5350e-03,  6.3818e-03,  7.9540e-03,  7.4693e-03,  6.7661e-03],\n",
      "          [ 9.8347e-04,  2.9435e-03,  3.8486e-03,  2.8106e-03,  2.6180e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7117e-04,  1.5764e-04,  3.0554e-04,  1.3259e-03,  1.4367e-03],\n",
      "          [-1.5130e-04, -5.6495e-04, -5.7928e-04,  1.2684e-04,  6.2960e-04],\n",
      "          [-5.0892e-05, -3.5593e-04, -6.4495e-04, -7.5192e-06,  4.5012e-04],\n",
      "          [-4.5332e-05, -7.0261e-05, -1.0877e-04,  6.4569e-04,  1.1252e-03],\n",
      "          [-9.7367e-06, -1.4021e-05,  1.6622e-04,  1.0089e-03,  1.5398e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.6177e-03,  4.6459e-03,  1.8073e-03, -1.5851e-03, -4.2463e-03],\n",
      "          [-7.0255e-04, -2.5429e-03, -3.2075e-03, -3.2127e-03, -2.4135e-03],\n",
      "          [-3.8284e-03, -3.6874e-03, -2.6906e-03, -1.8025e-04,  1.6716e-03],\n",
      "          [-2.3918e-03, -9.9705e-04,  1.8295e-03,  4.1477e-03,  4.9354e-03],\n",
      "          [ 4.0209e-04,  2.5104e-03,  4.7053e-03,  5.8477e-03,  5.3141e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1501e-03,  3.0394e-03,  3.2873e-03,  3.6656e-03,  2.4537e-03],\n",
      "          [ 1.5800e-03,  2.5545e-03,  2.7664e-03,  3.0999e-03,  1.2355e-03],\n",
      "          [ 3.5498e-03,  4.4292e-03,  4.2012e-03,  2.8419e-03,  9.0312e-04],\n",
      "          [ 3.8989e-03,  3.9723e-03,  2.8934e-03,  1.4534e-03,  5.2929e-04],\n",
      "          [ 2.1846e-03,  2.0733e-03,  1.2086e-03,  6.1504e-04, -1.0433e-04]]],\n",
      "\n",
      "\n",
      "        [[[-4.5538e-03, -5.5339e-03, -5.6873e-03, -5.3764e-03, -4.2124e-03],\n",
      "          [-2.5252e-03, -3.5399e-03, -4.8914e-03, -7.2244e-03, -6.9482e-03],\n",
      "          [ 3.5679e-04, -8.5335e-04, -3.3998e-03, -6.4750e-03, -7.1846e-03],\n",
      "          [ 1.6097e-03, -4.8364e-04, -2.6398e-03, -5.9625e-03, -6.5118e-03],\n",
      "          [ 4.0115e-04, -7.8563e-04, -2.1934e-03, -4.9279e-03, -5.1164e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.7659e-03, -4.8364e-04,  1.3303e-03,  3.6723e-03,  4.8992e-03],\n",
      "          [-4.5708e-04,  5.5749e-04,  1.5403e-03,  2.3893e-03,  2.3719e-03],\n",
      "          [ 1.2282e-03,  2.4165e-03,  2.5450e-03,  1.8539e-03,  1.6701e-03],\n",
      "          [ 2.7813e-03,  3.3340e-03,  3.6499e-03,  3.1464e-03,  2.7066e-03],\n",
      "          [ 3.4068e-03,  4.6197e-03,  4.4086e-03,  3.2949e-03,  2.8939e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.3827e-03, -2.4029e-03, -1.3351e-03,  3.6047e-04,  1.9422e-03],\n",
      "          [-2.0423e-03, -9.1989e-04,  5.0732e-04,  1.1466e-03,  2.5188e-03],\n",
      "          [-1.4561e-03, -5.9151e-04,  8.9697e-04,  1.5485e-03,  2.1950e-03],\n",
      "          [-5.1498e-04, -9.9756e-05,  4.7908e-04,  1.3229e-03,  8.1745e-04],\n",
      "          [-7.6221e-04, -6.4604e-05,  7.2069e-04,  1.3370e-03,  2.5221e-04]]],\n",
      "\n",
      "\n",
      "        [[[-4.4103e-03, -1.9988e-03, -3.0997e-04,  8.3425e-04,  2.3829e-03],\n",
      "          [-5.0673e-03, -2.4964e-03, -6.5420e-04,  6.9890e-04,  2.9444e-03],\n",
      "          [-6.1955e-03, -3.7670e-03, -1.4183e-03,  1.0136e-03,  4.2675e-03],\n",
      "          [-6.3599e-03, -3.6216e-03, -9.4328e-05,  3.0120e-03,  6.9725e-03],\n",
      "          [-5.6644e-03, -2.6901e-03,  6.8308e-04,  4.2702e-03,  8.3066e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.9108e-04,  3.2014e-04,  3.8906e-05, -4.0282e-04, -1.4881e-03],\n",
      "          [-1.4544e-03, -4.0453e-04,  3.9863e-04,  3.4944e-04, -4.2818e-04],\n",
      "          [-1.6670e-03, -8.4839e-04,  1.0580e-03,  1.4711e-03,  7.8971e-04],\n",
      "          [-7.6946e-04,  1.8799e-04,  2.0602e-03,  2.5217e-03,  2.5652e-03],\n",
      "          [ 1.6864e-04,  8.4544e-04,  1.5269e-03,  2.5950e-03,  3.1594e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.8826e-04,  1.5701e-03,  2.2173e-03,  2.2184e-03,  2.9480e-03],\n",
      "          [-2.4281e-04,  1.1714e-03,  1.8510e-03,  2.2689e-03,  2.9240e-03],\n",
      "          [-3.4773e-05,  3.3077e-05,  4.4825e-04,  8.4591e-04,  2.3253e-03],\n",
      "          [ 1.2678e-04,  8.5983e-05,  1.0388e-04,  2.7019e-04,  2.2832e-03],\n",
      "          [ 5.0906e-04,  4.0675e-04,  1.6840e-04,  6.4994e-04,  1.3915e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.1606e-02, -7.6315e-03, -3.3380e-03, -1.4553e-03, -2.3109e-03],\n",
      "          [-8.2603e-03, -5.2974e-03, -1.2924e-03, -4.9807e-04, -1.1580e-03],\n",
      "          [-4.4464e-03, -1.3595e-03,  1.3832e-03,  1.0213e-03,  3.6103e-04],\n",
      "          [-3.8606e-03, -5.2622e-04,  2.2400e-03,  3.4580e-03,  3.7922e-03],\n",
      "          [-4.0209e-03,  9.4387e-04,  5.5615e-03,  7.8772e-03,  9.7282e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.7329e-03,  6.0847e-03,  6.1844e-03,  6.4088e-03,  5.7132e-03],\n",
      "          [ 4.0105e-03,  3.6662e-03,  3.8849e-03,  4.1539e-03,  4.4200e-03],\n",
      "          [ 1.8615e-03,  1.6004e-03,  1.9549e-03,  2.9861e-03,  3.4650e-03],\n",
      "          [ 2.7802e-04,  4.8540e-04,  9.9742e-04,  1.5371e-03,  2.6575e-03],\n",
      "          [ 1.4772e-03,  1.7407e-03,  2.1342e-03,  2.2034e-03,  3.4852e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0737e-03,  2.7995e-03,  3.3598e-03,  4.0144e-03,  4.7007e-03],\n",
      "          [ 4.1617e-04,  6.7007e-04,  1.9656e-03,  4.1747e-03,  6.8960e-03],\n",
      "          [-1.4655e-03, -3.1698e-04,  2.6950e-03,  6.4262e-03,  7.4689e-03],\n",
      "          [-1.0923e-03,  5.9732e-04,  3.3686e-03,  5.3836e-03,  5.1739e-03],\n",
      "          [ 4.7700e-04,  1.2489e-03,  1.6753e-03,  9.5300e-04,  5.4074e-04]]],\n",
      "\n",
      "\n",
      "        [[[-6.9917e-04, -8.4242e-04, -6.4903e-04, -1.1626e-04,  1.4023e-04],\n",
      "          [-1.1757e-03, -1.1573e-03, -5.4196e-04, -5.7443e-06,  4.6015e-05],\n",
      "          [-9.9053e-04, -1.6010e-03, -1.6405e-03, -1.0505e-03, -1.2500e-03],\n",
      "          [-3.1207e-04, -1.6137e-03, -2.4870e-03, -2.7434e-03, -3.4041e-03],\n",
      "          [ 5.2457e-04, -5.2525e-04, -1.7983e-03, -2.7651e-03, -3.3810e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.5230e-03, -6.8986e-03, -7.1474e-03, -8.4620e-03, -9.0577e-03],\n",
      "          [-4.4418e-03, -4.2299e-03, -4.6084e-03, -6.2101e-03, -7.1545e-03],\n",
      "          [-7.8699e-03, -7.3434e-03, -5.9830e-03, -6.0139e-03, -6.0123e-03],\n",
      "          [-6.8745e-03, -6.5179e-03, -5.3808e-03, -4.8150e-03, -4.5857e-03],\n",
      "          [-3.5262e-03, -3.9205e-03, -3.2299e-03, -3.1113e-03, -2.8648e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.0508e-03, -3.8709e-03, -2.8854e-03, -2.8564e-04,  2.4437e-04],\n",
      "          [-5.3677e-03, -4.5579e-03, -2.3279e-03,  1.9065e-04,  4.8528e-04],\n",
      "          [-6.2389e-03, -3.9932e-03, -1.6545e-03, -1.7124e-05,  5.2908e-05],\n",
      "          [-5.9448e-03, -4.0667e-03, -1.2321e-03, -2.6391e-04, -5.0193e-04],\n",
      "          [-5.8723e-03, -4.0230e-03, -1.5264e-03, -1.2935e-03, -1.3423e-03]]]]), 'conv1.bias': tensor([ 0.0104,  0.0022,  0.0208,  0.0116, -0.0059,  0.0054,  0.0023, -0.0007,\n",
      "        -0.0036,  0.0023,  0.0024,  0.0095, -0.0005, -0.0031, -0.0266, -0.0085]), 'conv2.weight': tensor([[[[-5.8170e-03, -6.0676e-03, -3.9743e-03,  1.8585e-04,  2.1880e-03],\n",
      "          [-6.9517e-03, -7.9865e-03, -3.9591e-03, -2.7145e-03, -5.5348e-04],\n",
      "          [-6.5979e-03, -7.0595e-03, -5.2799e-03, -3.3523e-03, -1.9741e-03],\n",
      "          [-5.6502e-03, -4.9074e-03, -4.5085e-03, -1.2165e-03,  6.7146e-04],\n",
      "          [-4.8083e-03, -6.5568e-03, -6.1969e-03, -1.1068e-03,  1.1219e-03]],\n",
      "\n",
      "         [[-2.0898e-04, -8.7943e-05,  3.0199e-05,  1.5246e-04,  2.2334e-04],\n",
      "          [-2.6608e-04, -2.1336e-04, -9.1794e-05,  1.3876e-05,  5.3980e-06],\n",
      "          [-1.6270e-04, -1.8244e-04, -1.9141e-04,  6.0475e-05, -2.6897e-05],\n",
      "          [ 3.2978e-05,  3.5578e-05, -1.9615e-05, -1.8627e-05, -1.3610e-04],\n",
      "          [ 1.5060e-04,  1.0480e-04,  3.0807e-04,  1.2537e-04, -5.6081e-05]],\n",
      "\n",
      "         [[-8.0234e-03, -1.0278e-02, -7.9208e-03, -3.5409e-03,  1.7779e-04],\n",
      "          [-1.0629e-02, -1.1365e-02, -1.2604e-02, -7.3246e-03, -9.4892e-04],\n",
      "          [-9.4558e-03, -1.1520e-02, -1.3862e-02, -1.0490e-02, -4.6616e-03],\n",
      "          [-7.0252e-03, -8.2530e-03, -1.1215e-02, -9.0772e-03, -5.4045e-03],\n",
      "          [-7.6497e-03, -7.5853e-03, -8.5535e-03, -5.6523e-03, -1.9051e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4259e-03, -2.0653e-03, -7.7801e-04, -1.5814e-04, -5.5855e-05],\n",
      "          [-3.6015e-04, -9.8909e-04, -1.7859e-03, -1.5100e-03, -1.2230e-03],\n",
      "          [ 4.9812e-04, -2.5943e-04, -1.1706e-03, -7.9114e-04, -9.4623e-04],\n",
      "          [ 1.0964e-03,  7.5459e-04,  4.4476e-04,  1.7987e-04,  4.2312e-05],\n",
      "          [-2.9062e-04,  1.8294e-04,  4.2751e-04,  8.6289e-04,  5.7349e-04]],\n",
      "\n",
      "         [[-8.1500e-03, -8.2770e-03, -7.7348e-03, -4.7185e-03, -1.9812e-03],\n",
      "          [-9.6020e-03, -8.2814e-03, -9.0523e-03, -7.2584e-03, -2.5982e-03],\n",
      "          [-8.5128e-03, -8.2829e-03, -9.9074e-03, -8.2854e-03, -4.8203e-03],\n",
      "          [-7.0666e-03, -6.3014e-03, -7.5405e-03, -5.9516e-03, -3.8755e-03],\n",
      "          [-8.1335e-03, -8.2831e-03, -8.0230e-03, -4.3083e-03, -1.8671e-03]],\n",
      "\n",
      "         [[-5.0706e-05, -4.0814e-04, -2.2390e-03, -1.8789e-03, -1.5883e-03],\n",
      "          [-2.3455e-04, -1.7979e-03, -3.3362e-03, -3.0470e-03, -2.3632e-03],\n",
      "          [-7.0034e-04, -2.8498e-03, -3.4523e-03, -4.2008e-03, -2.2690e-03],\n",
      "          [-1.7824e-03, -2.3788e-03, -3.2132e-03, -4.6283e-03, -1.3472e-03],\n",
      "          [-1.2045e-03, -1.9179e-03, -3.8032e-03, -4.8820e-03, -1.4778e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.8970e-03, -5.0045e-03, -1.1292e-03,  3.3792e-03,  7.0682e-03],\n",
      "          [-5.4958e-03, -3.1607e-03,  3.6483e-03,  8.1605e-03,  1.1799e-02],\n",
      "          [-2.3489e-03,  1.8287e-03,  6.3315e-03,  9.0309e-03,  1.0466e-02],\n",
      "          [ 1.2940e-04,  1.8838e-03,  3.6295e-03,  5.9169e-03,  8.8054e-03],\n",
      "          [ 8.3557e-04,  1.8851e-03,  3.5843e-03,  8.1021e-03,  1.1577e-02]],\n",
      "\n",
      "         [[ 3.4193e-06, -1.9920e-04,  5.5467e-05, -7.7093e-05, -1.1905e-04],\n",
      "          [ 1.0201e-04, -1.6967e-05, -4.5270e-05,  1.3459e-05, -9.4657e-05],\n",
      "          [ 3.1989e-04,  5.8466e-05, -1.3912e-04,  9.4287e-05,  2.2588e-04],\n",
      "          [ 2.5011e-04,  1.0493e-04, -4.0401e-05,  4.3964e-04,  4.4850e-04],\n",
      "          [ 3.5119e-04,  2.5684e-04,  6.4945e-05,  5.3783e-04,  3.6064e-04]],\n",
      "\n",
      "         [[-1.0655e-02, -1.0212e-02, -6.4880e-03,  1.1635e-03,  7.3527e-03],\n",
      "          [-1.0254e-02, -7.9582e-03, -6.6528e-03, -1.1210e-05,  1.1420e-02],\n",
      "          [-8.0760e-03, -5.4345e-03, -1.7458e-03,  3.9617e-03,  1.3634e-02],\n",
      "          [-4.8593e-03, -4.2876e-05,  6.5439e-04,  6.0619e-03,  1.3455e-02],\n",
      "          [-1.7650e-03,  7.5620e-04,  2.2553e-03,  7.2158e-03,  1.4375e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8137e-04, -1.8549e-03, -1.3724e-03,  4.2759e-04,  6.4449e-04],\n",
      "          [ 7.0379e-04,  3.9261e-04, -4.2244e-04,  2.8596e-04,  4.7376e-04],\n",
      "          [ 7.7687e-04, -7.9881e-06, -5.6032e-04,  3.3606e-04,  9.3628e-04],\n",
      "          [ 2.4240e-04,  1.4272e-04, -5.0963e-04,  4.9801e-04,  1.6477e-03],\n",
      "          [ 4.7283e-04,  3.9789e-04,  1.0154e-04,  8.3314e-04,  1.2933e-03]],\n",
      "\n",
      "         [[-7.2781e-03, -6.9140e-03, -5.3407e-03, -2.6253e-03,  5.1380e-03],\n",
      "          [-7.2658e-03, -5.6340e-03, -1.5015e-03,  1.9300e-03,  1.0795e-02],\n",
      "          [-4.4885e-03, -4.3385e-04,  1.7441e-03,  4.5068e-03,  1.0052e-02],\n",
      "          [-1.8306e-03,  1.0723e-03,  1.2447e-03,  4.5807e-03,  8.1315e-03],\n",
      "          [-4.5149e-05,  1.0511e-03,  3.0088e-03,  7.0047e-03,  1.1243e-02]],\n",
      "\n",
      "         [[-1.5880e-03, -1.8761e-03, -4.0768e-03, -2.2709e-03,  8.0297e-04],\n",
      "          [-1.7604e-03, -2.0151e-03, -5.1474e-03, -2.1972e-03, -1.9347e-04],\n",
      "          [-1.3532e-03, -2.6337e-03, -3.9945e-03, -1.3640e-03,  1.7136e-04],\n",
      "          [-1.4775e-03, -2.1471e-03, -1.9817e-03, -1.5421e-03,  1.6228e-03],\n",
      "          [-5.3860e-04, -9.3867e-04, -9.7848e-04, -1.5736e-03,  2.6100e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.3701e-03,  2.9006e-03, -2.1493e-04, -1.9124e-03,  2.1082e-04],\n",
      "          [ 5.1885e-03,  3.3759e-03,  1.9613e-03,  1.3573e-04, -4.0902e-04],\n",
      "          [ 3.5122e-03,  3.8311e-03,  1.4280e-03, -7.8938e-04, -1.9902e-03],\n",
      "          [ 3.9787e-03,  4.8856e-03, -1.9788e-04, -3.3196e-03, -4.0147e-03],\n",
      "          [ 5.3818e-03,  4.2309e-03, -4.3173e-04, -4.1997e-03, -4.5189e-03]],\n",
      "\n",
      "         [[-3.3157e-04, -3.5354e-05, -9.0599e-05,  4.8824e-05,  1.2849e-04],\n",
      "          [ 6.2581e-05,  8.9099e-06, -9.7261e-05,  6.5003e-05,  3.6650e-04],\n",
      "          [ 2.3631e-04,  2.2928e-04, -7.4735e-05, -3.1891e-05,  1.0902e-04],\n",
      "          [ 7.2154e-05,  1.8071e-04, -1.4813e-04, -4.1609e-05, -6.8261e-05],\n",
      "          [-7.5893e-05, -1.9295e-06, -1.8312e-04, -1.2053e-04,  7.3423e-05]],\n",
      "\n",
      "         [[ 7.6256e-03,  6.1746e-03,  2.6071e-03, -1.4943e-03, -1.9551e-03],\n",
      "          [ 8.5252e-03,  7.5360e-03,  3.4309e-03, -5.9661e-04, -2.2891e-03],\n",
      "          [ 7.1325e-03,  9.1089e-03,  8.4000e-03,  2.5529e-03, -2.5318e-03],\n",
      "          [ 6.6988e-03,  6.6810e-03,  7.5209e-03,  3.9131e-03, -1.7004e-03],\n",
      "          [ 8.2883e-03,  7.4591e-03,  5.6721e-03,  2.2545e-03, -3.3506e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.1522e-04,  1.3729e-04, -1.5087e-04, -4.0135e-04, -5.3986e-04],\n",
      "          [ 6.4426e-04,  1.4237e-03,  2.6809e-04,  8.3515e-05, -3.5866e-04],\n",
      "          [ 2.2780e-04,  1.5036e-03,  9.7777e-04, -1.9164e-05, -4.1029e-04],\n",
      "          [ 3.0745e-04,  1.4383e-04,  1.9656e-04, -3.4392e-05, -1.4847e-04],\n",
      "          [-3.0866e-04, -4.2266e-04, -1.6347e-04, -1.7552e-04, -2.8303e-04]],\n",
      "\n",
      "         [[ 6.7305e-03,  5.1728e-03,  2.4674e-03,  1.0523e-03,  1.8151e-04],\n",
      "          [ 4.3599e-03,  5.0596e-03,  4.3755e-03,  2.5846e-03, -1.4128e-03],\n",
      "          [ 3.7445e-03,  4.6315e-03,  5.0424e-03,  2.9523e-03, -1.1747e-03],\n",
      "          [ 5.5346e-03,  4.8511e-03,  4.1782e-03,  3.5036e-03, -1.3389e-03],\n",
      "          [ 6.6732e-03,  5.8395e-03,  2.4620e-03, -4.8072e-04, -3.0436e-03]],\n",
      "\n",
      "         [[ 2.4281e-03,  3.0054e-03,  2.9739e-03,  2.2042e-03,  5.6548e-04],\n",
      "          [ 2.4478e-03,  2.6946e-03,  3.2744e-03,  2.0806e-03,  6.8883e-04],\n",
      "          [ 2.0960e-03,  1.5223e-03,  2.8953e-03,  2.4846e-03,  7.5764e-04],\n",
      "          [ 9.7183e-04,  6.4616e-04,  2.4633e-03,  1.7407e-03,  3.6147e-04],\n",
      "          [ 1.5571e-03,  1.8195e-03,  3.0895e-03,  2.0830e-03,  7.0194e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.2548e-03,  1.3802e-03,  7.7140e-05, -1.3681e-05, -1.1187e-05],\n",
      "          [ 1.2763e-03,  7.2662e-04,  1.0981e-04,  2.4685e-05, -1.4080e-06],\n",
      "          [ 1.2475e-03,  3.1172e-04,  1.5166e-04,  1.8952e-05,  3.8046e-06],\n",
      "          [ 5.3303e-04,  6.2243e-05,  4.0475e-05,  7.4775e-06,  1.5975e-07],\n",
      "          [ 5.5068e-04,  8.7498e-05,  8.8861e-05,  1.4466e-05,  4.4855e-06]],\n",
      "\n",
      "         [[ 8.3089e-05,  5.0326e-06,  2.5195e-07, -4.4506e-06, -2.8859e-06],\n",
      "          [ 4.9666e-05,  1.2750e-05, -1.4062e-07,  2.0975e-07,  6.5466e-06],\n",
      "          [ 5.2045e-05,  8.2964e-06,  2.9826e-07,  8.7418e-08, -3.3934e-06],\n",
      "          [ 1.5896e-05,  1.7477e-05,  7.0535e-06,  0.0000e+00,  0.0000e+00],\n",
      "          [ 1.2588e-05,  3.0038e-05,  1.9556e-05, -1.2640e-07, -1.0047e-07]],\n",
      "\n",
      "         [[ 3.8567e-03,  4.1137e-03,  2.3641e-03,  9.1700e-04,  6.1725e-04],\n",
      "          [ 3.2088e-03,  2.8837e-03,  1.6533e-03,  6.9350e-04,  4.9355e-04],\n",
      "          [ 2.9983e-03,  2.1682e-03,  1.6911e-03,  5.7577e-04,  4.9734e-04],\n",
      "          [ 2.4741e-03,  1.2641e-03,  1.0528e-03,  3.6937e-04,  2.5940e-04],\n",
      "          [ 1.6712e-03,  8.1134e-04,  4.8834e-04,  3.3676e-04,  2.2861e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7501e-04,  2.1728e-05, -6.5844e-07,  2.4723e-06, -4.7506e-06],\n",
      "          [ 1.6966e-04,  5.8120e-05,  1.7555e-05,  1.7114e-07,  4.0561e-07],\n",
      "          [ 1.3026e-04,  1.5464e-04,  3.4619e-05, -2.1568e-07, -6.6031e-07],\n",
      "          [ 6.4895e-05,  4.6871e-05,  3.6942e-05,  6.4009e-07, -3.9935e-08],\n",
      "          [ 1.1648e-04,  1.9509e-05,  4.5248e-05, -2.2814e-08,  0.0000e+00]],\n",
      "\n",
      "         [[ 3.2966e-03,  3.3806e-03,  1.7107e-03,  8.5618e-04,  7.4667e-04],\n",
      "          [ 2.8265e-03,  2.0483e-03,  1.9523e-03,  8.3662e-04,  6.6833e-04],\n",
      "          [ 3.3114e-03,  2.1597e-03,  1.9254e-03,  7.9709e-04,  6.6615e-04],\n",
      "          [ 1.6488e-03,  1.0169e-03,  8.4048e-04,  4.6723e-04,  3.5439e-04],\n",
      "          [ 1.0856e-03,  1.0072e-03,  4.5461e-04,  3.5812e-04,  3.1748e-04]],\n",
      "\n",
      "         [[ 1.8428e-04,  6.6674e-04,  9.0311e-04,  2.9283e-04, -2.9155e-06],\n",
      "          [-2.6311e-06,  9.5090e-04,  4.9801e-04,  6.4249e-06,  8.2647e-07],\n",
      "          [-8.3160e-05,  6.9132e-04,  1.1764e-04,  2.8657e-05, -2.2430e-06],\n",
      "          [ 5.8501e-04,  6.8160e-04,  1.0825e-04,  5.6807e-05,  5.1054e-07],\n",
      "          [ 6.5855e-04,  4.1685e-04,  7.2458e-05,  5.5574e-05,  2.5082e-06]]],\n",
      "\n",
      "\n",
      "        [[[-1.2316e-03, -2.9856e-03, -3.7563e-03, -3.9670e-03, -3.4638e-03],\n",
      "          [-5.0089e-03, -5.0407e-03, -2.1313e-03,  1.3449e-03,  1.6197e-03],\n",
      "          [-3.9247e-03, -1.1810e-03,  2.9534e-03,  6.7666e-03,  6.6708e-03],\n",
      "          [ 4.6774e-03,  7.1355e-03,  8.0175e-03,  1.0105e-02,  8.8965e-03],\n",
      "          [ 7.5576e-03,  6.8683e-03,  6.5916e-03,  7.9344e-03,  5.9907e-03]],\n",
      "\n",
      "         [[-1.0367e-04, -7.7032e-05,  5.1738e-05, -1.6438e-04, -4.2460e-04],\n",
      "          [ 1.6742e-04,  2.2354e-04,  3.1610e-04,  2.6274e-04, -1.1350e-04],\n",
      "          [ 1.2791e-04,  4.0250e-04,  2.4922e-04,  3.7196e-04,  1.9405e-05],\n",
      "          [ 1.1593e-04,  1.6143e-04,  3.3521e-04,  2.3800e-04,  8.1697e-05],\n",
      "          [ 1.2459e-04, -6.4448e-06,  1.5151e-04,  2.5364e-04,  6.3353e-05]],\n",
      "\n",
      "         [[ 7.4156e-03,  4.7446e-03,  1.3169e-03,  1.1930e-04, -2.6681e-03],\n",
      "          [ 1.9776e-03, -3.1266e-03, -4.2691e-03, -1.6666e-03,  1.9600e-03],\n",
      "          [-2.9648e-03, -6.3589e-03, -4.4756e-03,  5.0157e-04,  5.6794e-03],\n",
      "          [ 1.5522e-03,  3.4622e-04,  2.2700e-03,  4.8920e-03,  8.0719e-03],\n",
      "          [ 9.7836e-03,  1.0475e-02,  8.8353e-03,  1.0339e-02,  9.6963e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8784e-04,  3.0828e-04,  9.7087e-04,  1.8515e-03,  1.0708e-03],\n",
      "          [-4.0203e-04,  4.2877e-04,  5.5534e-04,  1.2456e-03,  6.2725e-04],\n",
      "          [ 6.0828e-04,  3.1251e-04, -2.6623e-04,  1.6948e-04,  3.0086e-04],\n",
      "          [ 1.8131e-03,  1.0365e-03,  7.6804e-04,  2.3030e-04,  7.8733e-05],\n",
      "          [ 2.0012e-03,  1.2527e-03,  9.4222e-04, -1.4880e-04, -1.3525e-04]],\n",
      "\n",
      "         [[ 5.3543e-03,  6.7198e-04, -3.0068e-03, -3.1439e-03, -1.9632e-03],\n",
      "          [-5.4260e-05, -4.7988e-03, -4.0985e-03, -2.4122e-03,  9.5574e-04],\n",
      "          [-1.5256e-03, -3.7155e-03, -1.3514e-03,  1.4534e-04,  3.4859e-03],\n",
      "          [ 4.8636e-03,  4.5596e-03,  4.3832e-03,  5.7230e-03,  6.1062e-03],\n",
      "          [ 9.6015e-03,  8.7474e-03,  8.7874e-03,  9.6033e-03,  7.8806e-03]],\n",
      "\n",
      "         [[ 4.4076e-04,  1.0929e-03,  1.0845e-04, -1.0811e-03, -2.1595e-03],\n",
      "          [ 1.5585e-03,  6.1769e-04, -9.4989e-04, -1.4647e-03, -6.0497e-04],\n",
      "          [ 1.8548e-03,  4.0809e-04, -8.9403e-04, -7.1958e-04,  1.3720e-03],\n",
      "          [ 8.5588e-04,  4.4193e-04,  4.3693e-04,  1.0721e-03,  1.9937e-03],\n",
      "          [ 4.8098e-04,  2.1079e-03,  2.0617e-03,  9.8788e-04,  2.3812e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4655e-03, -7.7700e-04,  1.5583e-04, -3.3580e-05, -1.2342e-04],\n",
      "          [-6.1324e-04,  1.2077e-04, -6.6279e-07,  4.3043e-04,  4.0443e-04],\n",
      "          [ 1.7955e-04, -5.4322e-04,  3.1080e-04,  1.6224e-03,  1.2404e-03],\n",
      "          [ 3.0657e-04,  7.1106e-04,  1.3597e-03,  1.6984e-03, -3.6291e-05],\n",
      "          [ 3.0498e-04,  1.3819e-03,  2.4355e-03,  1.4090e-03, -5.0364e-04]],\n",
      "\n",
      "         [[ 2.1881e-04,  2.6141e-04,  7.0078e-05,  5.3072e-05, -5.4972e-05],\n",
      "          [-3.2338e-05,  8.4417e-05,  7.8472e-05,  5.9071e-05, -1.3328e-05],\n",
      "          [-8.9199e-05,  2.7292e-05, -2.9060e-07,  8.8483e-05, -4.2932e-05],\n",
      "          [-2.6625e-05,  7.4814e-05,  9.4695e-05,  1.2479e-04, -1.3214e-04],\n",
      "          [ 2.6100e-06,  1.2475e-04,  4.5757e-04,  1.0963e-04, -2.1982e-04]],\n",
      "\n",
      "         [[-4.7401e-03, -1.5301e-03,  1.2019e-03,  4.2440e-03,  3.5427e-03],\n",
      "          [-2.3363e-03, -1.3794e-03, -1.3218e-03, -4.0227e-05, -5.4114e-04],\n",
      "          [-7.7427e-04, -5.9221e-04, -6.9617e-04,  2.3725e-04, -1.6075e-04],\n",
      "          [ 8.8808e-04,  5.2482e-04,  1.2621e-03,  3.7264e-04, -3.8974e-05],\n",
      "          [ 1.4683e-03,  8.4989e-04,  2.0985e-03,  1.9029e-03, -2.5489e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.2109e-04, -5.8914e-04, -2.5288e-04, -1.5799e-04, -4.1392e-04],\n",
      "          [-5.0184e-05, -1.0269e-04,  2.3274e-04,  5.2808e-04,  1.2134e-04],\n",
      "          [-3.6366e-04,  1.6469e-05,  4.7796e-04,  6.2659e-04, -1.7624e-05],\n",
      "          [ 2.5185e-06,  3.8929e-04,  5.9451e-04, -1.1328e-04, -5.6128e-04],\n",
      "          [ 1.6919e-04,  2.1188e-04,  9.3264e-04,  7.5268e-05, -8.9006e-04]],\n",
      "\n",
      "         [[-1.7116e-03, -4.5973e-04,  2.6575e-04,  1.4300e-03,  1.4724e-03],\n",
      "          [-9.4486e-04, -3.6839e-04, -1.7276e-03, -5.6141e-04, -1.0143e-03],\n",
      "          [ 2.9925e-04, -8.4556e-05, -4.4135e-04, -3.2849e-04, -5.4641e-04],\n",
      "          [ 1.2739e-03,  8.1085e-04,  9.1938e-04,  4.1253e-05, -3.9720e-04],\n",
      "          [ 1.6258e-03,  1.8069e-03,  1.0369e-03,  1.0483e-03, -6.7450e-04]],\n",
      "\n",
      "         [[-1.4961e-03, -1.3659e-03, -4.6366e-04,  5.1834e-04,  8.2092e-04],\n",
      "          [-7.6322e-04, -6.0038e-04, -3.9357e-04, -1.3379e-04,  2.7631e-07],\n",
      "          [-1.0042e-04, -2.7895e-04, -4.8258e-04, -1.4649e-04, -2.5157e-04],\n",
      "          [ 3.2115e-04,  1.7324e-04, -1.2940e-04,  4.3471e-04, -6.7122e-04],\n",
      "          [-2.6741e-04, -1.7679e-05,  1.7817e-04,  5.4846e-04, -5.9606e-04]]]]), 'conv2.bias': tensor([-0.0162,  0.0104,  0.0057,  0.0320, -0.0146, -0.0098, -0.0055, -0.0104,\n",
      "        -0.0051, -0.0337, -0.0465, -0.0161, -0.0234,  0.0038,  0.0146,  0.0204,\n",
      "        -0.0210, -0.0200,  0.0090,  0.0009,  0.0157, -0.0024, -0.0313,  0.0172,\n",
      "        -0.0072,  0.0006,  0.0557, -0.0034, -0.0004,  0.0114, -0.0092, -0.0093]), 'fc1.weight': tensor([[ 0.0002,  0.0034,  0.0068,  ...,  0.0008,  0.0013,  0.0007],\n",
      "        [ 0.0002,  0.0036,  0.0071,  ...,  0.0009,  0.0013,  0.0007],\n",
      "        [-0.0005, -0.0136, -0.0277,  ..., -0.0033, -0.0061, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0002,  0.0035,  0.0070,  ...,  0.0009,  0.0013,  0.0007],\n",
      "        [ 0.0002,  0.0035,  0.0070,  ...,  0.0009,  0.0013,  0.0007],\n",
      "        [ 0.0002,  0.0036,  0.0072,  ...,  0.0009,  0.0014,  0.0007]]), 'fc1.bias': tensor([ 0.0552,  0.0572, -0.2336, -0.2466,  0.0687,  0.0599,  0.0679,  0.0562,\n",
      "         0.0568,  0.0583])}\n",
      "!-- Client 0 is normal and start iterations. ---!\n",
      "Epoch [1/3], Average Loss: 0.2482401281595230, Average Accuracy: 0.9341989159584045, Average Error: 0.0658010542392731, Culminative Time Used: 2.2014074996113777\n",
      "Epoch [2/3], Average Loss: 0.0197842586785555, Average Accuracy: 0.9957086443901062, Average Error: 0.0042913733050227, Culminative Time Used: 4.502448599785566\n",
      "Epoch [3/3], Average Loss: 0.0135749178007245, Average Accuracy: 0.9968090057373047, Average Error: 0.0031910210382193, Culminative Time Used: 6.793127100914717\n",
      "{'conv1.weight': tensor([[[[-1.3043e-03, -2.9618e-03, -2.8293e-03, -1.0232e-03,  1.2237e-04],\n",
      "          [-6.5288e-04, -2.1539e-03, -1.3596e-03, -3.4617e-04, -6.8423e-04],\n",
      "          [-2.6327e-04, -4.2392e-04,  4.5042e-04,  5.2104e-04, -1.7256e-03],\n",
      "          [-4.0290e-04,  9.8099e-04,  1.7382e-03,  9.8454e-04, -3.8503e-03],\n",
      "          [-9.4679e-04,  1.3051e-03,  2.1319e-03,  6.0553e-04, -5.7023e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1961e-04,  1.4027e-03,  2.9438e-03,  3.2411e-03,  2.1319e-03],\n",
      "          [ 1.0619e-04,  8.7160e-04,  1.8085e-03,  2.0696e-03,  1.6388e-03],\n",
      "          [ 7.1046e-06,  3.7178e-04,  1.1964e-03,  1.9408e-03,  1.7172e-03],\n",
      "          [-5.6302e-06, -6.3659e-06, -3.1834e-04,  1.0495e-03,  1.5981e-03],\n",
      "          [-2.5949e-06, -2.4164e-05, -9.0562e-04, -8.3396e-04,  3.1303e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2214e-03,  3.3174e-03,  9.3824e-04,  9.3536e-04,  1.8457e-03],\n",
      "          [ 2.5763e-03,  2.5549e-03,  1.1820e-03,  8.3718e-04,  6.5058e-04],\n",
      "          [ 8.4713e-04,  1.4519e-03,  6.1972e-04, -6.0282e-04, -7.2213e-04],\n",
      "          [-4.7404e-05,  7.5096e-04, -2.9008e-05, -1.3274e-03, -1.6085e-03],\n",
      "          [-1.2831e-03,  6.3516e-04,  7.3078e-04, -9.0231e-04, -1.8698e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5639e-03,  1.6451e-03,  3.6784e-03,  6.7953e-03,  8.1446e-03],\n",
      "          [ 2.7926e-03,  2.3745e-03,  4.9435e-03,  7.5580e-03,  7.2387e-03],\n",
      "          [ 3.1950e-03,  3.4440e-03,  5.7702e-03,  7.2619e-03,  6.2140e-03],\n",
      "          [ 4.9146e-03,  5.5601e-03,  5.7111e-03,  6.2320e-03,  4.9937e-03],\n",
      "          [ 6.4501e-03,  6.0552e-03,  4.8688e-03,  4.8751e-03,  3.6413e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0586e-03,  1.6601e-03,  8.1141e-04, -1.1857e-03, -4.1049e-03],\n",
      "          [ 1.9015e-03,  9.3665e-04, -4.2068e-04, -2.3189e-03, -5.3351e-03],\n",
      "          [ 1.1511e-03, -3.5505e-04, -2.1196e-03, -3.3967e-03, -6.5976e-03],\n",
      "          [ 9.0203e-05, -1.2129e-03, -3.0616e-03, -4.4542e-03, -6.5868e-03],\n",
      "          [-3.0284e-04, -1.8450e-03, -3.5228e-03, -4.9722e-03, -5.4476e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.6728e-03, -1.7078e-03, -2.1862e-03, -5.7255e-03, -8.1632e-03],\n",
      "          [-3.2527e-03, -2.4417e-03, -4.5113e-03, -7.7038e-03, -9.4447e-03],\n",
      "          [-3.2587e-03, -3.1562e-03, -6.0992e-03, -8.0219e-03, -9.0253e-03],\n",
      "          [-3.2430e-03, -3.8732e-03, -6.7416e-03, -8.3499e-03, -8.7147e-03],\n",
      "          [-4.0199e-03, -5.1607e-03, -7.1400e-03, -7.9131e-03, -7.4808e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2882e-04,  6.3682e-04, -3.5916e-04, -3.6706e-03, -7.1102e-03],\n",
      "          [-2.3238e-04,  6.8199e-04, -9.8495e-05, -3.5096e-03, -7.0799e-03],\n",
      "          [-5.1167e-04,  2.9563e-04, -2.8220e-04, -2.4962e-03, -5.6122e-03],\n",
      "          [-3.3628e-04,  1.1668e-04,  2.6891e-06, -1.6947e-03, -4.3398e-03],\n",
      "          [ 6.1236e-04,  1.0133e-03,  1.2085e-03, -3.0217e-04, -2.8925e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.1757e-03,  4.0374e-03,  1.2635e-03, -2.4955e-03, -5.2305e-03],\n",
      "          [ 7.1338e-03,  4.0093e-03,  1.2836e-03, -2.4949e-03, -5.9330e-03],\n",
      "          [ 8.5637e-03,  4.7211e-03,  3.7340e-04, -3.5611e-03, -7.7670e-03],\n",
      "          [ 8.9578e-03,  3.9850e-03, -1.5110e-03, -4.8421e-03, -8.0498e-03],\n",
      "          [ 8.0974e-03,  2.0387e-03, -3.0705e-03, -5.5441e-03, -7.9659e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5453e-04, -1.7197e-03, -4.9041e-03, -7.4713e-03, -9.0130e-03],\n",
      "          [ 1.0919e-03, -2.1624e-03, -5.1134e-03, -7.5622e-03, -9.3582e-03],\n",
      "          [ 3.5146e-04, -2.4446e-03, -4.4774e-03, -7.0703e-03, -8.8574e-03],\n",
      "          [-6.4784e-04, -2.8010e-03, -3.8944e-03, -6.3836e-03, -7.2957e-03],\n",
      "          [-1.5754e-03, -2.4644e-03, -3.3081e-03, -5.1953e-03, -6.1333e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.9856e-04, -1.7588e-04, -1.9373e-05, -7.6606e-04, -4.8020e-03],\n",
      "          [-4.7741e-04, -2.2394e-04, -2.0946e-04, -9.9063e-04, -4.4187e-03],\n",
      "          [-5.8924e-05, -7.1813e-06, -1.2901e-04, -7.3103e-04, -4.8803e-03],\n",
      "          [ 1.5327e-04,  4.1032e-04,  1.0069e-04, -4.9756e-04, -5.9005e-03],\n",
      "          [ 2.3810e-03,  1.3284e-03,  1.5202e-04, -1.1199e-03, -5.5307e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2345e-03,  7.6745e-04,  3.7869e-04,  3.7619e-04,  4.2191e-04],\n",
      "          [ 1.5414e-03,  1.1559e-03, -3.9973e-04, -6.8255e-04, -6.5190e-04],\n",
      "          [ 2.8015e-04, -2.4742e-04, -1.7094e-03, -1.1264e-03, -5.7487e-04],\n",
      "          [-2.9002e-04, -7.8761e-04, -1.9259e-03, -1.6818e-03,  1.4825e-04],\n",
      "          [-9.5885e-04, -1.2914e-03, -2.1644e-03, -1.4814e-03,  9.4079e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8107e-03,  3.8262e-03,  4.9007e-03,  5.2702e-03,  4.0667e-03],\n",
      "          [ 1.5251e-03,  2.7574e-03,  4.7265e-03,  5.3447e-03,  4.6310e-03],\n",
      "          [ 7.9264e-04,  9.5178e-04,  2.2291e-03,  3.5558e-03,  3.6575e-03],\n",
      "          [-7.1836e-05,  5.1559e-05,  9.1518e-04,  1.8249e-03,  2.3247e-03],\n",
      "          [-1.2897e-04,  6.6214e-05,  8.5339e-04,  1.5309e-03,  2.0004e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.4163e-03, -3.5218e-03, -2.4447e-03,  2.8643e-05,  2.8023e-03],\n",
      "          [-1.2258e-03, -2.6789e-03, -1.6853e-03,  4.3168e-04,  3.0931e-03],\n",
      "          [ 5.5093e-04, -8.9215e-04, -5.3164e-04,  1.1380e-03,  3.1119e-03],\n",
      "          [ 1.5805e-03,  6.2703e-04,  4.4461e-04,  1.0979e-03,  2.6149e-03],\n",
      "          [ 1.8423e-03,  1.1471e-03,  5.5000e-04,  3.2286e-04,  1.4983e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.5643e-04, -6.0152e-04, -5.6266e-04, -3.2017e-04, -2.8015e-05],\n",
      "          [-6.5300e-04, -7.7365e-04, -6.1184e-04, -2.8373e-04, -1.1410e-04],\n",
      "          [-6.1140e-04, -6.5153e-04, -2.4372e-04, -1.3282e-04, -3.0508e-04],\n",
      "          [-3.1795e-04, -1.9936e-04,  1.6760e-04, -2.8629e-04, -1.0059e-03],\n",
      "          [ 1.4422e-04,  7.9599e-04,  9.0648e-04, -4.5076e-04, -1.6427e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.3553e-03,  3.2007e-03,  1.9585e-03,  5.3373e-03,  8.6706e-03],\n",
      "          [ 4.8735e-03,  3.1101e-03,  3.4006e-03,  7.3975e-03,  9.3282e-03],\n",
      "          [ 7.7299e-03,  6.9358e-03,  6.6139e-03,  8.9567e-03,  9.1395e-03],\n",
      "          [ 8.7447e-03,  9.4267e-03,  1.0088e-02,  1.0042e-02,  8.0469e-03],\n",
      "          [ 7.0839e-03,  9.8896e-03,  1.0422e-02,  9.1311e-03,  6.7426e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8729e-03,  2.1215e-03,  1.7624e-03, -2.2195e-04, -5.1096e-04],\n",
      "          [ 3.1137e-03,  2.5807e-03,  1.3968e-03, -1.1451e-04, -5.8855e-05],\n",
      "          [ 4.1109e-03,  3.3826e-03,  1.5108e-03,  2.8079e-04,  2.7177e-04],\n",
      "          [ 4.5158e-03,  4.1516e-03,  1.4147e-03,  5.6083e-04,  5.0854e-04],\n",
      "          [ 3.9828e-03,  4.1232e-03,  1.8023e-03,  9.5067e-04,  8.7548e-04]]]]), 'conv1.bias': tensor([-0.0065,  0.0036, -0.0016,  0.0114, -0.0066, -0.0100, -0.0046, -0.0087,\n",
      "        -0.0089, -0.0081,  0.0174,  0.0059,  0.0037, -0.0009,  0.0244,  0.0037]), 'conv2.weight': tensor([[[[ 2.9058e-03,  2.8052e-03,  1.7240e-03, -3.2662e-05, -8.8567e-04],\n",
      "          [ 2.9514e-03,  2.6543e-03,  9.2731e-04,  2.1296e-04,  1.4648e-03],\n",
      "          [ 2.4495e-03,  3.0964e-03,  1.5919e-03,  2.2933e-03,  5.4715e-03],\n",
      "          [ 1.6564e-03,  2.9133e-03,  3.7584e-03,  5.1439e-03,  6.1353e-03],\n",
      "          [ 1.9368e-03,  3.6012e-03,  5.8992e-03,  6.0883e-03,  5.3086e-03]],\n",
      "\n",
      "         [[-1.4762e-04,  2.1386e-04,  1.0138e-04,  2.7955e-04,  2.4282e-04],\n",
      "          [ 8.7398e-05,  5.0879e-04,  2.3901e-04,  2.5184e-04,  2.3650e-04],\n",
      "          [ 8.2204e-05,  5.5027e-04,  3.9998e-04,  2.0106e-04,  2.4707e-04],\n",
      "          [ 1.7934e-05,  3.0012e-04,  4.6995e-04,  1.2111e-04,  1.8942e-04],\n",
      "          [-4.9962e-06,  1.7411e-05,  2.4110e-04,  8.9300e-05,  1.3698e-04]],\n",
      "\n",
      "         [[ 3.2036e-03,  5.6748e-03,  6.0608e-03,  3.9468e-03,  3.8682e-03],\n",
      "          [ 4.8819e-03,  6.3317e-03,  8.2408e-03,  5.6631e-03,  4.2776e-03],\n",
      "          [ 6.7177e-03,  6.1271e-03,  8.2784e-03,  7.2797e-03,  6.5084e-03],\n",
      "          [ 6.5163e-03,  6.1156e-03,  8.3518e-03,  1.0392e-02,  9.0492e-03],\n",
      "          [ 5.4359e-03,  6.2984e-03,  9.4109e-03,  1.2256e-02,  1.0804e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.9368e-04,  1.5129e-03,  6.2136e-04,  4.4190e-04,  7.5107e-04],\n",
      "          [ 3.6069e-04,  7.4899e-04,  7.9683e-04,  4.6655e-04,  7.8085e-04],\n",
      "          [ 1.9220e-04,  5.5632e-04,  1.0182e-03,  4.1751e-04,  4.5537e-04],\n",
      "          [-1.8364e-04,  1.9377e-04,  9.2556e-04,  3.7992e-04,  2.0346e-04],\n",
      "          [-3.0793e-05,  2.3195e-05,  4.8239e-04,  4.7567e-04, -1.4339e-05]],\n",
      "\n",
      "         [[ 4.9349e-03,  5.6562e-03,  6.7401e-03,  5.3066e-03,  4.0665e-03],\n",
      "          [ 5.6592e-03,  5.2620e-03,  5.9309e-03,  5.1611e-03,  4.6803e-03],\n",
      "          [ 6.3369e-03,  5.5796e-03,  5.2858e-03,  6.3891e-03,  7.2894e-03],\n",
      "          [ 4.8283e-03,  4.9757e-03,  6.3875e-03,  9.2536e-03,  9.1279e-03],\n",
      "          [ 5.1028e-03,  6.5198e-03,  8.5512e-03,  9.8003e-03,  1.0140e-02]],\n",
      "\n",
      "         [[-1.2409e-03, -9.1974e-04,  4.0305e-04,  8.7676e-04,  2.9804e-04],\n",
      "          [ 5.0181e-04, -2.8013e-04,  1.2571e-03,  1.7678e-03,  1.0699e-03],\n",
      "          [ 1.2732e-03,  3.2959e-04,  1.5076e-03,  2.0727e-03,  1.5420e-03],\n",
      "          [ 1.7863e-03,  8.9568e-04,  1.5166e-03,  1.9958e-03,  1.9077e-03],\n",
      "          [ 1.6820e-03,  6.3618e-04,  1.1185e-03,  2.6877e-03,  3.3430e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.1641e-03, -3.6134e-03, -4.3351e-03, -4.9598e-03, -6.0224e-03],\n",
      "          [-4.3123e-03, -5.3883e-03, -4.2554e-03, -4.7610e-03, -7.2341e-03],\n",
      "          [-4.5723e-03, -3.6744e-03, -2.8858e-03, -3.3220e-03, -3.4718e-03],\n",
      "          [-1.9839e-03, -2.6493e-05,  1.1678e-03,  7.1708e-04,  1.2455e-03],\n",
      "          [ 1.1290e-03,  3.4526e-03,  4.0315e-03,  2.1618e-03,  2.8342e-03]],\n",
      "\n",
      "         [[-4.1532e-04, -3.3398e-04, -6.3596e-05, -5.5461e-05,  4.3556e-04],\n",
      "          [-2.7327e-04, -3.4496e-04, -3.1039e-04, -9.9159e-05,  5.3203e-05],\n",
      "          [-6.7379e-06, -2.4594e-05, -3.0311e-04, -2.0484e-04, -2.0748e-04],\n",
      "          [ 1.0011e-04,  5.7124e-05, -3.3188e-05, -1.1039e-04, -1.8285e-04],\n",
      "          [ 1.7880e-04,  9.8920e-05, -6.7588e-05, -1.7133e-04, -2.0494e-04]],\n",
      "\n",
      "         [[ 6.0587e-04, -4.8715e-03, -6.5126e-03, -5.5237e-03, -8.0599e-03],\n",
      "          [-8.8273e-04, -5.7101e-03, -7.9032e-03, -9.4451e-03, -1.1127e-02],\n",
      "          [-1.7653e-03, -5.9662e-03, -6.0154e-03, -8.9397e-03, -1.1129e-02],\n",
      "          [-1.0389e-03, -4.8066e-03, -4.0967e-03, -6.6430e-03, -6.7892e-03],\n",
      "          [ 2.6663e-03, -9.2729e-04, -4.2796e-05, -1.2494e-03, -4.6660e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1098e-03, -1.2984e-03, -1.1301e-03, -6.5270e-04, -3.6073e-04],\n",
      "          [-5.9309e-04, -4.5270e-04, -7.9819e-04, -4.4665e-04,  1.5477e-04],\n",
      "          [-6.5107e-05, -2.3927e-05,  2.8930e-04,  8.6554e-04,  5.4744e-04],\n",
      "          [ 6.1325e-04,  5.1344e-04,  1.2057e-03,  1.2993e-03,  9.0991e-04],\n",
      "          [ 1.1880e-03,  4.3053e-04,  5.8105e-04,  3.3884e-04,  6.8657e-04]],\n",
      "\n",
      "         [[-4.5162e-04, -5.1867e-03, -7.2027e-03, -6.9372e-03, -9.7119e-03],\n",
      "          [-7.8805e-04, -5.5914e-03, -5.7045e-03, -7.2675e-03, -1.0064e-02],\n",
      "          [-5.3519e-05, -4.3546e-03, -3.9099e-03, -5.9946e-03, -7.7170e-03],\n",
      "          [ 5.2722e-04, -3.6299e-03, -2.5956e-03, -3.2498e-03, -2.7012e-03],\n",
      "          [ 3.4731e-03,  1.0287e-03,  1.2935e-03,  1.1752e-04,  1.8276e-04]],\n",
      "\n",
      "         [[ 1.7152e-03,  2.7844e-04,  7.6035e-04,  2.4157e-04, -9.6795e-04],\n",
      "          [ 8.0645e-04,  1.7985e-04, -4.3896e-04, -9.8569e-04, -1.9363e-03],\n",
      "          [ 4.5848e-04, -5.2186e-04, -1.2091e-03, -9.9735e-04, -2.5185e-03],\n",
      "          [-4.2108e-05, -8.3648e-04, -9.4746e-04, -1.0489e-03, -2.9643e-03],\n",
      "          [-9.8369e-04, -1.1964e-03, -9.5576e-04, -8.1048e-05, -2.0806e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.1682e-03,  2.7916e-04, -8.6112e-05, -1.3162e-03, -4.7350e-04],\n",
      "          [-2.9578e-03, -9.7116e-04, -5.6908e-04,  1.2048e-03,  2.9631e-03],\n",
      "          [-5.1231e-03, -1.9844e-03,  4.4361e-04,  2.9452e-03,  4.6085e-03],\n",
      "          [-7.9352e-03, -3.3388e-03,  1.4288e-03,  4.3769e-03,  4.4504e-03],\n",
      "          [-7.2654e-03, -2.7008e-03,  2.2488e-03,  5.4208e-03,  1.8224e-03]],\n",
      "\n",
      "         [[-3.3453e-04,  1.6723e-04,  1.9353e-04,  7.5092e-04,  1.5083e-04],\n",
      "          [-2.1861e-04,  4.2698e-04,  9.5881e-05,  8.1411e-04,  3.1142e-04],\n",
      "          [-1.4816e-04,  5.7060e-04,  5.4756e-05,  4.7888e-04,  3.8029e-04],\n",
      "          [ 4.6926e-05,  7.5220e-04,  3.2681e-04,  2.5097e-04,  2.3073e-04],\n",
      "          [-1.2125e-04,  4.4136e-04,  3.1918e-04,  1.7099e-04,  1.0157e-04]],\n",
      "\n",
      "         [[-7.5679e-03, -1.7653e-03,  1.0701e-03,  1.8954e-03,  2.2702e-03],\n",
      "          [-8.5964e-03, -5.0076e-03, -2.9369e-03, -2.0637e-03,  1.7333e-03],\n",
      "          [-9.5811e-03, -6.2696e-03, -3.0413e-03,  4.5852e-04,  3.3790e-03],\n",
      "          [-1.3710e-02, -7.2058e-03, -2.3567e-03,  3.4464e-03,  4.2769e-03],\n",
      "          [-1.6822e-02, -9.3331e-03, -2.1901e-03,  4.9182e-03,  3.2819e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2698e-03, -8.9595e-04, -4.8610e-05,  4.7020e-04,  3.6034e-04],\n",
      "          [-5.0223e-04,  2.0994e-05,  2.5378e-04,  3.3863e-04,  5.5930e-04],\n",
      "          [-2.7318e-04, -1.1848e-04,  4.3962e-04,  4.0739e-04,  2.6375e-04],\n",
      "          [-2.3083e-04, -1.2739e-04,  5.9672e-04,  7.3575e-04, -2.8502e-04],\n",
      "          [-5.4579e-04, -2.4377e-04,  3.4486e-04,  3.1463e-04, -4.4034e-04]],\n",
      "\n",
      "         [[-4.1476e-03, -1.7700e-03, -1.9836e-03, -2.0955e-03, -4.2685e-04],\n",
      "          [-5.8589e-03, -4.6180e-03, -4.4573e-03, -2.1706e-03, -1.8270e-04],\n",
      "          [-7.5833e-03, -5.1764e-03, -3.7030e-03,  1.8585e-04,  8.8302e-04],\n",
      "          [-1.1757e-02, -6.3365e-03, -3.6838e-03,  2.2232e-03,  2.1767e-03],\n",
      "          [-1.1354e-02, -6.6418e-03, -2.3513e-03,  3.0015e-03,  9.2617e-04]],\n",
      "\n",
      "         [[-3.3350e-03, -1.1451e-03,  1.6079e-03,  2.9541e-03,  2.1179e-03],\n",
      "          [-3.5574e-03, -1.1394e-03,  4.4484e-04,  1.3509e-03,  4.0838e-04],\n",
      "          [-4.1230e-03, -1.7024e-03, -8.8867e-04,  4.6329e-04,  5.4103e-04],\n",
      "          [-4.8843e-03, -3.5041e-03, -2.3267e-03,  7.7054e-05,  1.1131e-03],\n",
      "          [-6.3887e-03, -4.7755e-03, -2.4806e-03,  2.3541e-04,  2.7156e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.9057e-04, -1.0658e-05,  3.8448e-06,  3.5815e-05,  9.6033e-05],\n",
      "          [ 1.4643e-05,  3.4269e-05, -4.3434e-05, -2.7940e-06,  2.9950e-05],\n",
      "          [-1.2127e-04, -1.2419e-04, -8.4631e-05, -8.3222e-06,  1.5374e-06],\n",
      "          [-1.3584e-04, -1.4156e-04, -6.0432e-05, -1.2836e-06,  6.7658e-07],\n",
      "          [-7.1552e-04, -1.7587e-04, -6.3825e-05, -7.1699e-07,  9.6496e-07]],\n",
      "\n",
      "         [[ 1.6894e-05, -2.8869e-06,  2.1378e-07, -1.4071e-06,  2.0289e-05],\n",
      "          [-1.0962e-05, -4.4560e-06, -8.4133e-07,  1.9618e-06,  1.0216e-05],\n",
      "          [-7.6342e-05, -1.3160e-05, -1.1063e-06, -1.2710e-07,  8.9639e-07],\n",
      "          [-5.4869e-05, -2.0620e-05, -4.9120e-06,  7.0593e-09,  1.2130e-08],\n",
      "          [-6.7234e-05, -2.0653e-05, -8.4367e-06, -1.4607e-08,  2.1716e-08]],\n",
      "\n",
      "         [[-2.4549e-04, -3.8197e-04, -7.5297e-04, -1.4595e-04,  5.4250e-05],\n",
      "          [-1.1988e-03, -9.9268e-04, -1.0078e-03, -4.0773e-04,  3.6919e-06],\n",
      "          [-2.4214e-03, -1.3819e-03, -1.1862e-03, -4.9260e-04, -4.4651e-05],\n",
      "          [-2.7842e-03, -1.3937e-03, -8.6974e-04, -5.1974e-04, -5.0054e-05],\n",
      "          [-2.6441e-03, -1.7288e-03, -8.5707e-04, -5.4983e-04, -5.6492e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2778e-05, -2.5964e-06,  9.8572e-08,  3.3572e-07, -3.8338e-06],\n",
      "          [-8.7024e-05, -3.6676e-05, -1.2666e-05,  3.1704e-08, -5.1895e-07],\n",
      "          [-1.1965e-04, -8.0206e-05, -2.6674e-05, -2.2784e-07,  2.7053e-08],\n",
      "          [-1.5594e-04, -3.5280e-05, -1.5526e-05, -1.1501e-10,  7.2909e-08],\n",
      "          [-2.0788e-04, -2.0635e-05, -1.7886e-05, -1.8953e-06,  7.7341e-08]],\n",
      "\n",
      "         [[-9.6770e-04, -8.2262e-04, -9.1324e-04, -1.0449e-04, -7.5792e-06],\n",
      "          [-1.8071e-03, -1.5110e-03, -1.4647e-03, -5.9901e-04, -5.1111e-05],\n",
      "          [-2.5384e-03, -1.9646e-03, -1.6516e-03, -6.8173e-04, -6.7230e-05],\n",
      "          [-2.1148e-03, -1.4899e-03, -9.8038e-04, -6.9162e-04, -6.8898e-05],\n",
      "          [-1.8309e-03, -1.7121e-03, -1.0178e-03, -7.1624e-04, -8.1169e-05]],\n",
      "\n",
      "         [[ 9.5365e-05,  2.9935e-04,  6.8425e-05, -3.8565e-05, -7.5010e-06],\n",
      "          [-4.7684e-05,  2.3256e-04,  1.6181e-05, -2.4906e-06,  3.8921e-07],\n",
      "          [-5.0227e-05,  1.2174e-04, -5.9666e-05, -1.8769e-05,  9.3467e-08],\n",
      "          [-2.0097e-04, -3.1914e-04, -1.5721e-04, -3.9347e-05, -5.9283e-07],\n",
      "          [-4.7433e-04, -5.8301e-04, -2.2436e-04, -3.8369e-05, -4.4467e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 5.1228e-03, -5.5491e-04, -1.2819e-03, -1.3902e-03, -2.5329e-04],\n",
      "          [ 3.2445e-03, -1.1786e-03, -3.9089e-04,  1.7915e-03,  2.9551e-03],\n",
      "          [-8.8692e-05, -1.5448e-03,  7.0946e-04,  5.3952e-03,  5.7375e-03],\n",
      "          [-3.6926e-03, -1.7977e-03,  2.3856e-03,  7.2537e-03,  6.8241e-03],\n",
      "          [-4.2749e-03, -9.3469e-04,  4.8599e-03,  7.8800e-03,  6.0812e-03]],\n",
      "\n",
      "         [[ 3.4962e-04,  1.7009e-04,  3.0653e-04, -1.0385e-04, -4.7266e-04],\n",
      "          [ 6.9003e-04,  2.2026e-04,  3.6576e-04,  1.7290e-04, -3.5467e-04],\n",
      "          [ 4.4017e-04,  3.7308e-04,  3.1998e-04,  2.8781e-04, -2.4453e-04],\n",
      "          [ 2.4826e-04,  2.8617e-04,  3.7973e-04,  4.1041e-04,  3.3557e-05],\n",
      "          [ 1.6925e-04,  1.3931e-04,  5.9098e-04,  7.7849e-04,  2.2742e-04]],\n",
      "\n",
      "         [[ 9.2389e-03,  6.8437e-03,  4.0776e-03,  3.6154e-03, -2.5858e-04],\n",
      "          [ 1.0624e-02,  7.5486e-03,  4.5626e-03,  5.6593e-03,  3.3524e-03],\n",
      "          [ 9.0419e-03,  6.8810e-03,  6.4418e-03,  8.7208e-03,  6.6842e-03],\n",
      "          [ 5.3705e-03,  3.9772e-03,  7.2585e-03,  1.2231e-02,  9.9397e-03],\n",
      "          [ 2.3689e-04,  1.7994e-03,  6.2314e-03,  1.2965e-02,  1.1928e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.6316e-04,  1.5328e-04,  3.8111e-04,  1.0066e-03,  5.3915e-04],\n",
      "          [ 1.1011e-03,  8.4071e-04,  3.7034e-04,  8.8213e-04,  6.9323e-04],\n",
      "          [ 3.0585e-04,  8.1524e-04,  8.8906e-04,  7.0239e-04,  6.7746e-04],\n",
      "          [ 6.5848e-05,  7.6539e-05,  6.2440e-04,  6.1390e-04,  5.8984e-04],\n",
      "          [ 4.9021e-05,  5.6328e-05,  2.5818e-04,  4.6290e-04,  4.8963e-04]],\n",
      "\n",
      "         [[ 9.1052e-03,  6.7465e-03,  4.8484e-03,  4.7101e-03,  2.1913e-03],\n",
      "          [ 9.4640e-03,  7.4040e-03,  5.3827e-03,  5.9244e-03,  3.2631e-03],\n",
      "          [ 7.2557e-03,  5.7590e-03,  7.1601e-03,  9.4732e-03,  5.4638e-03],\n",
      "          [ 4.2517e-03,  3.9792e-03,  6.3670e-03,  1.0478e-02,  7.0224e-03],\n",
      "          [ 1.2529e-03,  3.2803e-03,  6.8965e-03,  1.0472e-02,  7.7557e-03]],\n",
      "\n",
      "         [[ 5.9316e-04,  3.2501e-03,  7.6117e-04, -3.6377e-04, -4.7422e-04],\n",
      "          [ 2.1705e-03,  2.0691e-03, -2.3938e-04, -8.0619e-04,  3.7801e-04],\n",
      "          [ 3.0158e-03,  7.1173e-04, -9.6979e-04, -6.2255e-04,  1.8081e-03],\n",
      "          [ 1.6004e-03, -5.4620e-04, -1.0071e-03,  7.3054e-04,  3.5197e-03],\n",
      "          [-1.3610e-05, -1.3912e-03, -7.0382e-04,  1.7960e-03,  4.3145e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.3916e-03, -2.8053e-03, -1.3870e-03, -1.6306e-03, -6.7391e-03],\n",
      "          [-2.4271e-03, -1.1561e-03, -1.1865e-03, -4.7530e-03, -1.0730e-02],\n",
      "          [-1.6914e-03, -2.2399e-03, -4.6300e-03, -1.0008e-02, -1.2987e-02],\n",
      "          [-2.5057e-03, -5.8348e-03, -1.0196e-02, -1.3480e-02, -1.0203e-02],\n",
      "          [-3.6265e-03, -8.7134e-03, -1.1625e-02, -9.6922e-03, -4.6785e-03]],\n",
      "\n",
      "         [[-1.2032e-04, -3.6832e-05, -4.3257e-05, -1.8807e-04, -2.7837e-04],\n",
      "          [-1.6415e-04, -2.0083e-04, -1.0283e-04, -1.9903e-04, -3.3471e-04],\n",
      "          [-1.9777e-04, -2.6283e-04, -2.1788e-04, -1.6141e-04, -3.6326e-04],\n",
      "          [-2.6117e-04, -4.8214e-04, -2.2452e-04, -1.6658e-04, -4.4153e-04],\n",
      "          [-1.5283e-04, -3.5387e-04, -2.4536e-04, -1.7685e-04, -3.8085e-04]],\n",
      "\n",
      "         [[-7.2159e-03, -8.0882e-03, -7.0620e-03, -5.9478e-03, -9.3560e-03],\n",
      "          [-7.2369e-03, -7.2651e-03, -6.4492e-03, -6.2725e-03, -1.2913e-02],\n",
      "          [-6.6597e-03, -6.0212e-03, -7.0699e-03, -1.0852e-02, -1.5860e-02],\n",
      "          [-6.6075e-03, -7.9135e-03, -1.1581e-02, -1.5275e-02, -1.6939e-02],\n",
      "          [-8.1247e-03, -1.0830e-02, -1.6914e-02, -1.7705e-02, -1.4059e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2247e-04, -1.4452e-04, -9.7918e-05, -4.7645e-04, -7.0010e-04],\n",
      "          [-9.4846e-05, -3.0168e-04, -5.8834e-04, -5.7777e-04, -6.6630e-04],\n",
      "          [-4.3109e-04, -8.7786e-04, -1.1250e-03, -7.8517e-04, -3.8683e-04],\n",
      "          [-7.0622e-04, -1.5537e-03, -1.3884e-03, -3.0554e-04, -3.5149e-04],\n",
      "          [-4.0150e-04, -4.3152e-04, -6.6384e-04, -2.8340e-05, -2.4565e-04]],\n",
      "\n",
      "         [[-7.1242e-03, -7.1316e-03, -5.9206e-03, -4.5673e-03, -9.4417e-03],\n",
      "          [-7.0133e-03, -5.7405e-03, -5.3710e-03, -7.4665e-03, -1.3225e-02],\n",
      "          [-5.9195e-03, -5.9203e-03, -6.8100e-03, -1.2107e-02, -1.5685e-02],\n",
      "          [-6.5522e-03, -7.8305e-03, -1.2979e-02, -1.5729e-02, -1.4326e-02],\n",
      "          [-7.9081e-03, -1.1172e-02, -1.4329e-02, -1.3994e-02, -9.5549e-03]],\n",
      "\n",
      "         [[-8.0199e-05, -9.7243e-04, -1.3774e-03, -1.3015e-03, -7.8834e-04],\n",
      "          [-7.5290e-04, -1.3606e-03, -1.3195e-03, -1.0109e-03, -3.8816e-04],\n",
      "          [-1.7268e-03, -1.4240e-03, -9.1079e-04, -1.1209e-03, -1.5526e-03],\n",
      "          [-1.2964e-03, -6.0456e-04, -6.5543e-04, -1.7050e-03, -4.3332e-03],\n",
      "          [-5.9417e-04, -2.9722e-04, -1.3455e-03, -4.0231e-03, -5.8288e-03]]]]), 'conv2.bias': tensor([ 0.0225, -0.0038, -0.0243, -0.0272,  0.0042,  0.0121,  0.0391,  0.0341,\n",
      "         0.0254,  0.0411, -0.0112,  0.0048, -0.0193,  0.0277, -0.0023,  0.0364,\n",
      "         0.0178, -0.0029,  0.0216,  0.0130, -0.0238, -0.0163,  0.0304,  0.0147,\n",
      "        -0.0131,  0.0028,  0.0267, -0.0366,  0.0076, -0.0136,  0.0478, -0.0364]), 'fc1.weight': tensor([[-6.5065e-05, -5.4734e-03, -1.4732e-02,  ..., -6.6454e-04,\n",
      "         -2.4473e-03, -1.1914e-03],\n",
      "        [-6.7459e-06, -6.7302e-03, -1.2387e-02,  ..., -8.9717e-03,\n",
      "         -4.9463e-03, -2.0775e-03],\n",
      "        [ 9.2984e-06,  1.5451e-03,  3.4383e-03,  ...,  1.2079e-03,\n",
      "          9.3183e-04,  4.1281e-04],\n",
      "        ...,\n",
      "        [ 8.0511e-06,  1.4142e-03,  3.1285e-03,  ...,  1.1344e-03,\n",
      "          8.6353e-04,  3.8049e-04],\n",
      "        [ 8.2751e-06,  1.4156e-03,  3.1464e-03,  ...,  1.1259e-03,\n",
      "          8.6023e-04,  3.7956e-04],\n",
      "        [ 8.4809e-06,  1.4754e-03,  3.2690e-03,  ...,  1.1822e-03,\n",
      "          8.9889e-04,  3.9683e-04]]), 'fc1.bias': tensor([-0.1213, -0.2908,  0.0519,  0.0498,  0.0562,  0.0513,  0.0566,  0.0482,\n",
      "         0.0479,  0.0502])}\n",
      "!-- Client 6 is normal and start iterations. ---!\n",
      "Epoch [1/3], Average Loss: 0.2523038089275360, Average Accuracy: 0.9356464147567749, Average Error: 0.0643535852432251, Culminative Time Used: 2.8487979024648666\n",
      "Epoch [2/3], Average Loss: 0.0194346476346254, Average Accuracy: 0.9966264367103577, Average Error: 0.0033735795877874, Culminative Time Used: 6.02298180013895\n",
      "Epoch [3/3], Average Loss: 0.0123042901977897, Average Accuracy: 0.9979581236839294, Average Error: 0.0020419033244252, Culminative Time Used: 9.330319102853537\n",
      "{'conv1.weight': tensor([[[[-4.7454e-04, -8.0263e-04, -2.5364e-03, -3.6484e-03, -4.2408e-03],\n",
      "          [-1.4236e-03, -2.6619e-03, -5.0463e-03, -5.8098e-03, -4.9471e-03],\n",
      "          [-3.9836e-03, -5.3378e-03, -6.6503e-03, -6.8764e-03, -4.9789e-03],\n",
      "          [-6.6691e-03, -8.1135e-03, -8.5168e-03, -7.8475e-03, -5.5822e-03],\n",
      "          [-7.2062e-03, -8.0909e-03, -8.4087e-03, -7.5124e-03, -5.7077e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.1824e-03, -1.0054e-03, -7.2334e-04, -7.9103e-04, -8.2877e-04],\n",
      "          [-4.3033e-05,  3.2189e-04,  1.0200e-03,  1.0143e-03,  6.0443e-04],\n",
      "          [ 4.4562e-06,  2.3262e-04,  8.6514e-04,  9.2319e-04,  6.6735e-04],\n",
      "          [ 4.5384e-06,  2.9155e-05,  2.9613e-04,  7.4829e-04,  9.1003e-04],\n",
      "          [ 5.9292e-06, -8.7456e-06, -4.7925e-05,  3.9135e-04,  8.4827e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 9.7726e-03,  7.4251e-03,  5.2322e-03,  3.6609e-03,  1.7605e-03],\n",
      "          [ 8.3955e-03,  5.9187e-03,  3.8835e-03,  2.2588e-03,  1.4028e-03],\n",
      "          [ 6.1718e-03,  4.9692e-03,  2.8843e-03,  1.7032e-03,  1.3825e-03],\n",
      "          [ 6.1803e-03,  4.2014e-03,  1.8615e-03,  1.6480e-03,  1.7884e-03],\n",
      "          [ 5.5800e-03,  3.9581e-03,  2.9639e-03,  2.7432e-03,  2.8832e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4785e-03,  9.7234e-04,  1.9270e-03,  3.7582e-03,  5.1089e-03],\n",
      "          [ 3.8534e-04, -1.5942e-03, -1.8357e-04,  1.5448e-03,  2.3835e-03],\n",
      "          [-6.1078e-04, -2.2302e-03, -1.1257e-04,  1.2421e-03,  1.3188e-03],\n",
      "          [ 3.1045e-04,  3.9165e-05,  1.8219e-03,  2.6327e-03,  1.9396e-03],\n",
      "          [ 1.2267e-03,  1.4428e-03,  3.1011e-03,  3.7670e-03,  2.8375e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4988e-04, -2.5757e-04, -2.8214e-04,  4.4725e-04,  8.3717e-04],\n",
      "          [-1.2041e-03, -8.9478e-04, -8.6186e-04, -3.7709e-04,  8.4988e-05],\n",
      "          [-2.1052e-03, -1.9611e-03, -1.7071e-03, -1.7291e-03, -2.1645e-03],\n",
      "          [-2.7775e-03, -2.3041e-03, -1.8421e-03, -2.7555e-03, -3.9101e-03],\n",
      "          [-2.2341e-03, -1.5642e-03, -1.3530e-03, -2.2674e-03, -3.1716e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.6551e-03,  3.3456e-03,  1.9087e-03,  2.8404e-03,  4.2374e-03],\n",
      "          [ 2.8333e-03,  3.2181e-03,  3.3907e-03,  4.7519e-03,  5.7203e-03],\n",
      "          [ 1.5573e-03,  3.2020e-03,  5.0317e-03,  5.7373e-03,  5.7308e-03],\n",
      "          [ 1.3347e-03,  4.3944e-03,  7.1012e-03,  7.4943e-03,  6.3993e-03],\n",
      "          [ 2.1590e-03,  5.6018e-03,  7.6873e-03,  7.5243e-03,  5.9540e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.1496e-05,  2.9203e-04,  8.3395e-04,  1.8842e-03,  2.1023e-03],\n",
      "          [ 1.2903e-03,  1.4843e-03,  2.0297e-03,  2.4748e-03,  2.1624e-03],\n",
      "          [ 1.1876e-03,  1.4368e-03,  1.6202e-03,  9.5365e-04, -4.3596e-05],\n",
      "          [ 4.0101e-05,  6.6416e-04,  9.0462e-04, -7.0741e-05, -1.7749e-03],\n",
      "          [-9.5482e-04, -1.2817e-04,  5.9068e-04, -5.5454e-05, -1.8184e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.9236e-03, -1.9717e-03, -1.6468e-03, -5.5263e-04,  5.6295e-04],\n",
      "          [-7.2753e-04, -6.4011e-04, -5.6342e-04, -6.5259e-05,  4.8565e-04],\n",
      "          [-4.6406e-04, -4.1591e-04,  3.4180e-04,  5.3318e-04, -5.4554e-04],\n",
      "          [ 7.3553e-04,  1.1753e-03,  9.1208e-04, -5.4525e-04, -1.7788e-03],\n",
      "          [ 1.7415e-03,  1.8579e-03,  8.4734e-04, -9.5621e-04, -1.7535e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7448e-03,  2.5385e-03,  2.8604e-03,  4.1508e-03,  7.0317e-03],\n",
      "          [ 2.1998e-03,  2.0354e-03,  2.5155e-03,  3.7624e-03,  7.2382e-03],\n",
      "          [ 8.0647e-04,  9.7617e-04,  1.3142e-03,  3.3062e-03,  6.1974e-03],\n",
      "          [ 1.1324e-04,  8.3395e-04,  1.3979e-03,  3.5829e-03,  5.3954e-03],\n",
      "          [-4.4659e-04,  1.2041e-04,  1.0587e-03,  3.0670e-03,  4.6261e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.8399e-03,  2.6878e-03,  1.4403e-03,  1.0730e-03,  3.6151e-04],\n",
      "          [ 1.9533e-03,  9.3065e-04,  8.7894e-04,  7.6326e-04,  5.0213e-04],\n",
      "          [ 2.3620e-04,  2.4761e-04,  4.0158e-04,  3.0758e-04,  6.6099e-04],\n",
      "          [ 6.2830e-05,  1.4384e-04,  1.6152e-04,  3.2519e-04,  1.2519e-03],\n",
      "          [-3.7945e-04, -1.1544e-04,  3.1476e-04,  1.4156e-03,  2.3349e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.4612e-03, -6.5033e-03, -5.0929e-03, -2.9368e-03, -2.1132e-03],\n",
      "          [-9.0280e-03, -8.3489e-03, -5.4039e-03, -2.9101e-03, -1.9258e-03],\n",
      "          [-9.8626e-03, -8.0262e-03, -3.9019e-03, -2.3382e-03, -1.5111e-03],\n",
      "          [-6.9974e-03, -4.7333e-03, -2.7587e-03, -2.3236e-03, -3.2265e-03],\n",
      "          [-3.2981e-03, -2.9669e-03, -2.7074e-03, -2.9112e-03, -6.4906e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.0843e-02, -1.3140e-02, -1.4349e-02, -1.4106e-02, -1.1782e-02],\n",
      "          [-6.9038e-03, -8.8407e-03, -1.0837e-02, -1.1654e-02, -1.1089e-02],\n",
      "          [-2.7624e-03, -1.9149e-03, -2.6008e-03, -5.1299e-03, -7.0957e-03],\n",
      "          [-5.4248e-04, -8.7248e-05, -2.6812e-04, -1.4197e-03, -3.4147e-03],\n",
      "          [-4.1287e-04, -1.7836e-04, -4.7531e-04, -1.1980e-03, -2.2209e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.9257e-04, -1.1577e-03, -1.9425e-03, -2.0741e-03, -1.9057e-03],\n",
      "          [ 1.3328e-03,  1.0344e-03, -2.9888e-04, -1.6151e-03, -2.7864e-03],\n",
      "          [ 5.4081e-05,  2.2952e-04, -7.6614e-04, -3.2153e-03, -4.0350e-03],\n",
      "          [-1.8783e-03, -2.2590e-03, -2.3928e-03, -2.4129e-03, -2.1507e-03],\n",
      "          [-2.9718e-03, -3.5608e-03, -4.3189e-03, -4.1772e-03, -2.8229e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8073e-05, -1.1693e-04, -2.1696e-04, -7.9776e-05,  2.2820e-04],\n",
      "          [ 7.6043e-04,  5.0165e-04,  2.9194e-04,  4.4642e-04,  7.6790e-04],\n",
      "          [ 1.6634e-03,  1.5599e-03,  1.5496e-03,  1.4562e-03,  1.5525e-03],\n",
      "          [ 1.5057e-03,  1.5812e-03,  2.2305e-03,  2.6733e-03,  2.4406e-03],\n",
      "          [ 5.7215e-04,  9.8972e-04,  2.5238e-03,  3.5575e-03,  3.3108e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.7996e-03, -8.0350e-03, -8.1289e-03, -1.1633e-02, -1.5366e-02],\n",
      "          [-9.9934e-03, -9.1100e-03, -1.0273e-02, -1.4768e-02, -1.7919e-02],\n",
      "          [-1.3611e-02, -1.4756e-02, -1.5003e-02, -1.6445e-02, -1.6299e-02],\n",
      "          [-1.3497e-02, -1.5854e-02, -1.6744e-02, -1.4960e-02, -1.2019e-02],\n",
      "          [-1.0465e-02, -1.3581e-02, -1.3150e-02, -1.0548e-02, -7.8206e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.7637e-04,  3.0920e-04,  1.5293e-03,  1.8849e-03,  1.4320e-03],\n",
      "          [-5.3224e-04,  5.6739e-04,  1.3948e-03,  1.1825e-03,  9.7750e-04],\n",
      "          [-9.8331e-04, -1.7948e-04,  1.1555e-04,  4.2433e-05, -4.1466e-05],\n",
      "          [-1.1773e-03, -8.8439e-04, -4.4014e-04, -3.9940e-04, -2.2789e-04],\n",
      "          [-3.3737e-04, -2.6593e-04,  3.3224e-04,  5.4586e-04,  7.7158e-04]]]]), 'conv1.bias': tensor([-0.0071, -0.0005,  0.0144,  0.0330, -0.0041,  0.0083, -0.0002,  0.0171,\n",
      "         0.0089,  0.0041, -0.0266, -0.0165, -0.0027,  0.0043, -0.0298, -0.0005]), 'conv2.weight': tensor([[[[-2.4251e-03,  1.6436e-03,  3.3604e-03,  3.3976e-03,  1.7947e-03],\n",
      "          [ 1.1842e-03,  4.2943e-03,  4.4966e-03,  4.0781e-03,  1.9102e-03],\n",
      "          [ 1.3502e-03,  3.6087e-03,  4.6484e-03,  4.3792e-03,  1.4602e-03],\n",
      "          [ 4.4716e-04,  2.8454e-03,  3.6819e-03,  3.0473e-03,  9.6041e-04],\n",
      "          [-7.0615e-04,  9.7645e-04,  1.3681e-03,  6.8518e-04,  9.5206e-04]],\n",
      "\n",
      "         [[-3.0126e-05,  7.4763e-05,  3.1967e-05, -7.0208e-07, -3.0361e-04],\n",
      "          [ 3.6746e-05,  1.8316e-04,  5.6371e-05,  7.0499e-05, -3.9042e-05],\n",
      "          [ 1.6470e-04,  3.9700e-04,  1.5982e-04,  7.6371e-05, -9.7665e-05],\n",
      "          [ 2.5077e-04,  5.4128e-04,  4.5495e-04,  4.5652e-05, -2.2710e-04],\n",
      "          [ 1.4117e-04,  2.8674e-04,  5.1171e-04,  3.2063e-07, -1.8138e-04]],\n",
      "\n",
      "         [[-4.9712e-03, -3.5748e-03,  1.9545e-04,  2.1421e-03,  2.8778e-03],\n",
      "          [-3.7333e-03, -1.6334e-03,  1.3367e-03,  3.1240e-03,  2.2828e-03],\n",
      "          [-2.2814e-03,  8.1612e-04,  3.5150e-03,  4.8995e-03,  2.9854e-03],\n",
      "          [-1.3125e-03,  8.9270e-04,  5.1295e-03,  6.3455e-03,  3.5288e-03],\n",
      "          [-7.5874e-04,  5.0588e-04,  3.9057e-03,  5.2855e-03,  4.5346e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7620e-04, -3.5546e-04,  1.6535e-04,  2.0271e-04,  6.9057e-05],\n",
      "          [ 1.0268e-04,  3.1260e-04,  5.1161e-04,  2.0554e-04, -4.5440e-05],\n",
      "          [-5.5084e-05,  3.6643e-04,  4.6365e-04,  1.8809e-04,  1.0586e-04],\n",
      "          [-2.6402e-04,  7.5110e-05,  4.1389e-04,  2.5588e-04,  4.1576e-05],\n",
      "          [-3.1060e-04, -4.4958e-04, -8.4624e-05,  1.9307e-04,  1.1307e-04]],\n",
      "\n",
      "         [[-3.0018e-03, -2.0239e-03, -1.8457e-04,  9.8631e-04,  1.5517e-03],\n",
      "          [-2.0859e-03, -6.0452e-04,  6.3668e-04,  2.0866e-03,  1.2476e-03],\n",
      "          [-1.6638e-03, -5.4283e-04,  1.7983e-03,  3.3005e-03,  1.3192e-03],\n",
      "          [-4.4749e-04, -8.2193e-05,  2.2273e-03,  2.6346e-03,  1.5577e-03],\n",
      "          [-4.2368e-04, -2.3922e-04,  5.8193e-04,  1.6568e-03,  2.6383e-03]],\n",
      "\n",
      "         [[ 1.5372e-04, -9.9388e-04, -2.8076e-04,  1.2489e-03,  1.1006e-03],\n",
      "          [ 5.2024e-05, -1.0506e-03,  2.3179e-04,  1.3377e-03,  9.9275e-04],\n",
      "          [-2.2284e-05, -6.3255e-04,  4.8041e-04,  1.4759e-03,  1.7573e-03],\n",
      "          [-4.8072e-04, -1.0351e-03,  6.4581e-06,  1.8047e-03,  2.6330e-03],\n",
      "          [-8.2079e-04, -1.0097e-03, -4.1655e-04,  9.7509e-04,  1.2128e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6370e-03, -2.4015e-03, -4.4890e-03, -7.9642e-04, -2.9881e-03],\n",
      "          [ 3.2206e-03, -2.9159e-03, -1.9103e-03, -2.3340e-03, -5.7029e-03],\n",
      "          [ 1.3886e-03, -3.2737e-03, -1.7528e-03, -4.1601e-03, -6.9776e-03],\n",
      "          [-5.7018e-04, -3.3048e-03, -3.5186e-03, -5.3824e-03, -6.7548e-03],\n",
      "          [-2.5050e-03, -2.3850e-03, -2.8216e-03, -4.3512e-03, -6.0620e-03]],\n",
      "\n",
      "         [[-3.1450e-04, -6.8376e-04, -1.9073e-04,  5.3923e-05,  1.0118e-04],\n",
      "          [-5.3577e-04, -1.0326e-03, -4.4457e-04,  4.1712e-06,  3.8133e-05],\n",
      "          [-6.2546e-04, -9.8852e-04, -4.4385e-04, -1.0221e-04, -2.2780e-04],\n",
      "          [-4.8465e-04, -4.8809e-04, -1.5431e-04, -8.4832e-05, -2.1599e-05],\n",
      "          [-5.4213e-04, -1.9839e-04, -1.3920e-05,  1.9959e-04,  1.3384e-04]],\n",
      "\n",
      "         [[ 4.0866e-03, -7.4040e-04, -3.9423e-03, -2.3449e-03, -2.2862e-03],\n",
      "          [ 5.1521e-03, -5.1700e-04, -3.4465e-03, -3.0225e-03, -3.9962e-03],\n",
      "          [ 4.1198e-03, -1.1118e-03, -4.1199e-03, -4.9694e-03, -6.1054e-03],\n",
      "          [ 1.6124e-03, -2.6455e-03, -5.0345e-03, -6.0500e-03, -8.0736e-03],\n",
      "          [ 4.6904e-04, -4.0971e-03, -5.8091e-03, -6.1211e-03, -8.6497e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1093e-04,  5.0832e-05, -6.3889e-05, -1.4153e-05, -4.5073e-04],\n",
      "          [-2.4898e-04, -4.1303e-04, -1.9018e-04,  2.6157e-04, -6.5945e-04],\n",
      "          [-4.7388e-04, -6.4268e-04, -5.1287e-04, -4.0670e-04, -7.9734e-04],\n",
      "          [-5.0136e-04, -4.2664e-04, -2.2123e-04, -3.5642e-04, -7.1487e-04],\n",
      "          [-3.2759e-04, -7.2425e-05,  2.8195e-05, -4.1492e-04, -8.4488e-04]],\n",
      "\n",
      "         [[ 4.2448e-03,  1.0887e-03, -2.9440e-04,  5.1994e-04, -6.1450e-04],\n",
      "          [ 3.9704e-03, -2.4799e-04, -7.0865e-04, -2.4128e-03, -3.1203e-03],\n",
      "          [ 1.2307e-03, -1.4793e-03, -3.2418e-03, -5.2639e-03, -5.5804e-03],\n",
      "          [ 9.4726e-04, -1.4220e-03, -3.4398e-03, -3.9509e-03, -5.6321e-03],\n",
      "          [-8.4119e-05, -2.9721e-03, -3.9176e-03, -4.9208e-03, -6.7693e-03]],\n",
      "\n",
      "         [[ 7.1648e-04,  9.0233e-04, -2.0123e-03, -3.9474e-03, -1.0391e-03],\n",
      "          [ 8.3437e-04,  1.3899e-03, -2.0245e-03, -2.2014e-03, -3.6905e-04],\n",
      "          [ 1.7104e-03,  9.7418e-04, -1.3034e-03, -4.4698e-04,  6.8955e-04],\n",
      "          [ 2.4984e-03,  1.2800e-04, -9.7624e-04, -4.7705e-04,  5.4860e-04],\n",
      "          [ 3.4883e-03,  4.3949e-04, -5.6857e-04,  2.5633e-04,  2.0602e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 7.8633e-03,  6.0086e-03,  7.7593e-03,  8.9797e-03,  8.6744e-03],\n",
      "          [ 5.9463e-03,  6.8280e-03,  7.4969e-03,  7.5113e-03,  6.1222e-03],\n",
      "          [ 2.9513e-03,  3.6864e-03,  3.0175e-03,  3.4315e-03,  4.0342e-03],\n",
      "          [ 5.9963e-04,  1.5938e-04, -8.1304e-04,  7.0984e-05,  3.9513e-03],\n",
      "          [ 6.1038e-04, -7.7027e-04, -9.9814e-04,  2.3960e-03,  5.4864e-03]],\n",
      "\n",
      "         [[ 4.4151e-04,  4.8191e-05, -2.2235e-05,  1.7684e-04,  1.1866e-04],\n",
      "          [ 5.2757e-04,  1.2840e-04,  2.0909e-05,  2.5351e-04,  3.4654e-04],\n",
      "          [ 6.2476e-04,  3.1417e-04,  5.4842e-05,  2.8982e-04,  6.8022e-04],\n",
      "          [ 2.2628e-04,  1.6215e-04, -1.7795e-05,  1.4612e-04,  5.2622e-04],\n",
      "          [-1.5145e-04, -3.7022e-05,  9.8947e-05,  5.7173e-05,  2.0635e-04]],\n",
      "\n",
      "         [[ 1.0300e-02,  8.5920e-03,  6.7042e-03,  8.8740e-03,  1.3992e-02],\n",
      "          [ 1.2347e-02,  1.4247e-02,  1.3657e-02,  1.3328e-02,  1.5742e-02],\n",
      "          [ 1.1589e-02,  1.3453e-02,  1.4076e-02,  1.2665e-02,  1.2870e-02],\n",
      "          [ 7.1654e-03,  9.1381e-03,  8.6855e-03,  7.2763e-03,  8.6423e-03],\n",
      "          [ 3.1271e-03,  2.9961e-03,  2.5604e-03,  3.5154e-03,  6.4283e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.5855e-03,  1.5611e-03,  7.4882e-04,  1.1368e-03,  1.3146e-03],\n",
      "          [ 6.2572e-04,  8.5643e-04,  3.0935e-04,  3.0057e-04,  1.0108e-03],\n",
      "          [ 1.3126e-04, -1.0551e-04, -1.6880e-04, -1.8213e-04,  2.9781e-04],\n",
      "          [-1.0089e-04, -1.0238e-04, -3.1989e-04, -3.4171e-04,  3.7807e-05],\n",
      "          [ 2.2140e-04,  1.8304e-05,  3.6333e-04,  2.6995e-04,  2.1830e-04]],\n",
      "\n",
      "         [[ 6.9909e-03,  8.1290e-03,  9.3324e-03,  1.0539e-02,  1.3508e-02],\n",
      "          [ 8.5239e-03,  1.0852e-02,  1.2328e-02,  1.2263e-02,  1.1422e-02],\n",
      "          [ 8.5308e-03,  1.0323e-02,  1.0719e-02,  1.0164e-02,  9.8523e-03],\n",
      "          [ 5.3975e-03,  6.1055e-03,  5.5894e-03,  5.7121e-03,  8.0183e-03],\n",
      "          [ 2.3990e-03,  2.2376e-03,  2.2355e-03,  4.5834e-03,  6.9896e-03]],\n",
      "\n",
      "         [[ 3.8597e-03,  2.6777e-03,  1.0839e-04, -9.3077e-04,  8.4014e-04],\n",
      "          [ 2.6363e-03,  1.4751e-03,  1.2182e-03,  6.0763e-04,  2.7887e-03],\n",
      "          [ 3.9161e-04,  7.4631e-04,  1.6066e-03,  1.7245e-03,  2.6948e-03],\n",
      "          [-9.3234e-04,  4.6939e-04,  1.3072e-03,  1.7386e-03,  1.4947e-03],\n",
      "          [-5.9971e-04,  5.3768e-04,  3.0906e-04,  3.6667e-04,  7.0982e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.0328e-03,  1.1238e-03,  4.8400e-05,  7.7798e-05,  1.8916e-04],\n",
      "          [-8.8971e-05,  1.5014e-04, -5.1349e-05,  4.4685e-05,  1.1694e-04],\n",
      "          [-7.9860e-04, -9.0663e-05, -2.1108e-05,  2.4216e-07,  3.6758e-05],\n",
      "          [-3.1327e-04,  4.6479e-05,  1.4737e-05, -1.5245e-06, -3.2880e-07],\n",
      "          [-6.2234e-05, -6.5155e-05, -8.2370e-05, -7.4658e-06, -1.3140e-06]],\n",
      "\n",
      "         [[-2.0675e-05, -9.3527e-06, -1.5772e-06,  1.0357e-05,  4.3603e-05],\n",
      "          [ 1.0072e-04,  2.5153e-05, -1.7201e-08,  3.5482e-06,  5.1134e-05],\n",
      "          [ 2.5065e-04,  4.7229e-05,  5.0095e-07,  5.9025e-08,  1.6820e-05],\n",
      "          [ 6.0703e-05, -5.3118e-06, -1.3309e-06,  3.3981e-08, -2.4345e-07],\n",
      "          [-7.8731e-06, -1.0672e-05, -4.9219e-06,  1.6755e-08,  4.7332e-09]],\n",
      "\n",
      "         [[ 3.7487e-05,  3.4265e-04, -2.1742e-04, -6.7865e-05,  1.9787e-04],\n",
      "          [ 9.0792e-04,  9.2292e-04,  3.4590e-04,  2.1317e-04,  1.5365e-04],\n",
      "          [-2.9062e-04,  2.6968e-04,  1.0496e-04,  1.3310e-04,  1.0151e-04],\n",
      "          [-1.0755e-03, -3.3352e-04, -1.6462e-04,  1.0929e-05,  7.6426e-08],\n",
      "          [-1.1787e-03, -5.5263e-04, -2.3067e-04, -1.0090e-04, -1.0375e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.6236e-05,  1.8402e-05, -3.2763e-07, -1.7408e-07,  2.5935e-05],\n",
      "          [ 1.8681e-05,  9.8423e-06,  4.9209e-06, -3.2796e-07,  1.0092e-05],\n",
      "          [-9.4099e-06, -9.3578e-05, -2.2939e-05,  1.5662e-06,  1.4512e-07],\n",
      "          [-1.8259e-05, -1.9985e-05, -1.3666e-05,  5.6934e-07,  1.5152e-06],\n",
      "          [-1.9376e-05, -1.0804e-05, -8.6439e-06,  3.4046e-06,  1.1731e-06]],\n",
      "\n",
      "         [[ 3.2065e-04,  2.9299e-04, -3.7696e-04, -1.5185e-04,  9.0219e-05],\n",
      "          [ 2.4500e-04, -9.9415e-05,  1.6367e-05,  2.1796e-04,  1.0316e-04],\n",
      "          [-5.9929e-04, -2.1043e-04, -5.7108e-06,  1.4639e-04,  8.8822e-05],\n",
      "          [-5.8478e-04, -2.8292e-04, -9.9236e-05,  2.8529e-05, -4.6354e-06],\n",
      "          [-6.7023e-04, -5.0681e-04, -2.2547e-04, -9.9199e-05, -1.4623e-04]],\n",
      "\n",
      "         [[-2.8943e-05,  5.9172e-04,  6.9926e-04,  6.3419e-06,  4.9124e-07],\n",
      "          [-2.0592e-04,  8.2449e-04,  4.7722e-04, -9.3027e-07,  5.4683e-06],\n",
      "          [-5.4572e-04,  2.9489e-04,  2.8588e-05, -1.0286e-05,  2.2762e-06],\n",
      "          [-9.8296e-04, -7.9871e-05, -1.7783e-05, -2.0100e-05,  4.7916e-08],\n",
      "          [-1.1267e-03, -6.7798e-05, -3.8855e-05, -3.1251e-05, -6.0892e-07]]],\n",
      "\n",
      "\n",
      "        [[[-9.1663e-03, -5.6601e-03, -4.1567e-03, -1.1723e-03,  2.3237e-03],\n",
      "          [-1.2988e-02, -9.1602e-03, -6.4185e-03, -1.6645e-03,  4.1566e-04],\n",
      "          [-1.1992e-02, -8.9883e-03, -5.2164e-03, -2.4954e-03, -1.5684e-03],\n",
      "          [-6.4591e-03, -4.9316e-03, -3.4566e-03, -2.1588e-03, -2.7442e-03],\n",
      "          [-4.0869e-03, -4.8880e-03, -4.5091e-03, -3.2907e-03, -3.8596e-03]],\n",
      "\n",
      "         [[-3.6385e-04, -1.6944e-04, -2.7961e-04, -2.1604e-04, -3.0082e-04],\n",
      "          [-5.3542e-04, -1.6490e-04, -1.8093e-05, -2.1233e-04, -3.4179e-04],\n",
      "          [-3.0332e-04, -3.1728e-04,  9.2435e-05,  1.8625e-04, -3.1665e-05],\n",
      "          [-2.2007e-04, -2.9853e-04,  1.6436e-04,  4.4372e-04,  3.8567e-04],\n",
      "          [-2.8883e-04, -1.7709e-04,  1.3331e-04,  5.9871e-04,  3.9435e-04]],\n",
      "\n",
      "         [[-1.0343e-02, -9.1803e-03, -7.4834e-03, -5.9558e-03, -3.3294e-03],\n",
      "          [-1.4318e-02, -1.4038e-02, -1.0780e-02, -7.3334e-03, -5.0531e-03],\n",
      "          [-1.9686e-02, -1.8264e-02, -1.4483e-02, -8.4946e-03, -6.7761e-03],\n",
      "          [-2.0706e-02, -1.7400e-02, -1.5556e-02, -1.2060e-02, -8.8158e-03],\n",
      "          [-1.6551e-02, -1.5714e-02, -1.4255e-02, -1.2976e-02, -9.9065e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.9527e-04, -5.9705e-04, -6.8261e-04, -1.1804e-03, -1.3755e-03],\n",
      "          [-1.7616e-03, -1.3509e-03, -5.8229e-04, -1.0469e-03, -1.3251e-03],\n",
      "          [-1.0257e-03, -1.5202e-03, -1.2228e-03, -7.0266e-04, -7.7786e-04],\n",
      "          [-3.9155e-04, -7.1347e-04, -9.6654e-04, -6.4433e-04, -3.4767e-04],\n",
      "          [-4.2819e-04, -4.9945e-04, -3.8199e-04, -1.4571e-04, -1.9890e-04]],\n",
      "\n",
      "         [[-1.0256e-02, -9.3097e-03, -8.2170e-03, -6.0937e-03, -3.5294e-03],\n",
      "          [-1.3996e-02, -1.4299e-02, -1.0880e-02, -6.5664e-03, -5.6065e-03],\n",
      "          [-1.6940e-02, -1.4555e-02, -1.2353e-02, -9.6976e-03, -8.2723e-03],\n",
      "          [-1.5059e-02, -1.2976e-02, -1.1340e-02, -1.0590e-02, -9.4055e-03],\n",
      "          [-1.2538e-02, -1.3605e-02, -1.2053e-02, -1.2193e-02, -1.0471e-02]],\n",
      "\n",
      "         [[-3.3348e-03, -3.1601e-03, -1.4152e-03, -9.3931e-06,  1.7271e-03],\n",
      "          [-4.6206e-03, -2.3787e-03, -1.5437e-03, -4.8932e-04,  1.6036e-03],\n",
      "          [-4.5345e-03, -3.0259e-03, -2.1596e-03, -5.5652e-04,  1.0878e-03],\n",
      "          [-5.0102e-03, -3.4737e-03, -1.6555e-03, -7.5676e-04, -1.2534e-04],\n",
      "          [-4.2829e-03, -2.2867e-03, -1.3781e-03, -1.5618e-03, -1.4764e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.9829e-04,  2.1012e-04,  6.4210e-04,  7.6037e-04,  2.8761e-03],\n",
      "          [-8.9284e-04,  1.2261e-04,  1.0906e-04,  1.3317e-03,  5.2435e-03],\n",
      "          [-1.0439e-03, -1.5564e-03, -1.5470e-03,  1.9199e-03,  4.6348e-03],\n",
      "          [-2.7503e-03, -4.7645e-03, -3.4321e-03,  5.3089e-04,  1.6942e-03],\n",
      "          [-3.4553e-03, -3.8360e-03, -3.1267e-05,  2.1366e-03, -4.5225e-04]],\n",
      "\n",
      "         [[ 2.1075e-04,  6.0080e-05, -2.0706e-05,  1.4670e-05,  8.9898e-05],\n",
      "          [ 8.3182e-05,  1.0252e-04,  3.8391e-05,  3.6334e-05,  6.2689e-05],\n",
      "          [ 5.2561e-05,  2.4185e-05,  4.5573e-05,  5.7916e-06,  1.0487e-04],\n",
      "          [-5.6227e-05, -8.6355e-05,  2.8230e-05,  6.3664e-05,  1.7882e-04],\n",
      "          [ 2.0004e-05, -5.5413e-05, -8.0588e-05,  3.2591e-05,  1.7654e-04]],\n",
      "\n",
      "         [[ 1.2571e-03,  2.2145e-03,  3.0555e-03,  2.3446e-03,  3.4728e-03],\n",
      "          [-1.6923e-04,  9.5137e-04,  2.2670e-03,  1.8947e-03,  5.1181e-03],\n",
      "          [-1.1793e-03, -1.0764e-03, -1.2418e-04,  2.2774e-03,  5.0966e-03],\n",
      "          [-2.0194e-03, -3.0549e-03, -2.5062e-03,  9.8425e-04,  1.6245e-03],\n",
      "          [-4.2280e-03, -5.3766e-03, -3.4713e-03, -2.1396e-03, -1.9128e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.0328e-05,  8.6715e-05, -3.8320e-06, -1.8899e-05,  2.8018e-04],\n",
      "          [-8.5154e-06, -3.5689e-05, -1.5833e-05,  1.3391e-04,  1.6122e-04],\n",
      "          [-2.6345e-04, -4.3876e-04, -1.2760e-04, -1.2252e-04, -2.6996e-05],\n",
      "          [-2.5286e-04, -8.1480e-04, -1.0625e-03, -5.8588e-04, -4.6371e-04],\n",
      "          [ 2.5254e-04, -2.3115e-07, -5.8389e-04, -4.1800e-04, -1.4453e-04]],\n",
      "\n",
      "         [[ 8.5554e-05,  1.0578e-03,  2.4199e-03,  1.4164e-03,  3.5347e-03],\n",
      "          [-5.6852e-04,  2.7928e-04,  1.3469e-03,  1.9232e-03,  5.3361e-03],\n",
      "          [-2.5039e-04, -5.0957e-04,  3.0598e-04,  3.3625e-03,  4.2016e-03],\n",
      "          [-2.6677e-03, -3.4594e-03, -2.1824e-03,  1.4378e-04, -2.3820e-04],\n",
      "          [-4.3557e-03, -4.1001e-03, -1.2631e-04, -3.5051e-05, -1.8906e-03]],\n",
      "\n",
      "         [[-5.6374e-04, -4.4122e-04,  2.1396e-05,  8.0063e-04,  7.1111e-04],\n",
      "          [-6.7978e-04, -4.8662e-04,  1.8791e-04,  5.7630e-04,  1.4579e-04],\n",
      "          [-1.6494e-03, -8.3875e-04, -4.0326e-04, -2.3812e-04,  3.3671e-04],\n",
      "          [-7.6001e-04,  2.9106e-05, -8.1160e-05, -5.8759e-05,  1.4249e-03],\n",
      "          [-1.6304e-04, -6.8086e-05, -2.4815e-04,  2.1797e-06,  1.1798e-03]]]]), 'conv2.bias': tensor([-0.0147, -0.0022,  0.0306,  0.0272, -0.0197,  0.0478,  0.0092, -0.0424,\n",
      "         0.0107,  0.0058, -0.0051, -0.0020, -0.0137, -0.0198, -0.0475,  0.0204,\n",
      "        -0.0056, -0.0216,  0.0231, -0.0050, -0.0623, -0.0267,  0.0040, -0.0252,\n",
      "        -0.0017,  0.0073, -0.0369,  0.0088,  0.0003, -0.0015, -0.0432,  0.0086]), 'fc1.weight': tensor([[ 0.0002,  0.0024,  0.0047,  ...,  0.0009,  0.0010,  0.0004],\n",
      "        [ 0.0002,  0.0025,  0.0050,  ...,  0.0009,  0.0010,  0.0004],\n",
      "        [ 0.0002,  0.0027,  0.0053,  ...,  0.0010,  0.0011,  0.0004],\n",
      "        ...,\n",
      "        [-0.0014, -0.0144, -0.0220,  ..., -0.0038, -0.0038, -0.0015],\n",
      "        [ 0.0002,  0.0025,  0.0050,  ...,  0.0009,  0.0010,  0.0004],\n",
      "        [ 0.0002,  0.0026,  0.0050,  ...,  0.0009,  0.0010,  0.0004]]), 'fc1.bias': tensor([ 0.0461,  0.0482,  0.0519,  0.0496,  0.0569,  0.0507, -0.2016, -0.1992,\n",
      "         0.0482,  0.0491])}\n",
      "!-- Client 1 is normal and start iterations. ---!\n",
      "Epoch [1/3], Average Loss: 0.3544547259807587, Average Accuracy: 0.8722518086433411, Average Error: 0.1277481615543365, Culminative Time Used: 1.7587921023368835\n",
      "Epoch [2/3], Average Loss: 0.0814418569207191, Average Accuracy: 0.9814062714576721, Average Error: 0.0185937508940697, Culminative Time Used: 3.6912903003394604\n",
      "Epoch [3/3], Average Loss: 0.0392558649182320, Average Accuracy: 0.9902328252792358, Average Error: 0.0097671570256352, Culminative Time Used: 5.381122499704361\n",
      "{'conv1.weight': tensor([[[[ 3.9001e-03,  4.7341e-03,  4.8857e-03,  2.8732e-03, -1.8228e-04],\n",
      "          [ 3.1162e-03,  3.9082e-03,  4.8750e-03,  4.0133e-03,  1.1903e-03],\n",
      "          [ 1.0865e-03,  2.1770e-03,  3.2462e-03,  2.4393e-03,  2.6250e-04],\n",
      "          [-2.3725e-03, -9.9364e-04, -3.1837e-04, -9.3151e-04, -2.9352e-03],\n",
      "          [-5.6302e-03, -3.6059e-03, -2.2015e-03, -2.9181e-03, -5.1089e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5310e-04, -3.9962e-05, -1.8469e-04,  1.4499e-04,  1.5312e-05],\n",
      "          [-5.5252e-05, -4.7805e-04, -6.8099e-04, -2.7903e-04, -8.2225e-05],\n",
      "          [-6.7233e-05, -3.7221e-04, -7.5228e-04, -3.5014e-04,  3.5550e-05],\n",
      "          [-6.7301e-05, -1.0449e-04, -3.5180e-04,  3.0122e-04,  8.6330e-04],\n",
      "          [ 9.3113e-06, -9.7224e-06,  6.8297e-05,  8.4628e-04,  1.2763e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6506e-02,  1.4501e-02,  1.2084e-02,  1.0727e-02,  8.1583e-03],\n",
      "          [ 1.4077e-02,  1.1740e-02,  9.6247e-03,  7.9974e-03,  6.3595e-03],\n",
      "          [ 1.1678e-02,  1.0349e-02,  7.8781e-03,  5.8258e-03,  4.8191e-03],\n",
      "          [ 1.1957e-02,  9.7514e-03,  7.3500e-03,  7.1055e-03,  6.3785e-03],\n",
      "          [ 9.5011e-03,  8.7766e-03,  9.1608e-03,  8.7268e-03,  7.3564e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.9301e-03,  7.5857e-03,  7.4943e-03,  9.5563e-03,  1.0246e-02],\n",
      "          [ 1.0383e-02,  9.3957e-03,  1.1551e-02,  1.3264e-02,  1.1763e-02],\n",
      "          [ 1.2358e-02,  1.2147e-02,  1.4308e-02,  1.4399e-02,  1.1990e-02],\n",
      "          [ 1.2479e-02,  1.3054e-02,  1.2817e-02,  1.1383e-02,  9.5291e-03],\n",
      "          [ 1.1624e-02,  1.1038e-02,  9.2323e-03,  8.1252e-03,  7.4630e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.6034e-03, -1.8893e-03, -1.8592e-03, -2.2417e-03, -1.9621e-03],\n",
      "          [-1.5001e-03, -1.2629e-03, -1.8978e-03, -4.3725e-03, -5.0808e-03],\n",
      "          [ 3.3837e-04, -7.4299e-05, -8.5873e-04, -3.6829e-03, -5.3082e-03],\n",
      "          [ 3.5000e-03,  1.9368e-03,  8.7289e-04, -1.7760e-03, -3.6003e-03],\n",
      "          [ 5.1476e-03,  3.9620e-03,  1.7150e-03, -1.2885e-03, -2.8337e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.7817e-03, -5.5999e-03, -4.1940e-03, -3.3700e-03, -2.6652e-03],\n",
      "          [-6.2944e-03, -6.2877e-03, -6.1273e-03, -5.7175e-03, -5.1102e-03],\n",
      "          [-3.5917e-03, -3.9516e-03, -4.4755e-03, -4.0342e-03, -3.4482e-03],\n",
      "          [-3.2154e-04, -1.6618e-03, -2.9112e-03, -2.6478e-03, -1.8703e-03],\n",
      "          [-3.3589e-04, -2.6040e-03, -3.3336e-03, -2.1463e-03, -5.0967e-04]]],\n",
      "\n",
      "\n",
      "        [[[-8.0903e-03, -7.6593e-03, -7.6719e-03, -6.7648e-03, -3.9172e-03],\n",
      "          [-6.8374e-03, -7.2431e-03, -8.2760e-03, -7.9877e-03, -4.7860e-03],\n",
      "          [-7.6331e-03, -8.0218e-03, -8.9979e-03, -8.8904e-03, -5.9036e-03],\n",
      "          [-6.9132e-03, -7.2087e-03, -7.9078e-03, -7.7108e-03, -5.2197e-03],\n",
      "          [-6.5307e-03, -6.5747e-03, -5.9732e-03, -5.2397e-03, -3.5174e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.1160e-03, -1.0738e-03,  2.3498e-03,  5.0579e-03,  7.0835e-03],\n",
      "          [-6.7686e-03, -1.6870e-03,  1.0289e-03,  2.6203e-03,  5.6468e-03],\n",
      "          [-7.9863e-03, -4.2998e-03, -1.9201e-03,  6.2219e-04,  5.6796e-03],\n",
      "          [-8.0163e-03, -5.9156e-03, -2.2312e-03,  1.7079e-03,  6.2309e-03],\n",
      "          [-6.5297e-03, -4.6052e-03, -9.0858e-04,  3.1163e-03,  6.8832e-03]]],\n",
      "\n",
      "\n",
      "        [[[-8.6381e-04, -1.0773e-03, -1.0572e-03, -1.9345e-03, -4.2903e-03],\n",
      "          [ 3.4493e-04, -4.5616e-04, -6.6618e-04, -1.1370e-03, -3.2722e-03],\n",
      "          [ 1.6161e-03,  9.0900e-04,  3.3040e-04, -4.3004e-04, -2.1846e-03],\n",
      "          [ 2.2254e-03,  2.2143e-03,  1.8007e-03,  4.5405e-04, -8.3570e-04],\n",
      "          [ 1.6478e-03,  2.1071e-03,  1.8442e-03,  1.0697e-03,  2.2766e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.6478e-04,  9.1683e-06,  2.7058e-04,  3.1668e-04,  2.4463e-03],\n",
      "          [-3.6380e-04,  3.5875e-05,  3.6436e-04,  9.1371e-04,  2.0334e-03],\n",
      "          [-1.4645e-05, -6.2217e-06,  2.8855e-04,  6.5614e-04,  2.3282e-03],\n",
      "          [ 2.8969e-04,  3.0904e-04,  1.7104e-04,  4.7613e-04,  2.5000e-03],\n",
      "          [ 1.8358e-03,  9.1493e-04,  2.7959e-04,  8.0288e-04,  1.2630e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.7214e-02, -1.0767e-02, -4.9821e-03, -2.5776e-03, -2.2218e-03],\n",
      "          [-1.6392e-02, -1.0820e-02, -4.2635e-03, -2.0696e-03, -1.7747e-03],\n",
      "          [-1.2994e-02, -7.3812e-03, -1.7314e-03, -9.7318e-04, -4.5881e-04],\n",
      "          [-9.6091e-03, -4.4360e-03, -3.9373e-04,  8.1285e-04,  2.0251e-03],\n",
      "          [-6.8003e-03, -1.5404e-03,  2.5513e-03,  4.3904e-03,  6.6109e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7634e-03,  1.5452e-03,  7.1490e-04,  5.0071e-05, -3.5533e-04],\n",
      "          [-6.9125e-04, -1.0266e-03, -1.3268e-03, -1.5613e-03, -1.5408e-03],\n",
      "          [-9.2921e-04, -8.1025e-04, -6.0260e-04, -6.3224e-04, -7.2451e-04],\n",
      "          [-3.6322e-05,  1.0054e-05,  1.7029e-04,  3.1457e-04,  4.9711e-04],\n",
      "          [ 5.9103e-04,  3.1005e-04,  2.7996e-04,  3.3709e-04,  7.9158e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5657e-03,  1.9134e-03,  2.5749e-03,  4.4354e-03,  7.2156e-03],\n",
      "          [ 1.4683e-03,  1.4640e-03,  2.8367e-03,  5.5652e-03,  9.1173e-03],\n",
      "          [-3.9781e-04,  6.8426e-04,  3.2835e-03,  6.6784e-03,  8.2109e-03],\n",
      "          [-1.2732e-03,  4.8717e-04,  2.8167e-03,  4.3331e-03,  4.0350e-03],\n",
      "          [-2.0447e-03, -7.9907e-04, -7.6915e-04, -1.3943e-03, -1.7034e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.5608e-04, -2.8964e-04,  1.2143e-04,  4.8119e-04,  7.0764e-04],\n",
      "          [-5.3247e-04, -4.0445e-04,  1.6056e-04,  8.9355e-04,  1.0519e-03],\n",
      "          [-1.4764e-04, -1.1932e-04,  8.2201e-04,  1.2359e-03,  1.1797e-03],\n",
      "          [ 2.5801e-04,  3.1103e-04,  1.5706e-03,  2.3726e-03,  2.4580e-03],\n",
      "          [ 4.9743e-04,  8.5033e-04,  2.5917e-03,  3.4996e-03,  3.2638e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.2154e-02, -8.5516e-03, -5.0142e-03, -3.5346e-03, -1.2055e-03],\n",
      "          [-8.3503e-03, -4.4526e-03, -1.1823e-03,  2.0345e-04,  1.3845e-03],\n",
      "          [-8.7074e-03, -5.0708e-03, -6.6264e-04,  1.2977e-03,  2.2140e-03],\n",
      "          [-5.6172e-03, -3.5422e-03, -5.5617e-04,  1.6600e-03,  2.4664e-03],\n",
      "          [-2.8509e-03, -2.4814e-03, -2.9224e-04,  1.5409e-03,  2.2382e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.7128e-03,  1.8181e-03,  7.3241e-04,  3.8843e-04,  3.3335e-04],\n",
      "          [ 1.8952e-03,  1.6855e-03,  1.2476e-03,  1.4448e-03,  1.4303e-03],\n",
      "          [ 9.2108e-04,  1.0924e-03,  1.7553e-03,  1.9730e-03,  1.6344e-03],\n",
      "          [ 3.4037e-04,  7.0985e-04,  1.4951e-03,  2.0939e-03,  1.5762e-03],\n",
      "          [-5.4538e-04, -1.4777e-04,  2.2757e-04,  3.2700e-04,  9.6317e-05]]]]), 'conv1.bias': tensor([-0.0039,  0.0014,  0.0377,  0.0160, -0.0006, -0.0067, -0.0071, -0.0083,\n",
      "        -0.0027,  0.0075, -0.0344,  0.0030, -0.0066,  0.0036, -0.0523, -0.0002]), 'conv2.weight': tensor([[[[-9.1170e-04, -2.6551e-03, -2.7520e-03,  3.0389e-04,  2.2969e-03],\n",
      "          [-1.7525e-03, -3.6345e-03, -1.6259e-03, -1.2401e-03,  5.1987e-04],\n",
      "          [-1.2452e-03, -3.0695e-03, -3.6042e-03, -4.2139e-03, -3.6358e-03],\n",
      "          [-8.2315e-04, -2.7456e-03, -5.5159e-03, -4.4482e-03, -2.8766e-03],\n",
      "          [-1.9975e-03, -5.0666e-03, -7.1024e-03, -4.3082e-03, -3.0328e-03]],\n",
      "\n",
      "         [[-1.8006e-04, -1.4253e-04, -9.6564e-05,  2.9276e-04,  5.4643e-04],\n",
      "          [-2.0906e-04, -3.4065e-04, -1.3344e-04,  7.9423e-05,  1.3814e-04],\n",
      "          [-8.7088e-05, -3.7694e-04, -1.6148e-04,  1.2640e-04,  3.8732e-04],\n",
      "          [ 3.0129e-05, -1.8328e-04, -2.0159e-04,  8.7073e-06,  2.1110e-04],\n",
      "          [ 5.5604e-05, -1.2415e-04, -1.6920e-04,  5.3742e-05,  8.4323e-05]],\n",
      "\n",
      "         [[ 2.0223e-03, -1.4762e-03, -1.2287e-03,  5.4064e-04,  2.6925e-03],\n",
      "          [ 1.3399e-03, -2.5321e-03, -3.9910e-03, -8.7715e-05,  2.7543e-03],\n",
      "          [ 2.6541e-03, -1.0217e-03, -3.7452e-03, -2.1924e-03,  3.5841e-04],\n",
      "          [ 4.7267e-03,  8.2790e-04, -3.4784e-03, -3.7230e-03, -3.5172e-03],\n",
      "          [ 3.1384e-03,  2.2659e-04, -3.3489e-03, -3.1321e-03, -4.1534e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.1776e-04, -1.6119e-03, -5.5932e-04, -1.3745e-04,  3.8415e-04],\n",
      "          [-1.4296e-04, -9.9540e-04, -1.1739e-03, -7.4893e-04, -2.9278e-04],\n",
      "          [ 4.5234e-04, -2.8964e-04, -1.0306e-03, -3.9571e-04, -4.7044e-04],\n",
      "          [ 7.9762e-04,  3.2909e-04,  2.7477e-04,  8.5554e-05,  2.0716e-04],\n",
      "          [ 1.0635e-04, -1.2644e-04,  3.1265e-05,  2.5884e-04,  7.4018e-05]],\n",
      "\n",
      "         [[ 1.1010e-03, -7.7801e-04, -1.1212e-03,  9.9936e-04,  8.8424e-04],\n",
      "          [ 7.3184e-04, -3.4186e-04, -4.7286e-04,  1.3367e-03,  2.4528e-03],\n",
      "          [ 2.3165e-03,  1.8502e-03, -7.1569e-04, -1.0455e-03, -9.7175e-04],\n",
      "          [ 3.0590e-03,  2.0126e-03, -4.1620e-04, -1.6128e-04, -1.8715e-03],\n",
      "          [ 8.1184e-04, -5.9407e-04, -2.0577e-03, -1.2808e-03, -3.0257e-03]],\n",
      "\n",
      "         [[ 1.7728e-03,  6.0557e-04, -5.0395e-04, -1.7815e-04, -1.3089e-04],\n",
      "          [ 2.0048e-03, -1.2830e-04, -1.7337e-03, -1.7324e-03, -6.9196e-04],\n",
      "          [ 1.5388e-03, -1.3554e-03, -2.4602e-03, -2.1737e-03, -1.7197e-04],\n",
      "          [ 4.8299e-04, -1.5450e-03, -2.0008e-03, -2.4848e-03, -6.4589e-04],\n",
      "          [ 3.6441e-04, -9.0232e-04, -1.8011e-03, -2.3794e-03, -5.9792e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.5647e-02, -1.1661e-02, -2.7396e-03,  5.0562e-03,  1.1201e-02],\n",
      "          [-1.4320e-02, -8.5979e-03,  2.1482e-03,  9.9224e-03,  1.6268e-02],\n",
      "          [-9.8927e-03, -3.2754e-03,  4.6381e-03,  9.3502e-03,  1.1022e-02],\n",
      "          [-4.9092e-03, -6.8281e-04,  2.7737e-03,  2.7819e-03,  3.5937e-03],\n",
      "          [-2.6942e-03, -1.1761e-03, -8.6899e-04,  6.0038e-04,  5.4974e-03]],\n",
      "\n",
      "         [[-1.7312e-04,  1.7845e-04,  2.8022e-04,  1.9566e-04,  3.5632e-04],\n",
      "          [-2.0611e-04,  1.4681e-04,  3.2410e-04,  1.7110e-04,  5.2894e-04],\n",
      "          [ 6.1366e-05,  8.0258e-05, -3.2111e-05,  4.4205e-04,  5.6094e-04],\n",
      "          [ 1.2697e-04,  4.1662e-05, -1.4989e-05,  5.3370e-04,  5.0631e-04],\n",
      "          [ 1.8264e-04,  8.1577e-05,  1.5101e-05,  3.7487e-04,  3.5713e-04]],\n",
      "\n",
      "         [[-2.7410e-02, -2.6102e-02, -1.6058e-02, -1.8985e-03,  8.1072e-03],\n",
      "          [-2.8641e-02, -2.4926e-02, -1.4242e-02, -1.1898e-03,  1.3511e-02],\n",
      "          [-2.2833e-02, -1.8494e-02, -9.0594e-03,  2.6047e-03,  1.3890e-02],\n",
      "          [-1.6830e-02, -1.0647e-02, -5.0468e-03,  1.4301e-03,  8.9494e-03],\n",
      "          [-1.2892e-02, -6.3012e-03, -4.2209e-03, -1.0621e-03,  4.5045e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0256e-03, -1.1205e-03, -1.4941e-04,  1.3160e-03,  1.8558e-03],\n",
      "          [-7.2522e-04, -1.5111e-04,  4.3301e-04,  1.3768e-03,  1.1645e-03],\n",
      "          [-7.1947e-05, -3.6798e-04, -5.3593e-04,  4.9755e-05,  5.6516e-04],\n",
      "          [ 1.5299e-04,  7.4437e-05, -4.3126e-04, -8.5436e-05,  6.8517e-04],\n",
      "          [ 2.4725e-04,  8.2278e-05, -5.5031e-05,  5.1620e-04,  5.6076e-04]],\n",
      "\n",
      "         [[-2.1698e-02, -2.0790e-02, -1.3087e-02, -5.2578e-03,  5.0163e-03],\n",
      "          [-2.0567e-02, -1.6739e-02, -8.1030e-03,  1.7456e-04,  1.0879e-02],\n",
      "          [-1.5974e-02, -1.0984e-02, -4.4558e-03,  1.3876e-03,  7.9814e-03],\n",
      "          [-1.2207e-02, -5.7391e-03, -2.2905e-03, -1.8113e-04,  2.7104e-03],\n",
      "          [-8.8972e-03, -4.9177e-03, -4.4193e-03, -1.6908e-03,  2.5031e-03]],\n",
      "\n",
      "         [[-4.5378e-03, -5.0835e-03, -8.8272e-03, -4.3114e-03,  4.9095e-04],\n",
      "          [-3.5470e-03, -6.3408e-03, -1.0280e-02, -3.2765e-03, -2.3066e-04],\n",
      "          [-3.2961e-03, -6.6282e-03, -6.8796e-03, -2.0775e-03, -3.1208e-04],\n",
      "          [-3.6364e-03, -5.4086e-03, -3.9914e-03, -2.1862e-03,  1.0514e-04],\n",
      "          [-3.5684e-03, -3.8894e-03, -1.9272e-03, -2.0271e-03,  4.8815e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 9.5344e-03,  7.7364e-03,  4.3385e-03,  8.9414e-04,  1.3319e-03],\n",
      "          [ 1.2828e-02,  1.0571e-02,  6.6779e-03,  2.1327e-03,  8.8822e-04],\n",
      "          [ 1.2049e-02,  1.1980e-02,  6.1956e-03,  2.2949e-03,  8.4390e-04],\n",
      "          [ 1.3536e-02,  1.2276e-02,  4.3566e-03,  2.2123e-03,  1.2382e-03],\n",
      "          [ 1.0799e-02,  9.0482e-03,  5.1768e-03,  3.9265e-03,  1.5978e-03]],\n",
      "\n",
      "         [[-1.2857e-04,  1.6671e-04, -1.1676e-04,  8.4564e-05,  2.1775e-04],\n",
      "          [ 2.4545e-04,  1.4853e-04, -9.2956e-05, -7.0693e-05,  2.8742e-04],\n",
      "          [ 3.1901e-04,  2.3741e-04, -7.5629e-05, -1.3527e-04, -4.2363e-05],\n",
      "          [ 1.9103e-04,  3.8820e-04, -7.1232e-05, -5.6151e-05, -1.0860e-04],\n",
      "          [ 2.2765e-04,  3.7548e-04,  1.4471e-04, -6.6225e-05,  3.1715e-05]],\n",
      "\n",
      "         [[ 9.9431e-03,  1.1582e-02,  7.8471e-03,  2.5238e-03,  1.9624e-03],\n",
      "          [ 1.6535e-02,  1.9043e-02,  1.2834e-02,  5.1371e-03,  1.7913e-03],\n",
      "          [ 1.9875e-02,  2.3025e-02,  2.0279e-02,  1.0145e-02,  2.9001e-03],\n",
      "          [ 2.2855e-02,  2.2102e-02,  2.0716e-02,  1.3143e-02,  4.3861e-03],\n",
      "          [ 2.4748e-02,  2.1143e-02,  1.7292e-02,  1.4102e-02,  6.9155e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6919e-03,  1.0747e-03, -4.3384e-05, -4.2348e-04, -2.1872e-04],\n",
      "          [ 1.7650e-03,  2.3413e-03,  3.0135e-04, -2.5308e-04, -4.0254e-04],\n",
      "          [ 7.7226e-04,  1.7459e-03,  9.5178e-04,  5.3447e-05, -2.8982e-04],\n",
      "          [ 6.1458e-04,  6.6176e-04,  1.4239e-03,  5.1829e-04, -3.2583e-05],\n",
      "          [ 1.1146e-03,  5.1863e-04,  6.7905e-04,  5.4580e-04,  2.1891e-04]],\n",
      "\n",
      "         [[ 9.4964e-03,  1.1429e-02,  9.2712e-03,  6.1538e-03,  3.9221e-03],\n",
      "          [ 1.2968e-02,  1.5255e-02,  1.3337e-02,  8.6817e-03,  2.9202e-03],\n",
      "          [ 1.4908e-02,  1.6604e-02,  1.5302e-02,  1.0556e-02,  4.3439e-03],\n",
      "          [ 2.0341e-02,  1.6760e-02,  1.2848e-02,  1.1258e-02,  5.7796e-03],\n",
      "          [ 1.8205e-02,  1.6492e-02,  1.3487e-02,  1.2080e-02,  7.5265e-03]],\n",
      "\n",
      "         [[ 2.3245e-03,  2.7572e-03,  3.8365e-03,  3.0935e-03,  1.5277e-03],\n",
      "          [ 2.8219e-03,  3.3964e-03,  5.9239e-03,  3.4891e-03,  1.6587e-03],\n",
      "          [ 3.2593e-03,  4.0193e-03,  7.1779e-03,  4.1847e-03,  1.8240e-03],\n",
      "          [ 2.6186e-03,  4.0739e-03,  7.2622e-03,  4.0597e-03,  1.7125e-03],\n",
      "          [ 3.6384e-03,  5.5985e-03,  5.9059e-03,  3.0862e-03,  2.0576e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.8177e-04,  3.4823e-04,  1.4787e-05,  3.4274e-05,  6.6309e-05],\n",
      "          [ 1.0219e-03,  5.3215e-04,  1.4280e-04,  2.1686e-05,  2.6603e-05],\n",
      "          [ 1.4102e-03,  3.8070e-04,  1.9945e-04,  1.9250e-05,  1.9846e-08],\n",
      "          [ 6.6630e-04,  1.2177e-04,  5.7506e-05,  2.5213e-05,  4.3893e-07],\n",
      "          [ 5.4455e-04,  1.1530e-04,  1.3166e-04,  2.9651e-05,  8.2571e-06]],\n",
      "\n",
      "         [[ 6.9448e-05,  9.5257e-06,  1.9230e-06,  3.6994e-06,  3.0312e-05],\n",
      "          [ 6.6004e-05,  2.4373e-05,  1.5820e-06,  2.2487e-06,  1.6170e-05],\n",
      "          [ 5.9295e-05,  1.5111e-05,  1.1391e-06,  5.9619e-09,  2.4824e-06],\n",
      "          [ 2.4326e-05,  2.1917e-05,  5.1005e-06,  1.0678e-07,  4.4976e-08],\n",
      "          [ 1.5272e-05,  3.8696e-05,  2.1874e-05, -1.2497e-07,  5.9540e-08]],\n",
      "\n",
      "         [[ 3.3463e-03,  3.3837e-03,  2.2729e-03,  1.1085e-03,  7.9847e-04],\n",
      "          [ 2.6265e-03,  2.2633e-03,  1.5902e-03,  8.7405e-04,  4.3902e-04],\n",
      "          [ 3.8953e-03,  2.3868e-03,  1.8475e-03,  7.8764e-04,  3.8615e-04],\n",
      "          [ 4.1056e-03,  1.9406e-03,  1.5281e-03,  6.5831e-04,  1.7149e-04],\n",
      "          [ 2.7092e-03,  1.4038e-03,  9.8300e-04,  6.6313e-04,  1.6685e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4032e-04,  1.4309e-05,  1.3727e-06, -4.6852e-07,  1.5372e-05],\n",
      "          [ 2.4935e-04,  6.2693e-05,  4.3782e-06, -4.2646e-07, -7.2501e-07],\n",
      "          [ 1.9766e-04,  2.4288e-04,  6.8066e-05,  3.5865e-07, -1.4922e-08],\n",
      "          [ 6.1546e-05,  7.6173e-05,  7.0284e-05,  4.5041e-07,  2.4844e-07],\n",
      "          [ 5.6459e-05,  2.0613e-05,  7.5704e-05,  6.0414e-06,  7.4453e-07]],\n",
      "\n",
      "         [[ 2.7609e-03,  2.6743e-03,  1.9872e-03,  1.1550e-03,  6.8974e-04],\n",
      "          [ 3.1474e-03,  2.3788e-03,  2.1310e-03,  1.1365e-03,  5.5021e-04],\n",
      "          [ 4.3471e-03,  2.7633e-03,  2.3271e-03,  1.1152e-03,  5.0877e-04],\n",
      "          [ 2.8869e-03,  1.7399e-03,  1.3830e-03,  8.2386e-04,  2.3770e-04],\n",
      "          [ 1.7893e-03,  1.4617e-03,  9.5053e-04,  7.2230e-04,  2.4074e-04]],\n",
      "\n",
      "         [[ 3.3798e-04,  3.7204e-04,  3.4605e-04,  1.5571e-04,  1.9035e-05],\n",
      "          [ 2.3856e-04,  2.8354e-04,  1.2217e-04,  6.8875e-06,  3.3792e-06],\n",
      "          [ 4.2934e-04,  3.8677e-04,  1.0423e-04,  4.0579e-05,  7.5112e-08],\n",
      "          [ 1.1375e-03,  5.6405e-04,  1.5470e-04,  8.3534e-05,  1.9523e-06],\n",
      "          [ 1.2819e-03,  3.7603e-04,  9.6033e-05,  9.9455e-05,  1.3686e-05]]],\n",
      "\n",
      "\n",
      "        [[[-6.9740e-04, -2.4452e-03, -3.6165e-03, -5.3544e-03, -7.2412e-03],\n",
      "          [-7.7152e-03, -6.7277e-03, -5.2718e-03, -3.7984e-03, -5.3673e-03],\n",
      "          [-9.5689e-03, -7.6743e-03, -4.0509e-03, -1.2680e-03, -1.8125e-03],\n",
      "          [-3.8255e-03, -2.3806e-03,  1.0412e-04,  2.1323e-03, -8.0119e-05],\n",
      "          [-1.4995e-04,  5.7769e-04,  2.5710e-03,  4.1371e-03,  1.3956e-03]],\n",
      "\n",
      "         [[-5.8495e-05, -9.4829e-05,  3.1620e-05, -3.0530e-04, -6.5549e-04],\n",
      "          [ 1.4891e-04,  1.3807e-04,  2.3845e-04,  2.3390e-05, -3.9365e-04],\n",
      "          [ 1.0106e-04,  1.6552e-04,  2.3988e-04,  2.5563e-04, -2.1040e-04],\n",
      "          [-3.6560e-05,  4.5511e-05,  2.2302e-04,  1.7420e-04, -6.6399e-05],\n",
      "          [-2.0434e-04, -1.6380e-04,  1.2880e-04,  1.4818e-04, -8.1952e-05]],\n",
      "\n",
      "         [[ 9.9870e-03,  4.3178e-03,  3.3457e-04, -2.4503e-03, -8.8579e-03],\n",
      "          [ 3.4900e-03, -2.2598e-03, -3.7024e-03, -4.0000e-03, -6.6671e-03],\n",
      "          [-9.0614e-03, -1.1882e-02, -1.0165e-02, -6.1920e-03, -6.4954e-03],\n",
      "          [-1.3416e-02, -1.3775e-02, -1.0723e-02, -8.1089e-03, -6.4240e-03],\n",
      "          [-8.3447e-03, -9.2723e-03, -6.9403e-03, -4.6088e-03, -5.0522e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3504e-04,  2.9675e-04,  1.1479e-03,  1.7582e-03,  6.1414e-04],\n",
      "          [-7.1303e-04, -7.1212e-05,  5.0539e-04,  7.3536e-04,  2.2657e-05],\n",
      "          [-8.1023e-04, -1.0287e-03, -6.5757e-04,  1.6608e-04,  1.2180e-04],\n",
      "          [-7.6929e-05, -9.6044e-05, -4.0378e-04, -8.2080e-04, -5.8529e-04],\n",
      "          [ 6.0496e-04,  5.3929e-04,  3.7731e-04, -3.9768e-04, -6.5855e-04]],\n",
      "\n",
      "         [[ 7.5993e-03,  1.4129e-03, -2.1541e-03, -4.0842e-03, -6.4316e-03],\n",
      "          [-3.1310e-04, -5.5448e-03, -5.8733e-03, -6.0541e-03, -7.5034e-03],\n",
      "          [-7.7090e-03, -1.0485e-02, -8.7999e-03, -7.7150e-03, -7.4887e-03],\n",
      "          [-6.7692e-03, -8.9878e-03, -7.0240e-03, -6.3697e-03, -6.4723e-03],\n",
      "          [-4.5727e-03, -6.8844e-03, -4.9030e-03, -3.3061e-03, -5.1844e-03]],\n",
      "\n",
      "         [[ 8.5652e-04,  1.0933e-03, -2.6756e-04, -1.2861e-03, -2.6414e-03],\n",
      "          [ 8.0396e-04, -3.0783e-05, -1.0832e-03, -1.5803e-03, -1.4237e-03],\n",
      "          [ 2.3748e-04, -9.6624e-04, -1.8602e-03, -1.5205e-03, -2.3440e-04],\n",
      "          [-5.2556e-04, -2.0329e-03, -1.3351e-03, -3.8125e-04,  2.6630e-04],\n",
      "          [-5.8167e-04, -9.5888e-04,  1.6683e-06,  3.3553e-04,  1.5782e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.5366e-03, -1.1439e-03,  2.2040e-04, -6.8122e-05, -1.4216e-04],\n",
      "          [-2.6879e-03, -8.2754e-04, -3.6567e-04, -1.3665e-04,  8.0508e-06],\n",
      "          [-9.9961e-04, -6.3803e-04, -1.0819e-04,  1.3501e-03,  2.3126e-03],\n",
      "          [-8.2978e-05, -4.1477e-04,  1.0397e-03,  3.3360e-03,  3.1411e-03],\n",
      "          [-9.4320e-04, -8.9991e-04,  1.3828e-03,  2.7559e-03,  1.4153e-03]],\n",
      "\n",
      "         [[ 1.8486e-04,  2.0321e-04,  3.7211e-05, -3.1676e-05, -9.0943e-05],\n",
      "          [-5.4647e-05, -3.9787e-06,  3.0326e-05, -1.0846e-04, -1.2486e-04],\n",
      "          [-5.7558e-07, -3.3860e-05, -6.6261e-06, -4.6147e-05, -1.1009e-04],\n",
      "          [-1.7603e-05,  6.9725e-06,  1.0692e-04,  1.2966e-04, -7.8386e-05],\n",
      "          [-1.2247e-05,  7.2158e-05,  4.4459e-04,  2.1612e-04, -7.4508e-05]],\n",
      "\n",
      "         [[-4.9873e-03, -2.2695e-03,  6.9436e-04,  3.8734e-03,  2.3210e-03],\n",
      "          [-2.1319e-03, -1.1477e-03, -1.0404e-03,  2.4161e-04, -7.7968e-04],\n",
      "          [-1.5267e-03, -1.0190e-03, -1.4554e-03, -7.4569e-05,  3.6243e-04],\n",
      "          [-1.0302e-04, -5.3729e-04,  6.8994e-05,  6.1233e-04,  2.0445e-03],\n",
      "          [ 7.2698e-04, -7.7284e-04,  1.2453e-03,  2.4672e-03,  1.9530e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.5369e-04, -4.1244e-04, -1.1182e-04, -1.8023e-04, -1.5515e-04],\n",
      "          [-8.8372e-05, -3.9535e-04, -9.8596e-05,  3.5232e-04,  1.7373e-04],\n",
      "          [-3.6008e-04, -3.0382e-04,  5.1606e-04,  7.8632e-04,  1.5705e-04],\n",
      "          [-5.7302e-05,  4.5010e-04,  1.0296e-03,  2.8735e-04, -6.4847e-05],\n",
      "          [ 6.4113e-06,  2.7577e-04,  1.0168e-03,  2.2472e-05, -3.6361e-04]],\n",
      "\n",
      "         [[-1.5868e-03, -2.8357e-04,  4.2698e-04,  1.6752e-03,  7.6622e-04],\n",
      "          [-5.2111e-04,  2.7104e-04, -1.3539e-03, -1.1885e-04, -2.9792e-04],\n",
      "          [ 5.8050e-04,  2.2366e-04, -6.8378e-04, -1.9049e-04,  5.7263e-04],\n",
      "          [ 1.6483e-03,  6.2303e-04,  5.2228e-04,  8.5641e-04,  1.9644e-03],\n",
      "          [ 1.2606e-03,  8.0267e-04,  4.2393e-04,  1.2613e-03,  4.6505e-04]],\n",
      "\n",
      "         [[-1.6256e-03, -2.1853e-03, -1.0168e-03,  1.2475e-04,  5.6837e-04],\n",
      "          [-9.3006e-04, -1.3803e-03, -5.7999e-04, -1.7634e-04, -1.7023e-04],\n",
      "          [-9.4392e-04, -1.0203e-03, -6.6215e-04, -4.8142e-04, -5.9859e-04],\n",
      "          [-4.2560e-04, -2.4739e-04, -5.1378e-04, -4.0651e-04, -1.5686e-03],\n",
      "          [-1.6440e-04,  1.9385e-05, -4.0576e-04, -5.7046e-04, -1.4195e-03]]]]), 'conv2.bias': tensor([ 0.0284, -0.0174,  0.0363,  0.0058,  0.0069,  0.0007, -0.0365,  0.0199,\n",
      "        -0.0116, -0.0054, -0.0671, -0.0127, -0.0391,  0.0155, -0.0300,  0.0318,\n",
      "        -0.0519, -0.0354,  0.0227, -0.0050, -0.0187, -0.0374, -0.0444, -0.0188,\n",
      "         0.0214,  0.0202,  0.0265, -0.0134, -0.0039,  0.0152, -0.0247,  0.0022]), 'fc1.weight': tensor([[ 0.0001,  0.0028,  0.0054,  ...,  0.0008,  0.0011,  0.0007],\n",
      "        [ 0.0001,  0.0016,  0.0030,  ..., -0.0008,  0.0001,  0.0003],\n",
      "        [-0.0013, -0.0262, -0.0499,  ..., -0.0060, -0.0097, -0.0064],\n",
      "        ...,\n",
      "        [ 0.0001,  0.0029,  0.0054,  ...,  0.0008,  0.0011,  0.0007],\n",
      "        [ 0.0001,  0.0029,  0.0056,  ...,  0.0008,  0.0011,  0.0007],\n",
      "        [ 0.0001,  0.0030,  0.0057,  ...,  0.0008,  0.0012,  0.0007]]), 'fc1.bias': tensor([ 0.0471, -0.0098, -0.3991,  0.0496,  0.0583,  0.0506,  0.0576,  0.0474,\n",
      "         0.0485,  0.0496])}\n",
      "!-- Client 3 is normal and start iterations. ---!\n",
      "Epoch [1/3], Average Loss: 0.3637393116950989, Average Accuracy: 0.8814576864242554, Average Error: 0.1185423582792282, Culminative Time Used: 2.026190098375082\n",
      "Epoch [2/3], Average Loss: 0.0523986034095287, Average Accuracy: 0.9867050647735596, Average Error: 0.0132949557155371, Culminative Time Used: 4.121562097221613\n",
      "Epoch [3/3], Average Loss: 0.0349113717675209, Average Accuracy: 0.9906798005104065, Average Error: 0.0093201752752066, Culminative Time Used: 6.140867900103331\n",
      "{'conv1.weight': tensor([[[[ 1.3569e-03,  2.2586e-03,  5.2791e-03,  8.2994e-03,  1.0596e-02],\n",
      "          [ 2.4723e-03,  4.8313e-03,  1.0207e-02,  1.4763e-02,  1.5867e-02],\n",
      "          [ 4.0812e-03,  6.7050e-03,  1.1421e-02,  1.5470e-02,  1.6098e-02],\n",
      "          [ 4.7878e-03,  6.4214e-03,  8.7504e-03,  1.1090e-02,  1.2682e-02],\n",
      "          [ 3.5317e-03,  3.5082e-03,  4.6880e-03,  6.4661e-03,  8.8174e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2727e-04,  8.7572e-05, -9.1850e-05,  4.1128e-04,  8.3477e-04],\n",
      "          [-2.0614e-04, -4.7095e-04, -9.5041e-04, -5.3890e-04,  2.3698e-04],\n",
      "          [-3.7099e-05, -1.9029e-04, -9.0622e-04, -8.8821e-04, -3.4048e-04],\n",
      "          [ 1.2503e-05, -3.7468e-05, -4.6110e-04, -9.4860e-04, -7.8165e-04],\n",
      "          [ 9.0649e-05,  2.1989e-05, -2.2467e-05, -2.2734e-04, -3.3685e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.0932e-02, -1.0570e-02, -1.1687e-02, -1.4931e-02, -1.5205e-02],\n",
      "          [-1.6398e-02, -1.7083e-02, -1.6232e-02, -1.4870e-02, -1.1504e-02],\n",
      "          [-1.7857e-02, -1.8678e-02, -1.5731e-02, -1.0234e-02, -5.4589e-03],\n",
      "          [-1.6966e-02, -1.5208e-02, -1.0632e-02, -7.1082e-03, -3.1184e-03],\n",
      "          [-9.6645e-03, -8.2154e-03, -7.9158e-03, -6.2013e-03, -3.4755e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.0532e-03, -3.1925e-03, -1.8215e-03, -2.7927e-03, -5.8365e-03],\n",
      "          [-9.0142e-03, -5.2602e-03, -6.1121e-03, -6.8501e-03, -8.3619e-03],\n",
      "          [-8.6144e-03, -6.2162e-03, -7.9913e-03, -9.2332e-03, -9.7821e-03],\n",
      "          [-7.2767e-03, -7.3946e-03, -8.0900e-03, -8.4489e-03, -8.0249e-03],\n",
      "          [-8.3044e-03, -7.6834e-03, -6.8083e-03, -6.3992e-03, -6.1132e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.2249e-03, -4.5166e-03, -4.6269e-03, -3.7842e-03, -2.8040e-03],\n",
      "          [-1.6739e-03, -2.4902e-03, -3.5184e-03, -4.1883e-03, -3.8730e-03],\n",
      "          [ 1.1756e-04, -1.1283e-03, -2.9514e-03, -4.2861e-03, -4.7377e-03],\n",
      "          [-1.5450e-03, -1.9980e-03, -3.2659e-03, -5.2107e-03, -5.1857e-03],\n",
      "          [-4.7516e-03, -5.3056e-03, -4.7988e-03, -5.1942e-03, -3.9022e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0364e-03,  5.5870e-03,  7.1600e-03,  1.0327e-02,  1.1354e-02],\n",
      "          [ 5.0079e-03,  6.9688e-03,  9.3776e-03,  1.1163e-02,  1.1440e-02],\n",
      "          [ 4.8353e-03,  6.7163e-03,  8.4631e-03,  7.9750e-03,  7.6312e-03],\n",
      "          [ 4.5079e-03,  6.9731e-03,  9.2953e-03,  8.4183e-03,  7.5243e-03],\n",
      "          [ 5.5777e-03,  9.7299e-03,  1.0445e-02,  7.8798e-03,  5.8713e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.5543e-03,  2.5540e-03,  3.0660e-03,  3.9379e-03,  4.1097e-03],\n",
      "          [ 3.8769e-03,  4.7175e-03,  6.2432e-03,  6.5755e-03,  5.8949e-03],\n",
      "          [ 5.5275e-03,  6.6543e-03,  8.2817e-03,  8.3097e-03,  6.4427e-03],\n",
      "          [ 4.9876e-03,  5.8582e-03,  6.9802e-03,  7.1664e-03,  4.2210e-03],\n",
      "          [ 3.8839e-03,  4.6856e-03,  5.2553e-03,  4.8330e-03,  2.3511e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.5652e-04, -1.7050e-03, -2.8995e-03, -3.4849e-03, -2.7525e-03],\n",
      "          [-1.1158e-04, -1.6894e-03, -1.9826e-03, -1.2982e-03, -9.1627e-04],\n",
      "          [-1.5359e-04, -9.3001e-04, -7.1656e-04, -6.8585e-04, -1.1395e-03],\n",
      "          [-2.4376e-04, -4.4687e-04, -6.1379e-04, -1.0748e-03, -6.3611e-04],\n",
      "          [-7.0626e-04, -8.5164e-04, -1.3248e-03, -1.4437e-03, -1.0189e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9617e-04,  1.8804e-03,  1.7635e-03,  1.6868e-03,  2.1856e-03],\n",
      "          [-1.0853e-03,  4.8776e-04,  1.1283e-03,  1.2030e-03,  2.0855e-03],\n",
      "          [-2.8221e-03, -1.6434e-03,  1.6437e-04,  9.5385e-04,  1.5598e-03],\n",
      "          [-2.5000e-03, -1.4121e-03,  5.7900e-04,  1.5497e-03,  2.0611e-03],\n",
      "          [-1.3275e-03, -8.6616e-04,  7.6338e-04,  1.8149e-03,  2.5177e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.4490e-04,  1.8751e-03,  2.2735e-03,  2.0816e-03,  1.4267e-03],\n",
      "          [ 1.4447e-04,  1.4030e-03,  1.8394e-03,  1.6832e-03,  9.2172e-04],\n",
      "          [-2.4741e-05,  3.7941e-05,  3.0402e-04,  3.1884e-04,  3.2155e-04],\n",
      "          [-1.9495e-04, -1.7383e-04, -2.9625e-05,  5.4314e-05,  5.3547e-04],\n",
      "          [-1.1130e-03, -3.8531e-04, -2.5987e-05,  3.3946e-04,  6.6931e-04]]],\n",
      "\n",
      "\n",
      "        [[[-9.4696e-04, -2.1886e-03, -2.5951e-03, -2.5409e-03, -3.1607e-03],\n",
      "          [ 2.6941e-03,  1.5946e-03,  2.9246e-04, -3.2071e-04, -6.7542e-04],\n",
      "          [ 6.2195e-03,  5.5256e-03,  3.7022e-03,  2.6467e-03,  1.7025e-03],\n",
      "          [ 4.9966e-03,  4.5939e-03,  4.3676e-03,  5.2756e-03,  5.3559e-03],\n",
      "          [ 2.5711e-03,  3.6615e-03,  5.5506e-03,  7.0260e-03,  8.8077e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.8493e-03,  4.7440e-03,  6.1908e-03,  7.3153e-03,  6.6349e-03],\n",
      "          [ 4.7937e-03,  5.0227e-03,  5.6853e-03,  6.4200e-03,  6.5628e-03],\n",
      "          [ 2.8373e-03,  2.4220e-03,  2.6488e-03,  3.6120e-03,  4.6753e-03],\n",
      "          [ 2.0085e-04,  3.5482e-04,  9.3694e-04,  1.6761e-03,  2.5990e-03],\n",
      "          [ 1.1595e-03,  1.8583e-03,  2.6796e-03,  3.0482e-03,  3.3363e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0198e-03,  2.7923e-03,  3.4277e-03,  2.3245e-03,  1.3764e-04],\n",
      "          [-2.2457e-04,  8.3148e-04,  1.8571e-03,  1.8881e-03,  1.1170e-03],\n",
      "          [ 2.0796e-04,  1.0322e-03,  3.0147e-03,  4.3079e-03,  3.8548e-03],\n",
      "          [ 8.7391e-04,  1.9240e-03,  4.0692e-03,  5.2026e-03,  5.8152e-03],\n",
      "          [ 1.7465e-03,  2.1889e-03,  3.4422e-03,  3.8238e-03,  4.7723e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.8344e-04, -4.5740e-04, -6.8480e-04, -9.2438e-04, -8.3438e-04],\n",
      "          [-4.4222e-04, -4.9379e-04, -7.3576e-04, -1.2251e-03, -1.2530e-03],\n",
      "          [-5.6315e-04, -1.3684e-03, -2.6781e-03, -2.7571e-03, -2.6495e-03],\n",
      "          [-5.0269e-04, -1.9537e-03, -4.6352e-03, -5.8921e-03, -6.2712e-03],\n",
      "          [ 5.1616e-05, -1.1645e-03, -4.1821e-03, -6.3966e-03, -7.2225e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0548e-03, -7.6631e-04, -5.3321e-03, -1.0270e-02, -1.4639e-02],\n",
      "          [ 1.5606e-03, -2.4855e-03, -6.7216e-03, -1.1327e-02, -1.4663e-02],\n",
      "          [-2.8707e-03, -7.4238e-03, -1.0314e-02, -1.2589e-02, -1.3552e-02],\n",
      "          [-4.9810e-03, -8.2489e-03, -9.6566e-03, -1.0463e-02, -1.0012e-02],\n",
      "          [-3.1593e-03, -4.8780e-03, -5.6152e-03, -5.8348e-03, -5.9257e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.1551e-03, -3.8781e-03, -1.9665e-03, -8.9531e-05,  1.5487e-04],\n",
      "          [-5.0821e-03, -4.1132e-03, -2.1393e-03, -5.0793e-04, -2.4158e-04],\n",
      "          [-4.9904e-03, -3.3740e-03, -2.4991e-03, -1.4700e-03, -1.0048e-03],\n",
      "          [-4.7682e-03, -4.1727e-03, -2.5741e-03, -2.1853e-03, -1.7516e-03],\n",
      "          [-4.5180e-03, -4.1206e-03, -2.0630e-03, -1.9607e-03, -1.7671e-03]]]]), 'conv1.bias': tensor([ 0.0157, -0.0004, -0.0199, -0.0055, -0.0091,  0.0170,  0.0086,  0.0077,\n",
      "        -0.0008, -0.0036,  0.0322,  0.0085,  0.0132, -0.0075,  0.0066, -0.0065]), 'conv2.weight': tensor([[[[-4.7039e-03, -2.9209e-03, -4.1480e-04,  1.9040e-03,  2.1331e-03],\n",
      "          [-6.1291e-03, -4.6230e-03, -1.6919e-03, -1.0950e-03, -1.1932e-03],\n",
      "          [-6.3154e-03, -4.4935e-03, -2.3250e-03, -4.3379e-04,  2.4459e-04],\n",
      "          [-5.5932e-03, -2.5354e-03,  3.8250e-04,  3.1185e-03,  4.1213e-03],\n",
      "          [-4.0757e-03, -2.4346e-03,  2.5818e-04,  3.6603e-03,  4.9000e-03]],\n",
      "\n",
      "         [[-2.3030e-04,  4.3439e-05,  1.4338e-04,  4.2766e-05, -1.2483e-04],\n",
      "          [-1.3231e-04, -1.8391e-05, -3.4008e-05, -9.0835e-05, -1.1230e-04],\n",
      "          [-6.5276e-05,  5.3571e-05, -1.1351e-04, -1.7089e-04, -3.6091e-04],\n",
      "          [ 1.3408e-04,  2.6919e-04,  1.6692e-04, -6.6804e-05, -3.2709e-04],\n",
      "          [ 2.2496e-04,  3.8029e-04,  4.7159e-04,  1.6418e-04, -1.2447e-04]],\n",
      "\n",
      "         [[-8.3863e-03, -8.7095e-03, -5.7574e-03, -1.3142e-03,  1.3858e-03],\n",
      "          [-1.0850e-02, -8.5080e-03, -8.7577e-03, -5.4934e-03, -1.3612e-03],\n",
      "          [-1.2171e-02, -1.0023e-02, -1.0597e-02, -8.5120e-03, -4.6735e-03],\n",
      "          [-1.0673e-02, -8.4299e-03, -8.1069e-03, -6.4148e-03, -2.2059e-03],\n",
      "          [-1.0026e-02, -7.6138e-03, -5.5399e-03, -2.4235e-03,  3.3749e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-9.3923e-04, -1.1674e-03, -4.0438e-04, -3.8433e-05, -5.0778e-04],\n",
      "          [-3.5308e-04, -3.7684e-04, -1.2683e-03, -1.6093e-03, -1.4786e-03],\n",
      "          [-1.1437e-04, -2.4762e-04, -8.4364e-04, -6.4616e-04, -6.5666e-04],\n",
      "          [ 5.0160e-04,  8.1243e-04,  6.3218e-04,  4.1256e-04,  4.3546e-05],\n",
      "          [-3.8439e-04,  4.4392e-04,  8.6651e-04,  8.8893e-04,  6.7712e-04]],\n",
      "\n",
      "         [[-8.0676e-03, -6.7596e-03, -6.0594e-03, -3.2813e-03, -3.2452e-04],\n",
      "          [-9.7012e-03, -7.0460e-03, -7.4583e-03, -6.6164e-03, -3.7039e-03],\n",
      "          [-1.0243e-02, -8.9023e-03, -8.9864e-03, -7.3946e-03, -3.9547e-03],\n",
      "          [-8.6643e-03, -7.0704e-03, -6.7170e-03, -5.5744e-03, -1.4295e-03],\n",
      "          [-8.2753e-03, -7.5389e-03, -5.7389e-03, -1.7493e-03,  2.9661e-03]],\n",
      "\n",
      "         [[-8.8880e-04, -6.9403e-04, -1.4627e-03, -1.3482e-03, -9.3398e-04],\n",
      "          [-1.4374e-03, -1.4689e-03, -1.6804e-03, -1.3674e-03, -8.3616e-04],\n",
      "          [-1.7861e-03, -1.6588e-03, -1.5735e-03, -2.2392e-03, -1.1289e-03],\n",
      "          [-2.5432e-03, -1.4382e-03, -1.4846e-03, -2.5566e-03, -5.9112e-04],\n",
      "          [-1.6843e-03, -1.1716e-03, -2.2779e-03, -3.6765e-03, -1.6811e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8580e-03,  8.2859e-03,  6.0495e-03,  1.0475e-03, -1.1573e-03],\n",
      "          [ 7.6648e-03,  7.0077e-03,  4.4464e-03,  1.7277e-03, -6.7440e-04],\n",
      "          [ 6.6503e-03,  6.4023e-03,  3.9697e-03,  2.4771e-03,  9.2341e-04],\n",
      "          [ 4.1610e-03,  3.5569e-03,  2.3725e-03,  4.7787e-03,  7.2778e-03],\n",
      "          [ 3.5000e-03,  4.0262e-03,  5.8781e-03,  9.0343e-03,  1.1329e-02]],\n",
      "\n",
      "         [[-4.8290e-05, -3.4780e-04, -1.4220e-04, -1.1461e-04, -3.6439e-04],\n",
      "          [ 2.7726e-04, -5.4225e-05, -3.5539e-04, -1.5198e-04, -4.4849e-04],\n",
      "          [ 4.1485e-04,  2.0958e-04, -1.8926e-04, -2.2132e-04, -1.3020e-04],\n",
      "          [ 3.5608e-04,  2.7596e-04,  8.5533e-05,  7.7371e-05,  2.3453e-04],\n",
      "          [ 3.1624e-04,  3.0755e-04,  1.4354e-04,  1.9533e-04,  3.2620e-04]],\n",
      "\n",
      "         [[ 1.1022e-02,  1.2755e-02,  1.0544e-02,  6.8937e-03,  3.9767e-03],\n",
      "          [ 1.4898e-02,  1.5865e-02,  8.5678e-03,  4.8215e-03,  3.5123e-03],\n",
      "          [ 1.2663e-02,  1.3150e-02,  9.0603e-03,  5.3334e-03,  4.4875e-03],\n",
      "          [ 1.0108e-02,  1.0389e-02,  7.8160e-03,  5.8744e-03,  8.4426e-03],\n",
      "          [ 8.9016e-03,  6.7247e-03,  7.7657e-03,  9.6247e-03,  1.5119e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.0447e-03, -4.7782e-04, -9.8596e-04, -3.2310e-04, -1.0153e-03],\n",
      "          [ 1.7638e-03,  7.8298e-04, -5.8603e-04, -3.4185e-04, -5.2127e-04],\n",
      "          [ 8.7836e-04,  8.0629e-04,  1.8177e-04,  7.1034e-04,  8.2371e-04],\n",
      "          [ 2.5435e-04,  2.1891e-04, -5.9698e-05,  7.9814e-04,  1.9595e-03],\n",
      "          [ 4.2451e-04,  2.8970e-04,  4.6875e-05,  2.6360e-04,  1.3773e-03]],\n",
      "\n",
      "         [[ 1.0764e-02,  1.2575e-02,  8.0341e-03,  3.6997e-03,  3.0715e-03],\n",
      "          [ 1.1720e-02,  1.1192e-02,  7.5804e-03,  4.9903e-03,  4.0524e-03],\n",
      "          [ 1.0796e-02,  1.0599e-02,  8.1954e-03,  4.9550e-03,  4.2635e-03],\n",
      "          [ 9.3693e-03,  6.5847e-03,  4.9769e-03,  5.4779e-03,  7.5590e-03],\n",
      "          [ 7.9650e-03,  6.6021e-03,  8.8296e-03,  1.0608e-02,  1.4513e-02]],\n",
      "\n",
      "         [[ 1.3697e-03,  1.5947e-03,  3.4546e-03,  3.3266e-03,  1.4220e-03],\n",
      "          [ 5.4338e-04,  2.6346e-03,  4.0295e-03,  1.4358e-03,  3.4097e-04],\n",
      "          [ 9.0781e-04,  2.4221e-03,  1.7700e-03,  5.7982e-04,  1.4244e-03],\n",
      "          [ 8.1095e-04,  2.1766e-03,  1.4968e-03,  8.8192e-04,  2.2247e-03],\n",
      "          [ 1.8496e-03,  2.2282e-03,  7.8066e-04,  6.2780e-04,  2.2202e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.6770e-03, -4.2182e-03, -4.5454e-03, -3.9381e-03, -3.0788e-03],\n",
      "          [-5.5587e-03, -4.8726e-03, -3.3718e-03, -2.0548e-03, -1.2659e-03],\n",
      "          [-7.0666e-03, -6.0627e-03, -3.3822e-03, -2.5496e-03, -2.7503e-03],\n",
      "          [-8.9243e-03, -5.4679e-03, -4.3091e-03, -6.5075e-03, -6.8771e-03],\n",
      "          [-4.2953e-03, -3.0388e-03, -5.6748e-03, -9.7894e-03, -7.4450e-03]],\n",
      "\n",
      "         [[-3.4680e-04, -1.7968e-04, -8.3291e-05, -4.5081e-05, -4.7490e-05],\n",
      "          [-1.2460e-04, -6.4278e-05, -6.3743e-05,  1.8092e-04,  2.5996e-05],\n",
      "          [ 7.4507e-05,  3.3921e-04,  1.5533e-07,  1.4364e-05,  6.2718e-05],\n",
      "          [ 6.1968e-05,  3.0051e-04,  1.9261e-05, -2.1434e-05, -2.8903e-05],\n",
      "          [-2.7000e-04, -1.6195e-04, -2.7537e-04, -2.1932e-04, -1.0862e-04]],\n",
      "\n",
      "         [[-7.0414e-05, -3.4067e-03, -4.5341e-03, -5.4114e-03, -7.2876e-03],\n",
      "          [-5.1313e-03, -7.8569e-03, -8.4053e-03, -7.6004e-03, -7.3293e-03],\n",
      "          [-9.9238e-03, -8.9202e-03, -7.5199e-03, -7.4380e-03, -6.7818e-03],\n",
      "          [-1.3563e-02, -1.1817e-02, -7.8826e-03, -7.3431e-03, -6.9380e-03],\n",
      "          [-1.4247e-02, -1.0887e-02, -8.2243e-03, -1.0514e-02, -1.1220e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.4385e-03, -1.1511e-03, -3.1295e-04, -2.7866e-04, -6.1713e-04],\n",
      "          [-4.5654e-04, -1.0834e-04, -8.0529e-05,  1.8291e-04,  1.4120e-04],\n",
      "          [-4.7641e-04,  5.4654e-04,  1.7390e-04, -3.3783e-04, -3.7365e-04],\n",
      "          [-4.2645e-04, -3.7027e-04, -1.3234e-03, -1.2782e-03, -3.6168e-04],\n",
      "          [-1.4583e-03, -1.1165e-03, -8.0656e-04, -9.8234e-04, -8.9311e-04]],\n",
      "\n",
      "         [[-1.3101e-03, -4.6451e-03, -6.0188e-03, -5.8902e-03, -6.7064e-03],\n",
      "          [-6.7241e-03, -7.4858e-03, -7.6438e-03, -7.0939e-03, -5.7763e-03],\n",
      "          [-9.7300e-03, -1.0280e-02, -7.3525e-03, -6.6067e-03, -6.9977e-03],\n",
      "          [-1.2818e-02, -9.6109e-03, -6.3734e-03, -6.7331e-03, -7.6301e-03],\n",
      "          [-9.0835e-03, -8.0145e-03, -1.0303e-02, -1.2118e-02, -1.1312e-02]],\n",
      "\n",
      "         [[ 1.4618e-03,  9.1002e-04,  2.7364e-04,  3.2940e-04, -1.9274e-04],\n",
      "          [ 9.9417e-04,  1.3575e-05, -8.8607e-04, -2.5627e-04, -1.1609e-03],\n",
      "          [-2.2278e-04, -1.7578e-03, -2.3737e-03, -7.3029e-04, -1.1727e-03],\n",
      "          [-1.3689e-03, -3.3649e-03, -3.2225e-03, -1.5222e-03, -1.8007e-03],\n",
      "          [-2.4071e-03, -3.6660e-03, -1.5674e-03, -3.3503e-04, -1.7874e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.3573e-03,  1.5850e-03,  7.1024e-05, -9.7843e-05, -1.6806e-04],\n",
      "          [ 6.8955e-04,  4.4527e-04,  1.8212e-05,  5.4165e-06, -7.3105e-05],\n",
      "          [ 1.1657e-04,  2.0028e-05,  4.5643e-05,  2.5657e-05,  1.3145e-05],\n",
      "          [-1.6267e-04,  1.2574e-05,  2.5072e-05,  8.0585e-06,  1.6454e-06],\n",
      "          [-2.8690e-05,  7.5395e-05,  4.1483e-05,  4.5171e-06, -4.2670e-07]],\n",
      "\n",
      "         [[ 5.8500e-05, -2.4273e-06,  4.5267e-07, -1.6893e-05, -6.4500e-05],\n",
      "          [ 9.8481e-06, -1.2217e-05, -5.7673e-07, -1.0132e-06, -2.2208e-05],\n",
      "          [ 3.0626e-05,  3.4878e-06,  2.7491e-07, -1.9436e-08, -9.7276e-06],\n",
      "          [ 5.5383e-06,  6.4683e-06,  2.3731e-06,  9.9536e-08, -3.6299e-08],\n",
      "          [ 3.4826e-06,  8.0079e-06,  5.5778e-06,  8.1347e-07,  1.1107e-07]],\n",
      "\n",
      "         [[ 1.8383e-03,  2.4600e-03,  1.2556e-03,  3.2949e-04,  1.6637e-04],\n",
      "          [ 1.5401e-03,  1.6453e-03,  7.1005e-04,  8.8992e-05,  2.3868e-04],\n",
      "          [-4.4577e-04,  4.3941e-04,  4.9309e-04, -2.3733e-05,  2.9166e-04],\n",
      "          [-1.4639e-03, -3.9909e-04, -7.6672e-05, -1.1148e-04,  2.1665e-04],\n",
      "          [-1.0069e-03, -4.7238e-04, -2.6699e-04, -1.5187e-04,  1.6395e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.6565e-04,  2.1241e-05, -3.6317e-08, -1.9459e-06, -8.0041e-05],\n",
      "          [-3.1031e-05,  7.2879e-06,  4.2773e-06,  1.8109e-07, -2.8732e-07],\n",
      "          [-2.8342e-05,  4.0392e-05,  1.8847e-05,  1.4408e-06, -5.5935e-07],\n",
      "          [ 8.4816e-06,  1.5076e-05,  1.7104e-05,  6.1899e-07,  1.7484e-07],\n",
      "          [ 9.2290e-05,  1.3372e-05,  1.6699e-05,  3.6416e-07,  6.3454e-08]],\n",
      "\n",
      "         [[ 1.7990e-03,  1.9720e-03,  4.9604e-04,  8.2954e-05,  4.2928e-04],\n",
      "          [ 5.5127e-04,  3.3489e-04,  5.7764e-04,  5.4962e-06,  3.7200e-04],\n",
      "          [-2.6870e-04,  1.6538e-04,  3.8521e-04,  5.2900e-06,  4.4744e-04],\n",
      "          [-1.0387e-03, -5.4373e-04, -2.8498e-04, -1.8827e-04,  2.6656e-04],\n",
      "          [-6.3980e-04, -3.9283e-04, -4.0613e-04, -2.3578e-04,  2.2725e-04]],\n",
      "\n",
      "         [[-1.8789e-04,  4.3061e-04,  8.5751e-04,  2.6430e-04, -7.0707e-06],\n",
      "          [-2.3448e-04,  9.4719e-04,  5.2823e-04,  5.2633e-06, -2.1631e-06],\n",
      "          [-5.6091e-04,  3.9880e-04,  4.5995e-05,  7.9168e-06,  1.1101e-06],\n",
      "          [-6.3089e-04,  9.1518e-05,  7.5591e-06,  2.2533e-05,  1.6752e-06],\n",
      "          [-7.1138e-04, -1.0152e-05,  2.0488e-05,  2.4163e-05,  1.9742e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4442e-04, -2.5935e-04, -5.8842e-04, -9.3368e-04, -1.1623e-03],\n",
      "          [ 6.4903e-04,  1.7945e-04,  2.0228e-03,  3.3625e-03,  3.8048e-03],\n",
      "          [ 4.0776e-03,  5.2878e-03,  6.6292e-03,  7.6469e-03,  7.1702e-03],\n",
      "          [ 9.6081e-03,  1.0816e-02,  9.5541e-03,  9.1592e-03,  8.4495e-03],\n",
      "          [ 1.0879e-02,  9.7743e-03,  6.0412e-03,  5.1433e-03,  6.2927e-03]],\n",
      "\n",
      "         [[ 5.5887e-05,  6.0695e-05,  3.5221e-05, -9.3986e-05, -1.3671e-04],\n",
      "          [ 1.1342e-04,  1.9209e-04,  2.4306e-04,  3.0552e-04, -5.7050e-05],\n",
      "          [ 2.0356e-04,  4.4977e-04,  1.8405e-04,  3.2418e-04,  2.1682e-04],\n",
      "          [ 2.3393e-04,  4.0229e-04,  1.7199e-04,  1.3189e-04,  1.6521e-04],\n",
      "          [ 3.4555e-04,  2.0008e-04,  6.3750e-05,  6.1383e-05,  1.3449e-04]],\n",
      "\n",
      "         [[ 3.1455e-03,  4.2313e-03,  3.6195e-03,  3.1792e-03,  1.2131e-03],\n",
      "          [ 2.4255e-03,  1.0740e-03,  2.6332e-04,  2.1772e-03,  5.5549e-03],\n",
      "          [ 5.6750e-03,  3.8397e-03,  4.0107e-03,  5.3728e-03,  9.9336e-03],\n",
      "          [ 1.4473e-02,  1.2576e-02,  1.2272e-02,  1.1099e-02,  1.2991e-02],\n",
      "          [ 2.1587e-02,  2.1128e-02,  1.7138e-02,  1.5362e-02,  1.4979e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0990e-04,  2.1220e-04,  6.0772e-04,  1.0968e-03,  5.1092e-04],\n",
      "          [ 3.4329e-04,  7.2224e-04,  2.8096e-04,  9.8848e-04,  9.0257e-04],\n",
      "          [ 1.4777e-03,  1.2504e-03,  2.4892e-05,  3.6054e-05,  6.4828e-04],\n",
      "          [ 2.8498e-03,  1.8776e-03,  1.3996e-03,  6.6919e-04,  8.4822e-04],\n",
      "          [ 2.1100e-03,  1.0818e-03,  8.6294e-04,  2.9929e-04,  7.9505e-04]],\n",
      "\n",
      "         [[ 2.3372e-03,  1.1138e-03, -5.0572e-04, -2.5238e-04,  5.6782e-04],\n",
      "          [ 2.3649e-03,  6.9633e-04,  1.0046e-03,  1.6332e-03,  5.2758e-03],\n",
      "          [ 5.9846e-03,  5.1643e-03,  5.8362e-03,  5.8565e-03,  7.9124e-03],\n",
      "          [ 1.3051e-02,  1.3389e-02,  1.1863e-02,  1.0800e-02,  1.0476e-02],\n",
      "          [ 1.8274e-02,  1.7997e-02,  1.4392e-02,  1.3573e-02,  1.3797e-02]],\n",
      "\n",
      "         [[-3.1917e-04,  5.9933e-04,  6.6787e-04,  3.3378e-04, -7.0653e-05],\n",
      "          [ 7.8467e-04,  9.5117e-04,  1.2778e-04,  1.1159e-04,  4.7433e-04],\n",
      "          [ 1.8363e-03,  1.7149e-03,  7.9868e-04,  9.3620e-04,  1.5662e-03],\n",
      "          [ 1.8365e-03,  2.2883e-03,  1.6118e-03,  1.7480e-03,  1.7170e-03],\n",
      "          [ 1.9309e-03,  3.7785e-03,  2.3628e-03,  1.2509e-03,  7.0832e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2384e-03,  2.1543e-03,  1.9926e-04, -3.2334e-04,  3.1056e-04],\n",
      "          [ 3.4358e-03,  1.7360e-03,  4.6256e-04,  7.7086e-04,  1.0798e-03],\n",
      "          [ 2.1344e-03,  5.2203e-04,  3.7392e-04,  7.1024e-05,  1.6460e-05],\n",
      "          [ 8.9965e-04,  9.9389e-04,  1.7814e-04, -9.2015e-04, -1.3868e-03],\n",
      "          [ 1.0854e-03,  2.1347e-03,  1.4396e-03,  2.5455e-04, -7.2948e-04]],\n",
      "\n",
      "         [[ 6.4899e-05,  1.0486e-04,  7.9502e-05,  6.9253e-05,  4.9496e-05],\n",
      "          [ 9.6198e-05,  1.2017e-04,  5.0087e-05,  8.2153e-05,  1.5232e-04],\n",
      "          [ 6.0925e-05,  1.0083e-04,  8.6794e-05,  8.1621e-05,  7.8823e-05],\n",
      "          [ 5.6858e-06,  9.4812e-05,  1.0655e-04,  9.0038e-05,  1.0264e-05],\n",
      "          [ 5.8734e-05,  4.5215e-05,  5.5343e-05, -3.1828e-05, -5.2173e-06]],\n",
      "\n",
      "         [[-2.0646e-05,  1.5156e-03,  2.3660e-03,  2.0543e-03,  2.8925e-03],\n",
      "          [ 4.2547e-04,  8.7358e-04,  1.0415e-03,  5.0462e-04,  1.0293e-03],\n",
      "          [ 1.8086e-03,  1.5639e-03,  2.0020e-03,  1.4200e-03,  1.0982e-03],\n",
      "          [ 1.9352e-03,  1.8069e-03,  1.9963e-03,  1.2007e-03,  2.6798e-04],\n",
      "          [ 9.5449e-04,  1.5957e-03,  1.3129e-03,  1.1095e-03,  2.0745e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.0777e-04, -3.6297e-04, -3.7746e-04, -2.5778e-04, -8.0605e-05],\n",
      "          [ 4.2417e-06,  2.1018e-04,  4.7424e-04,  2.0513e-04,  9.9667e-05],\n",
      "          [-9.4672e-05,  2.3727e-04,  1.9356e-04,  1.2041e-04,  7.1528e-05],\n",
      "          [-5.8249e-08, -3.6626e-05,  9.4796e-05, -1.6147e-05, -4.2806e-04],\n",
      "          [ 8.6778e-05,  7.3493e-06, -3.7588e-05, -2.4296e-05, -6.7122e-04]],\n",
      "\n",
      "         [[ 8.8823e-04,  6.5730e-04,  1.3713e-03,  1.4474e-03,  2.6009e-03],\n",
      "          [ 5.8190e-04,  1.6073e-04,  7.5496e-04,  1.0638e-03,  1.1309e-03],\n",
      "          [ 4.9234e-04,  4.4498e-04,  1.0743e-03,  9.8781e-04,  1.1260e-03],\n",
      "          [ 2.3755e-04,  4.2117e-04,  8.3289e-04,  7.1549e-04,  6.6580e-04],\n",
      "          [ 3.3675e-04,  1.3307e-03,  1.5034e-03,  1.4904e-03,  8.6095e-04]],\n",
      "\n",
      "         [[-5.7926e-04,  1.0224e-03,  1.3680e-03,  7.6694e-04,  1.6154e-04],\n",
      "          [ 1.3102e-04,  1.3795e-03,  9.1337e-04,  3.1590e-04, -1.1404e-04],\n",
      "          [ 9.3048e-04,  1.1271e-03,  5.4962e-04,  2.3030e-04, -1.3946e-04],\n",
      "          [ 1.0057e-03,  4.6742e-04,  5.4778e-04,  8.0621e-04,  6.1866e-04],\n",
      "          [ 1.3300e-04,  6.9935e-06,  8.2191e-04,  1.3076e-03,  1.1951e-03]]]]), 'conv2.bias': tensor([-0.0318,  0.0299, -0.0321,  0.0372, -0.0215, -0.0259,  0.0194, -0.0170,\n",
      "        -0.0175, -0.0333, -0.0036, -0.0114,  0.0018, -0.0028,  0.0391, -0.0113,\n",
      "         0.0137, -0.0012, -0.0070,  0.0064,  0.0389,  0.0160, -0.0063,  0.0430,\n",
      "        -0.0275, -0.0290,  0.0454, -0.0043,  0.0033,  0.0008,  0.0122, -0.0054]), 'fc1.weight': tensor([[0.0003, 0.0033, 0.0058,  ..., 0.0008, 0.0011, 0.0004],\n",
      "        [0.0003, 0.0034, 0.0060,  ..., 0.0009, 0.0011, 0.0004],\n",
      "        [0.0003, 0.0037, 0.0064,  ..., 0.0009, 0.0012, 0.0004],\n",
      "        ...,\n",
      "        [0.0003, 0.0034, 0.0059,  ..., 0.0009, 0.0011, 0.0004],\n",
      "        [0.0003, 0.0034, 0.0059,  ..., 0.0009, 0.0011, 0.0004],\n",
      "        [0.0003, 0.0035, 0.0061,  ..., 0.0009, 0.0011, 0.0004]]), 'fc1.bias': tensor([ 0.0466,  0.0483,  0.0517, -0.3580, -0.0432,  0.0512,  0.0576,  0.0480,\n",
      "         0.0481,  0.0497])}\n",
      "!-- Client 7 is normal and start iterations. ---!\n",
      "Epoch [1/3], Average Loss: 0.7349189519882202, Average Accuracy: 0.7423465251922607, Average Error: 0.2576535046100616, Culminative Time Used: 0.8266631998121738\n",
      "Epoch [2/3], Average Loss: 0.3059764504432678, Average Accuracy: 0.8884429931640625, Average Error: 0.1115570142865181, Culminative Time Used: 1.6175602003932\n",
      "Epoch [3/3], Average Loss: 0.1317634731531143, Average Accuracy: 0.9683607220649719, Average Error: 0.0316392555832863, Culminative Time Used: 2.5274769999086857\n",
      "{'conv1.weight': tensor([[[[-1.2785e-03, -1.4811e-03, -5.2794e-04,  5.3887e-04,  1.8198e-04],\n",
      "          [-1.3152e-03, -2.0080e-03, -1.2533e-03, -1.1412e-03, -2.6611e-03],\n",
      "          [-1.7902e-03, -1.6578e-03, -1.3098e-03, -3.1205e-03, -6.4157e-03],\n",
      "          [-1.8753e-03, -1.3942e-03, -1.9972e-03, -5.2181e-03, -1.0151e-02],\n",
      "          [-1.4655e-03, -9.4581e-04, -2.0391e-03, -5.1029e-03, -1.0022e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.6646e-04, -6.7829e-04, -8.0964e-04, -7.3724e-04, -3.5862e-04],\n",
      "          [-1.8926e-04, -7.4105e-04, -1.2218e-03, -1.4762e-03, -1.2277e-03],\n",
      "          [ 2.7683e-05, -2.3197e-04, -9.1968e-04, -1.6199e-03, -1.6570e-03],\n",
      "          [ 1.2651e-04,  4.5998e-05, -3.8562e-04, -1.3937e-03, -1.8941e-03],\n",
      "          [ 1.0351e-04,  2.1306e-07, -1.4585e-04, -5.8466e-04, -9.3142e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 5.0795e-03,  2.8236e-03,  1.5142e-04, -1.8658e-03, -3.0938e-03],\n",
      "          [ 4.6015e-03,  2.7823e-03,  3.4979e-04, -1.6082e-03, -3.5805e-03],\n",
      "          [ 1.5398e-03,  3.2114e-04, -1.4053e-03, -2.9295e-03, -3.9246e-03],\n",
      "          [-1.7141e-03, -2.4749e-03, -3.0032e-03, -3.7474e-03, -2.5312e-03],\n",
      "          [-4.6057e-03, -3.8117e-03, -3.3479e-03, -2.6830e-03, -4.2667e-04]]],\n",
      "\n",
      "\n",
      "        [[[-2.7046e-03, -2.7146e-03, -1.7793e-03,  8.9193e-04,  4.2419e-03],\n",
      "          [-3.7861e-03, -3.7302e-03, -1.8112e-03,  1.8108e-03,  3.6619e-03],\n",
      "          [-3.8291e-03, -3.6103e-03, -4.8543e-04,  2.4267e-03,  2.2363e-03],\n",
      "          [-2.2252e-03, -1.4143e-03,  1.4255e-03,  2.4383e-03,  1.3340e-03],\n",
      "          [ 2.1257e-03,  1.6216e-03,  1.8062e-03,  2.0028e-03,  1.5251e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.2813e-03, -3.4363e-03, -3.7994e-03, -4.1326e-03, -5.0300e-03],\n",
      "          [-2.7529e-03, -3.1156e-03, -4.1812e-03, -6.3038e-03, -7.5883e-03],\n",
      "          [-2.8508e-03, -4.2090e-03, -5.7055e-03, -7.9092e-03, -9.5057e-03],\n",
      "          [-3.3839e-03, -4.0470e-03, -5.7491e-03, -8.5600e-03, -1.0313e-02],\n",
      "          [-3.2267e-03, -4.0323e-03, -5.9981e-03, -8.8746e-03, -1.0175e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.4801e-03, -4.3203e-03, -4.5682e-03, -3.9867e-03, -2.6822e-03],\n",
      "          [-3.2284e-04, -1.7822e-03, -2.5692e-03, -1.4072e-03, -1.4296e-05],\n",
      "          [ 4.5549e-04, -1.4165e-03, -1.7902e-03,  2.9490e-04,  1.4946e-03],\n",
      "          [-8.6773e-04, -2.2174e-03, -1.7114e-03,  1.0175e-03,  2.5543e-03],\n",
      "          [-2.3546e-03, -2.0078e-03, -1.1488e-03,  8.5900e-04,  2.3460e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1553e-03,  2.7069e-03,  2.4876e-03,  2.5562e-03,  2.6805e-03],\n",
      "          [ 2.0527e-03,  3.1737e-03,  3.7782e-03,  3.6055e-03,  3.2083e-03],\n",
      "          [ 1.0839e-03,  1.6631e-03,  2.9592e-03,  3.2494e-03,  2.4859e-03],\n",
      "          [ 2.0307e-04,  2.0629e-04,  1.2130e-03,  1.9172e-03,  1.6365e-03],\n",
      "          [ 7.7971e-04,  6.1772e-04,  7.5907e-04,  7.4823e-04,  9.1340e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6303e-03,  5.0188e-05, -1.9622e-03, -3.4145e-03, -4.7057e-03],\n",
      "          [ 8.7251e-04, -1.1033e-03, -3.3692e-03, -4.3007e-03, -5.2848e-03],\n",
      "          [-3.6467e-04, -3.1266e-03, -4.4946e-03, -4.3807e-03, -4.6028e-03],\n",
      "          [-8.1854e-04, -2.4828e-03, -2.8428e-03, -2.1484e-03, -1.7846e-03],\n",
      "          [ 1.5996e-03,  6.3110e-04,  7.7125e-04,  1.2003e-03,  3.4223e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.1166e-04, -1.5060e-04,  3.7722e-04,  1.8257e-03,  4.2577e-03],\n",
      "          [-1.8073e-04, -4.0409e-04, -1.9085e-04,  1.8156e-03,  4.4397e-03],\n",
      "          [-1.9900e-03, -2.3365e-03, -1.6816e-03, -2.1639e-04,  2.9418e-03],\n",
      "          [-3.2431e-03, -2.5894e-03, -1.8566e-03, -5.4659e-04,  1.6915e-03],\n",
      "          [-2.0066e-03, -1.6818e-03, -1.5272e-03, -1.9125e-04,  1.8086e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.3679e-04,  3.2333e-04,  3.7846e-04, -4.5522e-05, -6.3242e-04],\n",
      "          [-5.1918e-04, -4.3858e-04, -5.1472e-04, -9.1856e-04, -1.0843e-03],\n",
      "          [-1.1340e-04, -2.5137e-04, -5.4658e-04, -1.0842e-03, -1.3430e-03],\n",
      "          [-2.1451e-04, -1.7974e-04, -1.3254e-04, -3.2655e-04, -8.6683e-04],\n",
      "          [-3.1297e-03, -1.3989e-03, -2.6451e-04,  4.1115e-04,  2.1895e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3857e-02,  1.4035e-02,  1.0769e-02,  6.3536e-03,  5.6221e-03],\n",
      "          [ 1.7407e-02,  1.6006e-02,  8.4855e-03,  2.6770e-03,  3.1416e-03],\n",
      "          [ 1.8307e-02,  1.5900e-02,  7.5621e-03,  3.4306e-03,  4.5699e-03],\n",
      "          [ 1.3972e-02,  1.3156e-02,  9.3864e-03,  8.1735e-03,  9.7436e-03],\n",
      "          [ 9.5017e-03,  9.7537e-03,  9.0456e-03,  9.5938e-03,  1.3554e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3316e-03,  2.2562e-03,  3.1364e-03,  2.4829e-03,  8.7020e-05],\n",
      "          [ 1.1901e-03,  6.2203e-04,  2.0516e-03,  3.0093e-03,  2.0542e-03],\n",
      "          [ 8.5688e-04,  6.9311e-05,  1.2645e-03,  3.5893e-03,  3.6989e-03],\n",
      "          [ 7.1782e-04,  2.5885e-04,  1.3553e-03,  3.2044e-03,  4.1765e-03],\n",
      "          [ 1.4216e-03,  1.2868e-03,  2.4608e-03,  3.4478e-03,  3.9570e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.2458e-04,  4.6976e-04,  2.5335e-04,  3.6590e-04,  3.6981e-04],\n",
      "          [ 4.8695e-04,  5.8495e-05, -9.9075e-05,  5.4320e-04,  1.2157e-03],\n",
      "          [ 2.1185e-03, -1.5986e-04, -1.7958e-03, -1.2858e-03,  7.4985e-04],\n",
      "          [ 2.8789e-03,  7.7253e-04, -9.1377e-04, -6.2544e-04,  3.4888e-04],\n",
      "          [ 2.5685e-03,  2.1014e-03,  2.1361e-03,  1.3849e-03, -1.2529e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2285e-03,  1.1063e-03,  3.8483e-04, -4.3470e-04, -5.4213e-04],\n",
      "          [ 6.4012e-04,  4.8760e-04,  2.1114e-04, -1.2594e-04, -1.2320e-04],\n",
      "          [ 9.9666e-04,  9.8531e-04,  9.3127e-04,  7.5927e-04,  1.1388e-03],\n",
      "          [ 1.0218e-03,  1.1645e-03,  1.9867e-03,  3.3642e-03,  4.3946e-03],\n",
      "          [ 7.5037e-04,  1.5557e-03,  3.9662e-03,  5.7502e-03,  5.7023e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1481e-02,  9.3604e-03,  7.8933e-03,  1.2767e-02,  1.6004e-02],\n",
      "          [ 7.6375e-03,  6.2046e-03,  7.5885e-03,  1.4063e-02,  1.6356e-02],\n",
      "          [ 4.6862e-03,  6.5797e-03,  9.5803e-03,  1.3318e-02,  1.3275e-02],\n",
      "          [ 2.6790e-03,  6.0064e-03,  9.8311e-03,  1.0330e-02,  7.8800e-03],\n",
      "          [ 2.7530e-03,  5.5921e-03,  6.5751e-03,  4.5870e-03,  2.3522e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.4105e-03, -2.6708e-03, -1.5773e-03, -1.1517e-03, -4.7101e-04],\n",
      "          [-5.1014e-03, -3.0867e-03, -1.5539e-03, -1.0371e-03, -6.8309e-04],\n",
      "          [-3.6365e-03, -2.1428e-03, -1.5038e-03, -8.9788e-04, -7.2504e-04],\n",
      "          [-3.0881e-03, -2.3556e-03, -1.4245e-03, -1.3102e-03, -1.2668e-03],\n",
      "          [-3.5122e-03, -3.1017e-03, -1.8310e-03, -1.7561e-03, -1.4988e-03]]]]), 'conv1.bias': tensor([-0.0089, -0.0014,  0.0449,  0.0092, -0.0084, -0.0021,  0.0007, -0.0152,\n",
      "         0.0034, -0.0066,  0.0055,  0.0032,  0.0087,  0.0069,  0.0624, -0.0058]), 'conv2.weight': tensor([[[[-9.6028e-04, -3.8376e-04, -1.6412e-03, -6.0331e-03, -5.8370e-03],\n",
      "          [-1.5867e-03, -1.5005e-03, -1.6760e-03, -3.0769e-03, -4.9453e-04],\n",
      "          [-4.4085e-03, -3.0008e-03, -2.8790e-03, -9.2960e-04,  3.9054e-03],\n",
      "          [-4.4713e-03, -4.8367e-03, -4.7519e-03, -2.8186e-03,  5.0440e-04],\n",
      "          [-2.5919e-03, -4.2300e-03, -7.8808e-03, -5.1331e-03, -2.4906e-03]],\n",
      "\n",
      "         [[-9.0505e-05, -1.9570e-04, -3.1683e-04, -9.3770e-04, -1.0518e-03],\n",
      "          [ 1.2160e-04,  2.5881e-05, -2.6288e-04, -2.7587e-04, -3.4399e-04],\n",
      "          [ 2.6249e-04,  1.2238e-04, -1.4831e-04, -1.2534e-04,  9.6965e-05],\n",
      "          [ 5.0050e-05,  7.2223e-06, -3.4978e-04,  4.5206e-05,  4.5948e-04],\n",
      "          [-7.9255e-05, -2.2549e-04, -5.6757e-04,  1.4362e-04,  2.8055e-04]],\n",
      "\n",
      "         [[ 1.5829e-04, -1.2611e-03, -3.1526e-03, -5.2163e-03, -8.8179e-03],\n",
      "          [ 9.7116e-04, -1.2342e-03, -4.7799e-03, -7.6783e-03, -7.5366e-03],\n",
      "          [-2.1019e-03, -2.4717e-03, -5.5351e-03, -5.6196e-03, -2.7974e-03],\n",
      "          [-6.3708e-03, -4.9054e-03, -7.1852e-03, -4.2457e-03, -1.3761e-03],\n",
      "          [-6.6445e-03, -8.2881e-03, -9.4971e-03, -7.8504e-03, -4.6005e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1446e-04, -4.6384e-04, -6.3436e-04, -5.4288e-04, -5.0602e-04],\n",
      "          [ 1.3243e-04,  2.7487e-04,  1.1506e-04,  3.0927e-04,  4.7260e-04],\n",
      "          [-1.4094e-04, -1.8486e-04, -5.4444e-04, -4.2139e-05,  5.3013e-04],\n",
      "          [-1.0062e-03, -8.0663e-04, -1.7090e-03, -5.9040e-04,  8.2949e-05],\n",
      "          [-7.3672e-04, -1.3316e-03, -1.3607e-03, -5.6851e-04,  1.3548e-04]],\n",
      "\n",
      "         [[ 9.0046e-04,  4.2150e-04, -2.6203e-03, -5.5571e-03, -6.5272e-03],\n",
      "          [-1.2103e-03, -1.4892e-03, -3.7949e-03, -6.5144e-03, -4.8315e-03],\n",
      "          [-4.4691e-03, -3.2233e-03, -5.6112e-03, -3.5656e-03, -1.7944e-03],\n",
      "          [-5.5930e-03, -5.8819e-03, -6.3265e-03, -4.1428e-03, -3.8225e-03],\n",
      "          [-4.0732e-03, -6.7370e-03, -8.7353e-03, -7.0209e-03, -6.6791e-03]],\n",
      "\n",
      "         [[ 1.3867e-03, -5.6360e-04, -4.3242e-04,  2.4418e-04, -1.3229e-03],\n",
      "          [ 1.1147e-03, -2.4120e-04,  1.4229e-04, -4.8228e-04, -1.4405e-03],\n",
      "          [-3.7354e-04, -1.2892e-03, -3.6115e-04, -1.4563e-03, -1.4971e-03],\n",
      "          [-8.6770e-04, -1.6968e-03, -1.0543e-03, -2.7679e-03, -1.0298e-03],\n",
      "          [-5.3458e-04, -1.1763e-03, -1.5082e-03, -3.1219e-03, -6.2965e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.3165e-03, -9.0971e-04,  1.0682e-03,  1.4307e-03,  1.0674e-04],\n",
      "          [-1.2073e-03,  2.8281e-04,  1.9004e-03,  2.7102e-03,  3.2797e-03],\n",
      "          [ 1.0711e-03,  1.3849e-03,  2.2385e-03,  5.7332e-03,  4.2851e-03],\n",
      "          [ 1.7034e-03,  2.2742e-03,  4.0579e-03,  5.9704e-03,  2.3697e-03],\n",
      "          [-8.4828e-04,  2.6284e-03,  5.2411e-03,  4.2960e-03,  5.9623e-04]],\n",
      "\n",
      "         [[-5.1318e-04, -5.7505e-04, -1.3264e-04, -7.0420e-05, -8.2669e-04],\n",
      "          [-2.4722e-04, -4.7748e-04, -2.9498e-04, -4.7727e-05, -8.7359e-04],\n",
      "          [-2.1817e-04, -1.0014e-04,  5.5947e-05, -1.7942e-05, -4.4615e-04],\n",
      "          [ 9.5045e-05,  2.2414e-04,  3.6690e-04,  2.4412e-04, -2.8458e-05],\n",
      "          [ 2.2955e-04,  2.8257e-04,  4.1591e-04,  6.1052e-04,  1.4859e-04]],\n",
      "\n",
      "         [[-6.7047e-03, -6.5607e-03, -6.2342e-03, -2.6233e-03, -3.0392e-03],\n",
      "          [-5.6232e-03, -3.8093e-03, -3.6078e-03, -2.4337e-03,  8.2237e-04],\n",
      "          [-4.7910e-03, -2.3548e-03, -1.4788e-03, -4.0341e-04,  2.8813e-03],\n",
      "          [-2.1904e-03, -7.5853e-04,  1.3534e-03,  3.7632e-03,  4.0034e-03],\n",
      "          [-2.8490e-03,  1.4984e-03,  3.4410e-03,  4.0359e-03,  4.3768e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.3880e-04,  8.7438e-05,  1.4448e-04,  7.2613e-04,  5.1116e-05],\n",
      "          [-1.9960e-04, -1.7091e-04, -2.8769e-05,  3.2563e-04, -8.3184e-05],\n",
      "          [-2.3324e-04,  1.2537e-04,  1.3617e-04, -1.8989e-04, -6.3634e-05],\n",
      "          [-5.1746e-06,  3.0202e-04,  3.3374e-04,  3.8146e-05, -4.9592e-06],\n",
      "          [-2.7218e-04,  5.3974e-04, -1.4546e-04, -1.8826e-04,  5.4581e-04]],\n",
      "\n",
      "         [[-5.6021e-03, -3.6603e-03, -2.7126e-03, -2.9629e-03, -1.5748e-03],\n",
      "          [-5.7052e-03, -3.1860e-03, -2.8662e-03, -2.9903e-03,  1.6160e-03],\n",
      "          [-5.2812e-03, -4.1961e-03, -3.0329e-03, -6.1909e-04,  1.5756e-03],\n",
      "          [-3.5015e-03, -2.0987e-03,  2.4325e-04,  2.0294e-03,  1.5319e-03],\n",
      "          [-5.4588e-03, -1.1060e-03,  2.0099e-03,  4.3707e-04,  1.4355e-03]],\n",
      "\n",
      "         [[-1.6258e-03, -1.4320e-03, -1.9661e-03, -2.0051e-03, -1.0056e-03],\n",
      "          [-1.7174e-03, -1.0545e-03, -5.5138e-04, -1.3253e-04, -6.3483e-04],\n",
      "          [-1.5990e-03,  1.4237e-04,  1.1443e-03,  4.0666e-04,  1.0785e-03],\n",
      "          [-3.5665e-04,  9.4099e-04,  8.7946e-04,  1.3236e-03,  3.3640e-03],\n",
      "          [ 5.3390e-04,  1.1364e-03,  1.4441e-03,  2.3746e-03,  2.7917e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 3.9125e-03,  1.9645e-03, -1.9617e-03, -6.0721e-03, -8.1046e-03],\n",
      "          [ 2.9581e-03, -1.1119e-04, -3.1634e-03, -5.2271e-03, -3.8058e-03],\n",
      "          [-1.5408e-03, -3.8332e-03, -2.8605e-03, -2.8396e-03, -3.4993e-03],\n",
      "          [-3.2970e-03, -2.9316e-03, -6.0878e-04, -7.9502e-05, -2.7070e-03],\n",
      "          [-7.8139e-04,  3.3296e-04,  1.5301e-03, -3.7678e-04, -1.4209e-03]],\n",
      "\n",
      "         [[-2.7255e-04, -1.6567e-04, -1.9284e-04, -6.2021e-04, -2.6553e-04],\n",
      "          [-2.0203e-04, -1.6594e-04, -6.2723e-05, -1.0847e-03, -1.4321e-03],\n",
      "          [ 3.2267e-06, -2.2871e-05, -5.2481e-05, -4.3207e-04, -1.0818e-03],\n",
      "          [-7.9217e-06, -9.1212e-06,  5.8524e-05, -5.0975e-05, -1.2788e-04],\n",
      "          [-4.0473e-04, -2.2385e-04,  1.6804e-04,  7.3592e-05,  1.6728e-04]],\n",
      "\n",
      "         [[ 4.6250e-03,  2.1186e-03, -1.6440e-03, -7.9398e-03, -1.4227e-02],\n",
      "          [ 7.2808e-03,  4.4861e-03, -1.0314e-03, -5.6449e-03, -1.0912e-02],\n",
      "          [ 6.1138e-03,  2.2304e-03, -1.7562e-03, -4.5732e-03, -5.8271e-03],\n",
      "          [-9.5293e-04, -1.9084e-03, -1.4522e-03, -3.3854e-03, -4.6329e-03],\n",
      "          [-3.3260e-03, -2.6152e-03, -1.4789e-03, -1.5997e-03, -3.0029e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.7085e-04,  2.4106e-04,  3.2942e-05, -4.8915e-04, -5.2929e-04],\n",
      "          [ 3.4141e-04,  3.7518e-04,  1.3000e-04, -3.3264e-04, -1.6572e-03],\n",
      "          [-2.6646e-06,  2.1182e-04, -2.0807e-04, -3.5126e-04, -9.5308e-04],\n",
      "          [-2.4042e-04,  1.6904e-04,  8.0274e-04,  1.8153e-04, -3.9194e-04],\n",
      "          [-2.1510e-04,  2.6386e-04,  2.8434e-04,  8.5967e-04,  9.3169e-04]],\n",
      "\n",
      "         [[ 3.6520e-03,  2.6775e-03, -1.4828e-03, -5.9234e-03, -9.9789e-03],\n",
      "          [ 5.3058e-03,  2.6039e-03, -2.4320e-03, -4.9286e-03, -4.6125e-03],\n",
      "          [ 1.8677e-03, -8.3215e-04, -1.9733e-03, -4.1507e-03, -3.2103e-03],\n",
      "          [-1.8802e-03, -1.6773e-03, -5.6235e-04, -1.8457e-03, -3.4050e-03],\n",
      "          [-2.1675e-03, -1.6474e-03, -1.0911e-03, -2.0489e-03, -1.6536e-03]],\n",
      "\n",
      "         [[ 2.3979e-03,  1.2135e-03,  9.3466e-04, -5.9688e-04, -2.2220e-03],\n",
      "          [ 1.8985e-03,  1.2757e-03,  1.0539e-03, -1.0514e-03, -2.6955e-03],\n",
      "          [ 1.6303e-03,  1.6584e-03,  4.4554e-04, -1.5306e-03, -1.5246e-03],\n",
      "          [ 2.6807e-04,  1.8935e-04, -6.4164e-04, -5.4104e-04, -8.8555e-05],\n",
      "          [-3.7993e-04, -1.0167e-03, -6.9644e-04, -2.4358e-04, -4.0340e-04]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 5.9778e-04,  7.4907e-04,  6.8305e-05, -1.6803e-04, -2.5591e-04],\n",
      "          [ 2.7674e-04,  2.8266e-04,  2.6698e-05, -2.9004e-06, -1.5609e-04],\n",
      "          [-1.5754e-04,  9.6034e-07,  2.3247e-05,  4.9564e-06,  4.8392e-06],\n",
      "          [-1.2480e-04,  4.4810e-06,  1.4627e-05,  1.7925e-06,  9.8405e-07],\n",
      "          [-1.7694e-04,  1.4629e-05,  3.6052e-05,  1.0550e-05,  6.1344e-06]],\n",
      "\n",
      "         [[ 3.3756e-05, -9.1636e-07,  1.2830e-07, -2.7595e-05, -1.6441e-04],\n",
      "          [ 6.8558e-05,  1.7357e-05, -1.4008e-07,  2.0550e-06, -3.1196e-05],\n",
      "          [ 1.4957e-04,  3.2644e-05,  6.6425e-07,  5.1182e-07, -6.0351e-06],\n",
      "          [ 3.0278e-05,  3.9902e-06,  2.3268e-06,  2.1148e-07, -1.5301e-08],\n",
      "          [ 6.8564e-06,  3.3714e-06,  4.4652e-06,  1.7622e-07,  1.7761e-07]],\n",
      "\n",
      "         [[ 7.9185e-04,  5.3481e-04, -1.9354e-04, -7.9420e-05, -2.0836e-04],\n",
      "          [ 3.2464e-04,  7.2011e-04, -6.8194e-05, -2.3608e-04,  1.3822e-05],\n",
      "          [-8.5206e-04,  2.1948e-04,  1.0362e-04, -1.3746e-04,  9.4323e-06],\n",
      "          [-1.6532e-03, -5.5361e-04, -1.1752e-04, -7.1174e-05,  1.0241e-04],\n",
      "          [-1.3463e-03, -6.7386e-04, -2.8523e-04, -1.1326e-04,  9.1253e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.8173e-04,  2.5296e-05, -1.5763e-07, -8.7106e-07, -1.2454e-04],\n",
      "          [ 4.5240e-05,  1.8708e-05,  2.3749e-06,  5.1486e-07,  7.2165e-06],\n",
      "          [-7.7100e-05,  3.9807e-05,  2.3438e-05,  5.2016e-07,  1.7627e-07],\n",
      "          [-4.1960e-06,  5.8932e-06,  1.1992e-05,  1.2850e-06,  2.4061e-07],\n",
      "          [ 3.6105e-05, -1.3815e-06,  6.4281e-06, -8.7378e-07, -2.0833e-07]],\n",
      "\n",
      "         [[ 2.3095e-04,  3.1533e-04, -3.6847e-04, -2.8184e-04,  1.2473e-04],\n",
      "          [-4.8105e-04, -9.4377e-05, -1.7511e-04, -2.9208e-04,  2.1675e-05],\n",
      "          [-1.4317e-03, -6.4165e-04, -2.2196e-04, -1.2246e-04,  1.0888e-04],\n",
      "          [-1.1344e-03, -6.6364e-04, -3.2405e-04, -1.3367e-04,  1.5436e-04],\n",
      "          [-9.3642e-04, -6.3424e-04, -4.0557e-04, -1.9145e-04,  1.2498e-04]],\n",
      "\n",
      "         [[ 1.3254e-04,  3.2252e-04,  3.2549e-04,  6.9976e-05, -2.5335e-05],\n",
      "          [-5.9853e-05,  5.0115e-04,  2.2637e-04,  8.7239e-06,  1.2453e-07],\n",
      "          [-3.8301e-04,  4.0913e-04,  9.3876e-05,  1.4191e-05,  1.6660e-06],\n",
      "          [-9.3547e-04, -4.8583e-05,  4.2406e-05,  1.8023e-05, -9.6355e-08],\n",
      "          [-9.1846e-04, -1.2509e-04,  1.5717e-05,  1.5497e-05,  2.1579e-06]]],\n",
      "\n",
      "\n",
      "        [[[ 8.3067e-03,  8.9766e-03,  9.9147e-03,  1.0809e-02,  1.0344e-02],\n",
      "          [ 7.0316e-03,  4.5669e-03,  6.7491e-03,  7.2428e-03,  7.5565e-03],\n",
      "          [ 3.2253e-03,  2.5286e-03,  4.6009e-03,  8.0360e-03,  8.0203e-03],\n",
      "          [ 2.0816e-03,  3.3573e-03,  6.0691e-03,  8.2220e-03,  6.9614e-03],\n",
      "          [ 1.3715e-03,  4.1907e-03,  7.6502e-03,  4.9331e-03,  3.8518e-04]],\n",
      "\n",
      "         [[-1.4670e-04,  1.7321e-04,  1.2142e-03,  1.2632e-03,  9.8245e-04],\n",
      "          [-1.6264e-04,  1.9378e-04,  7.1293e-04,  1.7330e-03,  8.3680e-04],\n",
      "          [ 2.5704e-04,  8.0591e-04,  4.3579e-04,  3.9238e-04, -2.1013e-05],\n",
      "          [ 2.0275e-05,  6.6325e-04,  7.8365e-04,  8.0473e-05,  8.2978e-05],\n",
      "          [-9.5194e-05,  1.3441e-04,  7.2071e-04, -2.7060e-05, -4.9249e-05]],\n",
      "\n",
      "         [[ 1.2456e-02,  1.7118e-02,  1.9252e-02,  2.4498e-02,  2.4795e-02],\n",
      "          [ 1.3159e-02,  1.5613e-02,  1.7045e-02,  1.9774e-02,  2.2752e-02],\n",
      "          [ 9.5887e-03,  1.1265e-02,  1.5467e-02,  1.5635e-02,  2.0022e-02],\n",
      "          [ 1.1313e-02,  9.2345e-03,  1.4325e-02,  1.7241e-02,  1.5594e-02],\n",
      "          [ 1.0915e-02,  9.8941e-03,  1.1703e-02,  1.4023e-02,  9.9865e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.4569e-04,  2.7904e-04,  1.2717e-03,  2.6300e-03,  1.5150e-03],\n",
      "          [-2.5600e-04,  2.7568e-04,  2.4040e-04,  1.3368e-03,  1.0501e-03],\n",
      "          [-3.5730e-04,  4.4940e-04,  1.1596e-03,  2.1356e-04, -4.4749e-04],\n",
      "          [ 6.2799e-04,  1.5894e-04,  7.4400e-04, -1.6549e-04, -6.0293e-04],\n",
      "          [ 9.1358e-04,  1.3602e-04,  2.7101e-04,  2.0937e-04, -1.6671e-04]],\n",
      "\n",
      "         [[ 1.3699e-02,  1.5932e-02,  1.7817e-02,  1.9403e-02,  2.0807e-02],\n",
      "          [ 1.0610e-02,  1.2905e-02,  1.6009e-02,  1.4863e-02,  1.9395e-02],\n",
      "          [ 8.8172e-03,  1.0736e-02,  1.4878e-02,  1.6777e-02,  1.8486e-02],\n",
      "          [ 1.0434e-02,  1.1579e-02,  1.2867e-02,  1.6367e-02,  1.5575e-02],\n",
      "          [ 7.8495e-03,  1.1817e-02,  1.2416e-02,  1.0650e-02,  6.9500e-03]],\n",
      "\n",
      "         [[ 4.3206e-04,  2.0731e-03,  2.5633e-03,  3.2637e-03,  5.1765e-03],\n",
      "          [ 2.6469e-03,  4.1299e-03,  2.9126e-03,  3.2526e-03,  3.4845e-03],\n",
      "          [ 3.9620e-03,  2.6214e-03,  2.1897e-03,  2.9842e-03,  2.6640e-03],\n",
      "          [ 3.2704e-03,  1.8890e-03,  1.3252e-03,  2.6390e-03,  2.7647e-03],\n",
      "          [ 2.6569e-03,  1.1687e-03,  9.3734e-04,  2.5666e-03,  3.1427e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.4140e-03, -4.2313e-03, -4.0755e-03, -2.4907e-03, -3.4832e-03],\n",
      "          [-6.1169e-04, -1.9760e-03, -1.3439e-03, -3.3394e-03, -6.1143e-03],\n",
      "          [-1.8562e-04, -2.2872e-03, -4.3324e-03, -8.8716e-03, -1.1958e-02],\n",
      "          [-1.0900e-03, -3.7364e-03, -7.4519e-03, -1.2671e-02, -1.2198e-02],\n",
      "          [-2.0297e-04, -2.8607e-03, -7.0450e-03, -9.2686e-03, -8.1432e-03]],\n",
      "\n",
      "         [[-6.0986e-04, -3.9040e-04, -2.8336e-04, -3.4488e-04, -3.4555e-04],\n",
      "          [-2.5459e-04, -5.1865e-04, -3.0699e-04, -3.6332e-04, -4.1415e-04],\n",
      "          [-3.8291e-04, -4.2872e-04, -2.9441e-04, -2.0544e-04, -1.0960e-04],\n",
      "          [-2.8891e-04, -2.7449e-04, -1.7674e-04, -1.6895e-04, -4.5416e-04],\n",
      "          [-4.8541e-05, -2.1892e-04, -6.1490e-04, -4.5802e-04, -8.7760e-04]],\n",
      "\n",
      "         [[-3.1637e-03, -7.3305e-03, -1.1360e-02, -1.1975e-02, -1.1278e-02],\n",
      "          [-4.3080e-03, -7.0742e-03, -1.0285e-02, -9.7973e-03, -1.1883e-02],\n",
      "          [-1.3440e-03, -3.6700e-03, -7.2258e-03, -1.0676e-02, -1.5324e-02],\n",
      "          [ 9.0918e-05, -3.7633e-03, -9.6353e-03, -1.4206e-02, -1.8794e-02],\n",
      "          [ 2.2082e-04, -4.2196e-03, -1.1781e-02, -1.4954e-02, -1.6237e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.0332e-04, -7.8680e-04, -5.0307e-04, -1.0060e-03, -9.1804e-04],\n",
      "          [-8.6922e-05, -3.8401e-04, -7.3515e-04, -9.4330e-04, -1.2680e-03],\n",
      "          [-3.6736e-04, -5.0064e-04, -8.1810e-04, -1.1605e-03, -1.0239e-03],\n",
      "          [ 8.3748e-06, -1.4608e-04, -8.6274e-04, -6.0584e-04, -1.2799e-03],\n",
      "          [ 2.9750e-04, -3.0495e-04, -8.3457e-04, -9.4069e-05, -5.2905e-04]],\n",
      "\n",
      "         [[-4.9251e-03, -7.3298e-03, -1.1252e-02, -1.0045e-02, -1.1173e-02],\n",
      "          [-3.4744e-03, -4.6331e-03, -7.6101e-03, -8.7547e-03, -1.1817e-02],\n",
      "          [-1.6961e-03, -3.8225e-03, -7.5254e-03, -1.1722e-02, -1.6237e-02],\n",
      "          [-1.5436e-03, -4.5704e-03, -1.1060e-02, -1.4120e-02, -1.5563e-02],\n",
      "          [-3.4239e-04, -2.9356e-03, -9.8587e-03, -1.1956e-02, -1.2971e-02]],\n",
      "\n",
      "         [[ 1.4775e-03,  2.9633e-04, -9.4034e-04, -2.2146e-03, -1.6370e-03],\n",
      "          [ 1.0995e-03, -2.1943e-04, -1.5789e-03, -1.9926e-03, -9.9911e-04],\n",
      "          [ 8.2532e-04, -3.5903e-04, -6.8574e-04, -6.2019e-04, -1.0364e-03],\n",
      "          [ 1.4616e-03,  1.1716e-04, -1.5813e-04, -7.6134e-04, -2.4375e-03],\n",
      "          [ 7.4016e-04,  2.3832e-04, -3.2239e-04, -2.0698e-03, -3.2337e-03]]]]), 'conv2.bias': tensor([-0.0142, -0.0353, -0.0048, -0.0437,  0.0163,  0.0892, -0.0217, -0.0759,\n",
      "         0.0205, -0.0521, -0.0103,  0.0248,  0.0352,  0.0078,  0.0500, -0.0114,\n",
      "        -0.0177,  0.0521, -0.0180, -0.0046, -0.0330, -0.0006,  0.0291, -0.0022,\n",
      "        -0.0160,  0.0411,  0.0306, -0.0149,  0.0026, -0.0048,  0.0669, -0.0460]), 'fc1.weight': tensor([[ 0.0001,  0.0024,  0.0050,  ...,  0.0010,  0.0009,  0.0004],\n",
      "        [ 0.0001,  0.0025,  0.0054,  ...,  0.0011,  0.0010,  0.0004],\n",
      "        [ 0.0001,  0.0027,  0.0057,  ...,  0.0012,  0.0010,  0.0004],\n",
      "        ...,\n",
      "        [-0.0009, -0.0069, -0.0099,  ..., -0.0016, -0.0019, -0.0007],\n",
      "        [-0.0001, -0.0147, -0.0355,  ..., -0.0076, -0.0064, -0.0025],\n",
      "        [ 0.0001,  0.0026,  0.0054,  ...,  0.0011,  0.0010,  0.0004]]), 'fc1.bias': tensor([ 0.0468,  0.0498,  0.0533,  0.0510,  0.0581,  0.0527,  0.0593, -0.0917,\n",
      "        -0.3295,  0.0504])}\n",
      "!-- Server Model Status --!\n",
      "Epoch [1/100], Culminative Send Cost: 1157520.0, Culminative Time Used: 74.44285589829087\n",
      "Train Loss: 1.9862557649612427, Train Accuracy: 0.3801194727420807, Train Error: 0.6198804378509521\n",
      "Test Loss: 1.9792798757553101, Test Accuracy: 0.3928995132446289, Test Error: 0.6071004867553711\n",
      "Number of adversaries sampled: 0, Number of stragglers sampled: 0\n",
      "!-- Client 1 is normal and start iterations. ---!\n",
      "Epoch [1/3], Average Loss: 0.3127983212471008, Average Accuracy: 0.9233578443527222, Average Error: 0.0766421630978584, Culminative Time Used: 1.899159800261259\n",
      "Epoch [2/3], Average Loss: 0.1433848589658737, Average Accuracy: 0.9787867665290833, Average Error: 0.0212132353335619, Culminative Time Used: 3.5027037002146244\n",
      "Epoch [3/3], Average Loss: 0.2931345999240875, Average Accuracy: 0.9725766181945801, Average Error: 0.0274234060198069, Culminative Time Used: 5.225770000368357\n",
      "{'conv1.weight': tensor([[[[ 5.9445e-03,  7.3713e-03,  7.1309e-03,  4.7396e-03,  2.1250e-03],\n",
      "          [ 3.7975e-03,  5.0648e-03,  5.1817e-03,  3.8681e-03,  1.8774e-03],\n",
      "          [-2.4516e-03, -1.4236e-03, -7.5183e-04, -1.5055e-03, -2.4189e-03],\n",
      "          [-1.1627e-02, -1.2023e-02, -1.0991e-02, -9.9897e-03, -1.1499e-02],\n",
      "          [-1.8961e-02, -1.9367e-02, -1.7696e-02, -1.5851e-02, -1.8360e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 8.5426e-05, -1.0947e-04,  2.8758e-04,  7.3558e-04,  2.1977e-04],\n",
      "          [-2.2964e-04, -6.2031e-04, -6.4653e-04, -1.8037e-04, -1.4718e-04],\n",
      "          [-1.2912e-04, -4.4191e-04, -6.4341e-04, -2.5414e-04,  3.1090e-04],\n",
      "          [-1.0951e-04, -9.5579e-05,  4.1217e-05,  1.0565e-03,  2.0427e-03],\n",
      "          [-4.1033e-05,  5.5502e-06,  7.9752e-04,  1.9465e-03,  2.3099e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2183e-02,  1.4688e-02,  1.6017e-02,  1.7062e-02,  1.6058e-02],\n",
      "          [ 7.3614e-03,  7.3539e-03,  7.6201e-03,  9.1408e-03,  9.6820e-03],\n",
      "          [ 5.2690e-03,  3.7294e-03,  3.3820e-03,  5.1233e-03,  5.9183e-03],\n",
      "          [ 6.1982e-03,  4.3385e-03,  4.2522e-03,  5.2894e-03,  4.6888e-03],\n",
      "          [ 7.4623e-03,  5.7326e-03,  4.9418e-03,  4.6234e-03,  4.2783e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.5461e-03,  6.6863e-03,  9.2562e-03,  1.2300e-02,  1.3070e-02],\n",
      "          [ 4.1947e-03,  5.6828e-03,  8.8908e-03,  1.1458e-02,  1.0416e-02],\n",
      "          [ 4.0396e-03,  5.6883e-03,  8.7405e-03,  1.0628e-02,  8.7509e-03],\n",
      "          [ 4.8311e-03,  6.2746e-03,  8.2747e-03,  8.9569e-03,  7.2323e-03],\n",
      "          [ 5.6874e-03,  6.4529e-03,  6.7730e-03,  5.7762e-03,  4.2602e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.7011e-03, -4.9384e-03, -3.8151e-03, -3.0889e-03, -2.2328e-03],\n",
      "          [-5.9840e-03, -4.7074e-03, -5.5312e-03, -8.6143e-03, -8.7776e-03],\n",
      "          [-5.4598e-03, -5.3114e-03, -6.0429e-03, -8.8423e-03, -9.8671e-03],\n",
      "          [-2.2982e-03, -2.5654e-03, -3.0417e-03, -5.3740e-03, -6.0187e-03],\n",
      "          [ 1.8860e-03,  1.1253e-03,  1.5441e-04, -1.7200e-03, -2.0485e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.9652e-03, -5.1603e-03, -3.7139e-03, -2.1354e-03, -1.0555e-03],\n",
      "          [-4.5942e-03, -5.0873e-03, -4.8108e-03, -4.3350e-03, -4.1929e-03],\n",
      "          [-1.5452e-03, -2.3689e-03, -3.1687e-03, -3.2698e-03, -3.2804e-03],\n",
      "          [ 6.7183e-04, -8.9604e-04, -2.9835e-03, -3.3441e-03, -3.1231e-03],\n",
      "          [ 8.6576e-05, -2.5756e-03, -4.4489e-03, -3.8362e-03, -3.0196e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.5572e-02, -1.4640e-02, -1.5002e-02, -1.3344e-02, -6.7039e-03],\n",
      "          [-1.6592e-02, -1.7828e-02, -2.0172e-02, -1.7943e-02, -9.7566e-03],\n",
      "          [-2.0285e-02, -2.1897e-02, -2.4542e-02, -2.2485e-02, -1.4925e-02],\n",
      "          [-1.9988e-02, -2.1095e-02, -2.2774e-02, -2.2393e-02, -1.6512e-02],\n",
      "          [-1.6950e-02, -1.7095e-02, -1.6795e-02, -1.6621e-02, -1.3170e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.3534e-03, -2.5694e-03,  4.1262e-03,  1.0041e-02,  1.3570e-02],\n",
      "          [-1.4509e-02, -6.9167e-03,  1.2232e-04,  5.3665e-03,  9.5935e-03],\n",
      "          [-1.8431e-02, -1.1306e-02, -4.6079e-03,  8.0333e-04,  5.2601e-03],\n",
      "          [-1.9717e-02, -1.5348e-02, -8.7787e-03, -2.7386e-03,  1.1174e-03],\n",
      "          [-1.8295e-02, -1.5234e-02, -9.9654e-03, -4.4035e-03, -1.6929e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3103e-03,  1.0585e-03,  1.0940e-03, -9.3806e-05, -3.6013e-03],\n",
      "          [ 4.9130e-03,  4.4501e-03,  3.3206e-03,  1.2158e-03, -3.3054e-03],\n",
      "          [ 6.3405e-03,  5.2922e-03,  3.7704e-03,  1.0352e-03, -2.2336e-03],\n",
      "          [ 4.9269e-03,  4.1372e-03,  3.4524e-03,  1.2188e-03, -2.7533e-04],\n",
      "          [ 2.2596e-03,  2.0484e-03,  1.8035e-03,  1.4061e-03,  1.0182e-03]]],\n",
      "\n",
      "\n",
      "        [[[-3.2867e-03, -2.3254e-03, -9.9583e-04, -5.2733e-05,  2.3048e-03],\n",
      "          [-1.3555e-03, -7.7590e-04, -2.7682e-04,  7.2754e-04,  1.8502e-03],\n",
      "          [-8.6983e-05, -1.6541e-04,  1.5587e-04,  7.7922e-04,  2.4266e-03],\n",
      "          [ 3.2941e-04,  1.6370e-04,  7.0713e-05,  4.3252e-04,  2.4648e-03],\n",
      "          [ 2.1745e-03,  8.9790e-04,  1.8204e-04,  5.3211e-04,  7.8037e-04]]],\n",
      "\n",
      "\n",
      "        [[[-2.9194e-02, -2.0550e-02, -1.1200e-02, -5.9478e-03, -4.3462e-03],\n",
      "          [-2.9382e-02, -2.1093e-02, -1.0001e-02, -4.9431e-03, -3.1991e-03],\n",
      "          [-2.4207e-02, -1.5834e-02, -4.8284e-03, -1.6554e-03,  1.0195e-04],\n",
      "          [-1.6875e-02, -9.2148e-03, -1.2410e-03,  1.6169e-03,  4.5196e-03],\n",
      "          [-1.1140e-02, -4.1397e-03,  2.1910e-03,  5.9084e-03,  1.0705e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.2123e-03,  1.3928e-03, -5.9453e-04, -1.1414e-03, -8.8985e-04],\n",
      "          [-8.9511e-04, -2.0371e-03, -3.0685e-03, -3.1487e-03, -2.9036e-03],\n",
      "          [-8.1586e-04, -1.5651e-03, -1.2703e-03, -1.3839e-03, -1.7191e-03],\n",
      "          [ 6.1990e-04,  3.8583e-04,  7.4579e-04,  4.1008e-04,  3.5261e-06],\n",
      "          [ 2.0007e-03,  1.2734e-03,  1.2433e-03,  7.2595e-04,  6.4755e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4117e-03,  1.5190e-03,  2.2277e-03,  5.1759e-03,  9.7842e-03],\n",
      "          [ 1.4511e-03,  1.0540e-03,  2.8927e-03,  6.9062e-03,  1.2175e-02],\n",
      "          [-1.2510e-04,  2.5059e-04,  2.8586e-03,  6.9741e-03,  9.2918e-03],\n",
      "          [-1.7323e-03, -9.8982e-04,  5.4595e-04,  2.0394e-03,  1.5554e-03],\n",
      "          [-3.8068e-03, -3.3700e-03, -4.6291e-03, -5.4482e-03, -5.4970e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4113e-03, -1.1623e-03, -3.9973e-04,  4.5695e-04,  1.0200e-03],\n",
      "          [-1.5580e-03, -1.3429e-03, -4.3860e-04,  8.7830e-04,  1.3875e-03],\n",
      "          [-1.1642e-03, -1.1173e-03,  8.5977e-05,  8.6081e-04,  1.1805e-03],\n",
      "          [-3.3170e-04, -3.9825e-04,  9.1180e-04,  1.8790e-03,  2.4251e-03],\n",
      "          [ 2.5913e-04,  5.4235e-04,  2.4293e-03,  3.6309e-03,  3.6942e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.2528e-02, -1.7628e-02, -1.2488e-02, -9.2598e-03, -4.2488e-03],\n",
      "          [-2.1782e-02, -1.7400e-02, -1.2930e-02, -1.0017e-02, -5.7680e-03],\n",
      "          [-2.5899e-02, -2.2720e-02, -1.6059e-02, -1.1592e-02, -7.1116e-03],\n",
      "          [-2.2615e-02, -2.1256e-02, -1.7252e-02, -1.2487e-02, -8.3993e-03],\n",
      "          [-1.5456e-02, -1.6953e-02, -1.4543e-02, -1.1095e-02, -7.8609e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.8957e-03,  1.7408e-03,  1.7300e-03,  1.3596e-03,  1.1702e-03],\n",
      "          [ 7.3632e-04,  1.6647e-03,  2.2422e-03,  2.4017e-03,  2.5026e-03],\n",
      "          [-8.5589e-04,  6.9909e-04,  2.2438e-03,  2.5472e-03,  2.3763e-03],\n",
      "          [-2.2059e-03, -3.1799e-04,  1.5253e-03,  2.3319e-03,  2.1278e-03],\n",
      "          [-3.0285e-03, -1.6320e-03, -3.4723e-04,  3.5691e-05,  3.4681e-04]]]]), 'conv1.bias': tensor([-2.6523e-02,  3.1556e-03, -1.1202e-04, -1.7148e-02, -7.3598e-03,\n",
      "        -8.2650e-03, -2.6655e-02, -5.0417e-02, -4.8733e-04,  1.9943e-02,\n",
      "        -6.2802e-02,  4.3200e-03, -2.9821e-02,  4.1828e-03, -1.2342e-01,\n",
      "        -2.2243e-03]), 'conv2.weight': tensor([[[[ 2.4583e-03, -1.1701e-03, -1.2777e-03,  4.2232e-03,  1.1240e-02],\n",
      "          [ 1.2058e-03, -3.2845e-03, -1.6076e-03,  2.1846e-03,  6.4596e-03],\n",
      "          [ 1.6127e-03, -3.6743e-03, -6.7272e-03, -6.0071e-03, -5.0431e-03],\n",
      "          [-2.9666e-03, -9.5416e-03, -1.3862e-02, -1.1764e-02, -8.3895e-03],\n",
      "          [-7.7108e-03, -1.4360e-02, -1.6238e-02, -1.0264e-02, -4.9757e-03]],\n",
      "\n",
      "         [[-2.4484e-04, -2.3843e-04, -1.8787e-04,  2.5249e-04,  7.0410e-04],\n",
      "          [-2.8737e-04, -3.7669e-04, -1.8531e-04,  3.0572e-04,  1.5746e-04],\n",
      "          [-1.8443e-04, -3.9658e-04, -7.6040e-05,  5.2413e-04,  4.5052e-04],\n",
      "          [ 4.2859e-05, -2.6173e-04, -1.4662e-04,  2.7208e-04,  2.1466e-04],\n",
      "          [ 1.3746e-04, -1.9018e-04, -2.4335e-04,  2.2111e-04,  1.9040e-04]],\n",
      "\n",
      "         [[ 6.3624e-03,  2.3678e-03,  5.9129e-04,  6.1453e-03,  1.4709e-02],\n",
      "          [ 7.3367e-03, -3.3955e-04, -2.4756e-03,  6.7184e-03,  1.5477e-02],\n",
      "          [ 1.1563e-02,  1.5527e-03, -3.9131e-03,  1.2640e-03,  6.2989e-03],\n",
      "          [ 1.1451e-02,  8.0767e-04, -9.9129e-03, -9.6488e-03, -6.8936e-03],\n",
      "          [-6.1090e-04, -9.0549e-03, -1.7201e-02, -1.6489e-02, -1.2034e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-8.3996e-04, -1.1577e-03, -5.2564e-04,  3.4036e-04,  5.6273e-04],\n",
      "          [-3.0561e-04, -9.3750e-04, -1.0014e-03, -3.1194e-04, -3.4349e-04],\n",
      "          [ 7.1711e-04, -4.7612e-04, -1.0463e-03, -4.3601e-04, -3.3292e-04],\n",
      "          [ 6.7862e-04,  2.4735e-04, -3.3451e-05,  9.0840e-05,  2.4011e-04],\n",
      "          [-3.4947e-04, -3.5152e-04, -3.0331e-04, -1.3339e-05,  3.1309e-04]],\n",
      "\n",
      "         [[ 5.9497e-03,  3.2450e-03,  1.6294e-03,  8.1658e-03,  1.4654e-02],\n",
      "          [ 7.0158e-03,  2.1361e-03,  1.9587e-03,  9.7727e-03,  1.5555e-02],\n",
      "          [ 1.0414e-02,  5.5302e-03, -3.0110e-04,  1.7250e-03,  3.0902e-03],\n",
      "          [ 5.9631e-03, -4.2248e-04, -7.3190e-03, -6.9562e-03, -7.0667e-03],\n",
      "          [-5.4436e-03, -1.0814e-02, -1.5095e-02, -1.2486e-02, -8.7491e-03]],\n",
      "\n",
      "         [[ 1.6223e-03,  7.2420e-04,  2.5555e-04, -1.2479e-04, -6.7889e-05],\n",
      "          [ 2.5138e-03,  1.1362e-04, -1.5626e-03, -2.2902e-03, -6.0015e-04],\n",
      "          [ 2.0650e-03, -1.1798e-03, -2.7970e-03, -3.0099e-03, -9.7021e-05],\n",
      "          [ 1.2886e-03, -1.1471e-03, -2.4239e-03, -3.1475e-03, -4.5794e-04],\n",
      "          [ 8.9144e-04, -7.3675e-04, -2.1186e-03, -2.9250e-03, -8.6157e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.6494e-02, -2.4389e-02, -4.7082e-03,  1.2828e-02,  2.3037e-02],\n",
      "          [-3.1378e-02, -1.7939e-02,  3.9053e-04,  1.4814e-02,  2.5786e-02],\n",
      "          [-1.8202e-02, -7.2185e-03,  3.5261e-03,  1.2462e-02,  1.8955e-02],\n",
      "          [-7.6145e-03, -3.2717e-03,  1.8869e-04,  5.5514e-03,  1.0943e-02],\n",
      "          [-5.1295e-03, -5.4234e-03, -3.3647e-03,  4.0194e-03,  1.3196e-02]],\n",
      "\n",
      "         [[ 2.1399e-05,  4.8998e-04,  4.6281e-04,  2.3296e-04,  4.9605e-04],\n",
      "          [-1.1240e-04,  2.9012e-04,  4.0297e-04,  2.9315e-04,  5.5805e-04],\n",
      "          [ 1.1847e-04,  1.0581e-04,  2.6007e-05,  5.6738e-04,  6.8922e-04],\n",
      "          [ 1.3191e-04, -8.5046e-05, -1.1046e-04,  7.2187e-04,  8.1036e-04],\n",
      "          [ 1.8936e-04,  4.7763e-05, -1.4182e-05,  3.7327e-04,  5.8936e-04]],\n",
      "\n",
      "         [[-6.6695e-02, -5.4623e-02, -2.7954e-02,  2.8310e-03,  2.7708e-02],\n",
      "          [-6.9714e-02, -5.3643e-02, -2.5345e-02,  7.1330e-03,  3.6610e-02],\n",
      "          [-5.4437e-02, -4.0200e-02, -1.9036e-02,  6.4896e-03,  3.1104e-02],\n",
      "          [-3.4794e-02, -2.3163e-02, -1.2156e-02,  2.8171e-03,  2.0467e-02],\n",
      "          [-2.0108e-02, -1.4219e-02, -1.0002e-02,  9.8261e-04,  1.5848e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2711e-03, -9.6948e-04, -5.6764e-05,  1.2504e-03,  1.8729e-03],\n",
      "          [-8.2677e-04, -8.2027e-04, -1.6063e-04,  1.4268e-03,  1.5902e-03],\n",
      "          [ 1.0469e-04, -3.2280e-04, -8.3727e-04, -2.4274e-04,  7.9247e-04],\n",
      "          [ 2.0494e-04,  1.9654e-04,  6.6299e-05,  4.1656e-04,  8.1708e-04],\n",
      "          [ 2.6839e-04,  1.0746e-04,  1.9307e-04,  4.6682e-04,  6.8801e-04]],\n",
      "\n",
      "         [[-6.2219e-02, -4.9213e-02, -2.3335e-02,  2.3052e-03,  2.5928e-02],\n",
      "          [-5.9302e-02, -4.2520e-02, -1.7172e-02,  8.3369e-03,  3.2600e-02],\n",
      "          [-4.4270e-02, -2.8977e-02, -1.0814e-02,  7.1025e-03,  2.4240e-02],\n",
      "          [-2.6632e-02, -1.6513e-02, -8.1990e-03,  3.1611e-03,  1.5633e-02],\n",
      "          [-1.6278e-02, -1.3610e-02, -9.5284e-03,  1.5420e-03,  1.4411e-02]],\n",
      "\n",
      "         [[-5.8859e-03, -7.1581e-03, -9.9725e-03, -4.7874e-03,  1.4190e-04],\n",
      "          [-4.7853e-03, -8.3070e-03, -1.0436e-02, -4.1770e-03, -8.6719e-04],\n",
      "          [-4.3119e-03, -6.9895e-03, -6.6975e-03, -4.0308e-03, -1.6672e-03],\n",
      "          [-4.3796e-03, -4.9670e-03, -4.4316e-03, -4.2075e-03, -7.5778e-04],\n",
      "          [-3.1844e-03, -3.1404e-03, -3.1755e-03, -2.7700e-03,  5.8645e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 1.4655e-02,  1.2649e-02,  8.6463e-03,  3.9016e-03,  3.3959e-03],\n",
      "          [ 2.5698e-02,  2.3550e-02,  1.7464e-02,  7.3581e-03,  3.1910e-03],\n",
      "          [ 3.0895e-02,  3.0553e-02,  2.0140e-02,  8.1121e-03,  4.1208e-03],\n",
      "          [ 3.3133e-02,  3.1568e-02,  1.8130e-02,  9.4786e-03,  7.4356e-03],\n",
      "          [ 2.9299e-02,  2.6257e-02,  1.8321e-02,  1.3568e-02,  1.0036e-02]],\n",
      "\n",
      "         [[-2.1965e-04,  6.8428e-05, -4.3793e-05,  3.5663e-04,  4.4085e-04],\n",
      "          [ 3.4446e-04,  1.5606e-04, -2.2441e-04,  2.0505e-04,  5.1649e-04],\n",
      "          [ 5.1747e-04,  2.2103e-04, -3.7171e-04, -1.2538e-04,  1.0638e-04],\n",
      "          [ 4.3239e-04,  4.4973e-04, -2.2724e-04, -1.1714e-04, -4.0904e-05],\n",
      "          [ 5.8407e-04,  6.7095e-04,  3.3819e-04,  1.4085e-05,  1.6239e-04]],\n",
      "\n",
      "         [[ 1.6215e-02,  1.8118e-02,  1.3408e-02,  8.4131e-03,  8.7366e-03],\n",
      "          [ 3.4133e-02,  3.7658e-02,  2.7302e-02,  1.3165e-02,  5.8238e-03],\n",
      "          [ 5.0743e-02,  5.6643e-02,  4.6189e-02,  2.5473e-02,  8.9641e-03],\n",
      "          [ 5.8201e-02,  6.1914e-02,  5.2127e-02,  3.1905e-02,  1.4158e-02],\n",
      "          [ 5.9632e-02,  5.9995e-02,  5.0137e-02,  3.7305e-02,  2.3303e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.6657e-03,  8.7931e-04, -3.9738e-04, -4.9569e-04, -1.5151e-04],\n",
      "          [ 2.3392e-03,  2.5059e-03,  3.2486e-04, -3.0674e-04, -4.3272e-04],\n",
      "          [ 1.6625e-03,  1.9879e-03,  9.8757e-04,  1.7720e-04,  1.3228e-05],\n",
      "          [ 1.3037e-03,  1.3525e-03,  1.7648e-03,  7.3112e-04,  3.0272e-04],\n",
      "          [ 1.2175e-03,  9.7998e-04,  1.2576e-03,  9.5432e-04,  6.2344e-04]],\n",
      "\n",
      "         [[ 1.7061e-02,  2.0728e-02,  1.7226e-02,  1.2403e-02,  9.9789e-03],\n",
      "          [ 3.3208e-02,  3.7856e-02,  3.1121e-02,  1.9341e-02,  7.9250e-03],\n",
      "          [ 4.7234e-02,  5.2362e-02,  4.2355e-02,  2.6279e-02,  1.1205e-02],\n",
      "          [ 5.4757e-02,  5.5268e-02,  4.2097e-02,  2.9043e-02,  1.6554e-02],\n",
      "          [ 5.3618e-02,  5.3345e-02,  4.4996e-02,  3.6138e-02,  2.5591e-02]],\n",
      "\n",
      "         [[ 2.2396e-03,  3.1572e-03,  3.7084e-03,  3.9239e-03,  2.7304e-03],\n",
      "          [ 2.6861e-03,  3.9784e-03,  6.0913e-03,  5.5255e-03,  2.8515e-03],\n",
      "          [ 3.4448e-03,  4.6992e-03,  8.6968e-03,  7.1104e-03,  3.3729e-03],\n",
      "          [ 3.0372e-03,  5.1953e-03,  9.5941e-03,  6.9023e-03,  3.1887e-03],\n",
      "          [ 3.8112e-03,  7.0727e-03,  8.3228e-03,  5.3220e-03,  3.1098e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 8.9690e-03,  7.6096e-03,  1.9225e-03,  9.1265e-04,  1.0995e-03],\n",
      "          [ 1.1602e-02,  8.3256e-03,  3.3180e-03,  1.7426e-03,  1.3015e-03],\n",
      "          [ 1.2067e-02,  6.8780e-03,  2.9385e-03,  1.2397e-03,  7.1543e-04],\n",
      "          [ 9.7898e-03,  3.9578e-03,  1.6489e-03,  5.8245e-04,  1.7146e-04],\n",
      "          [ 7.9918e-03,  3.8960e-03,  2.7171e-03,  1.1771e-03,  6.2076e-04]],\n",
      "\n",
      "         [[ 3.2659e-04,  5.0998e-05,  9.4051e-06,  2.0932e-05,  7.2887e-05],\n",
      "          [ 4.4290e-04,  7.9427e-05,  1.5848e-06,  2.9727e-06,  2.2453e-05],\n",
      "          [ 4.0025e-04,  1.3584e-04,  7.8299e-06,  3.0169e-07,  5.9533e-06],\n",
      "          [ 1.8732e-04,  2.2421e-04,  3.6026e-05,  5.2982e-06,  4.6977e-06],\n",
      "          [ 1.1900e-04,  2.1126e-04,  8.2275e-05,  1.0001e-05,  4.5374e-06]],\n",
      "\n",
      "         [[ 2.5254e-02,  2.3046e-02,  1.3806e-02,  6.5804e-03,  5.1159e-03],\n",
      "          [ 2.4819e-02,  2.1594e-02,  1.2445e-02,  5.9308e-03,  4.3128e-03],\n",
      "          [ 2.6719e-02,  2.2053e-02,  1.4734e-02,  6.7936e-03,  4.4719e-03],\n",
      "          [ 2.4752e-02,  1.8804e-02,  1.2404e-02,  5.7363e-03,  2.8589e-03],\n",
      "          [ 1.9527e-02,  1.4104e-02,  9.3174e-03,  5.3298e-03,  2.3883e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 9.0785e-04,  3.0120e-04,  1.1294e-05,  8.1293e-06,  3.9741e-05],\n",
      "          [ 1.3547e-03,  5.9451e-04,  9.7547e-05,  2.0299e-05,  2.7670e-05],\n",
      "          [ 7.1922e-04,  8.6033e-04,  2.6414e-04,  4.9258e-05,  2.5607e-05],\n",
      "          [ 2.4849e-04,  4.4622e-04,  2.8908e-04,  3.9327e-05,  2.8634e-05],\n",
      "          [ 2.6258e-04,  2.5048e-04,  3.0098e-04,  7.9200e-05,  2.2363e-05]],\n",
      "\n",
      "         [[ 2.2602e-02,  2.0435e-02,  1.2076e-02,  7.1291e-03,  5.7726e-03],\n",
      "          [ 2.4333e-02,  2.0275e-02,  1.4184e-02,  7.8415e-03,  5.6405e-03],\n",
      "          [ 2.6096e-02,  2.0458e-02,  1.4824e-02,  8.0608e-03,  5.3034e-03],\n",
      "          [ 2.1830e-02,  1.5422e-02,  1.0484e-02,  6.0468e-03,  3.2668e-03],\n",
      "          [ 1.6766e-02,  1.3332e-02,  8.9637e-03,  5.8814e-03,  3.3231e-03]],\n",
      "\n",
      "         [[ 1.2037e-03,  2.4848e-03,  3.1065e-03,  8.4624e-04,  1.5128e-04],\n",
      "          [ 7.5071e-04,  3.2110e-03,  2.3986e-03,  3.1992e-04,  1.0113e-04],\n",
      "          [ 9.6994e-04,  3.2820e-03,  2.0281e-03,  5.7686e-04,  1.3157e-04],\n",
      "          [ 2.6329e-03,  3.5879e-03,  1.8154e-03,  6.8263e-04,  8.2773e-05],\n",
      "          [ 3.7491e-03,  2.9092e-03,  1.4989e-03,  7.7287e-04,  1.5990e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3173e-03, -1.4849e-03, -3.6466e-03, -8.9372e-03, -1.5398e-02],\n",
      "          [-1.5799e-02, -1.4414e-02, -1.0128e-02, -9.2653e-03, -1.3690e-02],\n",
      "          [-2.1875e-02, -1.8124e-02, -1.2690e-02, -1.0203e-02, -1.3336e-02],\n",
      "          [-1.2671e-02, -9.3567e-03, -6.1044e-03, -5.3915e-03, -7.8179e-03],\n",
      "          [-2.4957e-03, -5.3984e-04,  2.1066e-03,  3.0392e-03, -1.9333e-04]],\n",
      "\n",
      "         [[ 4.2548e-05, -8.4457e-05,  5.4733e-05, -3.8808e-04, -6.9184e-04],\n",
      "          [ 3.3568e-04,  2.4056e-04,  3.1326e-04,  7.5951e-05, -4.7141e-04],\n",
      "          [ 1.3677e-04,  3.1299e-04,  3.2944e-04,  1.6211e-04, -4.9130e-04],\n",
      "          [-2.5986e-04,  2.4720e-04,  3.7025e-04,  1.2445e-04, -2.0758e-04],\n",
      "          [-5.6610e-04, -2.1727e-04, -5.0743e-05, -1.5507e-04, -2.8851e-04]],\n",
      "\n",
      "         [[ 2.1692e-02,  1.1375e-02,  3.1851e-03, -6.0579e-03, -2.1626e-02],\n",
      "          [-1.3239e-04, -7.5620e-03, -7.5171e-03, -9.8973e-03, -1.7972e-02],\n",
      "          [-2.9424e-02, -3.1342e-02, -2.4486e-02, -1.9268e-02, -2.1458e-02],\n",
      "          [-3.4595e-02, -3.4983e-02, -2.8247e-02, -2.3684e-02, -2.4235e-02],\n",
      "          [-2.0756e-02, -2.1159e-02, -1.7219e-02, -1.4862e-02, -1.6738e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.6903e-04,  6.3961e-04,  1.6301e-03,  2.1585e-03,  5.0617e-04],\n",
      "          [-1.3510e-03, -1.3986e-04,  5.3984e-04,  5.8434e-04, -7.5028e-05],\n",
      "          [-1.3506e-03, -1.3659e-03, -1.2612e-03, -6.2465e-04, -3.6969e-04],\n",
      "          [-1.1122e-05,  9.9840e-05, -4.3766e-04, -1.1588e-03, -1.0658e-03],\n",
      "          [ 5.6619e-04,  6.4715e-04,  4.3878e-04, -4.5159e-04, -6.7783e-04]],\n",
      "\n",
      "         [[ 1.7963e-02,  6.2018e-03, -1.0679e-03, -1.0478e-02, -2.1433e-02],\n",
      "          [-8.1819e-03, -1.5719e-02, -1.3692e-02, -1.5611e-02, -2.1759e-02],\n",
      "          [-2.8405e-02, -3.1360e-02, -2.5369e-02, -2.2906e-02, -2.5521e-02],\n",
      "          [-2.6370e-02, -2.8696e-02, -2.3769e-02, -2.1144e-02, -2.3536e-02],\n",
      "          [-1.5750e-02, -1.7866e-02, -1.3824e-02, -1.1910e-02, -1.4672e-02]],\n",
      "\n",
      "         [[ 2.7159e-04,  8.0400e-04, -1.0492e-03, -1.3889e-03, -2.7535e-03],\n",
      "          [ 5.4981e-05, -8.8770e-04, -1.8463e-03, -1.5189e-03, -2.1573e-03],\n",
      "          [-4.8300e-04, -1.9340e-03, -2.7482e-03, -1.9693e-03, -1.2568e-03],\n",
      "          [-8.9050e-04, -2.0590e-03, -1.8802e-03, -8.3161e-04,  1.1671e-05],\n",
      "          [-4.5994e-04, -7.3682e-04, -3.1386e-04,  1.1918e-04,  1.4862e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.1202e-02, -5.5812e-03,  8.3008e-04,  1.0243e-03,  2.8115e-03],\n",
      "          [-8.8041e-03, -3.1942e-03, -5.9820e-04,  1.4500e-03,  3.5676e-03],\n",
      "          [-5.1597e-03, -3.0038e-03, -8.5677e-04,  2.7697e-03,  5.9097e-03],\n",
      "          [-2.6527e-03, -3.2130e-03, -3.2179e-04,  2.3540e-03,  5.0346e-03],\n",
      "          [-3.0814e-03, -3.7836e-03, -2.6837e-03, -4.9643e-04,  3.3420e-03]],\n",
      "\n",
      "         [[ 6.2569e-05,  1.8632e-04, -5.4334e-05, -9.7554e-05, -6.9394e-05],\n",
      "          [-1.2830e-04,  7.7500e-05,  2.1831e-05, -1.5663e-04, -8.1643e-05],\n",
      "          [-4.9625e-05, -6.9078e-05,  9.2165e-05,  1.1913e-04, -6.0752e-05],\n",
      "          [ 4.5705e-05,  3.0638e-05,  2.0005e-04,  2.6927e-04, -1.1610e-04],\n",
      "          [ 1.3329e-04,  1.5077e-04,  5.8775e-04,  3.7871e-04, -8.9363e-05]],\n",
      "\n",
      "         [[-2.3948e-02, -1.6083e-02, -2.7994e-03,  6.2865e-03,  7.0945e-03],\n",
      "          [-1.5735e-02, -1.1219e-02, -4.7342e-03,  7.5519e-04,  3.1933e-03],\n",
      "          [-1.0176e-02, -8.5516e-03, -4.7235e-03,  1.3495e-03,  7.2909e-03],\n",
      "          [-6.1442e-03, -6.5056e-03, -3.8655e-03,  9.1854e-04,  8.6796e-03],\n",
      "          [-2.6283e-03, -5.2116e-03, -3.4399e-03, -7.0885e-04,  5.1304e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.1039e-04, -4.3280e-04,  4.0238e-05,  1.2608e-04, -1.5967e-04],\n",
      "          [-1.4568e-04, -3.8757e-04,  2.7072e-04,  7.8739e-04,  2.6704e-04],\n",
      "          [-2.3403e-04, -4.2633e-04,  3.8611e-04,  8.1638e-04,  5.4412e-04],\n",
      "          [ 2.3689e-04,  5.3899e-04,  7.0961e-04,  3.0414e-04,  3.3163e-04],\n",
      "          [ 3.8760e-04,  7.4774e-04,  9.0205e-04,  4.2766e-05, -3.6179e-04]],\n",
      "\n",
      "         [[-1.7661e-02, -1.0789e-02, -1.6287e-03,  3.8455e-03,  5.4140e-03],\n",
      "          [-1.1047e-02, -6.8657e-03, -3.7790e-03,  1.0123e-03,  4.7471e-03],\n",
      "          [-5.9139e-03, -5.4522e-03, -2.6412e-03,  1.9111e-03,  7.7905e-03],\n",
      "          [-3.5508e-03, -4.5079e-03, -1.7883e-03,  1.4043e-03,  8.2806e-03],\n",
      "          [-1.4031e-03, -2.9327e-03, -3.8661e-03, -1.0851e-03,  5.0582e-03]],\n",
      "\n",
      "         [[-2.3832e-03, -4.3302e-03, -2.8411e-03, -1.4842e-04,  3.8167e-05],\n",
      "          [-2.1280e-03, -3.7011e-03, -1.7043e-03, -4.9900e-04, -1.1669e-03],\n",
      "          [-2.1134e-03, -2.3540e-03, -1.5393e-03, -1.4101e-03, -1.9655e-03],\n",
      "          [-1.0918e-03, -9.0131e-04, -1.2642e-03, -2.2961e-03, -3.4440e-03],\n",
      "          [-8.4056e-04, -1.7046e-04, -7.2142e-04, -2.7428e-03, -3.3960e-03]]]]), 'conv2.bias': tensor([ 0.0482, -0.0176,  0.0473,  0.0297,  0.0190, -0.0023, -0.0335,  0.0190,\n",
      "        -0.0066, -0.0011, -0.1058, -0.0234, -0.0800,  0.0142, -0.0394,  0.0455,\n",
      "        -0.0594, -0.0346,  0.0292, -0.0040, -0.0313, -0.0538, -0.0559, -0.0509,\n",
      "         0.0056,  0.0214,  0.0396, -0.0141, -0.0036,  0.0411, -0.0328,  0.0080]), 'fc1.weight': tensor([[ 0.0038,  0.0135,  0.0301,  ...,  0.0023,  0.0028,  0.0015],\n",
      "        [-0.0013,  0.0026,  0.0072,  ..., -0.0020, -0.0011, -0.0004],\n",
      "        [-0.0339, -0.1264, -0.2768,  ..., -0.0191, -0.0246, -0.0134],\n",
      "        ...,\n",
      "        [ 0.0029,  0.0102,  0.0211,  ...,  0.0017,  0.0020,  0.0011],\n",
      "        [ 0.0062,  0.0222,  0.0491,  ...,  0.0036,  0.0046,  0.0024],\n",
      "        [ 0.0031,  0.0102,  0.0221,  ...,  0.0019,  0.0023,  0.0012]]), 'fc1.bias': tensor([ 0.0448, -0.0276, -0.3817,  0.0473,  0.0671,  0.0545,  0.0549,  0.0324,\n",
      "         0.0718,  0.0364])}\n",
      "!-- Client 9 is normal and start iterations. ---!\n",
      "Epoch [1/3], Average Loss: 0.6150712370872498, Average Accuracy: 0.8609834313392639, Average Error: 0.1390165388584137, Culminative Time Used: 1.0408026985824108\n",
      "Epoch [2/3], Average Loss: 0.0807220563292503, Average Accuracy: 0.9829963445663452, Average Error: 0.0170036759227514, Culminative Time Used: 2.2399786971509457\n",
      "Epoch [3/3], Average Loss: 0.7964587211608887, Average Accuracy: 0.9004579186439514, Average Error: 0.0995420292019844, Culminative Time Used: 3.300941798835993\n",
      "{'conv1.weight': tensor([[[[-2.4172e-04, -5.4185e-03, -1.4194e-02, -1.7138e-02, -1.2580e-02],\n",
      "          [-1.4056e-03, -8.0562e-03, -1.7282e-02, -1.8660e-02, -1.1170e-02],\n",
      "          [-4.0012e-03, -1.0719e-02, -1.8211e-02, -1.7238e-02, -9.7414e-03],\n",
      "          [-7.3836e-03, -1.3047e-02, -1.5811e-02, -1.2805e-02, -7.4413e-03],\n",
      "          [-1.0823e-02, -1.2349e-02, -1.1457e-02, -7.1417e-03, -4.7376e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.9034e-04,  2.8254e-03,  6.0112e-03,  6.4547e-03,  4.3395e-03],\n",
      "          [ 1.9240e-04,  1.7841e-03,  4.9361e-03,  6.2906e-03,  5.2397e-03],\n",
      "          [ 1.4886e-05,  6.0472e-04,  4.0160e-03,  6.4517e-03,  5.9227e-03],\n",
      "          [ 2.0621e-05,  5.4378e-05,  1.7838e-03,  5.1993e-03,  5.4159e-03],\n",
      "          [-6.1437e-05,  2.2125e-06,  8.4633e-04,  2.6326e-03,  3.7351e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.0516e-02, -1.6950e-02, -1.8936e-02, -1.5529e-02, -5.0012e-03],\n",
      "          [-1.8731e-02, -2.8048e-02, -2.8682e-02, -2.0793e-02, -6.6613e-03],\n",
      "          [-2.2206e-02, -3.4076e-02, -3.4341e-02, -2.2875e-02, -6.3456e-03],\n",
      "          [-2.3528e-02, -3.3178e-02, -3.2497e-02, -2.2985e-02, -7.8574e-03],\n",
      "          [-2.1369e-02, -2.7182e-02, -2.7007e-02, -1.9367e-02, -9.7225e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.3908e-03, -6.5227e-03, -4.4060e-03, -4.4358e-05,  5.1394e-03],\n",
      "          [-1.1085e-02, -1.0877e-02, -8.2560e-03, -2.4242e-03,  2.4287e-03],\n",
      "          [-1.7421e-02, -1.5678e-02, -1.0175e-02, -2.1823e-03,  1.8577e-03],\n",
      "          [-2.0722e-02, -1.6115e-02, -5.9716e-03,  3.2308e-03,  4.1949e-03],\n",
      "          [-1.9375e-02, -1.1693e-02,  1.0238e-04,  5.9968e-03,  4.2767e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 8.8624e-03,  6.7982e-03,  4.1414e-03,  7.8492e-04, -1.6635e-03],\n",
      "          [ 5.3594e-03,  3.8299e-03,  1.8395e-03, -6.0220e-04, -2.0878e-03],\n",
      "          [ 5.0716e-04, -6.8615e-04, -1.2827e-03, -1.4149e-03, -1.4993e-03],\n",
      "          [-2.3397e-03, -3.0759e-03, -2.1465e-03,  4.8951e-05,  1.4791e-03],\n",
      "          [-8.0311e-04, -1.3511e-03, -4.5697e-04,  3.0590e-03,  4.8065e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.5928e-03, -4.6124e-03, -4.7125e-03, -8.2601e-03, -1.1006e-02],\n",
      "          [-6.1715e-03, -5.5922e-03, -7.9761e-03, -1.2152e-02, -1.4210e-02],\n",
      "          [-6.2811e-03, -7.5849e-03, -1.1614e-02, -1.3960e-02, -1.5629e-02],\n",
      "          [-4.7981e-03, -8.4340e-03, -1.5080e-02, -1.7879e-02, -1.8636e-02],\n",
      "          [-4.3560e-03, -8.7018e-03, -1.5267e-02, -1.9233e-02, -1.9582e-02]]],\n",
      "\n",
      "\n",
      "        [[[-6.6287e-03, -1.2490e-02, -2.5221e-02, -3.4940e-02, -3.0530e-02],\n",
      "          [-1.2053e-02, -2.1246e-02, -3.6901e-02, -4.1468e-02, -3.2126e-02],\n",
      "          [-1.9109e-02, -2.9660e-02, -4.3434e-02, -4.4107e-02, -3.2664e-02],\n",
      "          [-2.0559e-02, -3.1238e-02, -4.0582e-02, -4.0341e-02, -2.8680e-02],\n",
      "          [-1.9717e-02, -2.9350e-02, -3.3096e-02, -3.1131e-02, -2.2075e-02]]],\n",
      "\n",
      "\n",
      "        [[[-4.8174e-03, -4.0622e-03, -1.6103e-03,  3.8031e-04,  1.4534e-03],\n",
      "          [-7.0419e-03, -4.9009e-03,  6.1816e-05,  2.0613e-03, -4.3313e-04],\n",
      "          [-7.0720e-03, -3.7638e-03,  1.2846e-03,  1.9266e-03, -1.7586e-03],\n",
      "          [-6.0775e-03, -3.9134e-03, -1.5684e-04, -5.2189e-04, -3.1691e-03],\n",
      "          [-6.5891e-03, -5.1463e-03, -2.3135e-03, -1.9178e-03, -4.0298e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6135e-03, -8.7659e-04, -2.7785e-03, -2.7593e-03, -1.5811e-03],\n",
      "          [ 9.2108e-04, -3.8878e-03, -5.1848e-03, -4.4442e-03, -3.4883e-03],\n",
      "          [-2.9951e-03, -5.9923e-03, -6.0448e-03, -5.9143e-03, -6.1601e-03],\n",
      "          [-5.6912e-03, -6.3423e-03, -5.0230e-03, -6.1580e-03, -6.1527e-03],\n",
      "          [-6.5761e-03, -5.2347e-03, -3.9374e-03, -5.0977e-03, -5.4075e-03]]],\n",
      "\n",
      "\n",
      "        [[[-5.0616e-03, -4.4836e-03, -2.9979e-03, -3.8767e-03, -8.8690e-03],\n",
      "          [-1.4565e-03, -1.9562e-03, -2.4297e-03, -3.8045e-03, -7.0453e-03],\n",
      "          [-4.6268e-05, -8.1793e-05, -1.0564e-03, -2.3774e-03, -6.4197e-03],\n",
      "          [ 3.1825e-08,  1.6153e-04,  3.1911e-06, -8.6203e-04, -5.5606e-03],\n",
      "          [-1.0297e-03, -5.9854e-04, -3.9801e-04, -1.4391e-03, -4.7290e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.8929e-02, -1.5470e-02, -7.4621e-03, -2.1898e-03, -2.1686e-03],\n",
      "          [-2.5563e-02, -2.1209e-02, -9.3873e-03, -3.1109e-03, -2.3276e-03],\n",
      "          [-2.9780e-02, -2.3568e-02, -1.0575e-02, -5.3318e-03, -1.7720e-03],\n",
      "          [-2.7652e-02, -2.0874e-02, -1.1855e-02, -8.5464e-03, -2.8173e-03],\n",
      "          [-2.1685e-02, -1.6561e-02, -1.1220e-02, -7.0468e-03, -1.0111e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.3207e-03, -4.8330e-03, -3.1639e-03, -9.6843e-04, -5.5915e-04],\n",
      "          [-2.9941e-03, -2.2693e-03, -7.4195e-04,  6.3946e-04,  2.9426e-04],\n",
      "          [-1.2134e-03,  3.4174e-04,  9.9084e-04,  1.8686e-03,  1.3780e-03],\n",
      "          [-1.1010e-03, -3.6369e-04, -2.7070e-04,  4.8337e-04,  6.4567e-04],\n",
      "          [-1.2445e-03, -6.8212e-04, -1.3111e-03, -1.4880e-03, -1.2333e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.5521e-03, -5.1042e-03, -6.6104e-03, -3.6218e-03,  2.1236e-03],\n",
      "          [ 1.2154e-03, -1.9081e-03, -4.3312e-03, -2.5183e-03,  3.1437e-03],\n",
      "          [ 1.1073e-03,  2.3834e-04, -4.0190e-04,  2.1220e-03,  5.3854e-03],\n",
      "          [ 5.9000e-04,  1.0309e-03,  6.1187e-04,  1.1872e-03,  3.9532e-03],\n",
      "          [-9.8793e-04, -6.0756e-04, -6.9954e-04,  8.9963e-05,  1.9453e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.3674e-03, -1.6959e-03, -3.1333e-04,  2.8313e-04, -4.5177e-04],\n",
      "          [-3.6612e-03, -2.8865e-03, -1.3201e-03, -7.7712e-04, -1.0546e-03],\n",
      "          [-4.0335e-03, -4.0440e-03, -3.3828e-03, -2.3690e-03, -1.3787e-03],\n",
      "          [-2.4979e-03, -3.2848e-03, -3.9581e-03, -3.0996e-03, -4.8025e-04],\n",
      "          [-1.7635e-04, -5.8296e-04, -1.4689e-03, -9.8808e-04,  3.8645e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7343e-03, -1.9730e-03, -5.0906e-03, -6.8198e-03,  3.7269e-05],\n",
      "          [ 2.4349e-03, -6.6792e-03, -1.0545e-02, -1.1436e-02, -2.1288e-03],\n",
      "          [ 4.1975e-04, -9.7419e-03, -1.3426e-02, -1.2587e-02, -1.4518e-03],\n",
      "          [-2.6729e-03, -1.0636e-02, -1.2275e-02, -7.1221e-03,  2.3857e-03],\n",
      "          [-5.9541e-03, -1.0805e-02, -8.3039e-03, -1.3064e-03,  5.2563e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.7252e-03, -2.5220e-04, -2.6170e-03, -2.5745e-03, -1.8024e-03],\n",
      "          [ 5.6625e-03,  2.8720e-04, -1.1506e-03,  2.0565e-08,  4.9281e-04],\n",
      "          [ 5.1755e-03,  3.1199e-04,  8.5117e-04,  1.5993e-03,  1.6437e-03],\n",
      "          [ 5.2415e-03,  3.4805e-03,  1.8443e-03,  2.2806e-03,  2.1009e-03],\n",
      "          [ 6.5018e-03,  7.6914e-03,  5.0074e-03,  5.5243e-03,  5.3140e-03]]]]), 'conv1.bias': tensor([-0.0132,  0.0065, -0.0171, -0.0101,  0.0042, -0.0205, -0.0514, -0.0075,\n",
      "        -0.0040, -0.0295, -0.0103, -0.0044,  0.0067, -0.0008,  0.0413,  0.0121]), 'conv2.weight': tensor([[[[ 8.6376e-03,  1.0007e-03, -6.6664e-03, -1.1729e-02, -1.4718e-02],\n",
      "          [ 1.0396e-02,  7.9881e-04, -7.6794e-03, -1.1835e-02, -1.2003e-02],\n",
      "          [ 3.3339e-03, -4.5505e-03, -7.8654e-03, -5.3036e-03, -3.5533e-03],\n",
      "          [-4.5423e-03, -7.0139e-03, -1.5200e-03,  2.3692e-03, -9.5718e-04],\n",
      "          [-2.9637e-03,  1.4173e-03,  8.3124e-03,  4.4944e-03, -6.9200e-03]],\n",
      "\n",
      "         [[-5.0973e-05, -8.5747e-05,  1.5729e-04,  3.7500e-04,  7.9872e-04],\n",
      "          [ 4.0781e-04,  5.6215e-04,  6.0649e-04,  4.4954e-04,  1.6292e-04],\n",
      "          [ 3.3382e-04,  8.7259e-04,  1.0534e-03,  3.4159e-04, -1.3540e-04],\n",
      "          [ 9.2536e-05,  4.1221e-04,  7.3941e-04,  3.0631e-04, -9.7393e-05],\n",
      "          [ 1.4358e-04,  6.9551e-05,  5.0154e-04, -4.0583e-05, -2.9605e-04]],\n",
      "\n",
      "         [[ 1.4476e-02,  7.1574e-03, -2.6669e-03, -1.1969e-02, -1.6248e-02],\n",
      "          [ 1.5990e-02,  7.4134e-03, -1.5417e-03, -1.1786e-02, -1.9827e-02],\n",
      "          [ 1.5768e-02,  5.4369e-03, -8.7005e-04, -5.0441e-03, -1.2735e-02],\n",
      "          [ 6.4984e-03, -1.0672e-03,  1.1697e-03,  3.3516e-03, -2.5817e-03],\n",
      "          [-1.1951e-03,  1.9860e-04,  7.3137e-03,  7.9152e-03, -3.1038e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3113e-03,  1.1881e-03, -2.5869e-04, -9.5974e-04, -6.2800e-04],\n",
      "          [ 7.5010e-04,  1.3437e-03,  1.2955e-03,  6.6031e-04,  2.4276e-04],\n",
      "          [ 4.5778e-04,  8.5918e-04,  1.6239e-03,  5.1479e-04, -1.7549e-04],\n",
      "          [ 1.2482e-04,  6.0289e-04,  1.0775e-03, -1.9786e-05, -4.4848e-04],\n",
      "          [ 3.6907e-04,  4.8091e-04,  3.8204e-04, -2.1617e-04, -1.1729e-03]],\n",
      "\n",
      "         [[ 1.2210e-02,  3.7384e-03, -3.6482e-03, -1.1868e-02, -1.8312e-02],\n",
      "          [ 1.3373e-02,  3.0626e-03, -5.5278e-03, -1.2500e-02, -1.8933e-02],\n",
      "          [ 1.1406e-02, -1.1768e-03, -6.4481e-03, -5.4323e-03, -8.5952e-03],\n",
      "          [-3.9659e-04, -5.3194e-03, -1.3962e-04,  2.8241e-03, -1.5190e-03],\n",
      "          [-8.9450e-04,  2.4206e-03,  1.0179e-02,  6.7817e-03, -4.8767e-03]],\n",
      "\n",
      "         [[ 7.8245e-04,  1.6281e-03,  2.5738e-04, -4.2377e-04,  7.2473e-05],\n",
      "          [ 1.0742e-03,  1.8834e-03,  5.8760e-04,  6.4390e-05,  4.4820e-04],\n",
      "          [ 1.5355e-03,  9.9567e-04, -8.1091e-05,  1.4400e-04, -2.7565e-04],\n",
      "          [ 2.3428e-03,  7.2208e-04, -1.6476e-04, -2.9295e-05, -1.6388e-05],\n",
      "          [ 1.5112e-03, -2.3716e-04, -2.8143e-04,  1.8187e-03,  1.4320e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.7188e-02, -3.1631e-02, -2.6461e-02, -1.2588e-02, -2.7649e-03],\n",
      "          [-2.5735e-02, -3.5609e-02, -2.6600e-02, -1.6913e-02, -1.1141e-02],\n",
      "          [-1.9879e-02, -2.1061e-02, -1.7681e-02, -1.1347e-02, -8.6170e-03],\n",
      "          [-1.7469e-03, -7.3846e-06,  1.3970e-03,  1.8182e-03, -1.6335e-03],\n",
      "          [ 1.2203e-02,  1.3840e-02,  8.5616e-03, -1.7370e-03, -6.0024e-03]],\n",
      "\n",
      "         [[-1.4599e-03, -1.9292e-03, -2.3816e-04,  8.8376e-04,  1.4909e-03],\n",
      "          [-1.6069e-03, -2.8620e-03, -1.2431e-03,  1.1501e-04,  6.1856e-04],\n",
      "          [-1.4440e-03, -2.4216e-03, -1.9441e-03, -6.5784e-04, -2.0261e-04],\n",
      "          [-2.5950e-04, -1.1145e-03, -1.6168e-03, -1.2271e-03, -3.6613e-04],\n",
      "          [ 1.6443e-04, -3.2181e-04, -9.4502e-04, -2.0588e-03, -5.6756e-04]],\n",
      "\n",
      "         [[-9.4015e-03, -3.8834e-02, -4.6610e-02, -2.6171e-02, -3.6230e-03],\n",
      "          [-2.3452e-02, -4.8351e-02, -5.7551e-02, -4.2594e-02, -2.0576e-02],\n",
      "          [-2.7841e-02, -4.4047e-02, -5.2222e-02, -4.7744e-02, -3.3258e-02],\n",
      "          [-1.5615e-02, -2.1584e-02, -2.6520e-02, -3.1694e-02, -3.0119e-02],\n",
      "          [ 9.9349e-03,  7.1614e-03,  2.9867e-03, -1.1670e-02, -2.0977e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.8525e-03, -3.3669e-03, -2.9217e-03, -7.7903e-04,  2.6791e-04],\n",
      "          [-1.4495e-03, -2.6927e-03, -3.3838e-03, -1.7553e-03, -4.9370e-04],\n",
      "          [ 2.4357e-05, -8.0361e-04, -1.9027e-03, -1.8408e-03, -5.8684e-04],\n",
      "          [ 7.9078e-04,  6.9278e-04,  2.7129e-04, -1.4513e-03, -2.3361e-04],\n",
      "          [ 9.3789e-04,  4.7464e-04,  2.0171e-04, -9.1357e-04, -5.6945e-04]],\n",
      "\n",
      "         [[-1.5383e-02, -3.5761e-02, -3.9565e-02, -2.4514e-02, -8.9953e-03],\n",
      "          [-2.8645e-02, -4.3269e-02, -4.5356e-02, -3.4842e-02, -2.2294e-02],\n",
      "          [-2.8523e-02, -3.6505e-02, -3.8495e-02, -3.3996e-02, -2.7631e-02],\n",
      "          [-1.1214e-02, -1.4150e-02, -1.3922e-02, -1.6162e-02, -2.0549e-02],\n",
      "          [ 1.2601e-02,  1.1316e-02,  5.2820e-03, -7.8118e-03, -1.7248e-02]],\n",
      "\n",
      "         [[ 3.3842e-03, -5.5378e-04, -6.7698e-03, -6.9147e-03, -2.2114e-03],\n",
      "          [ 2.4301e-03, -1.6884e-03, -7.3735e-03, -7.0065e-03, -3.1706e-03],\n",
      "          [ 1.2921e-03, -1.8342e-03, -3.9608e-03, -4.7824e-03, -3.7530e-03],\n",
      "          [ 2.4351e-04, -5.4979e-04, -1.7935e-03, -3.3650e-03, -4.5899e-03],\n",
      "          [-1.4914e-04,  2.2444e-04, -8.0767e-04, -1.4350e-03, -3.5719e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.0097e-02, -1.8017e-02, -1.7601e-02, -1.2604e-02, -7.5598e-03],\n",
      "          [-2.1748e-02, -2.7702e-02, -2.2478e-02, -4.2734e-03,  3.0419e-03],\n",
      "          [-3.2012e-02, -3.8055e-02, -2.2550e-02, -3.5029e-04,  3.0570e-03],\n",
      "          [-4.3658e-02, -4.2380e-02, -1.7812e-02, -4.8918e-03, -5.5647e-03],\n",
      "          [-3.8348e-02, -2.9961e-02, -1.3503e-02, -7.6841e-03, -7.8416e-03]],\n",
      "\n",
      "         [[-1.4552e-03, -4.6747e-04,  4.5751e-04,  9.4795e-04,  2.0252e-04],\n",
      "          [-1.6225e-03, -5.6102e-04,  4.2770e-04,  1.2394e-03,  6.4683e-04],\n",
      "          [-1.3901e-03, -8.7911e-04,  2.6757e-04,  1.0120e-03,  9.3147e-04],\n",
      "          [-9.7789e-04, -1.1373e-03, -2.0830e-04,  6.3081e-04,  8.9447e-04],\n",
      "          [-1.2742e-03, -1.1042e-03, -2.7773e-04,  3.0100e-04,  5.1755e-04]],\n",
      "\n",
      "         [[-5.0149e-02, -4.4802e-02, -3.2771e-02, -1.7170e-02, -9.6516e-03],\n",
      "          [-4.8019e-02, -5.9275e-02, -4.8569e-02, -2.3419e-02, -3.7385e-03],\n",
      "          [-5.2771e-02, -6.9321e-02, -5.6082e-02, -2.1614e-02,  3.4967e-03],\n",
      "          [-6.5302e-02, -7.3906e-02, -5.7203e-02, -2.4273e-02, -5.3019e-03],\n",
      "          [-7.3606e-02, -7.2222e-02, -5.0354e-02, -2.9585e-02, -1.6742e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.7086e-03, -2.3247e-03, -2.9503e-04,  1.2878e-03,  5.7670e-04],\n",
      "          [-2.3442e-03, -2.2421e-03,  1.0798e-04,  1.2830e-03,  1.6813e-03],\n",
      "          [-1.7491e-03, -2.7481e-03, -1.7114e-03, -2.1565e-04,  6.6085e-04],\n",
      "          [-1.5288e-03, -1.9471e-03, -2.2591e-03, -8.7747e-04,  5.1275e-04],\n",
      "          [-1.3570e-03, -1.2769e-03, -6.9829e-04, -7.4818e-04, -4.4684e-04]],\n",
      "\n",
      "         [[-4.0858e-02, -4.1011e-02, -3.7197e-02, -2.5771e-02, -1.3903e-02],\n",
      "          [-4.2158e-02, -5.4956e-02, -4.7389e-02, -2.3564e-02, -3.8805e-03],\n",
      "          [-5.2403e-02, -6.3344e-02, -4.8588e-02, -1.9525e-02, -3.2422e-03],\n",
      "          [-6.9005e-02, -6.8574e-02, -4.5800e-02, -2.3798e-02, -1.2757e-02],\n",
      "          [-6.6731e-02, -5.9194e-02, -3.9222e-02, -2.4716e-02, -1.6402e-02]],\n",
      "\n",
      "         [[-5.9391e-03, -5.5557e-03, -3.1512e-03, -9.2644e-04,  1.0945e-03],\n",
      "          [-4.3016e-03, -4.2895e-03, -6.6130e-03, -5.1014e-03, -7.3965e-04],\n",
      "          [-3.2090e-03, -4.8904e-03, -1.1632e-02, -7.3377e-03,  1.4165e-05],\n",
      "          [-2.1937e-03, -7.7983e-03, -1.3346e-02, -6.2222e-03, -1.1515e-05],\n",
      "          [-4.9563e-03, -1.1975e-02, -1.1650e-02, -4.4092e-03, -1.0611e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-5.7655e-04,  1.0472e-03,  3.7538e-04, -9.2160e-05, -9.0262e-05],\n",
      "          [ 3.1879e-03,  1.3693e-03, -1.3905e-03, -3.3093e-04,  8.3092e-05],\n",
      "          [ 3.1138e-03, -1.3765e-03, -1.9498e-03, -5.5887e-04,  2.5270e-04],\n",
      "          [ 6.5278e-04, -2.5568e-03, -1.8146e-03, -5.1103e-04,  3.7550e-05],\n",
      "          [-3.2218e-03, -3.8131e-03, -2.6185e-03, -4.6792e-04,  1.6991e-04]],\n",
      "\n",
      "         [[ 2.7751e-04, -1.1444e-05,  5.9651e-07,  5.1589e-06,  7.7729e-06],\n",
      "          [ 1.4101e-04, -7.2892e-05, -1.7859e-06,  3.5872e-06,  1.2869e-06],\n",
      "          [-2.4052e-04, -1.7035e-04, -1.3283e-05, -3.8208e-07, -7.8721e-07],\n",
      "          [-1.9679e-04, -2.5299e-04, -1.0740e-04, -3.4461e-06, -2.4141e-06],\n",
      "          [-9.7129e-05, -2.5075e-04, -1.9524e-04, -1.8941e-05, -6.6860e-06]],\n",
      "\n",
      "         [[-3.1994e-03, -5.8258e-04, -1.9371e-03, -1.2713e-03, -7.2889e-04],\n",
      "          [-3.0936e-03,  2.3705e-04, -1.1353e-03, -9.9219e-04, -4.3106e-04],\n",
      "          [-1.6592e-03, -1.6654e-03, -4.3523e-03, -2.1949e-03, -2.5731e-04],\n",
      "          [-1.9131e-03, -4.1528e-03, -5.7730e-03, -3.0981e-03,  2.5716e-04],\n",
      "          [-3.1750e-03, -5.9139e-03, -5.1351e-03, -3.0034e-03,  2.8467e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.3194e-04, -5.2657e-05, -9.5849e-06, -2.2483e-06,  4.8111e-05],\n",
      "          [-1.9805e-04, -3.5294e-04, -8.3488e-05,  4.5569e-06,  2.7825e-05],\n",
      "          [-3.6569e-04, -8.5293e-04, -4.8025e-04, -1.3944e-05, -3.7522e-06],\n",
      "          [-3.5586e-04, -3.3915e-04, -4.1988e-04, -5.0422e-05, -7.5109e-06],\n",
      "          [-3.8694e-04, -9.7367e-05, -2.7310e-04, -1.0530e-04,  4.5607e-06]],\n",
      "\n",
      "         [[-3.8591e-03, -8.3337e-04, -1.1079e-03, -1.3295e-03, -9.6675e-04],\n",
      "          [-1.5092e-03, -2.2680e-04, -2.4953e-03, -1.8456e-03, -6.2430e-04],\n",
      "          [-7.4443e-04, -3.9139e-03, -4.8540e-03, -3.0421e-03, -4.8677e-04],\n",
      "          [-1.6694e-03, -4.7143e-03, -4.2761e-03, -2.7433e-03,  5.6042e-05],\n",
      "          [-3.1648e-03, -6.0316e-03, -3.8369e-03, -1.9804e-03,  5.4595e-04]],\n",
      "\n",
      "         [[-4.6412e-04,  8.9485e-04,  3.4124e-04, -3.1619e-04, -1.9936e-06],\n",
      "          [-1.0548e-03,  1.3988e-03,  7.2489e-04, -8.3039e-05, -2.0530e-05],\n",
      "          [ 5.1664e-04,  2.4543e-03, -1.1619e-04, -5.3822e-04, -1.0393e-04],\n",
      "          [ 1.7911e-03,  8.8267e-04, -1.0239e-03, -8.7886e-04, -1.5254e-04],\n",
      "          [ 8.8572e-04, -7.9937e-04, -1.2686e-03, -9.1803e-04, -2.2945e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 6.0753e-03, -4.5062e-03, -1.5547e-02, -1.9946e-02, -1.2815e-02],\n",
      "          [-6.4063e-04, -1.1446e-02, -1.8194e-02, -1.6134e-02, -7.3026e-03],\n",
      "          [-1.3536e-02, -2.0003e-02, -1.6971e-02, -7.7244e-03,  1.5234e-03],\n",
      "          [-2.5020e-02, -2.4878e-02, -1.4293e-02, -1.1625e-03,  6.7708e-03],\n",
      "          [-2.6550e-02, -2.2078e-02, -7.7761e-03,  4.9707e-03,  9.1530e-03]],\n",
      "\n",
      "         [[ 5.4388e-04, -7.0338e-05, -6.6054e-04, -9.7583e-04, -9.1381e-04],\n",
      "          [ 3.8791e-04, -8.1124e-05, -3.5453e-04, -8.0234e-04, -8.0370e-04],\n",
      "          [ 2.6876e-04, -9.0108e-05, -1.9207e-04, -4.3296e-04, -6.5980e-04],\n",
      "          [-6.5360e-05, -2.0453e-04,  9.6758e-05,  4.3512e-04,  2.2304e-04],\n",
      "          [-2.7639e-04,  1.2151e-04,  6.0890e-04,  1.1056e-03,  8.4418e-04]],\n",
      "\n",
      "         [[ 8.3594e-03, -5.0825e-05, -1.7573e-02, -3.1486e-02, -2.8139e-02],\n",
      "          [ 5.7463e-03, -5.6769e-03, -2.0253e-02, -2.6641e-02, -2.1522e-02],\n",
      "          [-6.5646e-03, -1.6170e-02, -2.0294e-02, -1.5355e-02, -1.0044e-02],\n",
      "          [-2.7560e-02, -3.0256e-02, -2.3200e-02, -6.9377e-03,  5.2122e-03],\n",
      "          [-4.3026e-02, -3.7564e-02, -2.0551e-02, -4.1433e-04,  1.2781e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7972e-04, -2.5330e-04, -9.4119e-04, -1.4515e-03, -1.4570e-03],\n",
      "          [ 3.9118e-04, -2.2266e-05, -2.8513e-04, -5.3333e-04, -6.8978e-04],\n",
      "          [-1.8420e-04,  2.3570e-04,  1.0755e-03,  8.9253e-04,  1.4500e-04],\n",
      "          [-1.0347e-03, -7.3165e-04, -2.5253e-05,  7.0918e-04,  1.0827e-03],\n",
      "          [-1.1787e-03, -6.1620e-04, -3.9019e-04, -2.4651e-04,  4.6241e-04]],\n",
      "\n",
      "         [[ 5.8047e-03, -3.1643e-03, -1.8732e-02, -2.7586e-02, -2.0994e-02],\n",
      "          [ 4.3294e-04, -1.1120e-02, -2.2500e-02, -2.2771e-02, -1.5198e-02],\n",
      "          [-1.3212e-02, -2.0892e-02, -2.2752e-02, -1.3672e-02, -4.5594e-03],\n",
      "          [-3.2035e-02, -3.1765e-02, -2.1883e-02, -5.5438e-03,  5.5497e-03],\n",
      "          [-4.1096e-02, -3.3205e-02, -1.5783e-02,  1.1296e-03,  1.0476e-02]],\n",
      "\n",
      "         [[ 2.3328e-03,  2.5198e-03,  6.8772e-05, -3.3699e-03, -5.9974e-03],\n",
      "          [ 1.2315e-03,  6.2451e-04, -1.8272e-03, -4.8359e-03, -5.1723e-03],\n",
      "          [-1.0805e-03, -2.5494e-03, -4.5508e-03, -5.1847e-03, -2.6803e-03],\n",
      "          [-2.4086e-03, -4.8888e-03, -5.4027e-03, -4.0408e-03,  1.4180e-04],\n",
      "          [-2.6126e-03, -5.5967e-03, -5.2868e-03, -1.8528e-03,  1.7580e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.2294e-02, -1.8964e-02, -9.9755e-03, -7.8866e-03, -1.7419e-02],\n",
      "          [-1.7279e-02, -1.0581e-02, -9.2150e-03, -1.4613e-02, -2.5643e-02],\n",
      "          [-1.6585e-02, -1.7102e-02, -2.0829e-02, -2.5167e-02, -2.8906e-02],\n",
      "          [-2.5016e-02, -3.1207e-02, -3.3868e-02, -2.8188e-02, -1.9665e-02],\n",
      "          [-3.1721e-02, -3.9265e-02, -3.1098e-02, -1.4959e-02, -2.8176e-03]],\n",
      "\n",
      "         [[-3.3388e-04, -3.2704e-04, -4.5619e-04, -8.4265e-04, -1.0435e-03],\n",
      "          [-6.8976e-04, -7.8122e-04, -5.8265e-04, -5.4504e-04, -5.3592e-04],\n",
      "          [-9.1472e-04, -8.8349e-04, -4.4666e-04, -1.2482e-04, -3.5825e-04],\n",
      "          [-8.8807e-04, -8.0196e-04,  2.2517e-04,  2.4701e-04, -5.9298e-04],\n",
      "          [-7.3428e-04, -6.3970e-04,  3.3581e-04,  4.5445e-04, -4.1206e-04]],\n",
      "\n",
      "         [[-4.9775e-02, -4.6592e-02, -3.9373e-02, -3.1292e-02, -3.5040e-02],\n",
      "          [-4.6968e-02, -4.0031e-02, -3.0927e-02, -2.7320e-02, -3.9864e-02],\n",
      "          [-4.2985e-02, -3.5350e-02, -3.5990e-02, -3.7587e-02, -4.5970e-02],\n",
      "          [-4.9145e-02, -5.0401e-02, -5.4532e-02, -5.0826e-02, -4.4940e-02],\n",
      "          [-6.4064e-02, -6.7633e-02, -6.7918e-02, -4.9978e-02, -2.8649e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.7477e-04, -6.6574e-04, -5.7447e-04, -5.4619e-04, -8.5269e-04],\n",
      "          [-7.3481e-04, -1.1687e-03, -1.0689e-03, -3.7013e-04, -9.8622e-05],\n",
      "          [-1.4290e-03, -1.9231e-03, -1.1217e-03, -1.0461e-04,  4.8277e-05],\n",
      "          [-2.4895e-03, -2.7318e-03, -1.1714e-03,  3.1842e-04,  1.9552e-05],\n",
      "          [-1.8165e-03, -1.4061e-03, -1.2063e-03,  2.2050e-04, -1.0682e-04]],\n",
      "\n",
      "         [[-4.8190e-02, -4.3276e-02, -3.4413e-02, -2.7687e-02, -3.6546e-02],\n",
      "          [-4.3943e-02, -3.3021e-02, -2.8788e-02, -3.1500e-02, -4.5340e-02],\n",
      "          [-3.9718e-02, -3.5326e-02, -3.9091e-02, -4.5700e-02, -5.1091e-02],\n",
      "          [-4.9050e-02, -5.2667e-02, -6.0350e-02, -5.6314e-02, -4.4175e-02],\n",
      "          [-6.2959e-02, -6.9449e-02, -6.3655e-02, -4.5395e-02, -2.2851e-02]],\n",
      "\n",
      "         [[-4.8623e-03, -4.7999e-03, -5.9391e-03, -4.8072e-03, -2.5065e-03],\n",
      "          [-6.0223e-03, -5.9787e-03, -5.5160e-03, -2.8442e-03, -1.2002e-03],\n",
      "          [-7.1982e-03, -5.1183e-03, -3.7241e-03, -2.6452e-03, -1.6053e-03],\n",
      "          [-5.8627e-03, -2.9630e-03, -3.4853e-03, -4.3046e-03, -4.1307e-03],\n",
      "          [-4.2730e-03, -2.7034e-03, -5.0666e-03, -7.5951e-03, -5.2769e-03]]]]), 'conv2.bias': tensor([-0.0175,  0.0022, -0.0593, -0.0734, -0.0246, -0.0349,  0.0479,  0.0245,\n",
      "         0.0360,  0.0488,  0.0229, -0.0211, -0.0479, -0.0123,  0.0276,  0.0251,\n",
      "         0.0637,  0.0496, -0.0364, -0.0105,  0.0029,  0.0557,  0.0407, -0.0293,\n",
      "        -0.0105,  0.0208, -0.0798,  0.0070,  0.0046, -0.0131, -0.0096, -0.0845]), 'fc1.weight': tensor([[-0.0209, -0.0599, -0.1683,  ..., -0.0159, -0.0166, -0.0076],\n",
      "        [ 0.0017,  0.0043,  0.0118,  ...,  0.0013,  0.0013,  0.0006],\n",
      "        [ 0.0047,  0.0140,  0.0369,  ...,  0.0034,  0.0036,  0.0017],\n",
      "        ...,\n",
      "        [ 0.0027,  0.0076,  0.0202,  ...,  0.0021,  0.0021,  0.0010],\n",
      "        [ 0.0040,  0.0110,  0.0306,  ...,  0.0030,  0.0031,  0.0015],\n",
      "        [-0.0084, -0.0212, -0.0519,  ..., -0.0060, -0.0057, -0.0032]]), 'fc1.bias': tensor([-0.2874,  0.0239,  0.0646,  0.0520,  0.0608,  0.0692,  0.0425,  0.0382,\n",
      "         0.0555, -0.1196])}\n",
      "!-- Client 3 is normal and start iterations. ---!\n",
      "Epoch [1/3], Average Loss: 0.2669235467910767, Average Accuracy: 0.9319529533386230, Average Error: 0.0680470466613770, Culminative Time Used: 1.9128793999552727\n",
      "Epoch [2/3], Average Loss: 0.2285103350877762, Average Accuracy: 0.9626625180244446, Average Error: 0.0373374149203300, Culminative Time Used: 3.6789299994707108\n",
      "Epoch [3/3], Average Loss: 0.2313516139984131, Average Accuracy: 0.9734242558479309, Average Error: 0.0265757329761982, Culminative Time Used: 5.5798615999519825\n",
      "{'conv1.weight': tensor([[[[-1.8298e-03, -1.3209e-03, -7.1806e-04,  1.0279e-03,  2.8252e-03],\n",
      "          [-4.6908e-03, -3.2411e-03, -1.0300e-03,  1.9657e-03,  3.7469e-03],\n",
      "          [-7.0478e-03, -5.8741e-03, -3.2485e-03,  6.7830e-04,  3.3566e-03],\n",
      "          [-7.8040e-03, -7.5935e-03, -4.8686e-03, -4.2511e-04,  3.7592e-03],\n",
      "          [-6.3672e-03, -5.1843e-03, -1.8065e-03,  1.8842e-03,  5.9307e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.4260e-05, -2.3723e-04, -4.5918e-04,  1.7451e-04,  7.2375e-04],\n",
      "          [-3.3228e-04, -9.3381e-04, -1.5712e-03, -1.0473e-03, -7.9772e-06],\n",
      "          [-6.5905e-05, -4.6910e-04, -1.5748e-03, -1.6792e-03, -1.1510e-03],\n",
      "          [ 9.8665e-06, -1.0813e-04, -8.8815e-04, -2.1048e-03, -2.5538e-03],\n",
      "          [ 1.1568e-04,  1.0445e-05, -2.9129e-04, -1.2248e-03, -1.9220e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.1416e-02, -2.4484e-02, -2.8275e-02, -3.4007e-02, -3.4663e-02],\n",
      "          [-3.2245e-02, -3.7124e-02, -3.8806e-02, -3.7460e-02, -3.1930e-02],\n",
      "          [-3.5877e-02, -3.8358e-02, -3.5343e-02, -2.7460e-02, -1.8835e-02],\n",
      "          [-2.9987e-02, -2.7191e-02, -2.0413e-02, -1.4507e-02, -9.1989e-03],\n",
      "          [-1.4080e-02, -1.1810e-02, -1.0083e-02, -7.8449e-03, -5.4449e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.6634e-02, -1.4306e-02, -1.2014e-02, -1.1977e-02, -1.4388e-02],\n",
      "          [-2.7615e-02, -2.4471e-02, -2.3887e-02, -2.2629e-02, -2.1586e-02],\n",
      "          [-2.8082e-02, -2.6673e-02, -2.6591e-02, -2.5311e-02, -2.3765e-02],\n",
      "          [-2.1768e-02, -2.2364e-02, -2.1411e-02, -1.9052e-02, -1.6793e-02],\n",
      "          [-1.4513e-02, -1.3291e-02, -1.1697e-02, -9.6997e-03, -8.1938e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.5636e-03, -7.3158e-03, -9.0296e-03, -8.7048e-03, -7.0994e-03],\n",
      "          [-2.4572e-03, -4.9056e-03, -8.9874e-03, -1.1916e-02, -1.1494e-02],\n",
      "          [-2.0627e-03, -7.2134e-03, -1.2420e-02, -1.5203e-02, -1.5782e-02],\n",
      "          [-6.6119e-03, -1.0138e-02, -1.3732e-02, -1.6567e-02, -1.6339e-02],\n",
      "          [-1.1952e-02, -1.4521e-02, -1.4486e-02, -1.4746e-02, -1.2029e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7670e-03,  4.0649e-03,  6.4126e-03,  1.0290e-02,  1.1133e-02],\n",
      "          [ 3.8005e-03,  6.5133e-03,  9.7609e-03,  1.1910e-02,  1.1549e-02],\n",
      "          [ 6.7836e-03,  1.0244e-02,  1.2768e-02,  1.1031e-02,  9.5269e-03],\n",
      "          [ 8.4276e-03,  1.2883e-02,  1.6288e-02,  1.4038e-02,  1.1405e-02],\n",
      "          [ 1.0174e-02,  1.5840e-02,  1.7240e-02,  1.3684e-02,  1.0255e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7960e-03,  5.2376e-03,  6.8641e-03,  7.8189e-03,  7.2410e-03],\n",
      "          [ 7.1191e-03,  9.6903e-03,  1.1504e-02,  1.0037e-02,  6.4572e-03],\n",
      "          [ 8.2393e-03,  9.9116e-03,  9.8169e-03,  5.5324e-03, -6.5688e-04],\n",
      "          [ 5.9783e-03,  5.9227e-03,  4.1356e-03, -4.5832e-04, -6.5745e-03],\n",
      "          [ 2.5446e-03,  1.5516e-03, -6.6264e-05, -2.6805e-03, -6.0667e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.7537e-03, -4.4837e-03, -7.3523e-03, -9.8790e-03, -1.0740e-02],\n",
      "          [-1.5644e-03, -3.5267e-03, -3.8773e-03, -3.7078e-03, -5.2520e-03],\n",
      "          [-6.1056e-04, -2.3854e-03, -3.3318e-03, -4.6065e-03, -7.0309e-03],\n",
      "          [-1.8923e-03, -3.9522e-03, -6.4581e-03, -8.2908e-03, -7.8714e-03],\n",
      "          [-3.7053e-03, -5.3689e-03, -7.4894e-03, -7.8951e-03, -5.0072e-03]]],\n",
      "\n",
      "\n",
      "        [[[-8.4803e-04, -1.4411e-03, -3.1832e-03, -3.6578e-03, -2.7880e-03],\n",
      "          [-2.6864e-03, -3.3095e-03, -3.5004e-03, -2.7932e-03, -1.4965e-03],\n",
      "          [-4.3526e-03, -4.1738e-03, -2.6590e-03, -1.4002e-03, -9.6983e-04],\n",
      "          [-3.8781e-03, -2.8591e-03, -7.3724e-04, -2.8277e-05,  1.0524e-04],\n",
      "          [-2.2862e-03, -1.6693e-03, -3.2538e-04,  2.6419e-04,  6.8540e-04]]],\n",
      "\n",
      "\n",
      "        [[[-3.9216e-03,  8.2081e-06,  1.3658e-03,  1.4160e-03,  1.3515e-03],\n",
      "          [-8.1337e-04,  1.4820e-03,  2.0643e-03,  1.9957e-03,  1.5645e-03],\n",
      "          [-1.3898e-04, -2.1123e-05,  3.8313e-04,  6.6475e-04,  9.7504e-04],\n",
      "          [-5.6318e-04, -4.4529e-04, -2.1015e-04,  6.0976e-05,  3.6041e-04],\n",
      "          [-1.8648e-03, -6.7303e-04, -2.4324e-04, -3.2180e-05, -8.5070e-05]]],\n",
      "\n",
      "\n",
      "        [[[-3.2316e-03, -2.3758e-03, -1.2476e-03, -1.0817e-03, -1.1331e-03],\n",
      "          [ 5.3293e-03,  6.5777e-03,  5.8195e-03,  4.1888e-03,  3.6459e-03],\n",
      "          [ 1.2140e-02,  1.2981e-02,  1.1244e-02,  8.8996e-03,  7.1320e-03],\n",
      "          [ 1.0442e-02,  1.1221e-02,  1.1481e-02,  1.2591e-02,  1.2377e-02],\n",
      "          [ 6.2025e-03,  8.2975e-03,  1.1237e-02,  1.3449e-02,  1.5762e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6087e-03,  7.3984e-04,  4.0121e-03,  6.5008e-03,  5.9578e-03],\n",
      "          [ 1.3044e-03,  2.7054e-03,  5.0850e-03,  6.9919e-03,  7.2516e-03],\n",
      "          [ 2.6344e-03,  2.9916e-03,  4.0916e-03,  5.5396e-03,  6.4000e-03],\n",
      "          [ 6.0215e-04,  1.0582e-03,  2.2085e-03,  3.4565e-03,  4.3397e-03],\n",
      "          [ 2.7835e-03,  3.7180e-03,  4.8790e-03,  5.2451e-03,  5.1339e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 6.2581e-03,  6.7312e-03,  6.4076e-03,  3.7734e-03,  3.5361e-04],\n",
      "          [ 2.5286e-03,  1.9337e-03,  1.4068e-03,  3.8458e-04,  1.3698e-04],\n",
      "          [ 3.5055e-03,  1.0632e-03,  1.2192e-03,  1.9373e-03,  1.8472e-03],\n",
      "          [ 4.1769e-03,  3.1596e-03,  3.8504e-03,  4.8052e-03,  5.3464e-03],\n",
      "          [ 5.7474e-03,  5.6065e-03,  6.8369e-03,  7.2262e-03,  7.2548e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.2967e-03, -1.5810e-03, -1.4471e-03, -1.3066e-03, -1.0341e-03],\n",
      "          [-1.2387e-03, -1.2042e-03, -1.2868e-03, -1.5098e-03, -1.2970e-03],\n",
      "          [-7.1536e-04, -1.4367e-03, -2.7633e-03, -2.7673e-03, -2.5135e-03],\n",
      "          [-2.5802e-04, -1.7383e-03, -4.6785e-03, -6.2097e-03, -6.2321e-03],\n",
      "          [ 3.2395e-04, -7.7030e-04, -4.1887e-03, -7.3550e-03, -8.0434e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.3725e-03, -8.2363e-03, -1.4171e-02, -2.1651e-02, -2.7365e-02],\n",
      "          [-9.7084e-03, -1.5286e-02, -2.3103e-02, -3.1363e-02, -3.5135e-02],\n",
      "          [-2.2079e-02, -2.8947e-02, -3.3698e-02, -3.6470e-02, -3.5265e-02],\n",
      "          [-2.2072e-02, -2.7274e-02, -2.9968e-02, -2.9497e-02, -2.5368e-02],\n",
      "          [-1.2066e-02, -1.4730e-02, -1.5202e-02, -1.3608e-02, -1.1797e-02]]],\n",
      "\n",
      "\n",
      "        [[[-9.4136e-03, -8.6324e-03, -5.4551e-03, -1.1608e-03,  2.2920e-04],\n",
      "          [-9.2693e-03, -8.7722e-03, -5.2858e-03, -9.0361e-04, -4.0077e-05],\n",
      "          [-9.1071e-03, -7.7921e-03, -5.4541e-03, -1.9642e-03, -1.1596e-03],\n",
      "          [-9.2797e-03, -8.7166e-03, -5.2894e-03, -3.4460e-03, -2.7988e-03],\n",
      "          [-1.0102e-02, -9.8367e-03, -6.6421e-03, -6.2132e-03, -5.4929e-03]]]]), 'conv1.bias': tensor([ 0.0006, -0.0020, -0.0188, -0.0127, -0.0221,  0.0237,  0.0077, -0.0001,\n",
      "        -0.0062,  0.0046,  0.0492,  0.0068,  0.0209, -0.0089,  0.0020, -0.0148]), 'conv2.weight': tensor([[[[-6.4728e-03, -2.7273e-03,  1.7342e-03,  4.9089e-03,  5.5596e-03],\n",
      "          [-1.0882e-02, -9.2837e-03, -4.5140e-03, -2.4848e-03, -1.0712e-03],\n",
      "          [-1.3142e-02, -8.7435e-03, -4.5640e-03, -1.8235e-03,  1.6895e-03],\n",
      "          [-1.1009e-02, -3.7429e-03,  6.8830e-04,  4.4052e-03,  9.1178e-03],\n",
      "          [-9.0469e-03, -4.7460e-03, -1.7285e-03,  4.2912e-03,  9.2281e-03]],\n",
      "\n",
      "         [[-2.3824e-04,  1.3098e-04,  2.5573e-04,  1.2262e-04, -9.7375e-05],\n",
      "          [-2.3822e-04,  1.7603e-05, -6.6226e-05, -1.7078e-04, -6.5981e-05],\n",
      "          [ 6.7595e-06,  1.1272e-04, -2.1093e-04, -3.4353e-04, -3.8812e-04],\n",
      "          [ 4.5398e-04,  5.0554e-04,  2.1996e-04, -9.1309e-05, -3.8012e-04],\n",
      "          [ 3.8774e-04,  6.1761e-04,  4.4636e-04,  1.4434e-04, -6.9909e-05]],\n",
      "\n",
      "         [[-1.7552e-02, -1.0438e-02, -1.9234e-03,  6.1843e-03,  1.2192e-02],\n",
      "          [-2.1977e-02, -1.6073e-02, -1.1738e-02, -6.4867e-03,  2.3599e-03],\n",
      "          [-2.4669e-02, -2.1290e-02, -1.8218e-02, -1.4428e-02, -5.0995e-03],\n",
      "          [-2.3472e-02, -1.5554e-02, -1.1554e-02, -8.2807e-03,  1.4106e-03],\n",
      "          [-2.1653e-02, -1.3169e-02, -7.3446e-03, -1.3786e-03,  1.0992e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.2711e-03, -1.0523e-03, -6.6173e-04, -2.6512e-04, -2.5950e-04],\n",
      "          [-9.2058e-04, -8.1903e-04, -1.7469e-03, -2.0797e-03, -1.3945e-03],\n",
      "          [ 2.3599e-04,  3.1491e-04, -1.0525e-03, -1.3151e-03, -5.5170e-04],\n",
      "          [ 8.8289e-04,  1.3284e-03,  4.3866e-04,  1.6497e-04,  4.2256e-04],\n",
      "          [-3.5137e-04,  3.8636e-04,  2.9357e-04,  3.1048e-04,  8.1110e-04]],\n",
      "\n",
      "         [[-1.5580e-02, -9.6499e-03, -3.6754e-03,  2.0031e-03,  8.3004e-03],\n",
      "          [-2.0580e-02, -1.7126e-02, -1.2691e-02, -9.4687e-03, -2.1430e-03],\n",
      "          [-2.4220e-02, -2.0215e-02, -1.6810e-02, -1.3033e-02, -4.6094e-03],\n",
      "          [-2.0940e-02, -1.4040e-02, -1.0205e-02, -5.8051e-03,  4.3832e-03],\n",
      "          [-1.9088e-02, -1.4148e-02, -8.8079e-03, -4.3725e-04,  1.0100e-02]],\n",
      "\n",
      "         [[-1.7773e-03, -5.3956e-04, -8.0647e-04, -9.3894e-04, -3.9177e-04],\n",
      "          [-1.8874e-03, -1.3936e-03, -1.6329e-03, -1.2036e-03, -6.7857e-04],\n",
      "          [-2.1475e-03, -2.0912e-03, -1.5888e-03, -2.1845e-03, -1.4411e-03],\n",
      "          [-3.1115e-03, -2.2406e-03, -1.5835e-03, -3.1846e-03, -1.5709e-03],\n",
      "          [-2.3648e-03, -1.4299e-03, -1.9790e-03, -4.3855e-03, -2.4058e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9558e-02,  2.0756e-02,  1.5016e-02,  4.3256e-03,  3.4033e-04],\n",
      "          [ 2.3961e-02,  2.0223e-02,  1.0341e-02,  3.3649e-03, -6.8084e-04],\n",
      "          [ 1.7484e-02,  1.3698e-02,  7.2007e-03,  5.0858e-03,  5.5059e-03],\n",
      "          [ 1.0835e-02,  1.0569e-02,  8.7795e-03,  1.3452e-02,  1.9541e-02],\n",
      "          [ 1.3711e-02,  1.5546e-02,  1.5731e-02,  1.8816e-02,  2.2834e-02]],\n",
      "\n",
      "         [[ 2.4647e-05, -2.5487e-04, -1.6594e-04, -1.6135e-04, -2.4007e-04],\n",
      "          [ 2.9960e-04, -1.6264e-04, -4.1070e-04, -2.3403e-04, -3.2095e-04],\n",
      "          [ 5.9672e-04,  2.9722e-04, -2.8453e-04, -1.9635e-04, -1.0974e-05],\n",
      "          [ 6.6208e-04,  5.6081e-04,  9.4162e-05,  1.5095e-04,  3.2845e-04],\n",
      "          [ 4.9640e-04,  4.8609e-04,  2.4019e-04,  2.7571e-04,  4.3577e-04]],\n",
      "\n",
      "         [[ 3.3727e-02,  3.4949e-02,  2.8421e-02,  1.8428e-02,  1.0699e-02],\n",
      "          [ 4.5586e-02,  4.4535e-02,  2.8535e-02,  1.3202e-02,  7.2719e-03],\n",
      "          [ 4.3038e-02,  4.0099e-02,  2.5984e-02,  1.2717e-02,  9.9946e-03],\n",
      "          [ 2.9613e-02,  2.9104e-02,  2.3036e-02,  1.8507e-02,  2.3373e-02],\n",
      "          [ 2.5200e-02,  2.5343e-02,  2.6880e-02,  3.0170e-02,  3.7953e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.3467e-03, -1.4246e-04, -1.1250e-03, -3.9087e-04, -4.5845e-04],\n",
      "          [ 2.4091e-03,  1.5201e-03, -4.7775e-04, -2.9447e-04, -1.2905e-04],\n",
      "          [ 1.0363e-03,  1.2484e-03,  2.1504e-04,  6.6508e-04,  1.3114e-03],\n",
      "          [ 4.9404e-04,  6.5728e-04,  2.1397e-04,  7.0378e-04,  2.0244e-03],\n",
      "          [ 9.9934e-04,  9.0016e-04,  4.3030e-04,  3.8157e-04,  1.2563e-03]],\n",
      "\n",
      "         [[ 3.5138e-02,  3.6128e-02,  2.7141e-02,  1.5153e-02,  9.2768e-03],\n",
      "          [ 4.4802e-02,  4.1032e-02,  2.5883e-02,  1.3380e-02,  7.1880e-03],\n",
      "          [ 3.7574e-02,  3.2186e-02,  2.2782e-02,  1.3385e-02,  1.1388e-02],\n",
      "          [ 2.7602e-02,  2.3841e-02,  2.0914e-02,  2.2335e-02,  2.7100e-02],\n",
      "          [ 2.7109e-02,  2.7723e-02,  2.9592e-02,  3.4049e-02,  3.8959e-02]],\n",
      "\n",
      "         [[ 2.7445e-03,  3.7914e-03,  5.1011e-03,  3.4997e-03,  1.2886e-03],\n",
      "          [ 2.0143e-03,  4.6353e-03,  5.7892e-03,  2.1212e-03,  6.8389e-04],\n",
      "          [ 2.3223e-03,  4.5665e-03,  4.0708e-03,  1.6315e-03,  2.0767e-03],\n",
      "          [ 2.2048e-03,  3.5999e-03,  3.5901e-03,  2.1016e-03,  2.3594e-03],\n",
      "          [ 2.6015e-03,  3.1414e-03,  2.9201e-03,  1.4298e-03,  2.3074e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.1495e-03, -8.8433e-03, -8.8566e-03, -7.3888e-03, -5.9339e-03],\n",
      "          [-1.2728e-02, -1.2663e-02, -8.6015e-03, -4.7644e-03, -1.6211e-03],\n",
      "          [-1.9484e-02, -1.5420e-02, -7.7431e-03, -3.2789e-03, -2.5775e-03],\n",
      "          [-2.2771e-02, -1.7181e-02, -1.1666e-02, -1.2342e-02, -1.1007e-02],\n",
      "          [-1.6639e-02, -1.3802e-02, -1.5504e-02, -1.6892e-02, -1.3024e-02]],\n",
      "\n",
      "         [[-4.5292e-04, -2.9213e-04, -9.7957e-05, -1.0264e-04, -7.0195e-05],\n",
      "          [-2.2016e-04, -7.8244e-05,  6.6826e-05,  1.8021e-04, -2.8342e-06],\n",
      "          [ 1.2045e-04,  4.9211e-04,  2.4414e-04,  1.2583e-04,  6.5890e-05],\n",
      "          [ 6.3319e-05,  3.6074e-04,  2.1714e-04,  1.2089e-04, -1.5895e-05],\n",
      "          [-4.5300e-04, -3.0656e-04, -2.2326e-04, -1.0547e-04, -6.5979e-05]],\n",
      "\n",
      "         [[ 2.8650e-03, -6.0019e-03, -8.8332e-03, -9.3051e-03, -1.1422e-02],\n",
      "          [-1.2815e-02, -1.9764e-02, -1.8955e-02, -1.5325e-02, -1.3762e-02],\n",
      "          [-2.6878e-02, -2.7267e-02, -2.0533e-02, -1.3714e-02, -9.9562e-03],\n",
      "          [-3.8556e-02, -3.3193e-02, -2.2286e-02, -1.5364e-02, -1.2700e-02],\n",
      "          [-4.0242e-02, -3.5245e-02, -2.8219e-02, -2.6455e-02, -2.2552e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.2359e-03, -1.6015e-03, -4.9170e-04, -2.8704e-04, -5.7797e-04],\n",
      "          [-9.3713e-04, -2.4381e-04,  1.8018e-04,  1.7280e-04, -1.0151e-04],\n",
      "          [-6.2538e-04,  5.4657e-04,  4.3265e-04,  1.5184e-04, -1.2557e-04],\n",
      "          [-1.3203e-03, -1.0891e-03, -1.4615e-03, -1.0351e-03, -8.7345e-04],\n",
      "          [-1.7958e-03, -1.5781e-03, -1.2148e-03, -9.6367e-04, -8.8744e-04]],\n",
      "\n",
      "         [[ 6.8157e-04, -8.9525e-03, -1.1947e-02, -1.1693e-02, -1.3065e-02],\n",
      "          [-1.6282e-02, -2.1569e-02, -2.0273e-02, -1.6260e-02, -1.2739e-02],\n",
      "          [-2.9311e-02, -2.8563e-02, -1.9423e-02, -1.1926e-02, -9.3574e-03],\n",
      "          [-3.7639e-02, -3.1500e-02, -2.1490e-02, -1.8047e-02, -1.6213e-02],\n",
      "          [-3.2691e-02, -3.0051e-02, -3.0054e-02, -2.9156e-02, -2.4632e-02]],\n",
      "\n",
      "         [[ 2.0227e-03,  1.1254e-03,  1.5397e-04,  2.8024e-04, -6.0107e-05],\n",
      "          [ 1.3793e-03, -2.9724e-04, -9.1035e-04, -5.0783e-04, -8.8637e-04],\n",
      "          [-7.7688e-04, -2.8475e-03, -3.3030e-03, -2.1250e-03, -1.6170e-03],\n",
      "          [-2.3306e-03, -5.1200e-03, -4.9597e-03, -2.7884e-03, -2.1655e-03],\n",
      "          [-3.7555e-03, -5.4754e-03, -3.0340e-03, -1.4651e-03, -2.4924e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 1.8274e-02,  1.6832e-02,  3.9803e-03,  5.6554e-04,  5.0947e-04],\n",
      "          [ 1.3428e-02,  9.4239e-03,  3.1194e-03,  1.3204e-03,  1.1808e-03],\n",
      "          [ 7.3900e-03,  5.0605e-03,  2.5757e-03,  1.4853e-03,  1.0109e-03],\n",
      "          [ 1.6846e-03,  2.1531e-03,  1.5174e-03,  7.1949e-04,  2.4659e-04],\n",
      "          [ 1.1258e-03,  2.9389e-03,  2.2363e-03,  4.5880e-04,  8.9005e-05]],\n",
      "\n",
      "         [[ 2.8848e-04,  1.2682e-04,  1.3923e-05,  5.5120e-06, -1.7975e-05],\n",
      "          [ 2.0912e-04,  4.2703e-05,  2.6247e-06,  9.3848e-07, -7.9920e-06],\n",
      "          [ 2.8529e-04,  1.0285e-04,  5.3986e-06,  5.6339e-07, -3.0038e-06],\n",
      "          [ 1.6304e-04,  2.5032e-04,  6.3301e-05,  8.6787e-06,  7.0653e-06],\n",
      "          [ 1.1400e-04,  2.2155e-04,  9.4590e-05,  1.9695e-05,  9.2399e-06]],\n",
      "\n",
      "         [[ 3.2827e-02,  3.4883e-02,  2.2788e-02,  8.3442e-03,  3.6458e-03],\n",
      "          [ 3.0815e-02,  2.7798e-02,  1.5534e-02,  6.4093e-03,  3.9582e-03],\n",
      "          [ 1.8352e-02,  1.7927e-02,  1.2474e-02,  5.8642e-03,  4.6730e-03],\n",
      "          [ 8.5143e-03,  1.0424e-02,  9.2777e-03,  5.2226e-03,  3.6027e-03],\n",
      "          [ 2.4150e-03,  5.1280e-03,  5.3853e-03,  3.4698e-03,  1.9008e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 7.6213e-04,  4.2133e-04,  7.5333e-05,  2.2187e-05,  1.5421e-06],\n",
      "          [ 4.8190e-04,  4.2522e-04,  7.1527e-05,  1.5123e-05,  2.5892e-05],\n",
      "          [ 2.4109e-04,  8.6043e-04,  3.6170e-04,  5.0725e-05,  2.6111e-05],\n",
      "          [ 2.0831e-04,  4.7094e-04,  3.5009e-04,  4.2965e-05,  1.0885e-05],\n",
      "          [ 3.9879e-04,  2.6506e-04,  2.1338e-04,  3.8657e-05,  3.0785e-06]],\n",
      "\n",
      "         [[ 3.2894e-02,  3.0933e-02,  1.6289e-02,  7.6754e-03,  4.8370e-03],\n",
      "          [ 2.6422e-02,  2.0517e-02,  1.2705e-02,  6.8736e-03,  5.5423e-03],\n",
      "          [ 1.5887e-02,  1.4412e-02,  1.0866e-02,  6.6934e-03,  5.8678e-03],\n",
      "          [ 7.0697e-03,  7.4091e-03,  6.9486e-03,  5.0633e-03,  4.1765e-03],\n",
      "          [ 2.7015e-03,  5.1603e-03,  4.3561e-03,  3.0824e-03,  2.4964e-03]],\n",
      "\n",
      "         [[ 5.6459e-04,  4.3724e-03,  6.9755e-03,  1.9173e-03,  1.1626e-04],\n",
      "          [ 1.1698e-03,  5.9084e-03,  4.9099e-03,  7.7387e-04,  1.1061e-04],\n",
      "          [ 5.8738e-04,  3.1041e-03,  2.2117e-03,  5.7351e-04,  9.7698e-05],\n",
      "          [-2.1991e-04,  1.3507e-03,  1.0953e-03,  6.0219e-04,  1.0623e-04],\n",
      "          [-8.6715e-04,  1.5530e-04,  8.6331e-04,  7.5110e-04,  1.2849e-04]]],\n",
      "\n",
      "\n",
      "        [[[-5.4965e-04, -2.5932e-03, -4.9299e-03, -6.1478e-03, -5.7225e-03],\n",
      "          [-1.2744e-03, -1.5160e-03,  4.3468e-04,  4.1008e-03,  7.1482e-03],\n",
      "          [ 1.1044e-02,  1.5379e-02,  1.9439e-02,  2.0543e-02,  1.8393e-02],\n",
      "          [ 2.6016e-02,  3.0363e-02,  2.6439e-02,  2.0282e-02,  1.7146e-02],\n",
      "          [ 2.6677e-02,  2.3256e-02,  1.2107e-02,  7.3787e-03,  1.0179e-02]],\n",
      "\n",
      "         [[-2.6042e-05,  1.3294e-04,  1.1946e-04,  8.3667e-05,  1.4675e-04],\n",
      "          [ 5.6495e-05,  3.0934e-04,  3.6487e-04,  2.2297e-04, -1.0103e-05],\n",
      "          [ 3.5044e-04,  5.5629e-04,  4.3912e-04,  3.1616e-04,  6.1924e-05],\n",
      "          [ 6.3578e-04,  5.6532e-04,  2.5814e-04,  2.7132e-04,  1.9734e-04],\n",
      "          [ 5.4765e-04,  3.1281e-04,  3.3978e-05,  1.7714e-04,  3.9539e-04]],\n",
      "\n",
      "         [[ 9.0782e-03,  1.2031e-02,  1.2420e-02,  8.4424e-03,  4.5912e-03],\n",
      "          [ 2.3625e-03, -1.1073e-03, -2.0410e-03,  9.4662e-04,  5.9473e-03],\n",
      "          [ 1.0652e-02,  1.1345e-02,  1.1753e-02,  1.4739e-02,  2.0151e-02],\n",
      "          [ 3.3357e-02,  4.0674e-02,  4.0969e-02,  3.4926e-02,  3.3663e-02],\n",
      "          [ 5.0363e-02,  5.4999e-02,  4.6395e-02,  3.5404e-02,  3.1797e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.3780e-03, -7.6331e-04, -5.1799e-05,  2.9070e-04,  6.1794e-04],\n",
      "          [ 7.4446e-04,  8.1193e-04,  6.6969e-04,  3.3117e-04,  8.5686e-05],\n",
      "          [ 2.6635e-03,  2.3136e-03,  6.8020e-04,  2.8960e-04,  7.8848e-04],\n",
      "          [ 3.0581e-03,  2.7749e-03,  1.3721e-03,  9.0789e-04,  1.7516e-03],\n",
      "          [ 1.4417e-03,  9.3477e-04,  5.3725e-04,  1.8226e-04,  6.3925e-04]],\n",
      "\n",
      "         [[ 6.7626e-03,  5.7967e-03,  2.8403e-03,  4.2934e-04, -1.5414e-04],\n",
      "          [ 1.9967e-03, -1.0850e-03, -1.6812e-03,  2.0977e-03,  8.2359e-03],\n",
      "          [ 1.2641e-02,  1.6314e-02,  2.0990e-02,  2.2167e-02,  2.3743e-02],\n",
      "          [ 3.6513e-02,  4.3464e-02,  4.2267e-02,  3.5009e-02,  3.0882e-02],\n",
      "          [ 5.0183e-02,  4.9224e-02,  3.8207e-02,  3.0254e-02,  2.8108e-02]],\n",
      "\n",
      "         [[-2.1376e-04,  2.0104e-04,  1.0177e-03,  7.3067e-04,  1.1364e-04],\n",
      "          [ 5.6409e-04,  9.6713e-04,  7.9746e-04,  6.1647e-04,  8.2879e-04],\n",
      "          [ 2.0996e-03,  2.5238e-03,  2.0187e-03,  1.6333e-03,  2.3485e-03],\n",
      "          [ 2.0126e-03,  2.8617e-03,  3.2579e-03,  2.7124e-03,  1.9531e-03],\n",
      "          [ 1.6295e-03,  4.2961e-03,  5.0238e-03,  2.6926e-03,  8.9171e-04]]],\n",
      "\n",
      "\n",
      "        [[[-2.0466e-03, -2.5344e-07, -7.9260e-04, -1.0696e-03,  7.1057e-04],\n",
      "          [ 3.1835e-03,  2.5492e-03,  4.8859e-04,  7.5431e-04,  2.0096e-03],\n",
      "          [ 2.2735e-03, -1.7231e-03, -1.9723e-03, -5.3535e-04,  1.4544e-03],\n",
      "          [-1.9640e-03, -3.4592e-03, -1.8583e-03, -2.0714e-04, -1.1197e-03],\n",
      "          [-1.5655e-03,  1.7032e-03,  5.5839e-03,  3.9996e-03, -3.3537e-03]],\n",
      "\n",
      "         [[ 8.4193e-05,  1.2247e-04,  1.2297e-04,  1.2623e-04,  7.3851e-05],\n",
      "          [ 9.8048e-06,  1.4106e-04,  1.6315e-04,  1.4441e-04,  3.5445e-04],\n",
      "          [-1.8383e-04,  5.0174e-05,  4.5064e-04,  3.5141e-04,  2.7053e-04],\n",
      "          [-2.1788e-04,  3.1956e-05,  4.4188e-04,  3.1840e-04,  1.1593e-04],\n",
      "          [ 3.0250e-06, -1.6218e-05,  1.0762e-04, -8.0421e-06,  4.1093e-05]],\n",
      "\n",
      "         [[-1.0388e-02, -4.3848e-03, -1.3948e-03, -6.1238e-05,  3.7862e-03],\n",
      "          [-8.2905e-03, -3.6897e-03, -2.1370e-03, -2.1179e-03,  1.3732e-04],\n",
      "          [-1.4290e-03, -1.6484e-03, -5.0499e-04,  1.2821e-03,  1.4642e-03],\n",
      "          [-1.2622e-03, -5.2878e-03, -3.4763e-03,  8.2540e-04,  1.3365e-03],\n",
      "          [-4.2527e-03, -4.4334e-03, -1.5981e-03,  1.4112e-03, -7.4641e-05]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.6903e-04, -5.9983e-04, -8.1707e-04, -7.7945e-04, -3.9437e-04],\n",
      "          [-3.3123e-04,  1.1082e-04,  9.6571e-04,  4.9721e-04,  3.4546e-04],\n",
      "          [-1.0222e-03, -2.0912e-04,  1.0736e-03,  9.8638e-04,  7.3653e-05],\n",
      "          [-4.6435e-04, -4.3657e-04,  2.6897e-04, -3.9304e-05, -1.0426e-03],\n",
      "          [ 2.7626e-04,  2.9241e-05, -3.0643e-04, -5.5538e-04, -1.0752e-03]],\n",
      "\n",
      "         [[-9.1929e-03, -4.2510e-03, -1.4512e-03, -7.6963e-05,  3.8623e-03],\n",
      "          [-5.7504e-03, -2.7870e-03, -1.7466e-03, -8.0413e-04,  8.1892e-04],\n",
      "          [-1.1355e-03, -3.1012e-03, -3.7367e-03, -9.4751e-04,  2.2887e-03],\n",
      "          [-4.9048e-03, -7.5011e-03, -5.5451e-03, -1.2550e-03,  1.4127e-03],\n",
      "          [-5.4382e-03, -1.4774e-03,  3.4103e-03,  3.6831e-03, -9.7929e-04]],\n",
      "\n",
      "         [[-1.5305e-03,  4.8228e-04,  1.0265e-03,  7.4045e-04,  8.0499e-05],\n",
      "          [-8.4720e-04,  4.3773e-04,  7.0323e-04,  3.8350e-04, -4.4110e-04],\n",
      "          [ 3.2218e-04,  7.9557e-04,  4.5883e-04,  3.3443e-07, -5.6119e-04],\n",
      "          [ 1.4120e-03,  8.1811e-04,  2.7777e-04,  4.2436e-04,  4.0526e-04],\n",
      "          [ 4.1295e-04, -4.9784e-05, -1.4395e-04,  1.4184e-03,  2.2297e-03]]]]), 'conv2.bias': tensor([-0.0335,  0.0456, -0.0359,  0.0551, -0.0229, -0.0295,  0.0134, -0.0095,\n",
      "        -0.0168, -0.0272,  0.0065, -0.0171, -0.0102, -0.0024,  0.0473, -0.0144,\n",
      "         0.0166, -0.0077,  0.0297,  0.0196,  0.0445,  0.0206, -0.0079,  0.0670,\n",
      "        -0.0534, -0.0378,  0.0482, -0.0206,  0.0016,  0.0211,  0.0160, -0.0172]), 'fc1.weight': tensor([[0.0044, 0.0148, 0.0290,  ..., 0.0025, 0.0027, 0.0011],\n",
      "        [0.0030, 0.0100, 0.0204,  ..., 0.0019, 0.0019, 0.0008],\n",
      "        [0.0058, 0.0196, 0.0370,  ..., 0.0031, 0.0035, 0.0014],\n",
      "        ...,\n",
      "        [0.0043, 0.0146, 0.0283,  ..., 0.0024, 0.0026, 0.0011],\n",
      "        [0.0059, 0.0199, 0.0402,  ..., 0.0035, 0.0037, 0.0015],\n",
      "        [0.0046, 0.0151, 0.0295,  ..., 0.0028, 0.0029, 0.0012]]), 'fc1.bias': tensor([ 0.0428,  0.0318,  0.0551, -0.3487, -0.0437,  0.0666,  0.0476,  0.0421,\n",
      "         0.0596,  0.0468])}\n",
      "!-- Client 8 is normal and start iterations. ---!\n",
      "Epoch [1/3], Average Loss: 0.5385980606079102, Average Accuracy: 0.8505960106849670, Average Error: 0.1494039893150330, Culminative Time Used: 2.1222380995750427\n",
      "Epoch [2/3], Average Loss: 0.3676761090755463, Average Accuracy: 0.9134282469749451, Average Error: 0.0865717604756355, Culminative Time Used: 4.114357400685549\n",
      "Epoch [3/3], Average Loss: 0.2339287102222443, Average Accuracy: 0.9467383623123169, Average Error: 0.0532616674900055, Culminative Time Used: 6.1926244013011456\n",
      "{'conv1.weight': tensor([[[[-2.2215e-03, -2.2567e-03, -3.3636e-03, -3.7245e-03, -3.1047e-03],\n",
      "          [-1.8270e-03, -3.5563e-03, -6.3893e-03, -5.7740e-03, -2.8085e-03],\n",
      "          [-2.2094e-03, -5.9150e-03, -9.8771e-03, -8.9389e-03, -4.6963e-03],\n",
      "          [-2.2912e-03, -6.9761e-03, -1.0316e-02, -8.9308e-03, -6.6363e-03],\n",
      "          [-2.0781e-03, -5.8777e-03, -7.5893e-03, -6.5569e-03, -6.5073e-03]]],\n",
      "\n",
      "\n",
      "        [[[-7.7567e-04, -1.6660e-03, -2.6728e-03, -2.5510e-03, -1.4764e-03],\n",
      "          [-2.7552e-04, -1.4602e-03, -2.5619e-03, -2.5201e-03, -1.7275e-03],\n",
      "          [ 1.0184e-04, -6.0907e-04, -2.0988e-03, -2.5509e-03, -1.9449e-03],\n",
      "          [ 2.2378e-04,  3.9616e-05, -7.9158e-04, -1.3537e-03, -1.1517e-03],\n",
      "          [ 1.9411e-04,  4.3584e-05,  2.9215e-04,  4.1975e-04,  1.1109e-04]]],\n",
      "\n",
      "\n",
      "        [[[-1.4208e-02, -1.7047e-02, -1.9763e-02, -2.1132e-02, -1.6342e-02],\n",
      "          [-1.9439e-02, -2.5582e-02, -2.9008e-02, -2.5902e-02, -1.6139e-02],\n",
      "          [-2.4232e-02, -3.2541e-02, -3.2536e-02, -2.3491e-02, -1.0913e-02],\n",
      "          [-2.8004e-02, -3.1974e-02, -2.8331e-02, -2.0043e-02, -9.6144e-03],\n",
      "          [-2.5371e-02, -2.8047e-02, -2.6255e-02, -1.8232e-02, -1.0403e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1063e-02, -1.0017e-02, -7.4206e-03, -4.3134e-03,  1.6988e-03],\n",
      "          [-1.6153e-02, -1.5472e-02, -1.3971e-02, -8.8695e-03, -2.7254e-03],\n",
      "          [-2.1003e-02, -2.2299e-02, -1.9628e-02, -1.1667e-02, -4.7736e-03],\n",
      "          [-2.2996e-02, -2.3865e-02, -1.7765e-02, -9.6131e-03, -4.7782e-03],\n",
      "          [-1.9839e-02, -1.7845e-02, -1.1410e-02, -6.0829e-03, -2.7313e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.6302e-03, -2.9044e-03, -5.1115e-03, -6.7442e-03, -7.2253e-03],\n",
      "          [-3.9607e-03, -3.4841e-03, -6.2720e-03, -1.0423e-02, -1.1144e-02],\n",
      "          [-5.0549e-03, -4.9789e-03, -6.8862e-03, -1.1041e-02, -1.2257e-02],\n",
      "          [-5.3302e-03, -3.9078e-03, -4.3848e-03, -6.5952e-03, -8.0412e-03],\n",
      "          [-2.0830e-03, -1.0821e-03, -1.5147e-03, -1.6909e-03, -3.3447e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.5906e-03, -2.5872e-03, -5.3390e-03, -9.9855e-03, -1.0787e-02],\n",
      "          [-1.6974e-03, -3.3102e-03, -6.7021e-03, -8.7151e-03, -7.0031e-03],\n",
      "          [-1.7819e-03, -3.4616e-03, -5.7138e-03, -5.4414e-03, -4.2676e-03],\n",
      "          [-2.2316e-05, -1.4207e-03, -3.4156e-03, -3.4154e-03, -3.0135e-03],\n",
      "          [ 1.4065e-03,  1.4085e-03, -1.1330e-03, -3.1582e-03, -3.6476e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 9.9874e-04, -1.2058e-03, -6.0173e-03, -1.0139e-02, -9.7697e-03],\n",
      "          [-3.1322e-03, -6.7515e-03, -1.2572e-02, -1.3945e-02, -1.1435e-02],\n",
      "          [-8.7749e-03, -1.2614e-02, -1.7186e-02, -1.7447e-02, -1.3477e-02],\n",
      "          [-9.6376e-03, -1.3689e-02, -1.7895e-02, -1.8751e-02, -1.2906e-02],\n",
      "          [-8.4650e-03, -1.3415e-02, -1.6245e-02, -1.6031e-02, -1.0546e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6630e-02, -1.5024e-02, -1.3096e-02, -1.0826e-02, -9.4180e-03],\n",
      "          [-2.2346e-02, -1.7989e-02, -1.1958e-02, -9.3158e-03, -1.0928e-02],\n",
      "          [-2.1849e-02, -1.7001e-02, -1.1011e-02, -9.1507e-03, -1.1826e-02],\n",
      "          [-2.0647e-02, -1.9438e-02, -1.3706e-02, -1.1472e-02, -1.1533e-02],\n",
      "          [-1.9442e-02, -1.9832e-02, -1.6010e-02, -1.2730e-02, -1.1602e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.4290e-05, -1.7350e-03, -2.7178e-03, -2.0200e-03,  3.1720e-04],\n",
      "          [-1.5829e-03, -3.3068e-03, -3.5434e-03, -1.6860e-03, -7.0721e-05],\n",
      "          [-5.0809e-03, -5.4635e-03, -4.4476e-03, -2.9887e-03, -1.4868e-03],\n",
      "          [-5.9010e-03, -5.2927e-03, -4.3036e-03, -3.4516e-03, -1.9099e-03],\n",
      "          [-3.5790e-03, -3.7854e-03, -4.1013e-03, -4.0602e-03, -2.6534e-03]]],\n",
      "\n",
      "\n",
      "        [[[-1.4022e-03, -1.9999e-03, -1.9333e-03, -2.4506e-03, -4.9129e-03],\n",
      "          [-5.3767e-05, -1.3191e-03, -1.5918e-03, -2.1574e-03, -3.3533e-03],\n",
      "          [ 1.2453e-04,  6.4373e-05, -3.6577e-04, -1.0833e-03, -2.4633e-03],\n",
      "          [ 2.3099e-04,  5.4607e-04,  3.0214e-04, -1.0027e-04, -9.8696e-04],\n",
      "          [-1.3558e-03, -3.7324e-04,  3.7276e-04,  9.8768e-04, -1.0176e-04]]],\n",
      "\n",
      "\n",
      "        [[[ 2.4013e-03,  1.4434e-04,  1.0743e-04,  1.3354e-04,  6.8144e-04],\n",
      "          [-1.4084e-03, -2.6039e-03, -1.9494e-03, -1.0351e-03,  7.9112e-05],\n",
      "          [-4.0127e-03, -2.4927e-03, -1.4800e-04,  5.8414e-05,  2.3777e-03],\n",
      "          [-4.0653e-03, -3.4455e-04,  2.4533e-03,  2.9063e-03,  4.7432e-03],\n",
      "          [-3.4025e-03,  3.0317e-04,  3.6289e-03,  5.3850e-03,  6.9432e-03]]],\n",
      "\n",
      "\n",
      "        [[[-8.8452e-03, -1.0092e-02, -8.9742e-03, -6.8708e-03, -5.9978e-03],\n",
      "          [-5.9976e-03, -7.0983e-03, -7.1668e-03, -6.1602e-03, -6.4773e-03],\n",
      "          [-1.8642e-03, -1.5043e-03, -1.7986e-03, -2.2939e-03, -3.8788e-03],\n",
      "          [ 3.7749e-05, -3.9899e-05, -4.6980e-04, -8.6403e-04, -2.7535e-03],\n",
      "          [-4.8309e-04, -8.4227e-04, -1.7540e-03, -2.7424e-03, -4.7479e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.6171e-03, -3.4494e-03, -3.8388e-03, -2.3222e-03, -7.3955e-04],\n",
      "          [-3.8487e-03, -3.1352e-03, -2.1461e-03, -6.9906e-04,  7.3416e-04],\n",
      "          [-6.6491e-03, -3.5086e-03, -3.1639e-04,  1.7931e-03,  3.6984e-03],\n",
      "          [-7.1217e-03, -2.9487e-03,  1.2392e-03,  3.3143e-03,  4.6098e-03],\n",
      "          [-3.6473e-03, -3.6765e-05,  3.3602e-03,  4.5936e-03,  3.3499e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 7.7743e-04,  8.6750e-04,  6.0570e-04, -6.0326e-05, -9.4662e-04],\n",
      "          [ 1.0493e-04,  4.0597e-04,  2.3173e-04, -7.4802e-04, -1.2556e-03],\n",
      "          [-1.0920e-04,  2.9273e-04,  1.4813e-05, -4.9562e-04, -1.1151e-04],\n",
      "          [ 9.4378e-05,  3.7538e-04,  4.5002e-04,  1.8571e-03,  4.0971e-03],\n",
      "          [ 4.6292e-04,  1.0689e-03,  2.6999e-03,  4.5385e-03,  5.7872e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 1.1215e-02,  1.2167e-02,  9.4807e-03,  6.1450e-03,  4.4699e-03],\n",
      "          [ 8.3511e-03,  6.6846e-03,  2.0368e-03, -5.5443e-04,  1.6726e-03],\n",
      "          [ 2.3791e-03, -5.2852e-04, -4.3924e-03, -4.5221e-03,  9.6736e-04],\n",
      "          [-8.1512e-04, -3.4217e-03, -5.9551e-03, -4.4287e-03,  8.1636e-04],\n",
      "          [ 1.0976e-04, -3.0772e-03, -5.3137e-03, -4.3302e-03, -1.4950e-03]]],\n",
      "\n",
      "\n",
      "        [[[-4.6717e-03, -6.9972e-03, -7.0706e-03, -3.7210e-03, -1.5140e-03],\n",
      "          [-6.4847e-03, -7.1349e-03, -4.2680e-03, -9.7950e-04, -1.3391e-04],\n",
      "          [-6.5754e-03, -5.9568e-03, -2.4881e-03, -1.6552e-04,  3.5742e-04],\n",
      "          [-6.9620e-03, -6.2458e-03, -2.7846e-03, -9.8648e-04, -5.7134e-04],\n",
      "          [-6.6272e-03, -5.7456e-03, -2.3442e-03, -8.9191e-04, -8.6723e-04]]]]), 'conv1.bias': tensor([-0.0054, -0.0020,  0.0178, -0.0099, -0.0057, -0.0060, -0.0186, -0.0236,\n",
      "        -0.0026, -0.0309, -0.0125, -0.0112, -0.0003,  0.0053,  0.0782, -0.0057]), 'conv2.weight': tensor([[[[-8.3932e-03, -7.0070e-03, -6.9121e-03, -9.1133e-03, -1.1815e-02],\n",
      "          [-1.0394e-02, -9.7727e-03, -1.0726e-02, -1.0929e-02, -1.0485e-02],\n",
      "          [-1.7006e-02, -1.6952e-02, -1.9166e-02, -1.8062e-02, -1.1344e-02],\n",
      "          [-2.0253e-02, -2.2424e-02, -2.4297e-02, -2.1198e-02, -1.4394e-02],\n",
      "          [-1.3729e-02, -1.7318e-02, -2.3059e-02, -2.1626e-02, -1.7262e-02]],\n",
      "\n",
      "         [[ 2.3540e-04, -8.1916e-05, -5.6991e-04, -5.6559e-04, -9.4093e-04],\n",
      "          [ 2.7083e-04, -3.6649e-05, -7.0524e-04, -5.7567e-04, -3.9700e-04],\n",
      "          [-1.9198e-04, -3.1753e-04, -4.3964e-04, -3.9243e-04, -8.2601e-05],\n",
      "          [-4.9292e-04, -3.1394e-04, -4.0290e-04, -1.9833e-04, -8.6069e-05],\n",
      "          [-2.7492e-04, -1.6932e-04, -3.9480e-04,  6.8397e-05, -7.2676e-05]],\n",
      "\n",
      "         [[-6.8709e-03, -9.8898e-03, -1.2571e-02, -1.5581e-02, -1.9210e-02],\n",
      "          [-1.2051e-02, -1.4165e-02, -1.8355e-02, -2.2977e-02, -2.4408e-02],\n",
      "          [-2.1115e-02, -2.1428e-02, -2.7197e-02, -3.0367e-02, -2.8833e-02],\n",
      "          [-3.3970e-02, -3.3877e-02, -3.9573e-02, -4.1187e-02, -3.3336e-02],\n",
      "          [-3.3471e-02, -3.6713e-02, -4.3981e-02, -4.6508e-02, -4.0885e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.7855e-04, -8.2992e-04, -2.2202e-03, -2.2611e-03, -1.2373e-03],\n",
      "          [-1.8161e-04, -5.6720e-04, -1.1912e-03, -9.6534e-04, -1.2326e-04],\n",
      "          [-7.9814e-04, -1.1910e-03, -1.7881e-03, -1.4257e-03, -8.2714e-04],\n",
      "          [-1.6844e-03, -1.5476e-03, -2.4550e-03, -1.6451e-03, -8.0959e-04],\n",
      "          [-4.1365e-04, -4.0298e-04, -1.4025e-03, -1.8102e-03, -6.9491e-04]],\n",
      "\n",
      "         [[-8.9851e-03, -1.0694e-02, -1.2764e-02, -1.7010e-02, -2.1108e-02],\n",
      "          [-1.3777e-02, -1.5257e-02, -1.8455e-02, -2.2093e-02, -2.5684e-02],\n",
      "          [-2.3617e-02, -2.4913e-02, -2.9548e-02, -3.0529e-02, -2.8494e-02],\n",
      "          [-3.4594e-02, -3.6437e-02, -3.9764e-02, -3.9140e-02, -3.4549e-02],\n",
      "          [-2.6822e-02, -3.3530e-02, -4.0118e-02, -4.1799e-02, -3.9930e-02]],\n",
      "\n",
      "         [[-3.0460e-04, -5.7235e-04, -1.5216e-05,  1.6551e-05,  5.5574e-04],\n",
      "          [-2.4650e-03, -2.0801e-03, -1.2749e-03, -9.1225e-04, -6.0063e-04],\n",
      "          [-4.4633e-03, -3.3676e-03, -1.3585e-03, -1.8736e-03, -3.0969e-03],\n",
      "          [-3.1977e-03, -2.4355e-03, -1.1369e-03, -3.8900e-03, -4.8153e-03],\n",
      "          [-2.6677e-03, -1.7183e-03, -1.3681e-03, -5.1694e-03, -5.6702e-03]]],\n",
      "\n",
      "\n",
      "        [[[-9.5642e-03, -1.5153e-02, -8.8795e-03, -7.7445e-03, -1.7718e-02],\n",
      "          [-1.1057e-02, -1.1360e-02, -8.1839e-03, -1.6145e-02, -2.6311e-02],\n",
      "          [-5.5814e-03, -5.2704e-03, -8.5545e-03, -1.6769e-02, -2.4107e-02],\n",
      "          [ 2.7021e-03,  3.7171e-03, -7.5749e-04, -1.3312e-02, -1.6496e-02],\n",
      "          [ 6.8453e-03,  8.1552e-03, -2.2006e-03, -1.3724e-02, -7.0547e-03]],\n",
      "\n",
      "         [[-7.5175e-04, -1.0442e-03, -2.7139e-04, -3.7174e-04, -8.9479e-04],\n",
      "          [-1.3329e-03, -1.5042e-03, -3.7276e-04, -3.5029e-04, -5.1248e-04],\n",
      "          [-1.4141e-03, -1.0011e-03, -1.2334e-04, -1.5808e-04, -4.0635e-04],\n",
      "          [-1.6421e-04, -1.7850e-04, -2.2227e-04, -4.3549e-04, -5.8297e-04],\n",
      "          [ 3.5174e-04,  2.1708e-04, -6.3492e-05, -7.9030e-04, -3.1115e-04]],\n",
      "\n",
      "         [[-1.1655e-02, -2.3169e-02, -2.3553e-02, -1.9766e-02, -2.9454e-02],\n",
      "          [-1.3416e-02, -2.0420e-02, -1.9636e-02, -2.3113e-02, -3.7736e-02],\n",
      "          [-1.2016e-02, -1.5975e-02, -2.0765e-02, -3.4099e-02, -4.3730e-02],\n",
      "          [-3.9267e-03, -5.5681e-03, -1.2997e-02, -3.0395e-02, -3.6513e-02],\n",
      "          [ 5.3165e-03,  8.4238e-03, -3.9520e-03, -2.3023e-02, -2.3635e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-1.1737e-04, -6.0536e-04, -3.3931e-04, -3.9229e-04, -1.0130e-03],\n",
      "          [-8.9646e-04, -1.3797e-03, -7.4556e-04, -7.6747e-04, -6.9386e-04],\n",
      "          [-3.1702e-04, -5.4404e-04, -7.2877e-04, -1.0822e-03, -5.7361e-04],\n",
      "          [ 2.3167e-04,  4.9264e-04,  6.0853e-05, -5.2605e-04,  2.5384e-04],\n",
      "          [ 2.5567e-04,  4.8255e-04,  2.4989e-04, -2.9512e-04,  4.9835e-04]],\n",
      "\n",
      "         [[-1.4206e-02, -2.0344e-02, -1.7704e-02, -1.7609e-02, -2.9593e-02],\n",
      "          [-1.5456e-02, -1.7785e-02, -1.8327e-02, -2.6615e-02, -4.0459e-02],\n",
      "          [-1.3145e-02, -1.5081e-02, -1.9861e-02, -3.3015e-02, -4.1152e-02],\n",
      "          [-4.0671e-03, -4.1195e-03, -1.1291e-02, -2.9278e-02, -3.1584e-02],\n",
      "          [ 4.0520e-03,  7.2259e-03, -7.7140e-03, -2.2318e-02, -1.7345e-02]],\n",
      "\n",
      "         [[ 3.1091e-04, -1.9984e-03, -5.1264e-03, -2.9537e-03, -9.5343e-04],\n",
      "          [-5.9220e-04, -3.3571e-03, -3.5522e-03, -2.9180e-04, -6.4350e-04],\n",
      "          [-7.8061e-04, -3.1107e-04,  9.3014e-04,  4.8101e-04, -2.5129e-03],\n",
      "          [ 5.3711e-04,  2.1730e-03,  1.9271e-03,  8.8822e-04, -4.8151e-03],\n",
      "          [ 8.7416e-04,  2.6396e-03,  2.8066e-03, -5.2599e-05, -6.3900e-03]]],\n",
      "\n",
      "\n",
      "        [[[-6.1676e-03, -5.2355e-03, -8.4035e-03, -9.6367e-03, -8.2448e-03],\n",
      "          [-5.5308e-03, -1.2311e-02, -1.6398e-02, -1.1546e-02, -6.0236e-03],\n",
      "          [-1.3878e-02, -2.1877e-02, -1.7865e-02, -9.1483e-03, -8.6579e-03],\n",
      "          [-1.6061e-02, -1.7052e-02, -8.7419e-03, -6.3151e-03, -1.2329e-02],\n",
      "          [-5.7396e-03, -6.5830e-03, -5.6527e-03, -7.0904e-03, -7.9973e-03]],\n",
      "\n",
      "         [[-2.5379e-04, -5.4957e-05,  6.0195e-06,  1.5740e-04, -1.0189e-04],\n",
      "          [-5.0672e-04, -3.0864e-04, -8.1395e-05, -1.5029e-04, -5.7822e-04],\n",
      "          [-4.1672e-04, -6.1741e-04, -3.3085e-04, -3.0492e-04, -4.6561e-04],\n",
      "          [-2.7372e-04, -1.0704e-03, -4.3581e-04, -1.0374e-04,  3.2991e-05],\n",
      "          [-6.1985e-04, -1.0486e-03, -1.4787e-04,  3.6932e-04,  2.4848e-04]],\n",
      "\n",
      "         [[-1.3972e-02, -1.4233e-02, -1.2591e-02, -1.1064e-02, -1.2218e-02],\n",
      "          [-8.7171e-03, -1.7409e-02, -2.1491e-02, -1.7680e-02, -1.2963e-02],\n",
      "          [-1.0458e-02, -2.4669e-02, -2.9819e-02, -2.1547e-02, -1.5924e-02],\n",
      "          [-2.0447e-02, -2.8803e-02, -2.8245e-02, -2.1376e-02, -2.0645e-02],\n",
      "          [-1.8860e-02, -2.0853e-02, -2.0583e-02, -1.9982e-02, -2.0360e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-6.6734e-04, -1.2310e-03, -6.3560e-04,  1.8356e-04, -7.8217e-05],\n",
      "          [-5.6995e-04, -1.2298e-03, -4.9977e-04, -3.4899e-04, -8.5278e-04],\n",
      "          [ 3.8434e-04, -7.3692e-04, -1.6460e-03, -1.5348e-03, -2.2092e-03],\n",
      "          [ 3.4287e-04, -6.1113e-04, -8.7023e-04, -9.2685e-06,  2.7826e-04],\n",
      "          [-6.9968e-05, -4.7295e-04,  2.3304e-04,  6.9653e-04,  6.1515e-04]],\n",
      "\n",
      "         [[-1.0694e-02, -1.1612e-02, -1.4398e-02, -1.4888e-02, -1.3221e-02],\n",
      "          [-5.5156e-03, -1.5844e-02, -2.1754e-02, -1.6207e-02, -1.0370e-02],\n",
      "          [-1.4777e-02, -2.5881e-02, -2.7017e-02, -1.9063e-02, -1.6061e-02],\n",
      "          [-2.2219e-02, -2.4090e-02, -1.9645e-02, -1.8592e-02, -2.2196e-02],\n",
      "          [-1.3812e-02, -1.5356e-02, -1.6826e-02, -1.7533e-02, -1.6174e-02]],\n",
      "\n",
      "         [[-1.2287e-03, -1.4272e-03, -6.8151e-04, -7.4732e-04, -2.4426e-04],\n",
      "          [-1.8159e-03, -1.5328e-03, -2.7256e-03, -3.1979e-03, -2.3391e-03],\n",
      "          [-6.6257e-04, -7.2453e-04, -4.2966e-03, -4.8462e-03, -1.5041e-03],\n",
      "          [ 6.3444e-05, -1.7497e-03, -4.9104e-03, -3.2149e-03,  3.1088e-04],\n",
      "          [-2.4364e-03, -3.4700e-03, -3.2673e-03, -1.6708e-03, -1.1069e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.1809e-03, -3.6857e-03, -1.6819e-03, -2.1013e-04, -4.2565e-04],\n",
      "          [-7.9715e-04, -2.8641e-03, -8.6534e-04, -1.1407e-04, -3.9804e-04],\n",
      "          [ 2.8299e-03, -7.7271e-04, -9.3746e-04, -2.7027e-04, -1.4781e-04],\n",
      "          [ 4.8227e-03,  1.5071e-04, -6.2432e-04, -2.7496e-04, -5.4566e-05],\n",
      "          [ 2.7501e-03, -1.1783e-03, -1.3302e-03, -3.1760e-04, -1.8701e-05]],\n",
      "\n",
      "         [[-4.3525e-05, -1.1278e-04, -4.7624e-06, -9.5175e-06, -1.1842e-04],\n",
      "          [-1.3571e-04, -1.5242e-04, -2.3538e-06, -5.3573e-07, -4.5763e-05],\n",
      "          [-3.9347e-04, -1.5702e-04, -4.6170e-06, -5.2103e-07, -1.5374e-05],\n",
      "          [-1.4155e-04, -7.3545e-05, -2.6356e-05,  7.5965e-07, -3.1549e-06],\n",
      "          [ 5.6497e-05, -1.8071e-04, -7.6719e-05, -1.4700e-06, -2.3626e-06]],\n",
      "\n",
      "         [[ 2.3564e-03, -3.9316e-03, -6.1473e-03, -2.3797e-03, -9.9388e-04],\n",
      "          [ 2.2253e-03, -1.3745e-03, -3.6737e-03, -1.7929e-03, -6.6864e-04],\n",
      "          [ 3.1356e-03, -2.0133e-04, -2.2719e-03, -1.1201e-03, -6.1556e-04],\n",
      "          [ 8.0451e-03,  2.0867e-03, -1.5567e-03, -8.8673e-04, -2.4317e-06],\n",
      "          [ 1.1239e-02,  3.4469e-03, -1.0246e-03, -7.2199e-04,  5.2101e-04]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2097e-03, -2.3839e-05, -1.8818e-05, -3.7710e-06, -9.5514e-05],\n",
      "          [ 4.7835e-04,  1.4575e-04,  2.6005e-05,  2.0988e-06, -2.7630e-07],\n",
      "          [ 1.4667e-05, -4.6825e-04, -2.3122e-04, -4.5053e-06, -3.1582e-07],\n",
      "          [ 7.5673e-05, -2.0129e-04, -1.7666e-04, -3.6697e-06, -4.8664e-07],\n",
      "          [ 1.6238e-04, -1.4121e-04, -2.0516e-04, -1.2420e-05, -1.2357e-06]],\n",
      "\n",
      "         [[ 2.8757e-04, -2.8522e-03, -3.4611e-03, -2.0655e-03, -9.0111e-04],\n",
      "          [-6.7277e-05, -1.3158e-03, -1.6912e-03, -1.4450e-03, -8.2508e-04],\n",
      "          [ 3.1620e-03, -8.8026e-05, -1.8401e-03, -1.2368e-03, -6.8666e-04],\n",
      "          [ 7.8920e-03,  2.2481e-03, -6.8361e-04, -7.4607e-04,  5.7741e-05],\n",
      "          [ 8.6818e-03,  3.0390e-03, -1.2900e-04, -1.9737e-04,  7.4721e-04]],\n",
      "\n",
      "         [[ 3.3645e-04, -7.5996e-05, -2.2382e-03, -7.9369e-04, -2.5907e-06],\n",
      "          [ 3.4898e-04,  2.8450e-04, -1.5250e-03, -3.5287e-04, -2.0535e-06],\n",
      "          [ 1.1063e-03,  1.2401e-03, -5.0856e-04, -2.4616e-04, -1.9084e-05],\n",
      "          [ 2.2540e-03,  1.7520e-03, -2.4967e-04, -3.7545e-04, -2.9984e-05],\n",
      "          [ 3.0901e-03,  1.5435e-03, -3.0322e-04, -5.1200e-04, -7.4323e-05]]],\n",
      "\n",
      "\n",
      "        [[[ 5.8234e-03,  2.7141e-03, -1.4138e-03, -5.2579e-03, -7.3080e-03],\n",
      "          [ 4.1191e-03, -3.3391e-03, -6.9030e-03, -7.5108e-03, -6.6420e-03],\n",
      "          [ 2.7647e-04, -6.5752e-03, -6.1745e-03, -5.9288e-03, -6.5380e-03],\n",
      "          [-4.5777e-03, -8.9360e-03, -6.2454e-03, -6.2228e-03, -7.7790e-03],\n",
      "          [-8.1981e-03, -8.9254e-03, -3.7630e-03, -4.5836e-03, -6.2183e-03]],\n",
      "\n",
      "         [[-4.3425e-05,  6.7012e-05,  5.7293e-04,  5.5476e-04,  2.4484e-04],\n",
      "          [-2.3084e-04, -2.2931e-05,  3.7289e-04,  4.6060e-04,  3.1462e-04],\n",
      "          [-2.7650e-04, -3.9210e-04, -2.7275e-04, -9.8200e-04, -6.6779e-04],\n",
      "          [-5.3047e-04, -7.4185e-04, -2.5145e-04, -7.5609e-04, -4.6011e-04],\n",
      "          [-4.7880e-04, -3.0078e-04,  1.7113e-04,  2.7627e-05,  1.8038e-04]],\n",
      "\n",
      "         [[ 1.5571e-02,  1.1183e-02,  7.0549e-03,  2.7877e-03, -6.6047e-04],\n",
      "          [ 1.2191e-02,  3.7779e-03, -2.6089e-03, -5.6244e-03, -6.4133e-03],\n",
      "          [ 7.8287e-03, -3.9302e-03, -6.1228e-03, -5.3031e-03, -7.4991e-03],\n",
      "          [ 2.7807e-03, -7.7928e-03, -8.7381e-03, -6.9493e-03, -8.9293e-03],\n",
      "          [-2.9134e-03, -9.1699e-03, -8.1233e-03, -6.6621e-03, -8.8022e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.9704e-04, -4.6911e-04, -1.3305e-04,  2.1554e-04, -3.1163e-04],\n",
      "          [-6.0614e-04, -7.6220e-04, -1.1152e-04, -1.5472e-04, -1.6779e-04],\n",
      "          [-2.3104e-04, -4.5094e-04,  7.9472e-04,  2.9082e-04, -9.6105e-04],\n",
      "          [-4.7635e-04, -1.2157e-03, -6.0894e-04, -7.1602e-05, -1.0582e-04],\n",
      "          [-5.8160e-04, -1.0488e-03, -8.8598e-04, -7.5133e-04, -1.8245e-04]],\n",
      "\n",
      "         [[ 1.3905e-02,  1.0012e-02,  4.5191e-03, -4.1072e-04, -1.9016e-03],\n",
      "          [ 8.8582e-03,  5.9701e-04, -4.0908e-03, -5.0234e-03, -3.4311e-03],\n",
      "          [ 4.9799e-03, -2.8645e-03, -4.7522e-03, -4.4490e-03, -4.6324e-03],\n",
      "          [-1.2559e-03, -6.4094e-03, -7.9778e-03, -6.5701e-03, -7.2690e-03],\n",
      "          [-6.6566e-03, -7.2002e-03, -4.5579e-03, -6.1185e-03, -7.9033e-03]],\n",
      "\n",
      "         [[ 3.6127e-03,  2.1735e-03,  9.2943e-04,  7.5180e-04,  4.8726e-04],\n",
      "          [ 2.8891e-03,  2.0799e-03, -7.7453e-05, -1.1936e-03, -1.9505e-03],\n",
      "          [ 2.3989e-03,  2.1470e-04, -2.1288e-03, -1.9814e-03, -1.0655e-03],\n",
      "          [ 2.7301e-03, -6.4909e-04, -2.1125e-03, -6.8947e-04,  1.0070e-04],\n",
      "          [ 3.1869e-03, -4.4562e-04, -8.3441e-04,  1.2736e-03,  9.6556e-04]]],\n",
      "\n",
      "\n",
      "        [[[-7.4706e-03, -1.0051e-02, -8.9925e-03, -5.5401e-03, -7.3507e-03],\n",
      "          [-4.1804e-03, -5.5351e-03, -3.2532e-03, -2.8795e-03, -1.0688e-02],\n",
      "          [-1.2236e-03, -4.1207e-03, -3.7122e-03, -4.7857e-03, -1.4337e-02],\n",
      "          [-3.2018e-03, -6.0137e-03, -6.2455e-03, -8.2827e-03, -1.3424e-02],\n",
      "          [-5.9426e-03, -8.8357e-03, -8.6845e-03, -8.5490e-03, -1.2293e-02]],\n",
      "\n",
      "         [[-5.5755e-04, -5.0065e-04, -5.1590e-04, -8.8774e-04, -1.0203e-03],\n",
      "          [-4.7653e-04, -7.1982e-04, -5.0981e-04, -5.7588e-04, -1.0131e-03],\n",
      "          [-6.8046e-04, -8.3427e-04, -3.2100e-04,  4.2430e-05, -4.4126e-04],\n",
      "          [-3.1455e-04, -5.1204e-04, -2.0853e-05,  2.4902e-04, -5.4642e-04],\n",
      "          [-9.6775e-05, -2.0140e-04, -2.3789e-04, -2.4254e-04, -7.7314e-04]],\n",
      "\n",
      "         [[-1.3452e-02, -1.9261e-02, -2.3549e-02, -2.2401e-02, -2.3100e-02],\n",
      "          [-1.5260e-02, -1.9646e-02, -2.1760e-02, -1.6723e-02, -2.1469e-02],\n",
      "          [-9.3070e-03, -1.2722e-02, -1.5513e-02, -1.5292e-02, -2.5424e-02],\n",
      "          [-5.7240e-03, -1.2002e-02, -1.6725e-02, -1.7220e-02, -2.5230e-02],\n",
      "          [-8.1675e-03, -1.4003e-02, -1.8989e-02, -1.8190e-02, -1.8540e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.2500e-04, -1.0290e-03, -7.6602e-04, -4.8421e-04, -7.3988e-04],\n",
      "          [-1.8237e-04, -5.5391e-04, -9.2861e-04, -4.6594e-04, -7.4420e-04],\n",
      "          [-2.9284e-04, -6.0018e-04, -2.4655e-04,  9.3898e-05, -5.8327e-04],\n",
      "          [-5.6722e-04, -7.4612e-04, -4.7732e-04,  3.5029e-06, -2.7681e-04],\n",
      "          [-4.2324e-04, -1.1447e-03, -1.7782e-03, -6.4002e-04, -5.1949e-04]],\n",
      "\n",
      "         [[-1.5915e-02, -2.0612e-02, -2.4637e-02, -2.1580e-02, -2.2677e-02],\n",
      "          [-1.5264e-02, -1.7736e-02, -1.9155e-02, -1.7732e-02, -2.5801e-02],\n",
      "          [-9.6957e-03, -1.3641e-02, -1.7717e-02, -2.0380e-02, -3.1269e-02],\n",
      "          [-8.3991e-03, -1.3366e-02, -1.8915e-02, -2.1896e-02, -2.7255e-02],\n",
      "          [-1.0148e-02, -1.4497e-02, -1.8351e-02, -2.0283e-02, -2.1666e-02]],\n",
      "\n",
      "         [[-1.1337e-03, -1.2988e-03, -1.9021e-03, -2.8475e-03, -1.5567e-03],\n",
      "          [-7.2157e-04, -1.2056e-03, -2.5780e-03, -2.4245e-03, -7.0075e-06],\n",
      "          [-1.7879e-04, -5.2141e-04, -1.4020e-03, -7.8745e-04,  1.1572e-03],\n",
      "          [ 2.8048e-04,  5.7766e-05, -9.0490e-04, -1.3458e-03, -1.3447e-04],\n",
      "          [-8.0955e-05, -3.1934e-04, -1.7610e-03, -2.1496e-03, -2.0159e-04]]]]), 'conv2.bias': tensor([-0.0454, -0.0298, -0.0116, -0.1034,  0.0061, -0.0043, -0.0088, -0.0634,\n",
      "         0.0162, -0.0026,  0.0158, -0.0047,  0.0449,  0.0175,  0.0599, -0.0241,\n",
      "         0.0249,  0.0601, -0.0299, -0.0162,  0.0096,  0.0585,  0.0571, -0.0414,\n",
      "         0.0247,  0.0138, -0.0473, -0.0043, -0.0085, -0.0019,  0.0150, -0.0726]), 'fc1.weight': tensor([[ 0.0026,  0.0072,  0.0183,  ...,  0.0019,  0.0019,  0.0009],\n",
      "        [ 0.0025,  0.0064,  0.0170,  ...,  0.0019,  0.0018,  0.0009],\n",
      "        [ 0.0040,  0.0116,  0.0284,  ...,  0.0028,  0.0028,  0.0014],\n",
      "        ...,\n",
      "        [ 0.0031,  0.0084,  0.0211,  ...,  0.0023,  0.0022,  0.0011],\n",
      "        [-0.0123, -0.0371, -0.0980,  ..., -0.0101, -0.0093, -0.0041],\n",
      "        [-0.0163, -0.0422, -0.1037,  ..., -0.0112, -0.0113, -0.0061]]), 'fc1.bias': tensor([ 0.0350,  0.0346,  0.0533,  0.0487,  0.0706,  0.0617,  0.0469,  0.0419,\n",
      "        -0.1624, -0.2303])}\n",
      "!-- Client 7 is normal and start iterations. ---!\n",
      "Epoch [1/3], Average Loss: 0.7502052783966064, Average Accuracy: 0.7872422933578491, Average Error: 0.2127576768398285, Culminative Time Used: 0.8040135018527508\n",
      "Epoch [2/3], Average Loss: 0.5482037067413330, Average Accuracy: 0.9013487100601196, Average Error: 0.0986513122916222, Culminative Time Used: 1.6710968986153603\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe current train start time is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_start_time\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     35\u001b[0m current_method_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScaffold\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 36\u001b[0m \u001b[43mexperiment_Scaffold_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_distributing_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodelType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizerType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitera_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_epochs_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_epochs_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_clients_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_sample_client_number_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step_size_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggregate_func_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_func_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_func_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mScaffold_update_controls_use_gradient_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstraggler_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madversary_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madversary_attack_func_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madversary_attack_value_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madversary_attack_Scaffold_all_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_rounds\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 1914\u001b[0m, in \u001b[0;36mexperiment_Scaffold_model\u001b[1;34m(train_dataset, test_dataset, dataset_distributing_func, modelClass, optimizerClass, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds, show_history, save_result)\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m save_file_extra_information\n\u001b[0;32m   1856\u001b[0m save_file_extra_information \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;124m=== \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ===\u001b[39m\n\u001b[0;32m   1858\u001b[0m \u001b[38;5;124mThe experiment ID is: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_id\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1911\u001b[0m \u001b[38;5;124madversary_attack_Scaffold_all = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madversary_attack_Scaffold_all\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m-> 1914\u001b[0m cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_Scaffold_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mglobal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_sample_client_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mScaffold_update_controls_use_gradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggregate_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_history\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1916\u001b[0m cost_history_total\u001b[38;5;241m.\u001b[39mappend(cost_history)\n\u001b[0;32m   1917\u001b[0m time_history_total\u001b[38;5;241m.\u001b[39mappend(time_history)\n",
      "Cell \u001b[1;32mIn[28], line 1263\u001b[0m, in \u001b[0;36mtrain_Scaffold_model\u001b[1;34m(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, global_step_size, Scaffold_update_controls_use_gradient, aggregate_func, loss_func, accuracy_func, error_func, show_history, save_result, save_path_str)\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_Scaffold_model\u001b[39m(global_model, train_dataloader, test_dataloader, client_list, random_sample_client_number, global_epochs, local_epochs, global_step_size, Scaffold_update_controls_use_gradient, aggregate_func\u001b[38;5;241m=\u001b[39mfederated_averaging_Scaffold, loss_func\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mcross_entropy, accuracy_func\u001b[38;5;241m=\u001b[39mget_accuracy, error_func\u001b[38;5;241m=\u001b[39mget_error, show_history\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, save_path_str\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScaffold\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1263\u001b[0m     cost_history, time_history, adversary_history, straggler_history, train_loss_history, train_accuracy_history, train_error_history, test_loss_history, test_accuracy_history, test_error_history \u001b[38;5;241m=\u001b[39m \u001b[43miterate_Scaffold_global\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_sample_client_number\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglobal_step_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mScaffold_update_controls_use_gradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maggregate_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_history\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;66;03m# Print learned parameters\u001b[39;00m\n\u001b[0;32m   1266\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m global_model\u001b[38;5;241m.\u001b[39mnamed_parameters():\n",
      "Cell \u001b[1;32mIn[28], line 1157\u001b[0m, in \u001b[0;36miterate_Scaffold_global\u001b[1;34m(train_dataloader, test_dataloader, global_model, client_list, random_sample_client_number, global_epochs, global_step_size, local_epochs, Scaffold_update_controls_use_gradient, aggregate_func, loss_func, accuracy_func, error_func, show_history)\u001b[0m\n\u001b[0;32m   1155\u001b[0m send_cost \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(value\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m server_controls\u001b[38;5;241m.\u001b[39mvalues())\n\u001b[0;32m   1156\u001b[0m client\u001b[38;5;241m.\u001b[39mload_global_model(global_model)\n\u001b[1;32m-> 1157\u001b[0m delta_weights, delta_client_controls \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_Scaffold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_controls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mScaffold_update_controls_use_gradient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1158\u001b[0m delta_weights_total\u001b[38;5;241m.\u001b[39mappend(delta_weights)\n\u001b[0;32m   1159\u001b[0m delta_client_controls_total\u001b[38;5;241m.\u001b[39mappend(delta_client_controls)\n",
      "Cell \u001b[1;32mIn[28], line 609\u001b[0m, in \u001b[0;36mClientDevice.train_Scaffold\u001b[1;34m(self, server_controls, num_epochs, Scaffold_update_controls_use_gradient, show_message, plot_history)\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m show_message:\n\u001b[0;32m    608\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m!-- Client \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is normal and start iterations. ---!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 609\u001b[0m         loss_history, accuracy_history, error_history, time_history, delta_weights, delta_client_controls \u001b[38;5;241m=\u001b[39m \u001b[43miterate_Scaffold_client\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_controls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccuracy_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mScaffold_update_controls_use_gradient\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    610\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m plot_history:\n\u001b[0;32m    611\u001b[0m     plot_time_history(time_history)\n",
      "Cell \u001b[1;32mIn[28], line 1019\u001b[0m, in \u001b[0;36miterate_Scaffold_client\u001b[1;34m(client, server_controls, dataloader, num_epochs, optimizer, loss_func, accuracy_func, error_func, Scaffold_update_controls_use_gradient, show_history)\u001b[0m\n\u001b[0;32m   1017\u001b[0m accuracies \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1018\u001b[0m errors \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataloader:\n\u001b[0;32m   1020\u001b[0m     features, labels \u001b[38;5;241m=\u001b[39m batch\n\u001b[0;32m   1021\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m local_model(features)\n",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m, in \u001b[0;36mDeviceDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__iter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdl:\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m to_device(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataset.py:399\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx]] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataset.py:399\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 399\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataset.py:335\u001b[0m, in \u001b[0;36mConcatDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    334\u001b[0m     sample_idx \u001b[38;5;241m=\u001b[39m idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcumulative_sizes[dataset_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 335\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torch\\utils\\data\\dataset.py:391\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[1;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\datasets\\mnist.py:145\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    142\u001b[0m img \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mfromarray(img\u001b[38;5;241m.\u001b[39mnumpy(), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\transforms.py:137\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pic):\n\u001b[0;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    132\u001b[0m \u001b[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\torchvision\\transforms\\functional.py:171\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pic\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    170\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;241m*\u001b[39m img\n\u001b[1;32m--> 171\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpic\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_image_num_channels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpic\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[38;5;66;03m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m    173\u001b[0m img \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mpermute((\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mcontiguous()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 100]\n",
    "random_sample_client_number_list = [10, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = [True]\n",
    "straggler_list = [0]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 2\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FedProx Stragglers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [100]\n",
    "random_sample_client_number_list = [20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0, 50, 90, 0, 50, 90, 0, 50, 90]\n",
    "mu_list = [0.2, 0.2, 0.2, 0.5, 0.5, 0.5, 0.8, 0.8, 0.8]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 9\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = False\n",
    "custom_split_dataset_power_law = True\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [100]\n",
    "random_sample_client_number_list = [20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0, 50, 90, 0, 50, 90, 0, 50, 90]\n",
    "mu_list = [0.2, 0.2, 0.2, 0.5, 0.5, 0.5, 0.8, 0.8, 0.8]\n",
    "adversary_list = [0]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [10000]\n",
    "\n",
    "experiment_rounds = 9\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FedProx Adversaries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_FedProx\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10]\n",
    "random_sample_client_number_list = [10]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "straggler_list = [0]\n",
    "mu_list = [1.0, 1.0, 1.0, 1.0]\n",
    "adversary_list = [1]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [0, 1, 10, 10000]\n",
    "\n",
    "experiment_rounds = 4\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedProx\"\n",
    "experiment_FedProx_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, straggler_list, mu_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FedAvg Adversary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 10, 10, 10, 100, 100, 100, 100]\n",
    "random_sample_client_number_list = [10, 10, 10, 10, 20, 20, 20, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_averaging\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [1, 1, 1, 1, 20, 20, 20, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [0, 1, 10, 1000, 0, 1, 10, 1000]\n",
    "\n",
    "experiment_rounds = 8\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FedMedian**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = optimizer_type_preset\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 10, 10, 10, 100, 100, 100, 100]\n",
    "random_sample_client_number_list = [10, 10, 10, 10, 20, 20, 20, 20]\n",
    "learning_rate_list = 0.03\n",
    "batch_size_list = 128\n",
    "aggregate_func_list = federated_median\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "adversary_list = [1, 1, 1, 1, 20, 20, 20, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value]\n",
    "adversary_attack_value_list = [0, 1, 10, 1000, 0, 1, 10, 1000]\n",
    "\n",
    "experiment_rounds = 8\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"FedAvg\"\n",
    "experiment_FedAvg_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SCAFFOLD Weight Adversary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 10, 10, 10, 100, 100, 100, 100]\n",
    "random_sample_client_number_list = [10, 10, 10, 10, 20, 20, 20, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = [False]\n",
    "straggler_list = [0]\n",
    "adversary_list = [1, 1, 1, 1, 20, 20, 20, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_control_variable_Scaffold]\n",
    "adversary_attack_value_list = [0, 1, 10, 10000, 0, 1, 10, 10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 8\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SCAFFOLD Control Variable Adversary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 10, 10, 10, 100, 100, 100, 100]\n",
    "random_sample_client_number_list = [10, 10, 10, 10, 20, 20, 20, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_averaging_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = [False]\n",
    "straggler_list = [0]\n",
    "adversary_list = [1, 1, 1, 1, 20, 20, 20, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_control_variable_Scaffold]\n",
    "adversary_attack_value_list = [0, 1, 10, 10000, 0, 1, 10, 10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 8\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ScaffoldMedian Weight**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 10, 10, 10, 100, 100, 100, 100]\n",
    "random_sample_client_number_list = [10, 10, 10, 10, 20, 20, 20, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_median_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = [False]\n",
    "straggler_list = [0]\n",
    "adversary_list = [1, 1, 1, 1, 20, 20, 20, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_value_Scaffold]\n",
    "adversary_attack_value_list = [0, 1, 10, 10000, 0, 1, 10, 10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 8\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ScaffoldMedian Control Variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelType = model_type_preset\n",
    "optimizerType = ScaffoldOptimizer\n",
    "itera_func = iterate_model_simple\n",
    "dataset_distributing_func = split_datasets_for_clients_custom\n",
    "\n",
    "custom_split_dataset_iid = True\n",
    "custom_split_dataset_power_law = False\n",
    "custom_split_dataset_balance = False\n",
    "custom_split_dataset_seed = 42\n",
    "\n",
    "global_epochs_list = 100\n",
    "local_epochs_list = 3\n",
    "num_clients_list = [10, 10, 10, 10, 100, 100, 100, 100]\n",
    "random_sample_client_number_list = [10, 10, 10, 10, 20, 20, 20, 20]\n",
    "learning_rate_list = 0.03\n",
    "global_step_size_list = 1.0\n",
    "batch_size_list = [128]\n",
    "aggregate_func_list = federated_median_Scaffold\n",
    "loss_func_list = loss_func_preset\n",
    "accuracy_func_list = get_accuracy\n",
    "error_func_list = get_error\n",
    "Scaffold_update_controls_use_gradient_list = [False]\n",
    "straggler_list = [0]\n",
    "adversary_list = [1, 1, 1, 1, 20, 20, 20, 20]\n",
    "adversary_attack_func_list = [adversarial_attack_by_control_variable_Scaffold]\n",
    "adversary_attack_value_list = [0, 1, 10, 10000, 0, 1, 10, 10000]\n",
    "adversary_attack_Scaffold_all_list = [False]\n",
    "\n",
    "experiment_rounds = 8\n",
    "\n",
    "print(f'The current dataset is {current_dataset_name}.')\n",
    "train_start_time = datetime.now().strftime(\"%Y-%m-%d %H.%M.%S\")\n",
    "print(f'The current train start time is {train_start_time}.')\n",
    "\n",
    "current_method_name = \"Scaffold\"\n",
    "experiment_Scaffold_model(train_dataset, test_dataset, dataset_distributing_func, modelType, optimizerType, itera_func, global_epochs_list, local_epochs_list, num_clients_list, random_sample_client_number_list, learning_rate_list, global_step_size_list, batch_size_list, aggregate_func_list, loss_func_list, accuracy_func_list, error_func_list, Scaffold_update_controls_use_gradient_list, straggler_list, adversary_list, adversary_attack_func_list, adversary_attack_value_list, adversary_attack_Scaffold_all_list, experiment_rounds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3 Analysis ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3.0 Loading Data ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Clear and Initialize Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cost_history_total = []\n",
    "data_time_history_total = []\n",
    "data_adversary_history_total = []\n",
    "data_straggler_history_total = []\n",
    "data_train_loss_history_total = []\n",
    "data_train_accuracy_history_total = []\n",
    "data_train_error_history_total = []\n",
    "data_test_loss_history_total = []\n",
    "data_test_accuracy_history_total = []\n",
    "data_test_error_history_total = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading Data Manually**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the filename_load path manually here!!\n",
    "filename_load_list = [\"MNIST_Scaffold_GE_50_LE_3_C_50_RC_25_lr_0.03_B_128_2024-04-07 16.25.58_1.npy\",\n",
    "                      \"MNIST_Scaffold_GE_50_LE_3_C_50_RC_25_lr_0.03_B_128_2024-04-07 16.25.58_2.npy\"]\n",
    "data_append_load = True\n",
    "load_consider_cost_bool = True\n",
    "load_consider_time_bool = True\n",
    "load_consider_adversary_bool = True\n",
    "load_consider_straggler_bool = True\n",
    "\n",
    "for filename_load in filename_load_list:\n",
    "    print(\"============================================\")\n",
    "    print(\"*** Loading file...                     ***\")\n",
    "    print(\"============================================\")\n",
    "    try:\n",
    "        # Load the file\n",
    "        load_result = np.load(filename_load)\n",
    "        print('Result has been loaded from the file: ', filename_load)\n",
    "\n",
    "        # Load the attributes from the file\n",
    "        if load_consider_cost_bool is True:\n",
    "            data_cost_history = load_result['cost_history']\n",
    "        if load_consider_time_bool is True:\n",
    "            data_time_history = load_result['time_history']\n",
    "        if load_consider_adversary_bool is True:\n",
    "            data_adversary_history = load_result['adversary_history']\n",
    "        if load_consider_adversary_bool is True:\n",
    "            data_straggler_history = load_result['straggler_history']\n",
    "        data_train_loss_history = load_result['train_loss_history']\n",
    "        data_train_accuracy_history = load_result['train_accuracy_history']\n",
    "        data_train_error_history = load_result['train_error_history']\n",
    "        data_test_loss_history = load_result['test_loss_history']\n",
    "        data_test_accuracy_history = load_result['test_accuracy_history']\n",
    "        data_test_error_history = load_result['test_error_history']\n",
    "\n",
    "        print(\"=======Content of the File=======\")\n",
    "        print(load_result.files)\n",
    "\n",
    "        print(\"=======VISUALIZATION RESULT=======\")\n",
    "        if load_consider_cost_bool is True:\n",
    "            plot_cost_history([data_cost_history], save=False)\n",
    "        if load_consider_time_bool is True:\n",
    "            plot_time_history([data_time_history], save=False)\n",
    "        if load_consider_adversary_bool is True:\n",
    "            plot_adversary_history([data_adversary_history], save=False)\n",
    "        if load_consider_straggler_bool is True:\n",
    "            plot_straggler_history([data_straggler_history], save=False)\n",
    "        plot_loss_history([data_train_loss_history], [data_test_loss_history], save=False)\n",
    "        plot_accuracy_history([data_train_accuracy_history], [data_test_accuracy_history], save=False)\n",
    "        plot_error_history([data_train_error_history], [data_test_error_history], save=False)\n",
    "\n",
    "        print(\"=======STATUS RESULT=======\")\n",
    "        if load_consider_cost_bool is True:\n",
    "            print(\"Cost History: \", data_cost_history)\n",
    "        if load_consider_time_bool is True:\n",
    "            print(\"Time History: \", data_time_history)\n",
    "        if load_consider_adversary_bool is True:\n",
    "            print(\"Adversary History: \", data_adversary_history)\n",
    "        if load_consider_straggler_bool is True:\n",
    "            print(\"Straggler History: \", data_straggler_history)\n",
    "\n",
    "        print(\"=======TRAIN RESULT=======\")\n",
    "        print(\"Train Loss History: \", data_train_loss_history)\n",
    "        print(\"Train Accuracy History: \", data_train_accuracy_history)\n",
    "        print(\"Train Error History: \", data_train_error_history)\n",
    "\n",
    "        print(\"=======TEST RESULT=======\")\n",
    "        print(\"Test Loss History: \", data_test_loss_history)\n",
    "        print(\"Test Accuracy History: \", data_test_accuracy_history)\n",
    "        print(\"Test Error History: \", data_test_error_history)\n",
    "\n",
    "        # Append the data\n",
    "        if data_append_load:\n",
    "            if load_consider_cost_bool is True:\n",
    "                data_cost_history_total.append(data_cost_history)\n",
    "            if load_consider_time_bool is True:\n",
    "                data_time_history_total.append(data_time_history)\n",
    "            if load_consider_adversary_bool is True:\n",
    "                data_adversary_history_total.append(data_adversary_history)\n",
    "            if load_consider_straggler_bool is True:\n",
    "                data_straggler_history_total.append(data_straggler_history)\n",
    "            data_train_loss_history_total.append(data_train_loss_history)\n",
    "            data_train_accuracy_history_total.append(data_train_accuracy_history)\n",
    "            data_train_error_history_total.append(data_train_error_history)\n",
    "            data_test_loss_history_total.append(data_test_loss_history)\n",
    "            data_test_accuracy_history_total.append(data_test_accuracy_history)\n",
    "            data_test_error_history_total.append(data_test_error_history)\n",
    "    except (FileNotFoundError, IOError):\n",
    "        print(\"Failed to load the file: \", filename_load)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3.1 Data Visualization ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize All Data Directly**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost_history(data_cost_history_total, save=False)\n",
    "plot_time_history(data_time_history_total, save=False)\n",
    "plot_adversary_history(data_adversary_history_total, save=False)\n",
    "plot_straggler_history(data_straggler_history_total, save=False)\n",
    "plot_loss_history(data_train_loss_history_total, data_test_loss_history_total, save=False)\n",
    "plot_accuracy_history(data_train_accuracy_history_total, data_test_accuracy_history_total, save=False)\n",
    "plot_error_history(data_train_error_history_total, data_test_error_history_total, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment Graph in Centralized Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameter_list = [1, 2, 3, 4, 5, 10]\n",
    "plot_save_fig_bool = False\n",
    "plot_show_train_bool = True\n",
    "plot_show_test_bool = True\n",
    "plot_log_scale = False\n",
    "\n",
    "plot_different_parameter_train_loss_history = convert_to_list(data_train_loss_history_total)\n",
    "plot_different_parameter_test_loss_history = convert_to_list(data_test_loss_history_total)\n",
    "if plot_show_train_bool is True:\n",
    "    for i, plot_train_loss_history in enumerate(plot_different_parameter_train_loss_history):\n",
    "        plt.plot(plot_train_loss_history, label=f\"Train Loss History\")\n",
    "if plot_show_test_bool is True:\n",
    "    for i, plot_test_loss_history in enumerate(plot_different_parameter_test_loss_history):\n",
    "        plt.plot(plot_test_loss_history, label=f\"Test Loss History\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Loss\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History\")\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_loss_history_centralized_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_train_accuracy_history = convert_to_list(data_train_accuracy_history_total)\n",
    "plot_different_parameter_test_accuracy_history = convert_to_list(data_test_accuracy_history_total)\n",
    "if plot_show_train_bool is True:\n",
    "    for i, plot_train_accuracy_history in enumerate(plot_different_parameter_train_accuracy_history):\n",
    "        plt.plot(plot_train_accuracy_history, label=f\"Train Accuracy History\")\n",
    "if plot_show_test_bool is True:\n",
    "    for i, plot_test_accuracy_history in enumerate(plot_different_parameter_test_accuracy_history):\n",
    "        plt.plot(plot_test_accuracy_history, label=f\"Test Accuracy History\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Accuracy\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy History\")\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_accuracy_history_centralized_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_train_error_history = convert_to_list(data_train_error_history_total)\n",
    "plot_different_parameter_test_error_history = convert_to_list(data_test_error_history_total)\n",
    "if plot_show_train_bool is True:\n",
    "    for i, plot_train_error_history in enumerate(plot_different_parameter_train_error_history):\n",
    "        plt.plot(plot_train_error_history, label=f\"Train Error History\")\n",
    "if plot_show_test_bool is True:\n",
    "    for i, plot_test_error_history in enumerate(plot_different_parameter_test_error_history):\n",
    "        plt.plot(plot_test_error_history, label=f\"Test Error History\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Error\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Error\")\n",
    "plt.title(\"Error History\")\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_error_history_centralized_{train_start_time}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiment Graph between different parameters in Federated Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_parameters_list = [0, 1]\n",
    "plot_title_strings = \"different stragglers\"\n",
    "plot_legend_strings = \"stragglers\"\n",
    "plot_save_fig_bool = False\n",
    "plot_show_train_bool = True\n",
    "plot_show_test_bool = False\n",
    "plot_log_scale = False\n",
    "\n",
    "plot_different_parameter_train_loss_history = convert_to_list(data_train_loss_history_total)\n",
    "plot_different_parameter_test_loss_history = convert_to_list(data_test_loss_history_total)\n",
    "if plot_show_train_bool is True:\n",
    "    for i, plot_train_loss_history in enumerate(plot_different_parameter_train_loss_history):\n",
    "        plt.plot(plot_train_loss_history, label=f\"Train Loss History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "if plot_show_test_bool is True:\n",
    "    for i, plot_test_loss_history in enumerate(plot_different_parameter_test_loss_history):\n",
    "        plt.plot(plot_test_loss_history, label=f\"Test Loss History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Loss\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History with \" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_loss_history_{plot_title_strings}_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_train_accuracy_history = convert_to_list(data_train_accuracy_history_total)\n",
    "plot_different_parameter_test_accuracy_history = convert_to_list(data_test_accuracy_history_total)\n",
    "if plot_show_train_bool is True:\n",
    "    for i, plot_train_accuracy_history in enumerate(plot_different_parameter_train_accuracy_history):\n",
    "        plt.plot(plot_train_accuracy_history, label=f\"Train Accuracy History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "if plot_show_test_bool is True:\n",
    "    for i, plot_test_accuracy_history in enumerate(plot_different_parameter_test_accuracy_history):\n",
    "        plt.plot(plot_test_accuracy_history, label=f\"Test Aacuracy History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Accuracy\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Accuracy History with \" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_accuracy_history_{plot_title_strings}_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_train_error_history = convert_to_list(data_train_error_history_total)\n",
    "plot_different_parameter_test_error_history = convert_to_list(data_test_error_history_total)\n",
    "if plot_show_train_bool is True:\n",
    "    for i, plot_train_error_history in enumerate(plot_different_parameter_train_error_history):\n",
    "        plt.plot(plot_train_error_history, label=f\"Train Error History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "if plot_show_test_bool is True:\n",
    "    for i, plot_test_error_history in enumerate(plot_different_parameter_test_error_history):\n",
    "        plt.plot(plot_test_error_history, label=f\"Test Error History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Error\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Error\")\n",
    "plt.title(\"Error History with \" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_error_history_{plot_title_strings}_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_time_history = convert_to_list(data_time_history_total)\n",
    "for i, plot_time_history in enumerate(plot_different_parameter_time_history):\n",
    "    plt.plot(plot_time_history, label=f\"Time History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Culminative Time Used\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Culminative Time Used\")\n",
    "plt.title(\"Time History with \" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_time_history_{plot_title_strings}_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_cost_history = convert_to_list(data_cost_history_total)\n",
    "for i, plot_cost_history in enumerate(plot_different_parameter_cost_history):\n",
    "    plt.plot(plot_cost_history, label=f\"Time History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Cost\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Cost\")\n",
    "plt.title(\"Culminative Send Cost History with \" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_cost_history_{plot_title_strings}_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_adversary_history = convert_to_list(data_adversary_history_total)\n",
    "for i, plot_adversary_history in enumerate(plot_different_parameter_adversary_history):\n",
    "    plt.plot(plot_adversary_history, label=f\"Adversary History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Adversaries\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Adversaries\")\n",
    "plt.title(\"Number of Adversary History with \" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_adversary_history_{plot_title_strings}_{train_start_time}.png')\n",
    "plt.show()\n",
    "\n",
    "plot_different_parameter_straggler_history = convert_to_list(data_adversary_history_total)\n",
    "for i, plot_straggler_history in enumerate(plot_different_parameter_straggler_history):\n",
    "    plt.plot(plot_straggler_history, label=f\"Straggler History with {plot_legend_strings} = {plot_parameters_list[i]}\")\n",
    "plt.xlabel(\"Communication Rounds\")\n",
    "if plot_log_scale is True:\n",
    "    plt.ylabel(\"Log Stragglers\")\n",
    "    plt.yscale('log')\n",
    "else:\n",
    "    plt.ylabel(\"Stragglers\")\n",
    "plt.title(\"Number of Stragglers History with \" + plot_title_strings)\n",
    "plt.legend()\n",
    "if plot_save_fig_bool is True:\n",
    "    plt.savefig(f'Analysis_{current_dataset_name}_straggler_history_{plot_title_strings}_{train_start_time}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section 3.2 Analysing ####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Variance Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_id = 0\n",
    "for data_cost_history, data_time_history, data_train_loss_history, data_train_accuracy_history, data_train_error_history, data_test_loss_history, data_test_accuracy_history, data_test_error_history in zip(data_cost_history_total, data_time_history_total, data_train_loss_history_total, data_train_accuracy_history_total, data_train_error_history_total, data_test_loss_history_total, data_test_accuracy_history_total, data_test_error_history_total):\n",
    "    analysis_id += 1\n",
    "    print(f'<!======Analaysis ID = {analysis_id}=======!>')\n",
    "    cost_variance = statistics.variance(data_cost_history)\n",
    "    time_variance = statistics.variance(data_time_history)\n",
    "    train_loss_variance = statistics.variance(data_train_loss_history)\n",
    "    train_accuracy_variance = statistics.variance(data_train_accuracy_history)\n",
    "    train_error_variance = statistics.variance(data_train_error_history)\n",
    "    test_loss_variance = statistics.variance(data_test_loss_history)\n",
    "    test_accuracy_variance = statistics.variance(data_test_accuracy_history)\n",
    "    test_error_variance = statistics.variance(data_test_error_history)\n",
    "    print(\"=======VARIANCE RESULT=======\")\n",
    "    print(\"Cost Variance: \", cost_variance)\n",
    "    print(\"Time Variance: \", time_variance)\n",
    "    print(\"Train Loss Variance: \", train_loss_variance)\n",
    "    print(\"Train Accuracy Variance: \", train_accuracy_variance)\n",
    "    print(\"Train Error Variance: \", train_error_variance)\n",
    "    print(\"Test Loss Variance: \", test_loss_variance)\n",
    "    print(\"Test Accuracy Variance: \", test_accuracy_variance)\n",
    "    print(\"Test Error Variance: \", test_error_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_variance_subset_min = 0\n",
    "analysis_variance_subset_max = len(data_cost_history) // 2\n",
    "\n",
    "analysis_id = 0\n",
    "for data_cost_history, data_time_history, data_train_loss_history, data_train_accuracy_history, data_train_error_history, data_test_loss_history, data_test_accuracy_history, data_test_error_history in zip(data_cost_history_total, data_time_history_total, data_train_loss_history_total, data_train_accuracy_history_total, data_train_error_history_total, data_test_loss_history_total, data_test_accuracy_history_total, data_test_error_history_total):\n",
    "    analysis_id += 1\n",
    "    print(f'<!======Analaysis ID = {analysis_id}=======!>')\n",
    "    cost_variance_subset = statistics.variance(data_cost_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    time_variance_subset = statistics.variance(data_time_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    train_loss_variance_subset = statistics.variance(data_train_loss_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    train_accuracy_variance_subset = statistics.variance(data_train_accuracy_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    train_error_variance_subset = statistics.variance(data_train_error_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    test_loss_variance_subset = statistics.variance(data_test_loss_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    test_accuracy_variance_subset = statistics.variance(data_test_accuracy_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    test_error_variance_subset = statistics.variance(data_test_error_history[analysis_variance_subset_min:analysis_variance_subset_max])\n",
    "    print(f'=======VARIANCE RESULT IN SUBSET BETWEEN {analysis_variance_subset_min} and {analysis_variance_subset_max}=======')\n",
    "    print(\"Cost Variance in Subset: \", cost_variance_subset)\n",
    "    print(\"Time Variance in Subset: \", time_variance_subset)\n",
    "    print(\"Train Loss Variance in Subset: \", train_loss_variance_subset)\n",
    "    print(\"Train Accuracy Variance in Subset: \", train_accuracy_variance_subset)\n",
    "    print(\"Train Error Variance in Subset: \", train_error_variance_subset)\n",
    "    print(\"Test Loss Variance in Subset: \", test_loss_variance_subset)\n",
    "    print(\"Test Accuracy Variance in Subset: \", test_accuracy_variance_subset)\n",
    "    print(\"Test Error Variance in Subset: \", test_error_variance_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_id = 0\n",
    "for data_cost_history, data_time_history, data_train_loss_history, data_train_accuracy_history, data_train_error_history, data_test_loss_history, data_test_accuracy_history, data_test_error_history in zip(data_cost_history_total, data_time_history_total, data_train_loss_history_total, data_train_accuracy_history_total, data_train_error_history_total, data_test_loss_history_total, data_test_accuracy_history_total, data_test_error_history_total):\n",
    "    analysis_id += 1\n",
    "    print(f'<!======Analaysis ID = {analysis_id}=======!>')\n",
    "    cost_variance_subset = statistics.variance(data_cost_history[:len(data_cost_history) // 2])\n",
    "    time_variance_subset = statistics.variance(data_time_history[:len(data_time_history) // 2])\n",
    "    train_loss_variance_subset = statistics.variance(data_train_loss_history[:len(data_train_loss_history) // 2])\n",
    "    train_accuracy_variance_subset = statistics.variance(data_train_accuracy_history[:len(data_train_accuracy_history) // 2])\n",
    "    train_error_variance_subset = statistics.variance(data_train_error_history[:len(data_train_error_history) // 2])\n",
    "    test_loss_variance_subset = statistics.variance(data_test_loss_history[:len(data_test_loss_history) // 2])\n",
    "    test_accuracy_variance_subset = statistics.variance(data_test_accuracy_history[:len(data_test_accuracy_history) // 2])\n",
    "    test_error_variance_subset = statistics.variance(data_test_error_history[:len(data_test_error_history) // 2])\n",
    "    print(\"=======VARIANCE FIRST SUBSET RESULT=======\")\n",
    "    print(\"Cost Variance in Subset: \", cost_variance_subset)\n",
    "    print(\"Time Variance in Subset: \", time_variance_subset)\n",
    "    print(\"Train Loss Variance in Subset: \", train_loss_variance_subset)\n",
    "    print(\"Train Accuracy Variance in Subset: \", train_accuracy_variance_subset)\n",
    "    print(\"Train Error Variance in Subset: \", train_error_variance_subset)\n",
    "    print(\"Test Loss Variance in Subset: \", test_loss_variance_subset)\n",
    "    print(\"Test Accuracy Variance in Subset: \", test_accuracy_variance_subset)\n",
    "    print(\"Test Error Variance in Subset: \", test_error_variance_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_id = 0\n",
    "for data_cost_history, data_time_history, data_train_loss_history, data_train_accuracy_history, data_train_error_history, data_test_loss_history, data_test_accuracy_history, data_test_error_history in zip(data_cost_history_total, data_time_history_total, data_train_loss_history_total, data_train_accuracy_history_total, data_train_error_history_total, data_test_loss_history_total, data_test_accuracy_history_total, data_test_error_history_total):\n",
    "    analysis_id += 1\n",
    "    print(f'<!======Analaysis ID = {analysis_id}=======!>')\n",
    "    cost_variance_subset = statistics.variance(data_cost_history[len(data_cost_history) // 2:])\n",
    "    time_variance_subset = statistics.variance(data_time_history[len(data_time_history) // 2:])\n",
    "    train_loss_variance_subset = statistics.variance(data_train_loss_history[len(data_train_loss_history) // 2:])\n",
    "    train_accuracy_variance_subset = statistics.variance(data_train_accuracy_history[len(data_train_accuracy_history) // 2:])\n",
    "    train_error_variance_subset = statistics.variance(data_train_error_history[len(data_train_error_history) // 2:])\n",
    "    test_loss_variance_subset = statistics.variance(data_test_loss_history[len(data_test_loss_history) // 2:])\n",
    "    test_accuracy_variance_subset = statistics.variance(data_test_accuracy_history[len(data_test_accuracy_history) // 2:])\n",
    "    test_error_variance_subset = statistics.variance(data_test_error_history[len(data_test_error_history) // 2:])\n",
    "    print(\"=======VARIANCE LAST SUBSET RESULT=======\")\n",
    "    print(\"Cost Variance in Subset: \", cost_variance_subset)\n",
    "    print(\"Time Variance in Subset: \", time_variance_subset)\n",
    "    print(\"Train Loss Variance in Subset: \", train_loss_variance_subset)\n",
    "    print(\"Train Accuracy Variance in Subset: \", train_accuracy_variance_subset)\n",
    "    print(\"Train Error Variance in Subset: \", train_error_variance_subset)\n",
    "    print(\"Test Loss Variance in Subset: \", test_loss_variance_subset)\n",
    "    print(\"Test Accuracy Variance in Subset: \", test_accuracy_variance_subset)\n",
    "    print(\"Test Error Variance in Subset: \", test_error_variance_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Average Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_average_subset_min = 0\n",
    "analysis_average_subset_max = len(data_cost_history) // 2\n",
    "\n",
    "analysis_id = 0\n",
    "for data_cost_history, data_time_history, data_train_loss_history, data_train_accuracy_history, data_train_error_history, data_test_loss_history, data_test_accuracy_history, data_test_error_history in zip(data_cost_history_total, data_time_history_total, data_train_loss_history_total, data_train_accuracy_history_total, data_train_error_history_total, data_test_loss_history_total, data_test_accuracy_history_total, data_test_error_history_total):\n",
    "    analysis_id += 1\n",
    "    print(f'<!======Analaysis ID = {analysis_id}=======!>')\n",
    "    cost_average_subset = statistics.mean(data_cost_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    time_average_subset = statistics.mean(data_time_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    train_loss_average_subset = statistics.mean(data_train_loss_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    train_accuracy_average_subset = statistics.mean(data_train_accuracy_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    train_error_average_subset = statistics.mean(data_train_error_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    test_loss_average_subset = statistics.mean(data_test_loss_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    test_accuracy_average_subset = statistics.mean(data_test_accuracy_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    test_error_average_subset = statistics.mean(data_test_error_history[analysis_average_subset_min:analysis_average_subset_max])\n",
    "    print(f'=======AVERAGE RESULT IN SUBSET BETWEEN {analysis_average_subset_min} and {analysis_average_subset_max}=======')\n",
    "    print(\"Cost Average in Subset: \", cost_average_subset)\n",
    "    print(\"Time Average in Subset: \", time_average_subset)\n",
    "    print(\"Train Loss Average in Subset: \", train_loss_average_subset)\n",
    "    print(\"Train Accuracy Average in Subset: \", train_accuracy_average_subset)\n",
    "    print(\"Train Error Average in Subset: \", train_error_average_subset)\n",
    "    print(\"Test Loss Average in Subset: \", test_loss_average_subset)\n",
    "    print(\"Test Accuracy Average in Subset: \", test_accuracy_average_subset)\n",
    "    print(\"Test Error Average in Subset: \", test_error_average_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Image Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = \"Test.png\"\n",
    "test_model_type = MNIST_CNN_Model\n",
    "test_model_path = \"MNIST_FedAvg_with_global_epochs_100_local_epochs_3_num_clients_1_batch_size_128_2024-03-01 16.14.36_model_state_dict.pth\"\n",
    "test_image_resize = 28\n",
    "test_image_togrey = True\n",
    "\n",
    "test_global_model = test_model_type()\n",
    "test_global_model.load_state_dict(torch.load(test_model_path, map_location=device))\n",
    "\n",
    "if test_image_togrey is True:\n",
    "    test_image = 1.0 - cv2.cvtColor(cv2.resize(load_image(test_image_path), (test_image_resize, test_image_resize)), cv2.COLOR_RGB2GRAY)\n",
    "else:\n",
    "    test_image = cv2.resize(load_image(test_image_path), (test_image_resize, test_image_resize))\n",
    "plt.imshow(test_image, cmap='gray')\n",
    "\n",
    "test_image_torch = torch.Tensor(test_image[np.newaxis, np.newaxis])\n",
    "test_predicted_label_array = test_global_model(test_image_torch).detach().numpy()[0, ...]\n",
    "print('The chances for predicted labels are: ', test_predicted_label_array)\n",
    "\n",
    "test_predicted_label = np.argmax(test_predicted_label_array)\n",
    "\n",
    "print('The predicted label is: ', test_predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
